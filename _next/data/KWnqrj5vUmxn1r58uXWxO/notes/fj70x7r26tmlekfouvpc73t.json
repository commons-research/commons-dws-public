{"pageProps":{"note":{"id":"fj70x7r26tmlekfouvpc73t","title":"2023-05-30","desc":"","updated":1685538307575,"created":1685450346784,"traitIds":["open-notebook-commons-pmallard"],"custom":{},"fname":"open-notebook.commons.pmallard.2023.05.30","type":"note","vault":{"fsPath":"vault"},"contentHash":"f78cdca6849862b7425a58f69f129946","links":[],"anchors":{"this-is-pmass-commons-lab-daily-open-notebook":{"type":"header","text":"This is PMAS's COMMONS Lab daily Open Notebook.","value":"this-is-pmass-commons-lab-daily-open-notebook","line":10,"column":0,"depth":1},"todo-today":{"type":"header","text":"Todo today","value":"todo-today","line":14,"column":0,"depth":2},"have-a-look-at-the-commons-research-discussion-forum":{"type":"header","text":"Have a look at the COMMONS research discussion forum","value":"have-a-look-at-the-commons-research-discussion-forum","line":16,"column":0,"depth":3},"":{"type":"header","text":"","value":"","line":18,"column":0,"depth":3},"-1":{"type":"header","text":"","value":"-1","line":19,"column":0,"depth":3},"doing":{"type":"header","text":"Doing","value":"doing","line":21,"column":0,"depth":2},"chatgpt-exchanges-leading-to-the-previous-selected-papers":{"type":"header","text":"ChatGPT exchanges leading to the previous selected papers","value":"chatgpt-exchanges-leading-to-the-previous-selected-papers","line":62,"column":0,"depth":2},"paused":{"type":"header","text":"Paused","value":"paused","line":120,"column":0,"depth":2},"done":{"type":"header","text":"Done","value":"done","line":122,"column":0,"depth":2},"notes":{"type":"header","text":"Notes","value":"notes","line":124,"column":0,"depth":2},"todo-tomorrow-one-day--or-never":{"type":"header","text":"Todo tomorrow, one day ... or never","value":"todo-tomorrow-one-day--or-never","line":126,"column":0,"depth":2},"-2":{"type":"header","text":"","value":"-2","line":129,"column":0,"depth":3},"-3":{"type":"header","text":"","value":"-3","line":130,"column":0,"depth":3},"today-i-learned-that":{"type":"header","text":"Today I learned that","value":"today-i-learned-that","line":133,"column":0,"depth":2}},"children":[],"parent":"9b49puh3v8vw0juio3r5953","data":{}},"body":"<h1 id=\"2023-05-30\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#2023-05-30\"></a>2023-05-30</h1>\n<h1 id=\"this-is-pmass-commons-lab-daily-open-notebook\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#this-is-pmass-commons-lab-daily-open-notebook\"></a>This is PMAS's COMMONS Lab daily Open Notebook.</h1>\n<p>Today is 2023.05.30</p>\n<h2 id=\"todo-today\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#todo-today\"></a>Todo today</h2>\n<h3 id=\"have-a-look-at-the-commons-research-discussion-forum\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#have-a-look-at-the-commons-research-discussion-forum\"></a>Have a look at the COMMONS research discussion forum</h3>\n<pre><code>- https://github.com/orgs/commons-research/discussions\n</code></pre>\n<h3 id=\"\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#\"></a></h3>\n<h3 id=\"-1\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#-1\"></a></h3>\n<h2 id=\"doing\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#doing\"></a>Doing</h2>\n<p>Activity report and was browsing Marco's note.\nWent for some papers on image reconstructiuon from partial inputs </p>\n<p>Image reconstruction from partial subband images and its application in packet video transmission\n<a href=\"https://doi.org/10.1016/0923-5965(91)90010-Y\">https://doi.org/10.1016/0923-5965(91)90010-Y</a></p>\n<p><a href=\"https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-020-06892-5\">https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-020-06892-5</a></p>\n<p>Phylogenetic imputation of plant functional trait databases\n<a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1600-0587.2013.00528.x\">https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1600-0587.2013.00528.x</a>\nCheck citing articles <a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1600-0587.2013.00528.x\">https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1600-0587.2013.00528.x</a></p>\n<p><a href=\"https://digitalcommons.aaru.edu.jo/cgi/viewcontent.cgi?article=1019&#x26;context=fej\">https://digitalcommons.aaru.edu.jo/cgi/viewcontent.cgi?article=1019&#x26;context=fej</a></p>\n<p><a href=\"https://arxiv.org/pdf/2303.11396.pdf\">https://arxiv.org/pdf/2303.11396.pdf</a></p>\n<p>A real data-driven simulation strategy to select an imputation method for mixed-type trait data\n<a href=\"https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010154\">https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010154</a></p>\n<p>Using phylogenetic information to impute missing functional trait values in ecological databases\n<a href=\"https://www.sciencedirect.com/science/article/pii/S1574954121001060\">https://www.sciencedirect.com/science/article/pii/S1574954121001060</a></p>\n<p>Machine learning based imputation techniques for estimating phylogenetic trees from incomplete distance matrices\n<a href=\"https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-020-06892-5\">https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-020-06892-5</a></p>\n<p>A General Method for Simultaneously Accounting for Phylogenetic and Species Sampling Uncertainty via Rubinâ€™s Rules in Comparative Analysis\n<a href=\"https://doi.org/10.1093/sysbio/syy089\">https://doi.org/10.1093/sysbio/syy089</a></p>\n<p>Handling missing values in trait data\n<a href=\"https://onlinelibrary.wiley.com/doi/pdf/10.1111/geb.13185\">https://onlinelibrary.wiley.com/doi/pdf/10.1111/geb.13185</a></p>\n<p>mbImpute: an accurate and robust imputation method for microbiome data\n<a href=\"https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02400-4\">https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02400-4</a>\n<a href=\"https://github.com/ruochenj/mbImpute\">https://github.com/ruochenj/mbImpute</a></p>\n<h2 id=\"chatgpt-exchanges-leading-to-the-previous-selected-papers\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#chatgpt-exchanges-leading-to-the-previous-selected-papers\"></a>ChatGPT exchanges leading to the previous selected papers</h2>\n<p>What are the methods to construct (infer or expand) a full image from partial inputs (bits of the big picture). These methods should not involve automated learning.\nChatGPT\nConstructing or inferring a full image from partial inputs without involving automated learning can be challenging, as it typically requires complex computational algorithms or manual interventions. However, there are a few methods that can be used to reconstruct or expand a full image from partial inputs without relying on automated learning. Here are a few approaches:</p>\n<p>Patch-based methods: In this approach, the partial inputs or patches are analyzed individually, and then these patches are combined or stitched together to form the full image. This method requires a prior understanding of the spatial relationships between patches. Various algorithms, such as graph cuts or seam carving, can be used to combine the patches effectively.</p>\n<p>Image inpainting techniques: Image inpainting aims to fill in missing or occluded regions in an image. By applying inpainting algorithms, you can reconstruct the missing parts of the image based on the surrounding information or by propagating the existing image content. Techniques like texture synthesis, diffusion-based methods, or exemplar-based approaches can be used for image inpainting.</p>\n<p>Structure-from-Motion (SfM): SfM is a technique used to reconstruct 3D scenes from 2D image sequences. If you have partial inputs from different viewpoints or angles, you can use SfM algorithms to estimate the camera poses and 3D structure of the scene. By combining the reconstructed 3D information, you can generate a full image or a more complete representation of the scene.</p>\n<p>Image completion with manual interventions: If automated learning is not allowed, manual interventions can be used to complete or expand an image from partial inputs. This approach involves human interaction or expertise to fill in missing details or to infer the complete image based on the available information. Tools like image editing software can be employed to manually paint or draw missing parts of the image.</p>\n<p>It's important to note that these methods may require some level of computational algorithms or techniques, but they do not rely on automated learning specifically. Instead, they involve manual interventions or computational procedures that do not involve training on large datasets.</p>\n<p>Let's say that this patchy dataset is a table of occurence of molecules within living organisms. We thus have phylogenetic relationshsips across the organisms and chemical class taxonomy across the molecules. What approch would you propose to reconstruct a full dataset from a patchy dataset ?\nChatGPT\nIn the case of a patchy dataset representing the occurrence of molecules within living organisms, where phylogenetic relationships across organisms and chemical class taxonomy across molecules are known, you can leverage these relationships to reconstruct a more complete dataset. Here's an approach you can consider:</p>\n<p>Phylogenetic imputation: Given the phylogenetic relationships among organisms, you can utilize this information to infer missing values in the dataset. This approach assumes that closely related organisms have similar characteristics, including the occurrence of molecules. You can estimate missing values by propagating the observed data from closely related organisms to fill in the gaps in less studied or missing organisms.</p>\n<p>Chemical class-based imputation: If you have a taxonomy of chemical classes for the molecules, you can use this information to infer missing values. Explore the chemical classes present in the dataset and their relationships to impute missing occurrences based on the patterns observed within each class. This could involve considering the distribution of occurrences within a chemical class or using statistical measures within specific chemical class groups.</p>\n<p>Cross-validation: To enhance the reliability of the reconstructed dataset, you can perform cross-validation techniques. Split the available data into training and testing sets and use the known data to impute the missing values in the testing set. Then compare the imputed values with the actual values to evaluate the accuracy and adjust the imputation method if necessary.</p>\n<p>Expert validation: Given the complexity and domain-specific nature of the dataset, it is valuable to involve experts in the field. Experts can provide insights, validate the reconstructed dataset, and refine the imputation process based on their knowledge of the organisms, molecules, and their interactions.</p>\n<p>It's important to note that imputation methods rely on assumptions and might introduce some level of uncertainty. The quality and accuracy of the reconstructed dataset will depend on the availability and quality of the existing data, the accuracy of the phylogenetic relationships and chemical class taxonomy, and the effectiveness of the imputation methods employed.</p>\n<p>Overall, combining phylogenetic relationships, chemical class taxonomy, statistical imputation, and expert input can help you reconstruct a more complete dataset of molecule occurrences within living organisms.</p>\n<p>Great. Would their be an approach that could combine both the Phylogenetic imputation and the Chemical class-based imputation ? That is a method which would exploit the structure on both dimension of the datset for the inputation\nChatGPT\nYes, it is indeed possible to combine both phylogenetic imputation and chemical class-based imputation to exploit the structure on both dimensions of the dataset for imputation. Here's an approach that combines these two methods:</p>\n<p>Phylogenetic imputation: Use the phylogenetic relationships among organisms to propagate information and impute missing values. Start by identifying closely related organisms with available data. For each missing value, find the closest related organisms with observed data and use their values as a basis for imputation. This imputation process takes into account the assumption that closely related organisms share similar characteristics, including the occurrence of molecules.</p>\n<p>Chemical class-based imputation: Leverage the chemical class taxonomy to further refine the imputation process. Within each chemical class, observe the distribution of occurrences and utilize statistical measures such as mean, median, or mode to estimate missing values. Consider the patterns and tendencies within each chemical class while imputing missing values.</p>\n<p>Combination and refinement: Combine the imputed values from the phylogenetic imputation and chemical class-based imputation approaches. This can be achieved by assigning weights or merging the imputed values based on the confidence or reliability of each approach. You can also consider using statistical techniques such as ensemble methods or weighted averaging to combine the imputations effectively.</p>\n<p>Expert validation: As mentioned before, involving domain experts in the validation process is crucial. Experts can provide insights on the reliability and biological plausibility of the imputed values. They can also suggest adjustments or refinements to the imputation process based on their knowledge of the organisms, molecules, and their relationships.</p>\n<p>By combining phylogenetic imputation with chemical class-based imputation, you leverage both the phylogenetic relationships among organisms and the chemical class taxonomy of molecules to impute missing values. This approach takes advantage of the structural information present in both dimensions of the dataset, resulting in a more comprehensive and accurate imputation process.</p>\n<h2 id=\"paused\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#paused\"></a>Paused</h2>\n<h2 id=\"done\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#done\"></a>Done</h2>\n<h2 id=\"notes\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#notes\"></a>Notes</h2>\n<h2 id=\"todo-tomorrow-one-day--or-never\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#todo-tomorrow-one-day--or-never\"></a>Todo tomorrow, one day ... or never</h2>\n<h3 id=\"-2\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#-2\"></a></h3>\n<h3 id=\"-3\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#-3\"></a></h3>\n<h2 id=\"today-i-learned-that\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#today-i-learned-that\"></a>Today I learned that</h2>\n<ul>\n<li></li>\n</ul>","noteIndex":{"id":"QvYK9hGbCvPpEfSRYhV8j","title":"Welcome to the COMMONS Lab Open Dendron","desc":"","updated":1693056226815,"created":1630130450048,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"20f67df3dd870fc450a162c202c9ff41","links":[{"type":"wiki","from":{"fname":"root","id":"QvYK9hGbCvPpEfSRYhV8j","vaultName":"vault"},"value":"open-notebook.commons.setup","position":{"start":{"line":43,"column":118,"offset":1871},"end":{"line":43,"column":149,"offset":1902},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"open-notebook.commons.setup"}}],"anchors":{"what-is-this-note":{"type":"header","text":"What is this note","value":"what-is-this-note","line":16,"column":0,"depth":2},"tutorial":{"type":"header","text":"Tutorial","value":"tutorial","line":20,"column":0,"depth":2},"dendron":{"type":"header","text":"Dendron.","value":"dendron","line":22,"column":0,"depth":3},"what-is-dendron-":{"type":"header","text":"What is Dendron ?","value":"what-is-dendron-","line":24,"column":0,"depth":4},"where-to-get-more-info-on-dendron-":{"type":"header","text":"Where to get more info on Dendron ?","value":"where-to-get-more-info-on-dendron-","line":30,"column":0,"depth":4},"concrete-steps-to-access-and-contribute-to-the-dbgi-dendron":{"type":"header","text":"Concrete steps to access and contribute to the DBGI Dendron","value":"concrete-steps-to-access-and-contribute-to-the-dbgi-dendron","line":35,"column":0,"depth":4},"questions-comments-suggestions-":{"type":"header","text":"Questions, comments, suggestions ?","value":"questions-comments-suggestions-","line":52,"column":0,"depth":2}},"children":["5o0tvzf4l6t6moau7en1v48","e4ul30admmxm9ilxfq275cq","h78qbvh1fd9bwcykmcm9uo3","6ooxuf27zzf3grb14o18qf2","tiqo5upbg6224t7i8p87iok","ltq8wcrabmq6mlescrdi4m0","bdq3suiz8yriznljea2zpug","ih6vyup3yre4m9woc9ldl7k","vDTgZL9UHWqYtBFdtD3vK","69ekb2qhuwukr0jwrzy6tnw","373694o1o6ocqohko4um7c9","jldFUSJGjDf1mFH8c2yUI","dh2qp7w4tl6otf89xrmxitv","2rvdf4t5qnx5hqjj29bojcc","stj9lq0lxhfuk5ntomiozz0","gvdyfgvq0z08fcfaqzmhtjo","2rvclk21kfedpvxuzjpizi7","dcwgamgyghrlyau1avlh6ug","432qdutuo1i8h5pcuh39ytt","2npxodkvs5jk6p1eksi551b","h81rw16zzgh9kix8ti1mbam","lco50o42dfeph5i5f2k981w","46d1odkovrpdi6g16992phy","s9gzk7nphtjzmpdqvk5y4vj","82ra6p4ykf814hp8yfw4wp6","hpnaglyhnb48vuiniqecnqf","y7nk7xmiht44neo0q7cl5cs","2cxr093kvrg4jojokwgqrbj","8vfu5h3617jbzy78xr2hlo1","w75krbmkkvla3hwd66hn5bh","40po5od17ekcr1e77dluxao","4pqppog2u66rx1tkc8jy5v9","ektni5nfulyro7dkrbtek7j","vfsp2aci6vy7kg2jsyy8tzu","0wm4geq40t6nscn88rcwu47","ib4jmxy1x3l1r0ewe6hln4j","0h57aw0be2jnc3dxcpn3ajn","4789z8f1dqdh5k3nmgr1m4z","p5dszyuhj1klgje0brtv0xj","sk4m9gq7vz2t9phcxlxvqpw","43p60vv8btyhaclugl93jok","zhc9hhpaobkbo4e2votv6wr","ylulfzi7ra5yv6ja7j78t6e","wj0i9czxvt4v0b674nb8501","ovslc641d0h00s16tf6kl8w","4zmlbmcp6q4q69ycvhavzr6","59ftsVxFXXM9bB43vfKwK","nmnpsy2e1rwqnqgurogi2u6","6b5uf8hv44mbgircddcb46i","s9j6c26u6qgl5dvnqv8opam","je0ksq927btmorptaje6a4p","xm4a1smh9gcahxda5bssxfi","3cgqlppr4es3iuoa2o3mhn8","d6edcr5j5kjgdt791uujpn0","zfu2gniwqhgo1j44r3yfx7y","gap1pjhvt94m5izg0zlef0w","o3y0vguickctv1yx4z42qev","g78c0e4ts7wgkof1ykkgzbl","hsqldiv7revakz0fqay51eu","99wwtyhexdqu5bxrtgn9whw","m8e37qw6n4i3cfv9ohq7e82","ds1s2fjqhwvw1zqst8l4z4f","ec4pkybo5iwljo3zdr9894x","cbikmu2vjnxulf5tf9xfist","1icb0ka0yjwpoerg4zym9la"],"parent":null,"data":{},"body":"\n![](/assets/images/allard-lab.jpg)\n\nWelcome the the COMMONS Lab Open Dendron !\n\nIn the [COMMONS Lab](https://www.unifr.ch/bio/en/groups/allard/) we intent to follow the [Open Notebook Science](https://en.wikipedia.org/wiki/Open-notebook_science) approach to document our research.\n\nFor this we use the [Dendron](https://www.dendron.so/) system as a mean to efficiently capture notes and publish them.\n\n## What is this note\n\nThis note is a succinct tutorial note aiming to get you started in the use of the COMMONS Lab Dendron.\n\n## Tutorial\n\n### Dendron. \n\n#### What is Dendron ?\n\n> Dendron is an open-source, local-first, markdown-based, note-taking tool. Think of it as a cache for everything that you care about - if you've spent more then five minutes solving a problem, you should never spent any more time solving the same exact problem.\n> \n> Dendron is a knowledge base built by and for developers and integrates natively with IDEs like VS Code and VSCodium.\n\n#### Where to get more info on Dendron ?\n\n- You can get more information in the Dendron system at the official website www.dendron.so\n- All the Dendron documentation is hosted here https://wiki.dendron.so/. It is, obviously, a Dendron itself.\n\n#### Concrete steps to access and contribute to the DBGI Dendron\n\n1. Install [VSCode](https://code.visualstudio.com/download)\n2. Install [Dendron](https://marketplace.visualstudio.com/items?itemName=dendron.dendron) from the VSCode marketplace \n3. Clone the COMMONS Dendron repo\n\n    In your terminal\n    ```\n    git clone https://github.com/commons-research/commons-dws-public.git\n    ```\n4. In VSCode open (File/Open) the cloned repository.\n5. Voila ! You should now be in the COMMONS Lab Open Dendron.\n\nFeel free to explore and contribute.\nA first, important step could be to configure VSCode so that you can easily add a daily note. See steps described at [[open-notebook.commons.setup]]\n\n\n## Questions, comments, suggestions ?\n\nFeel free to contribute here https://github.com/orgs/commons-research/discussions\n\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"vaultSelectionModeOnCreate":"smart","fuzzThreshold":0.2}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.112.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"assetsPrefix":"/commons-dws-public","copyAssets":true,"siteHierarchies":["root"],"enableSiteLastModified":true,"siteRootDir":"docs","siteUrl":"https://commons-research.github.io","enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"writeStubs":false,"seo":{"title":"COMMONS DWS Public","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Click here to edit this page on Github !","editBranch":"main","editViewMode":"edit","editRepository":"https://github.com/commons-research/commons-dws-public"},"enablePrettyLinks":true,"enableTaskNotes":true,"siteFaviconPath":"favicon.ico","siteIndex":"root","searchMode":"lookup"}}},"__N_SSG":true}