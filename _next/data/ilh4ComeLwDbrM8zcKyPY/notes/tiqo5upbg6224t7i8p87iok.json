{"pageProps":{"note":{"id":"tiqo5upbg6224t7i8p87iok","title":"Best Practices","desc":"","updated":1714662280611,"created":1714662217081,"custom":{},"fname":"best-practices","type":"note","vault":{"fsPath":"vault"},"contentHash":"dc7c7e9c1d9d01386ed7bcedc2f32a6f","links":[{"type":"wiki","from":{"fname":"best-practices","id":"tiqo5upbg6224t7i8p87iok","vaultName":"vault"},"value":"user.cmungall","alias":"@cmungall","position":{"start":{"line":43,"column":26,"offset":1762},"end":{"line":43,"column":35,"offset":1771},"indent":[]},"xvault":false,"to":{"fname":"user.cmungall"}},{"type":"wiki","from":{"fname":"best-practices","id":"tiqo5upbg6224t7i8p87iok","vaultName":"vault"},"value":"user.channel","alias":"@channel","position":{"start":{"line":830,"column":7,"offset":28717},"end":{"line":830,"column":15,"offset":28725},"indent":[]},"xvault":false,"to":{"fname":"user.channel"}},{"type":"wiki","from":{"fname":"best-practices","id":"tiqo5upbg6224t7i8p87iok","vaultName":"vault"},"value":"user.today","alias":"@today","position":{"start":{"line":892,"column":10,"offset":31923},"end":{"line":892,"column":16,"offset":31929},"indent":[]},"xvault":false,"to":{"fname":"user.today"}}],"anchors":{},"children":[],"parent":"QvYK9hGbCvPpEfSRYhV8j","data":{}},"body":"<h1 id=\"best-practices\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#best-practices\"></a>Best Practices</h1>\n<p>Have a look at <a href=\"http://berkeleybop.github.io/best_practice/\">http://berkeleybop.github.io/best_practice/</a></p>\n<p>This is the best practice / house style guide for the BBOP group. Inspired by / cribbed from Knocean practice and other sources.</p>\n<p>Source: berkeleybop/berkeleybop.github.io/blob/master/best_practice</p>\n<p>We are a diverse group working on many different projects with different stakeholders and sets of collaborators. Nevertheless we strive to follow a set of core best practices so we can be most efficient and develop the highest quality code, ontologies, standards, schemas, and analyses.</p>\n<p>This document may be overwhelming at first but as you become more familiar with projects it should become second nature. If there is anything you don’t understand, ask on slack!</p>\n<p>Git and GitHub\nuse git ubiquitously\ncommit early, commit often\nperfect later!\nyou should always be working on a branch, so don’t worry about breaking things\nmake a PR for your branch - mark as draft if not ready\nMake repos public by default\nUse standard repo layouts\nchoose a cookiecutter\nmonarch-project-template for code-oriented projects\ndon’t reinvent\nlook at exemplars\nInclude standard files:\nREADME.md\nLICENSE (BSD3 or Apache preferred for software)\nCONTRIBUTING.md\nCODE_OF_CONDUCT.md (see for example kgx CoC\nChanges.md\n.gitignore\nMakefile or equivalent\nsee below for more specific recommendations for specific kinds of repos\nuse GitHub\nLike GitLab in principle, but GitHub has network effect\nprefer to work on the main repo, not forks, but defer to project-specific guidelines\nRead our GitHub Overview\nUse GitHub issues\nin general you should always be working to a ticket assigned to you\ntry to assign every issue to somebody\ntry to have a single assignee / responsible person\ntag people if necessary\nnote: if you tag me with <a title=\"Private\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\" class=\"private\">@cmungall (Private)</a> it’s likely I won’t see it. alert me to a ticket via slack if I am required\nuse GitHub’s default labels: bug, question, enhancement, good first issue, etc.\nset up standard issue templates (helps ensure tickets are auto-assigned)\nWhen creating issues:\ngive a meaningful issue title\nword title as a bug, e.g. “under condition X, Y fails” or a request, e.g. “add option A to method B”\ngive issue actionable descriptions, make it clear when an issue can be closed\nsee Seth’s suggestions for creating awesome issues\nuse GitHub Pull Requests\nread the obook PR review guide\nmark as draft until ready for review, then assign reviewers\ndescription should link to an issue (“Resolves #1234”) to automatically close issue when PR is merged\notherwise you have to clean up issues manually\nupdate description as needed\nalways look over your commits before making a PR\nare there unexpected changes? You should only see YOUR changes\nIs it adding files unexpectedly? Some git clients are eager to do this\nare some changes not recognizable as yours? Be careful not to clobber\nfollow repo-standard practice for rebase etc\nAVOID:\nmaking PRs too large\nmixing orthogonal concerns in one PR. Generally 1 PR = 1 issue\nmixing in formatting changes on sections of the code unrelated to the semantic changes you are making\nworking on a PR for too long a time without feedback from others\nworking on “invisible” branches. ALWAYS make a PR, ALWAYS push. You can mark as draft!\ngive PRs a meaningful title and description\nremember: titles will be used when auto-making release notes\nuse GitHub Milestones to plan releases\nuse GitHub Releases to tag versions and attach binaries\nuse semver (except for ontologies)\nuse the auto-generate release notes feature\ncorollary: write informative PR titles and never commit on main\nif making a non-patch release, select the previous minor/major to diff from\nuse GitHub Pages for simple static content and documentation\nprefer the docs/ directory option\nSee exemplars: OAK, Biolink Model\nuse GitHub Projects (“project boards”) for coordinating issues and PRs\nthree columns:\nTo do: for manager to fill and prioritize\nIn progress: for developer to keep up-to-date\nReady for review: for manager to empty\norder of preference for cards: PR link, issue link, text\nset up GitHub actions to do CI\nMigrate if you are on an old travis repo\nAll changes should be on PRs thus validated\nmain branch should never ever be failing\nEVERY repo should have actions and PR checking\nset up GitHub teams\ndefault to public membership\nmake sure it is clear who has permission to merge PRs\nset up badges\nalways: CI\npypi, downloads, codecov, zenodo, …\nConfigure the “About” (see gear icon on right)\nuse standard topics\nbiolink\nlinkml\nobofoundry\nmonarchinitiative\ngeneontology\nOrgs\ndefine a standard topic (see above)\ninclude a .github\nexamplar: github.com/linkml\npin repos\nmake sure all relevant artefacts are checked in\nuse git status and .gitignore\nin general avoid checking in derived products (but see below)\navoid checking in .xslx files (use TSVs; or consider cogs instead)\nversioning\ndo not check in files with version numbers e.g. foo.v1.txt into GitHub - git does versioning for you\nuse the GitHub release mechanism\nuse ISO-8601 or semver schemes (see guidelines on specific repo types below)\ntend your repos\nremove cruft such as obsolete files (GitHub preserves history)\navoid random stuff at top level\nkeep README in sync\navoid using spaces in filenames\nalways use standard suffixes (e.g. .tsv, .txt, .md)\nkabob-case-is-a-good-default.txt. See filenames in google developer guide\nDon’t rename files and commit - use “git mv” instead, so that the history of the file is preserved\nuse topics and “star” relevant repos\n<a href=\"https://github.com/topics/linkml\">https://github.com/topics/linkml</a>\n<a href=\"https://github.com/topics/obofoundry\">https://github.com/topics/obofoundry</a>\n<a href=\"https://github.com/topics/geneontology\">https://github.com/topics/geneontology</a>\n<a href=\"https://github.com/topics/monarchinitiative\">https://github.com/topics/monarchinitiative</a>\nalways star your own repos\nstar your colleagues and collaborator’s repos\ntips\nthe gh github cli client is very useful, e.g. gh pr Software:\nNico recommends gh Desktop\nCode-centric Repos\nUse an existing repo from a group member as template for best practice, e.g.,\nkgx\nlinkml\nOAK\nOr better: monarch project cookiecutter\nInclude a README.md\nprovide sufficient context\ndon’t boil the ocean - put reference material in a separate reference guide\ninclude examples and use examples as tests\nCreate reference documentation using RTD/Sphinx\nlet inline docstrings in Python do most of the work for you\nread writethedocs\nInclude installation instructions\nuse an OSI approved LICENSE, BSD3 preferred\nUse unit tests\nconsult others on framework\nUse GitHub-integrated CI\nformerly Travis\nuse GitHub actions\nRelease code to PyPI or appropriate repo\nuse GitHub releases\nuse GitHub actions to trigger releases to PyPI\nuse GitHub actions to trigger releases to PyPI\nsee nmdc-schema as exemplar\nmake release notes automatically see github guide\nrelies on using PRs with well-described titles\nalways have multiple owners of a pypi package on the pypi site\nuse standard semver, start from 0.1.0, move to 1.0.0 when stable\nConsider a Dockerfile\nFor ETL repos, follow standard templates for\nkg-hub\nkoza\nFor ETL repos\nUse Jenkins pipelines\nBadges\nCI\nCode coverage\nPyPI\nTODO: ADD MORE\nSchema/Standards-centric Repos, Data and metadata repos\nUse LinkML\nCreate repo from LinkML template\nExamples:\nNMDC\nMIxS\nGFF3 linkml\nchemkg/chemrof\nRegister with w3id.org\nInclude comprehensive examples\nUse LinkML mkdocs framework\nUnderstand the difference between OWL-centric and KG-centric modeling\ninclude mappings to Biolink Model\nalways include examples\nintegrate these with documentation\nintegrate these with unit tests\nalso include counter-examples\ndata deliberately designed to fail validation\ncheck validation correctly identifiers these in github actions\nenable zenodo syncing\nFor repos that have data:\nconsider a dashboard (see semantic dashbaord patterns)\nOntology-centric Repos\nUse ODK seed\nRegister ontology with OBO if appropriate\ninclude detailed metadata\ninclude all products\ninclude descriptive material in markdown\nExceptions:\napplication ontologies\nontologies that deliberately not OBO-esque\nRegister non OBOs with Bioportal + w3id\nUse GitHub for .owl distribution unless ontology is large, then consider:\nGitHub releases\nS3\nSee Nico’s application ontology tutorial\nFollow group exemplars: Uberon, Mondo, GO, ENVO, CL, PATO, BERO, PhenIO\nbut be aware each has their quirks\ndistribute useful products\ndistribute SSSOM\nalways distribute an .obo\nalways distribute a obo .json\ndistribute a kgx file (NEW)\ndistribute a rdftab/semsql sqlite file (NEW)\nuse a sensible source format (foo-edit.owl)\n.obo is best for diffs but less expressive and gotchas for CURIEs\nfunctional syntax is often preferred\nfor template-based ontologies, much of the source may be TSVs\nenable zenodo syncing\nUnderstand issues relating to git conflicts with ontologies\n.obo as source mitigates some of these\nSee this thread\nSee this post\nmany issues have since been resolved but unfortunately some remain\nAnalysis/Paper-centric Repos\nOne repo per paper\nEntire analysis must be reproducible via Makefile\nAll steps:\ndownload\nclean/pre-process\ntransform\ntraining\nevaluation\ncheck with Chris before using snakemake/CWL/alternatives\nUse TSVs as default\nmake pandas-friendly\nuse unix newline characters, not dos\nuse human readable but computationally friendly column headers\nNO ALL CAPS\nalphanumeric characters preferred\nspaces or underscores as word separators OK, but underscores preferred for formal formats\ncsvkit is your friend\nALL TSVs MUST have data dictionaries\nuse LinkML (see above)\ncheck in small-mid size data files (&#x3C;10m)\nconsider cogs if TSVs must be managed in google sheets\nuse JSON for complex data\nuse KGX for anything that should be modeled as a KG\nuse descriptive filenames\nmanage metadata in GitHub\nenable zenodo syncing\nuse S3 for larger files\nrelease files to Zenodo\nDockerize\nUse Jupyter notebooks\nConsider Manubot\nOther recommended best practices\ndatadryad\nDevelopment Environment Setup\nCode Editors:\nvscode\npycharm\nget professional, we will pay\nGitHub copilot can be purchased as well, and is an excellent addition to a pycharm environment.\nKeyboard Shortcuts\nCommand palette: Cmd/Ctrl + Shift + P\nSearch for file in project: Cmd/Ctrl + P\nOpen integrated terminal in VSCode: Cmd/Ctrl + ~\nOpen settings page: Cmd/Ctrl + ,\nSet up custom keymap bindings\nMac\nCode > Preferences > Keyboard Shortcuts > +`\nType in the key combination you want to use and assign it to an action of your choice\nFor ex., Cmd/Ctrl + i as a shortcut for selecting the Python interpreter\nEssentials\nGit configuration\nSet username: git config --global user.name \"YOUR_USERNAME\"\nSet password: git config --global user.email \"<a href=\"/commons-dws-public/mailto:YOUR_EMAIL@EXAMPLE.COM\">YOUR_EMAIL@EXAMPLE.COM</a>\"\nWorkspace setup\nMake sure you have correctly selected the Python interpreter\nSave workspace in order to open a specific view of the project directory\nFile > Save Workspace As\nFile > Open Workspace From File\nUseful Extensions\nPython\nPython IntelliSense\nLinting\nDebugging\nCode navigation\nFormatting\nRefactoring\nAutoDocstring\nDocstring for Python methods\nblack\nOpinionated Python code formatter\nGitLens\nVisualize code authorship\nBetter Comments\nHuman friendly comments\nRainbow CSV\nHighlight columns in csv and tsv files\nTransforms and filtering using querying language\nMarkdown All in One\nKeyboard shortcuts\nTable of contents\nAuto preview\nPrettier\nFormatting YAML, JSON\nBut primarily an opinionated formatter for frontend web code like JS, TS, etc.\nYAML\nYAML validation\nAuto completion\nHover support\nUseful while writing LinkML schemas\nvs-code-icons\nBeautiful icons\nAustin VS Code\nCode profiler\nCan be used when trying to optimize Python codebase\nSimple Websites\nGitHub pages favored over google sites over wikis\nManage and author content as markdown, managed in github, with PRs as for code\nGoogle Analytics\nExample GA 4 conversion and walkthrough info at <a href=\"https://github.com/berkeleybop/bbops/issues/28#issuecomment-1712154894\">https://github.com/berkeleybop/bbops/issues/28#issuecomment-1712154894</a>\navoid manually authoring anything that can be derived from metadata\nexamplars: obofoundry.github.io, this site\nuse CC-BY 4.0 or the CC0 public domain declaration\nExamplars:\nLinkML splash page\nPhenopackets splash page\nCell Ontology splash page\nDocumentation\nSee google guide on Writing inclusive documentation\nAvoid ableist language\nAvoid unnecessarily gendered language\nAvoid unnecessarily violent language\nall code, schemas, analyses, ontologies, MUST be documented\ndocumentation is a love-letter to your future self\nunderstand the Diataxis four-way distinction: tutorial, how-to, reference, explanation\nexemplar: OBOOK\nexemplar: LinkML docs\ngoogle API documentation guide\nhave strategies to avoid staleness and documentation getting out of sync\nuse inline documentation\npublish via appropriate framework (RTD for code, mkdocs for schema, etc)\nfollow appropriate style guide\nuse and test docstring in python\n<a href=\"https://docs.python.org/3/library/doctest.html\">https://docs.python.org/3/library/doctest.html</a>\nexamples, examples, examples\nfenced examples in markdown docs\nexample standalone scripts\nexample Jupyter notebooks\ndouble up: unit tests can serve as examples and vice versa\nSee linkml-run-examples framework\nUse existing templates\nmonarch-project-template for code-oriented projects\nlinkml cookiecutter for schema projects\nODK for ontology projects\nkghub template for KG projects\nuse Markdown as default\nRST for Sphinx/Code projects\nGoogle docs acceptable for initial brainstorming\nDon’t use Wikis (mediawiki, GitHub wiki)\nManage markdown docs as version control\npublish as static site (RTD, mkdocs, etc)\nCoding/Python\nPython is the default language; use others as appropriate\njavascript/typescript for client-side\ndon’t implement domain/business logic in js. use python + APIs\nuse typescript\ngenerate typescript datamodels using linkml gen-typescript\nRust for speed\nshould always have PyO3 wrappers\nfollow semsimian GH actions for wheels\nScala for performance reasoners or anything requiring owlapi\nHistorically we used Java for anything requiring OWLAPI but being phased out\nWhy Python?\nubiquitous, cross-platform\ngood for scripting, interactive development\nstrong ecosystem of libraries for almost anything\nEasy for developers to pick up\nMost bioinformaticians know it\nuse for anything more than about 10 lines of Bash/Perl\nuse Python 3.8+\nEnsure github actions tests 3.9, 3.11\nConform to the group style guide, or at least some style guide\npep-0008 for Python\nuse type annotations PEP484\ngoogle style guide\nWe are inspired by knocean/practices/python but differ in some places\nWe make use of OO as appropriate - just don’t go overboard like in java\nFollow conventional variable naming\nExample: <a href=\"https://docs.fast.ai/dev/abbr.html\">https://docs.fast.ai/dev/abbr.html</a>\nSee the Working with Python Environments guide for details on installing Python versions and managing virtual environments.\nAll repos should use poetry\nSet up this way: poetry new --src my-project-name\nOR use linkml-ws new for schema-centric repos\nfollow standard layouts, with code in src/\nLinting/formatting:\nUse black and flake8 and ruff\nTest Runners\nTo automate building and testing distributions in multiple Python versions\ntox\nDE FACTO: Github hosted runner via Github Actions\nCLI development\nclick\nTesting\nunittest\nDE FACTO: pytest\nTest coverage\nCoverage.py\ncodecov\ndocument all public classes, methods, functions\nAlways Use type annotations\nAlways provide docstrings\nReST (reStructuredText) » numpy-style docstrings or google style » nothing\nSOME standard is always better than none\nBe sure to set up your IDE for automatic docstring generation\nuse flask/fastAPI for web apps\nNEVER author OpenAPI directly; ALWAYS derive\nwe are exploring GraphQL frameworks like strawberry.rocks\nuse dataclasses or pydantic\nfor DAOs, ALWAYS derive from linkml\navoid authoring data models directly in python\nlist comprehensions » lambdas\nuse fstrings; never write java-style python\nALWAYS use typing\nmakes code more understandable\nallows code completion in PyCharm etc\nhelps find bugs\nuse an IDE\nPyCharm or VS is equally popular in the group\nETL/ingest\nfollow existing exemplar repos\nRead Chris’ 10 simple rules for semantic ETL\nuse requests for URL calls\nAlways provide a CLI\nseparate CLI logic from core logic\nRead CLIG guidelines\nSee also [Documenting command-line syntax ]<a href=\"https://developers.google.com/style/code-syntax\">https://developers.google.com/style/code-syntax</a>) in google style guide\nPython: use click\ndesign for composability\nprovide shortforms for common options\nDisplay help text when passed no options, the -h flag, or the –help flag\nuse de-facto standards\n-i, --input\n-o, --output\n-h, --help\nalways use dashes as separators, NOT underscores\nclick will make corresponding python vars with underscores\nFollow exemplars\nROBOT\nSSSOM\nOAK\nlinkml\nAlways write unittests for CLIs\nsee OAK for examples\nProfiling:\ncProfile and SnakeViz are useful for profiling Python code ```bash\nGenerate the profile results:\npython -m cProfile -o output.prof my_program.py</p>\n<p>View them:\npipx run snakeviz output.prof ```</p>\n<p>Examplars:\nsssom-py\nlinkml\nOAK\nLearning resources\nCharlie’s Recommended Python Programming Videos\nOBOOK - Open Biological and Biomedical Ontologies Organized Knowledge\nWeb APIs\nAuthoring\nFastAPI » Flask\nSeperate business logic from API code\nthis should be independently testable\nTesting\nuse fastapi.testclient\nfollow GO exemplar\nAccessing\nUse python requests library (unless a higher level lib is available)\nDo not construct URL strings yourself - use params instead\nfor non-trivial tasks consider building a reusable client library\nuse a client library if it already exists!\nexamplars: OAK bioportal implementation\nwhen querying a sparql endpoint\nsparqlfun > sparqlwrapper > requests > curl\nif constructing sparql is necessary\nuse a query builder rather than string manipulation\nShell\nProgramming\nbash/sh\nPersonal\nUse ohmyz\nDatabase Engines\nCurrent preferred stack\nsqlite or postgres (normalized/write)\nsolr (denormalized/read)\nthat’s it\nBUT: use whatever is appropriate for the job\nblazegraph/joseki for ttl\nneo4j for KGs\nPostgresql for SQL db server\nnever use non-open SQL db solutions\nSome legacy apps may use MySQL but Pg is preferred\nsqlite for lightweight tabular\nmongo for docs\navoid vendor lock-in\nuse generic sparql 1.1 API vs triplestore specific APIs\nsolr for searchable / denormalized / analytics\nalways use golr patterns\nread semantic columnar store patterns\nalways have a schema no matter what the task\nalways author in LinkML\ntranslate to SQL schema, JSON-Schema, Solr schema etc\nfamiliarize yourself with the tools to do this\nSQL vs other DB engines\nthis is an evolving area\nsee Knocean SQL guide\nLLMs\nontogpt\ncurategpt\nFor command line usage and direct Python usage:\n<a href=\"https://llm.datasette.io/en/stable/\">https://llm.datasette.io/en/stable/</a>\nalso follow Simon’s blog for practical guides to LLMs for engineers:\n<a href=\"https://simonwillison.net/\">https://simonwillison.net/</a>\ncode assistance\nmany of us use copilot + vscode/pycharm; see onboarding for how to charge\ngpt-4 works better for de-novo\nOpenAI accounts\nsee onboarding doc on how to get added to Mungall group account\nHandy developer and command line tools\nrunoak\nGNU Make – see Knocean guide\ncogs\nodk\nq – query TSVs via SQL\ncsvkit\njq/yq\nrobot\nbash; small scripts only\npandoc\nDocker\neditor of your choice\nProgramming Libraries\nData science\nthis is a fast changing field so recommendations here are general/loose\ngenerally prefer Python » R » other languages for data sciences\nwe frequently use tensorflow, scikitlearn, keras\nscikit-learn\ncatboost, xgboost\npandas\nTSV » CSV\nparquet or sqlite for large files\nuse # for header comments\nalways have a data dictionary in LinkML\nalways be working in a github repo (see below)\nnotebooks:\nseaborn for plotting\nUse notebooks for:\ngenerating figs for paper\nexploration\nNEVER use notebooks for\ncore logic (extract into separate lib with tests)\nETL\nanything that should be run in a pipeline\nall notebooks MUST be reproducible\ncheck small files into github\nreproducible Makefile or snakemake for obtaining other files\nideally test all notebooks via gh-actions\nKGs\nkgx\nBMT\nEnsmallenGraph, (Rust + Python bindings), fast graph ML\nEmbiggen graph ML (e.g. node2vec), and some other things like word2vec\nNEAT is a Python wrapper for reproducible graph ML in a YAML-driven way\nalso exploring pykeen ampligraph\nFollow FAIR in a meaningful way\ndata dictionaries with LinkML\nfollow identifier best practice\nOntologies\nRead the OAK guide\nUse OAK for everything\nontobio is deprecated for non-GO specific tasks\nOWLAPI (JVM) – only where absolutely necessary\nbeware of using rdflib and RDF-level libraries for working with OWL files, too low level (and slow)\naccess Ubergraph through OAK\naccess semsql through OAK\nobographviz (js)\nnever, ever use XML parsers to parse RDF/XML\ndon’t every write a new obo format parser\nobographs json direct access sometimes OK\nNER/NLP\nRead Harry’s awesome caufieldjh/awesome-bioie list\nfast changing but some tools to consider:\nontorunNER (which wraps OGER)\nBERT for language models (experimental)\nNote we are now wrapping more of this functionality in OAK\nnow subsumed by LLMs\njoin the monarch nlp slack channel\nShell commands\nsh > subprocess\nFile formats, languages, and standards\nGeneral\nTSVs for columnar data\nalways have a data dictionary (use LinkML)\nmake it pandas-friendly\nmeaningful column names\nSSSOM is an exemplar\nunderstand TidyData and Codd’s normal forms and when to use them\nhand-author YAML over JSON (+ follow schema)\nUse JSON-LD / YAML-LD as appropriate\nunderstand JSON-LD contexts\nget context for free with LinkML\nTurtle for some purposes\nRDF/XML as default for OWL\nOntologies\nUse OAK to access everything\nOWL\nOBO JSON\nconsider obo format deprecated. Exception: easier to maintain edit file as obo for git diff/PR purposes\nCOB as upper ontology, but also pay attention to biolink\nAlways use official PURLs for downloads\nthe OBO page gives the list of products. E.g. obofoundry.org/ontology/pato\nMappings (ontology or otherwise)\nSSSOM with skos predicates\nCookiecutters for starting a new project.\nGeneral-purpose projects using monarch-project-template\nLinkML based projects using linkml-project-cookiecutter\nOntology Access Kit (oaklib) plugin projects using `oakx-plugin-cookiecutter\nKGs\nbiolink\nkgx » rdf* » rdf\nmake available as:\nRDF dump\nNeo4J dump\nsparql endpoint (consider putting into larger endpoint and segregating with NGs)\nneo4j endpoint\nKGX dump\nKGX summary stats\nSchemas\neverything must have a schema, including:\nall TSVs should have data dictionary\nJSON/YAML\nKGs\nOWL ontologies and OWL instance graphs\nUnderstand basic concepts:\nnormalized vs de-normalized\nidentifiers and URIs\nclosed-world vs open-world\nschema vs ontology\nAlways author schemas in linkml\nderive alternate representations (e.g. json-schema)\nJSON-schema for JSON-centric projects (never author, always derive from LinkML)\nShEx or SHACL for ontology-centric (try and derive from LinkML)\nDon’t use kwalify any more\nAlways have a LinkML schema even when using:\npython dicts\nopen-ended JSON/YAML\nRDF\nNeo4J\nad-hoc TSVs\nInclude mappings:\nmap to biolink\nVersioning\nSemantic Versioning (semver) by default\nsoftware MUST use semver\nschemas SHOULD use semver, but OBO-style may sometimes be appropriate\nISO-8601 OBO style for OBO ontologies\nuse GitHub releases for versioning as appropriate\nalways use the autofill feature to make release notes and to name releases\nfor software follow the group github-action best practice to auto-release to pypi\nrelease versions to appropriate repository/archive\nCompression\nuse .gz instead of .zip\nif compressing multiple files in an archive, use .tar.gz, not .zip\nRememeber compressed files are not diffable in git\nFor very large files consider distributing gz files via S3 or zenodo rather than in GitHub\nremember: if a repo has 10 x 50m files that change every release, the repo will be 10g in size in 20 releases\nAs a general rule of thumb, think very carefully before committing files > 1m to github\nexceptions for existing best practice e.g. odk\nask if unsure\nText\nmarkdown by default\nfrontmatter metadata where appropriate\ntrack in version control\nuse .rst for sphinx sites where autodoc features are needed\ndon’t use wikis or github wikis except where precedent is set\nAPIs\nRESTfulness\ntrue REST may be too high a barrier\nRPC-style (i.e. swagger/openAPI) may be fine\nAll web APIs should have OpenAPI exploration interface\nderive OpenAPI from Python code\nfastapi > flask »> others\nconsidering GraphQL\nMust have Docker container\nDeprecated: Use grlc or sparqlfun to make APIs from sparql endpoints\nCURIEs and IRIs\nRead McMurry et al.\nPrefixmaps (a Python library for retrieving semantic prefix maps) is now our source of truth for all things prefix/namespace related\nTake the time to read ALL docs on bioregistry.io\nalways use CURIEs for IDs\nCURIEs + prefixmap » URIs »» ad-hoc\nalways use prefixes registered in bioregistry.io\nunderstand at a broad level the different registries:\n<a href=\"http://identifiers.org\">http://identifiers.org</a>\n<a href=\"http://n2t.net\">http://n2t.net</a> – synced(?) with identifiers.org but broader context\n<a href=\"http://bioregistry.io/\">http://bioregistry.io/</a>\nhas a lot of advantages over id.org: more transparent, github metadata based, lightweight\n<a href=\"https://github.com/prefixcommons/biocontext\">https://github.com/prefixcommons/biocontext</a>\nwe developed this as an “overlay” on existing registries\nhave an explicit JSON-LD context or prefixes yaml file\nUse the prefixcommons curie util library\nRead the identifiers guides closely, even for projects you are not on\nTranslator SRI/biolink identifiers\nIdentifiers in NMDC\nIdentifiers in GO\nGenomics\nGFF3\nSO\nAnnotation\nGAF\nGPAD\nPhenopackets\nDates\nuse ISO-8601\nuse ISO-8601\nuse ISO-8601\nuse ISO-8601\nnever, ever write a date in non-ISO-8601\nPortability\nit should be easy for anyone to install from any of our repos\neverything should run on macos or linux\nprovide a Docker image for anything complex\nuse standard installation idioms\nKey specialized libraries and command line tools\nOAK, for ontologies\nkgx\nODK and ROBOT, for ontologies\nontorunNER for NER\nBuilding Ontologies\nontologies are for users, not ontologists\nOWL and description logic is necessary for building robust ontologies, but needn’t be exposed\nMinimize philosophy\navoid unnecessary abstractions\nontologies should have annotations\nannotations, as in the sense used by curators\nontologies without annotations are generally of limited use, avoid working on them\nlearn tools and best practice for robust ontology engineering\nRead Onto-Tips\nUse and understand ODK\nUse ROBOT\nTake the OBO Academy training\nwork on the components on your own\nattend the Monarch tutorials\nuse the ontologies we work on as examplars\nGO\nUberon\nMondo\nPhenotype Ontologies\nENVO\nRO\nCL\nfollow OBO best practice and principles\nontologies should be open\nif OBO is underspecified, follow the examples of projects done in this group\nNEW: see ontology-metadata in OAK\noio » IAO\nliberal axiom annotations\nkey annotation properties: synonyms, definitions, mappings\nSee documentation on uberon synonyms, this is an exemplar for us\nProgrammatic generation\nlinkml-owl\ndosdp OR robot template\nalways use the more appropriate tool for the job\ninclude comprehensive definitions clear to biologists\nread definitions guide\nunderstand compositional patterns\navoid overmodeling\nDocument ontologies\ndocument design decisions\nwrite clear operational definitions\ndocument your design patterns\nWatch design pattern presentation\nDOSDP repo\nMondo is our exemplar\nunderstand limitations\nuse ontologies only where appropriate\nvocabularies\ndescriptors\ndon’t use an ontology where a schema is more appropriate\ndon’t use an ontology where a KG is more appropriate. See KG vs ontology DPs\nmake best effort attempt to provide mappings\nuse SSSOM\nuse boomer\nuse oak lexmatch\nCollaboration\nwe are a collaborative group, reach out if you have issues\njoin relevant channels on bbop and other Slack workspaces\nquestions always welcome but make best effort to see if information available in group reference guides\ndon’t struggle alone!\nothers are likely to either have similar questions/frustrations to you, or will have faced them in the past\nquestions are always welcome but always check standard sources first\nfor programming questions, search Stack Overflow\nfor questions regarding group or collaborator tools, is it in the FAQ?\nmake it easy for people to help you\nbe concise, yet provide sufficient relevant context\nmake it actionable\nDiscouraged: X doesn’t work\nEncouraged: when I do A, I get result B, but I expect C\ncreate issues with concise, actionable titles\nyour problem should be reproducible as far as possible\nideally contribute a a test case following idioms of appropriate repo (learn how to do this)\nmake things easier for those who follow you\nthe same questions often come up repeatedly\nif someone answers a question for you, update the relevant guide (FAQ etc) to make it clearer for others\nupvote answers on Stack Overflow you find useful\ngive thumbs up to helpful comments\nstar repos you find useful\nfollow codes of conduct\nbe constructive in any criticism\nuse your Berkeley Lab account for email, calendars\nkeep your calendar up to date, this facilitates scheduling meetings\nSlack\navoid <a title=\"Private\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\" class=\"private\">@channel (Private)</a> unless necessary\ndiscussion about tickets OK but decisions and key points must be recorded in ticket\nuse GitHub for requests\nUse GitHub for requesting terms from ontologies etc\nData mapping guide: selecting and requesting terms from ontologies, data models, and standards\nGoogle docs/slides/sheets hygiene\nRead Julie’s awesome intro to Google Drive\nRead [Data Organization in Spreadsheets for Ecologists](<a href=\"https://datacarpentry.org/spreadsheet-ecology-lesson/\">https://datacarpentry.org/spreadsheet-ecology-lesson/</a> from datacarpentry\nRead Data Organization in Spreadsheets by Bronan and Woo\nbe consistent\nwrite dates like YYYY-MM-DD\nput just one thing in a cell\nno not merge cells\norganize the data as a single rectangle (with subjects as rows and variables as columns, and with a single header row)\ncreate a data dictionary\ndo not include calculations in the raw data files\ndo not use font color or highlighting as data\nchoose good names for things\nmake backups\nuse data validation to avoid data entry errors\nsave the data in plain text files\nUse google docs/slides over Microsoft/Apple/Desktop\nbut sometimes markdown+git is more appropriate than either\nfor grants, papers, and other collaborative documents, move to Word at last possible minute (if at all)\npandocs can be used to make markdown\navoid latex/beamer unless it is really called for\nUse tagging/comments/modes appropriately\nIf it’s not your doc, default to Suggesting mode\nuse your judgment; minor direct edits to correct typos usually OK\nrespect conventions of document owner\nuse comment feature to make comments, don’t write your comment in a different color\navoid use of text color as semantics\nassign/tag people appropriately\navoid comment wars\nMake the doc outline-mode-friendly\nuse H1/H2/etc. for headers (don’t just style normal text)\nalways have outline mode on (list-like icon near top left)\nassume the reader has outline mode on\nrarely need for a TOC\nFor google sheets / excel\nnever manually color code or use font/strikethrough. Always add an explicit field and use conditional formatting\nalways have a schema, even if it is a flat data dictionary. linkml-model-enrichment will derived one\nfavour TSV+github over google sheets\nworkflows clearly favor sheets\nwhen using sheets, use cogs\nfollow TSV guidelines for google sheets\nUse formatted templates where appropriate (grants, papers)\nUse Paperpile for citations / reference management (you have access via the Lab)\nGive documents meaningful names (e.g., not just “meeting”)–assume that most people will find the doc via search rather than by going through the folder hierarchy\ndon’t use camelcase or underscores in google doc names, it hinders search\norganize google docs in the relevant folder depending on what project is funding the work\nunderstand how navigation works for google docs\nmake docs and folders viewable by all by default, unless sensitive\ninclude links to slides of general relevance from project repos\nreuse slides from existing slide decks, but provide attribution\nTips\nsearch operators\nBest practices for meetings\nSee Best practices for writing a good meeting reminder\nUse a rolling agenda/notes doc, rather than one doc per meeting\nmost recent first\nISO-8601 » human readable dates » anything else\nThe auto <a title=\"Private\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\" class=\"private\">@today (Private)</a> feature is useful\nalways have a google doc for every meeting you are in\nrecord decisions\ninclude a link to the rolling doc in calendar invites\ninclude the Zoom / videoconference link in the rolling notes doc\nDevOps\n12 factor app\nGeneral Principles\nDRY: Don’t Repeat Yourself\nbut avoid over-abstraction and frameworkitis\nvarious 10 simple guides:\n10 simple rules of quick and dirty scientific programming\nAlways reuse\nwe probably have a Python library for it\nreuse general design patterns\nGitHub templates\nfollow exemplar repos\nkgx and linkml for general python\nkg-covid-19 for ETL\ntry especially hard not to reinvent what someone in the group or our collaborator has done\nAvoid perfectionism\niterate on solutions\nsmaller batches of incremental progress » long delays on perfect solution (that may turn out to be flawed)\nFor many tasks, the 80/20 rule may suffice\nDon’t boil the ocean\nbeware of rabbit holes\nMore to come…</p>","noteIndex":{"id":"QvYK9hGbCvPpEfSRYhV8j","title":"Welcome to the COMMONS Lab Open Dendron","desc":"","updated":1693056226815,"created":1630130450048,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"20f67df3dd870fc450a162c202c9ff41","links":[{"type":"wiki","from":{"fname":"root","id":"QvYK9hGbCvPpEfSRYhV8j","vaultName":"vault"},"value":"open-notebook.commons.setup","position":{"start":{"line":43,"column":118,"offset":1871},"end":{"line":43,"column":149,"offset":1902},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"open-notebook.commons.setup"}}],"anchors":{"what-is-this-note":{"type":"header","text":"What is this note","value":"what-is-this-note","line":16,"column":0,"depth":2},"tutorial":{"type":"header","text":"Tutorial","value":"tutorial","line":20,"column":0,"depth":2},"dendron":{"type":"header","text":"Dendron.","value":"dendron","line":22,"column":0,"depth":3},"what-is-dendron-":{"type":"header","text":"What is Dendron ?","value":"what-is-dendron-","line":24,"column":0,"depth":4},"where-to-get-more-info-on-dendron-":{"type":"header","text":"Where to get more info on Dendron ?","value":"where-to-get-more-info-on-dendron-","line":30,"column":0,"depth":4},"concrete-steps-to-access-and-contribute-to-the-dbgi-dendron":{"type":"header","text":"Concrete steps to access and contribute to the DBGI Dendron","value":"concrete-steps-to-access-and-contribute-to-the-dbgi-dendron","line":35,"column":0,"depth":4},"questions-comments-suggestions-":{"type":"header","text":"Questions, comments, suggestions ?","value":"questions-comments-suggestions-","line":52,"column":0,"depth":2}},"children":["5o0tvzf4l6t6moau7en1v48","e4ul30admmxm9ilxfq275cq","h78qbvh1fd9bwcykmcm9uo3","6ooxuf27zzf3grb14o18qf2","tiqo5upbg6224t7i8p87iok","ltq8wcrabmq6mlescrdi4m0","bdq3suiz8yriznljea2zpug","ih6vyup3yre4m9woc9ldl7k","vDTgZL9UHWqYtBFdtD3vK","69ekb2qhuwukr0jwrzy6tnw","8us579vydjfskegndhvdzsl","373694o1o6ocqohko4um7c9","jldFUSJGjDf1mFH8c2yUI","dh2qp7w4tl6otf89xrmxitv","2rvdf4t5qnx5hqjj29bojcc","stj9lq0lxhfuk5ntomiozz0","gvdyfgvq0z08fcfaqzmhtjo","2rvclk21kfedpvxuzjpizi7","dcwgamgyghrlyau1avlh6ug","432qdutuo1i8h5pcuh39ytt","2npxodkvs5jk6p1eksi551b","h81rw16zzgh9kix8ti1mbam","lco50o42dfeph5i5f2k981w","46d1odkovrpdi6g16992phy","sw67lr6069gwhqmdym2l9na","s9gzk7nphtjzmpdqvk5y4vj","82ra6p4ykf814hp8yfw4wp6","hpnaglyhnb48vuiniqecnqf","y7nk7xmiht44neo0q7cl5cs","2cxr093kvrg4jojokwgqrbj","8vfu5h3617jbzy78xr2hlo1","w75krbmkkvla3hwd66hn5bh","40po5od17ekcr1e77dluxao","4pqppog2u66rx1tkc8jy5v9","ektni5nfulyro7dkrbtek7j","vfsp2aci6vy7kg2jsyy8tzu","0wm4geq40t6nscn88rcwu47","ib4jmxy1x3l1r0ewe6hln4j","0h57aw0be2jnc3dxcpn3ajn","4789z8f1dqdh5k3nmgr1m4z","p5dszyuhj1klgje0brtv0xj","sk4m9gq7vz2t9phcxlxvqpw","43p60vv8btyhaclugl93jok","zhc9hhpaobkbo4e2votv6wr","ylulfzi7ra5yv6ja7j78t6e","wj0i9czxvt4v0b674nb8501","ovslc641d0h00s16tf6kl8w","4zmlbmcp6q4q69ycvhavzr6","59ftsVxFXXM9bB43vfKwK","nmnpsy2e1rwqnqgurogi2u6","yi9sq691cas9eyjfx8x7atd","hmn2egle6t4foxe01xup7xt","3yysbx5aor30qd48lqaulbt","nq0iph4a21h5alnuip05j6z","y4t7h534eugai0bjr3mgfjn","zlbfl274tfdx3ix844jt5bm","ulasj276ktykjhdco456wan","au21tj497d981l8pdsily19","8zdzqjzai32lw7xbn30khlt","rjq88ar936t5kn7i86dnfb2","q1yxhdq1jqazej8hq8qzqrb","9mwhjkgi6lx9icrry5qwcg7","3j65st8vcb7mztobso4xk1m","t4z6dnhqmj5axvc2d1esbnn","quvftc4ygczckg0vfltkxbb","jka9lkt701hkbxyfs0qujnx","ivro3wr1xttk7fh7ikp0mvx","alwx9pow583s15xgx2gecjv"],"parent":null,"data":{},"body":"\n![](/assets/images/allard-lab.jpg)\n\nWelcome the the COMMONS Lab Open Dendron !\n\nIn the [COMMONS Lab](https://www.unifr.ch/bio/en/groups/allard/) we intent to follow the [Open Notebook Science](https://en.wikipedia.org/wiki/Open-notebook_science) approach to document our research.\n\nFor this we use the [Dendron](https://www.dendron.so/) system as a mean to efficiently capture notes and publish them.\n\n## What is this note\n\nThis note is a succinct tutorial note aiming to get you started in the use of the COMMONS Lab Dendron.\n\n## Tutorial\n\n### Dendron. \n\n#### What is Dendron ?\n\n> Dendron is an open-source, local-first, markdown-based, note-taking tool. Think of it as a cache for everything that you care about - if you've spent more then five minutes solving a problem, you should never spent any more time solving the same exact problem.\n> \n> Dendron is a knowledge base built by and for developers and integrates natively with IDEs like VS Code and VSCodium.\n\n#### Where to get more info on Dendron ?\n\n- You can get more information in the Dendron system at the official website www.dendron.so\n- All the Dendron documentation is hosted here https://wiki.dendron.so/. It is, obviously, a Dendron itself.\n\n#### Concrete steps to access and contribute to the DBGI Dendron\n\n1. Install [VSCode](https://code.visualstudio.com/download)\n2. Install [Dendron](https://marketplace.visualstudio.com/items?itemName=dendron.dendron) from the VSCode marketplace \n3. Clone the COMMONS Dendron repo\n\n    In your terminal\n    ```\n    git clone https://github.com/commons-research/commons-dws-public.git\n    ```\n4. In VSCode open (File/Open) the cloned repository.\n5. Voila ! You should now be in the COMMONS Lab Open Dendron.\n\nFeel free to explore and contribute.\nA first, important step could be to configure VSCode so that you can easily add a daily note. See steps described at [[open-notebook.commons.setup]]\n\n\n## Questions, comments, suggestions ?\n\nFeel free to contribute here https://github.com/orgs/commons-research/discussions\n\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"vaultSelectionModeOnCreate":"smart","fuzzThreshold":0.2}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.112.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"assetsPrefix":"/commons-dws-public","copyAssets":true,"siteHierarchies":["root"],"enableSiteLastModified":true,"siteRootDir":"docs","siteUrl":"https://commons-research.github.io","enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"writeStubs":false,"seo":{"title":"COMMONS DWS Public","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Click here to edit this page on Github !","editBranch":"main","editViewMode":"edit","editRepository":"https://github.com/commons-research/commons-dws-public"},"enablePrettyLinks":true,"enableTaskNotes":true,"siteFaviconPath":"favicon.ico","siteIndex":"root","searchMode":"lookup"}}},"__N_SSG":true}