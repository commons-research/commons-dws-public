{"pageProps":{"note":{"id":"6qK8k4MF0vooncgMJZw5W","title":"Isfrag","desc":"","updated":1635171184446,"created":1621006125043,"custom":{},"fname":"tools.chemoinformatics.isfrag","type":"note","vault":{"fsPath":"vault"},"contentHash":"911c3f1effa29164cae59d45a61e8b08","links":[{"type":"wiki","from":{"fname":"tools.chemoinformatics.isfrag","id":"6qK8k4MF0vooncgMJZw5W","vaultName":"vault"},"value":"202002251433","position":{"start":{"line":6,"column":11,"offset":55},"end":{"line":6,"column":27,"offset":71},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"202002251433"}}],"anchors":{"tutorial-for-npatlas-in-silico-fragmentation-data-treatment":{"type":"header","text":"Tutorial for NPatlas in silico fragmentation data treatment","value":"tutorial-for-npatlas-in-silico-fragmentation-data-treatment","line":20,"column":0,"depth":1},"prior-to-fragmentation":{"type":"header","text":"Prior to fragmentation","value":"prior-to-fragmentation","line":23,"column":0,"depth":2},"prepare-space-delimited-input-file":{"type":"header","text":"Prepare space delimited input file","value":"prepare-space-delimited-input-file","line":25,"column":0,"depth":3},"split-the-file":{"type":"header","text":"Split the file","value":"split-the-file","line":33,"column":0,"depth":3},"when-using-the-docker-cli-files-need-to-have-an-extension-or-taken-as-folder-":{"type":"header","text":"When using the docker cli files need to have an extension (or taken as folder ?)","value":"when-using-the-docker-cli-files-need-to-have-an-extension-or-taken-as-folder-","line":46,"column":0,"depth":3},"prepare-mutilple-bash-file-to-launch-on-baobab":{"type":"header","text":"Prepare mutilple bash file to launch on baobab","value":"prepare-mutilple-bash-file-to-launch-on-baobab","line":54,"column":0,"depth":3},"fetching-cfm-predict-results":{"type":"header","text":"Fetching cfm-predict results","value":"fetching-cfm-predict-results","line":62,"column":0,"depth":2},"we-might-eventually-need-to-move-all-files-from-subfolders-recursively-to-a-superior-folder":{"type":"header","text":"We might eventually need to move all files from subfolders recursively to a superior folder","value":"we-might-eventually-need-to-move-all-files-from-subfolders-recursively-to-a-superior-folder","line":81,"column":0,"depth":2},"pruning-the-raw-log-files":{"type":"header","text":"Pruning the raw log files","value":"pruning-the-raw-log-files","line":90,"column":0,"depth":2},"populating-the-mgf-headers":{"type":"header","text":"Populating the mgf headers","value":"populating-the-mgf-headers","line":185,"column":0,"depth":2},"preparation-of-the-adducted-metadata-table":{"type":"header","text":"Preparation of the adducted metadata table","value":"preparation-of-the-adducted-metadata-table","line":187,"column":0,"depth":3},"addition-of-the-metadata-to-the-individual-mgf-headers":{"type":"header","text":"Addition of the metadata to the individual mgf headers","value":"addition-of-the-metadata-to-the-individual-mgf-headers","line":210,"column":0,"depth":3},"generating-the-final-spectral-file":{"type":"header","text":"Generating the final spectral file","value":"generating-the-final-spectral-file","line":227,"column":0,"depth":2},"outputting-non-fragmented-entries":{"type":"header","text":"Outputting non-fragmented entries","value":"outputting-non-fragmented-entries","line":235,"column":0,"depth":2},"check-molvs-for-structure-standardization":{"type":"header","text":"check molVS for structure standardization","value":"check-molvs-for-structure-standardization","line":252,"column":0,"depth":3}},"children":[],"parent":"0z3q4615wyjhfg7p4d2tizl","data":{}},"body":"<h1 id=\"isfrag\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#isfrag\"></a>Isfrag</h1>\n<p>Pasting an old recipee from ZettelKasten</p>\n<p>Linked to <a title=\"Private\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\" class=\"private\">202002251433 (Private)</a> in silico fragmentation worflow.</p>\n<p>Children workflow on the beast MAPP </p>\n<p>Side notes : try to write everything as scripts so that they can be launched without a GUI (ex on X2Go or directly Boabab).</p>\n<h1 id=\"tutorial-for-npatlas-in-silico-fragmentation-data-treatment\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#tutorial-for-npatlas-in-silico-fragmentation-data-treatment\"></a>Tutorial for NPatlas in silico fragmentation data treatment</h1>\n<h2 id=\"prior-to-fragmentation\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#prior-to-fragmentation\"></a>Prior to fragmentation</h2>\n<h3 id=\"prepare-space-delimited-input-file\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#prepare-space-delimited-input-file\"></a>Prepare space delimited input file</h3>\n<p>Complete metadate file is converted to list of Unique ID and smiles space separated (for cfm id input)</p>\n<p>python frag_list_preparator.py ../npatlas_data/np_atlas_2019_12.tsv ../npatlas_data/np_atlas_2019_12_for_frag.tsv NPAID SMILES</p>\n<p>python frag_list_preparator.py ../open_np_db_data/open_NP_db.tsv ../open_np_db_data/open_NP_db_tofrag.txt shortinchikey shortinchikey smiles</p>\n<h3 id=\"split-the-file\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#split-the-file\"></a>Split the file</h3>\n<p>(Works on Linux based shells)</p>\n<p>split -a 5 -l 500 -d ../open<em>np_db_data/open_NP_db_tofrag.txt ../open_np_db_data/opennpdb_tofrag/opennpdb</em>\nsplit -a 5 -l 500 -d ./lotus<em>data/lotus_data_for_frag.txt ./lotus_data/lotus_data_for_frag/lotus_data</em></p>\n<p>split -a 5 -l 500 -d ./ ./lotus<em>data/lotus_data_for_frag/lotus_data</em>\nsplit -a 5 -l 500 -d cfm/cfm<em>input/platinum_tofrag.tsv cfm/cfm_input/splitted/lotus_to_frag</em></p>\n<p>This one allows to preserve extensions and is build on number of desired chunks without splitting lines\nsplit -a 5 -n l/199 -d --additional-suffix=.txt  cfm<em>input/sub_platinum_tofrag.tsv cfm_input/splitted/lotus_to_frag</em></p>\n<h3 id=\"when-using-the-docker-cli-files-need-to-have-an-extension-or-taken-as-folder-\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#when-using-the-docker-cli-files-need-to-have-an-extension-or-taken-as-folder-\"></a>When using the docker cli files need to have an extension (or taken as folder ?)</h3>\n<p>for f in *; do mv \"<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mi mathvariant=\"normal\">\"</mi><mi mathvariant=\"normal\">\"</mi></mrow><annotation encoding=\"application/x-tex\">f\" \"</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord\">\"\"</span></span></span></span></span>f.txt\"; done</p>\n<p>if you made a mistacke </p>\n<p>find / -type f -name '*.txt' -exec sh -c 'mv -- \"<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0</mn><mi mathvariant=\"normal\">\"</mi><mi mathvariant=\"normal\">\"</mi></mrow><annotation encoding=\"application/x-tex\">0\" \"</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord\">0\"\"</span></span></span></span></span>{0%.txt}\"' {} \\;</p>\n<h3 id=\"prepare-mutilple-bash-file-to-launch-on-baobab\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#prepare-mutilple-bash-file-to-launch-on-baobab\"></a>Prepare mutilple bash file to launch on baobab</h3>\n<p>(strangely enough the .sh incrementer script return an error on Linux, runned OK on MacOS command line )</p>\n<p>Note: apparently sbatch as been replaced by srun on the boabab server side. Be sure to update the scripts accordingly</p>\n<h2 id=\"fetching-cfm-predict-results\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#fetching-cfm-predict-results\"></a>Fetching cfm-predict results</h2>\n<p>Download cfm-predict fragmentation results from the baob server using rsync command</p>\n<p>rsync -rvz -e 'ssh' --progress <a href=\"/commons-dws-public/mailto:allardp@baobab2.unige.ch\">allardp@baobab2.unige.ch</a>:/home/allardp/CFM_results/npatlas ./results\nrsync -rvz -e 'ssh' --progress <a href=\"/commons-dws-public/mailto:allardp@baobab2.unige.ch\">allardp@baobab2.unige.ch</a>:/home/allardp/CFM_results/coconut/ .</p>\n<p>find ./ -type f -name '*.mgf' | wc  </p>\n<p>allows to count all file in a folder\nHere 25090 files for NPatalas</p>\n<p>Coconut 384222 .log files</p>\n<p> 384150 mgf files</p>\n<h2 id=\"we-might-eventually-need-to-move-all-files-from-subfolders-recursively-to-a-superior-folder\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#we-might-eventually-need-to-move-all-files-from-subfolders-recursively-to-a-superior-folder\"></a>We might eventually need to move all files from subfolders recursively to a superior folder</h2>\n<p>find ./bacasable -type f -print0 | xargs -0 mv -t ./bacasable</p>\n<p>find ./results_coconut -type f -print0 | xargs -0 mv -t ./results_coconut</p>\n<h2 id=\"pruning-the-raw-log-files\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#pruning-the-raw-log-files\"></a>Pruning the raw log files</h2>\n<p>The output of cfm-predict consist of .log file containing mass spectra, where each fragments are individually labelled and eventually linked to a substrcture. Such information might be usefull later but for now we only want to keep the raw ms data</p>\n<p>(need to define a help function here)</p>\n<p>python raw_log_treater_npatlas.py ../npatlas_data/results_npatlas/npatlas/ .log\npython raw_log_treater.py ../coconut_data/results_coconut/ .log</p>\n<p>At this step .log file should be pruned and contains only digits (m/z and intensities)</p>\n<p>for coconut Parsing directory../coconut_data/results_coconut/ with file extension :.log</p>\n<p>'mass' ../coconut_data/results_coconut/CNP0402147.log\n'mass' ../coconut_data/results_coconut/CNP0153817.log\n'mass' ../coconut_data/results_coconut/CNP0155980.log\n'mass' ../coconut_data/results_coconut/CNP0086807.log\n'mass' ../coconut_data/results_coconut/CNP0199206.log\n'mass' ../coconut_data/results_coconut/CNP0334817.log\n'mass' ../coconut_data/results_coconut/CNP0366374.log\n'mass' ../coconut_data/results_coconut/CNP0232712.log\n'mass' ../coconut_data/results_coconut/CNP0370068.log\n'mass' ../coconut_data/results_coconut/CNP0055178.log\n'mass' ../coconut_data/results_coconut/CNP0228597.log\n'mass' ../coconut_data/results_coconut/CNP0119974.log\n'mass' ../coconut_data/results_coconut/CNP0132139.log\n'mass' ../coconut_data/results_coconut/CNP0145457.log\n'mass' ../coconut_data/results_coconut/CNP0230801.log\n'mass' ../coconut_data/results_coconut/CNP0310370.log\n'mass' ../coconut_data/results_coconut/CNP0149436.log\n'mass' ../coconut_data/results_coconut/CNP0396848.log\n'mass' ../coconut_data/results_coconut/CNP0401434.log\n'mass' ../coconut_data/results_coconut/CNP0101561.log\n'mass' ../coconut_data/results_coconut/CNP0390928.log\n'mass' ../coconut_data/results_coconut/CNP0405256.log\n'mass' ../coconut_data/results_coconut/CNP0395006.log\n'mass' ../coconut_data/results_coconut/CNP0159145.log\n'mass' ../coconut_data/results_coconut/CNP0131085.log\n'mass' ../coconut_data/results_coconut/CNP0230696.log\n'mass' ../coconut_data/results_coconut/CNP0014450.log\n'mass' ../coconut_data/results_coconut/CNP0214739.log\n'mass' ../coconut_data/results_coconut/CNP0302005.log\n'mass' ../coconut_data/results_coconut/CNP0279314.log\n'mass' ../coconut_data/results_coconut/CNP0177036.log\n'mass' ../coconut_data/results_coconut/CNP0274256.log\n'mass' ../coconut_data/results_coconut/CNP0403745.log\n'mass' ../coconut_data/results_coconut/CNP0039287.log\n'mass' ../coconut_data/results_coconut/CNP0238803.log\n'mass' ../coconut_data/results_coconut/CNP0014261.log\n'mass' ../coconut_data/results_coconut/CNP0077076.log\n'mass' ../coconut_data/results_coconut/CNP0125300.log\n'mass' ../coconut_data/results_coconut/CNP0228582.log\n'mass' ../coconut_data/results_coconut/CNP0393136.log\n'mass' ../coconut_data/results_coconut/CNP0338003.log\n'mass' ../coconut_data/results_coconut/CNP0070182.log\n'mass' ../coconut_data/results_coconut/CNP0230961.log\n'mass' ../coconut_data/results_coconut/CNP0001326.log\n'mass' ../coconut_data/results_coconut/CNP0088652.log\n'mass' ../coconut_data/results_coconut/CNP0045797.log\n'mass' ../coconut_data/results_coconut/CNP0175458.log\n'mass' ../coconut_data/results_coconut/CNP0300969.log\n'mass' ../coconut_data/results_coconut/CNP0030335.log\n'mass' ../coconut_data/results_coconut/CNP0126194.log\n'mass' ../coconut_data/results_coconut/CNP0334816.log\n'mass' ../coconut_data/results_coconut/CNP0290616.log\n'mass' ../coconut_data/results_coconut/CNP0386127.log\n'mass' ../coconut_data/results_coconut/CNP0406328.log\n'mass' ../coconut_data/results_coconut/CNP0127289.log\n'mass' ../coconut_data/results_coconut/CNP0032755.log\n'mass' ../coconut_data/results_coconut/CNP0258640.log\n'mass' ../coconut_data/results_coconut/CNP0199475.log\n'mass' ../coconut_data/results_coconut/CNP0350989.log\n'mass' ../coconut_data/results_coconut/CNP0333350.log\n'mass' ../coconut_data/results_coconut/CNP0213544.log\n'mass' ../coconut_data/results_coconut/CNP0204567.log\n'mass' ../coconut_data/results_coconut/CNP0148525.log\n'mass' ../coconut_data/results_coconut/CNP0053639.log\n'mass' ../coconut_data/results_coconut/CNP0118368.log\n'mass' ../coconut_data/results_coconut/CNP0226584.log\n'mass' ../coconut_data/results_coconut/CNP0254221.log\n'mass' ../coconut_data/results_coconut/CNP0241364.log\n'mass' ../coconut_data/results_coconut/CNP0348684.log\n'mass' ../coconut_data/results_coconut/CNP0053255.log\n'mass' ../coconut_data/results_coconut/CNP0167909.log\n'mass' ../coconut_data/results_coconut/CNP0142603.log\nTreated 384150 files, skipped 72</p>\n<h2 id=\"populating-the-mgf-headers\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#populating-the-mgf-headers\"></a>Populating the mgf headers</h2>\n<h3 id=\"preparation-of-the-adducted-metadata-table\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#preparation-of-the-adducted-metadata-table\"></a>Preparation of the adducted metadata table</h3>\n<p>We need to prepare and adducted dataframe containing the protonated and deprotonated masses</p>\n<p>This script recquire rdkit so we build a environment.yml file from a dedicated conda env</p>\n<p>conda env export -n conda-env -f /path/to/environment.yml</p>\n<p>Eventually you need to fetch the file from the internet (use wget )</p>\n<p>wget <a href=\"https://zenodo.org/record/3547718/files/COCONUT4MetFrag.csv?download=1\">https://zenodo.org/record/3547718/files/COCONUT4MetFrag.csv?download=1</a></p>\n<p>Sometimes since SMILES or INchi can yield error and since there is a MF field, the emass can be calculated directly form the MF as described here\n<a href=\"https://bioinformatics.stackexchange.com/a/9273\">https://bioinformatics.stackexchange.com/a/9273</a>. Noooop actually not working since the GetMass() function yield a molecular weight and not and exact mass ....</p>\n<p>Script table_adducter_script.py is adapted to cope with different delimiters ... beware and note that $ is mandatory to input the tab delim</p>\n<p>python table_adducter_npatlas_script.py ../npatlas_data/np_atlas_2019_12.tsv ../npatlas_data/np_atlas_2019_12_adducted.tsv</p>\n<p>python table_adducter_script.py ../coconut_data/COCONUT4MetFrag.csv ',' ../coconut_data/COCONUT4MetFrag_adducted.csv $'\\t'</p>\n<h3 id=\"addition-of-the-metadata-to-the-individual-mgf-headers\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#addition-of-the-metadata-to-the-individual-mgf-headers\"></a>Addition of the metadata to the individual mgf headers</h3>\n<p>We can now populate each raw mgf with its corresponding metadata. For this we use the treat_npatlas.py script</p>\n<p>python treat_npatlas.py ../npatlas_data/np_atlas_2019_12_adducted.tsv ../npatlas_data/results_npatlas/npatlas/</p>\n<p>python mgf_header_populater.py ../coconut_data/COCONUT4MetFrag_adducted.csv ../coconut_data/results_coconut/ Identifier</p>\n<p>on coconut </p>\n<p>Treated 384150 files, skipped 28161.</p>\n<h2 id=\"generating-the-final-spectral-file\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#generating-the-final-spectral-file\"></a>Generating the final spectral file</h2>\n<p>We concatenate each documented mgf files to a single spectral mgf file.</p>\n<p>find ./ -type f -name '<em>.mgf' | while read F; do cat ${F} >> ../../npatlas_ISDB_pos.mgf; done\nfind ./ -type f -name '</em>.mgf' | while read F; do cat ${F} >> ../../coconut_ISDB_pos.mgf; done</p>\n<h2 id=\"outputting-non-fragmented-entries\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#outputting-non-fragmented-entries\"></a>Outputting non-fragmented entries</h2>\n<p>For several reasons (charged compounds, some tautomers, structures too heavy to be fragmented in a reasonable amount of time) some entries might not have been fragmented. </p>\n<p>To find them we will first list all correctly converted mgf</p>\n<p>find ./ -type f -name '<em>.mgf' | sed 's!.</em>/!!' | sed 's!^!!' >  list_mgf.txt</p>\n<p>%%here eventually without the extension</p>\n<p>find ./ -type f -name '<em>.mgf' | sed 's!.</em>/!!' | sed 's!.mgf!!' >  ../../list_mgf.txt</p>\n<p>And then the list is compared to the initial input using the table_comparator.py </p>\n<p>python table_comparator.py ../npatlas_data/npatlas_for_frag.txt ../npatlas_data/list_mgf.txt ../npatlas_data/unfragged_list.txt</p>\n<h3 id=\"check-molvs-for-structure-standardization\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#check-molvs-for-structure-standardization\"></a>check molVS for structure standardization</h3>\n<p><a href=\"https://molvs.readthedocs.io/en/latest/index.html\">https://molvs.readthedocs.io/en/latest/index.html</a></p>","noteIndex":{"id":"QvYK9hGbCvPpEfSRYhV8j","title":"Welcome to the COMMONS Lab Open Dendron","desc":"","updated":1693056226815,"created":1630130450048,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"20f67df3dd870fc450a162c202c9ff41","links":[{"type":"wiki","from":{"fname":"root","id":"QvYK9hGbCvPpEfSRYhV8j","vaultName":"vault"},"value":"open-notebook.commons.setup","position":{"start":{"line":43,"column":118,"offset":1871},"end":{"line":43,"column":149,"offset":1902},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"open-notebook.commons.setup"}}],"anchors":{"what-is-this-note":{"type":"header","text":"What is this note","value":"what-is-this-note","line":16,"column":0,"depth":2},"tutorial":{"type":"header","text":"Tutorial","value":"tutorial","line":20,"column":0,"depth":2},"dendron":{"type":"header","text":"Dendron.","value":"dendron","line":22,"column":0,"depth":3},"what-is-dendron-":{"type":"header","text":"What is Dendron ?","value":"what-is-dendron-","line":24,"column":0,"depth":4},"where-to-get-more-info-on-dendron-":{"type":"header","text":"Where to get more info on Dendron ?","value":"where-to-get-more-info-on-dendron-","line":30,"column":0,"depth":4},"concrete-steps-to-access-and-contribute-to-the-dbgi-dendron":{"type":"header","text":"Concrete steps to access and contribute to the DBGI Dendron","value":"concrete-steps-to-access-and-contribute-to-the-dbgi-dendron","line":35,"column":0,"depth":4},"questions-comments-suggestions-":{"type":"header","text":"Questions, comments, suggestions ?","value":"questions-comments-suggestions-","line":52,"column":0,"depth":2}},"children":["5o0tvzf4l6t6moau7en1v48","e4ul30admmxm9ilxfq275cq","h78qbvh1fd9bwcykmcm9uo3","6ooxuf27zzf3grb14o18qf2","tiqo5upbg6224t7i8p87iok","ltq8wcrabmq6mlescrdi4m0","bdq3suiz8yriznljea2zpug","ih6vyup3yre4m9woc9ldl7k","vDTgZL9UHWqYtBFdtD3vK","69ekb2qhuwukr0jwrzy6tnw","8us579vydjfskegndhvdzsl","373694o1o6ocqohko4um7c9","jldFUSJGjDf1mFH8c2yUI","dh2qp7w4tl6otf89xrmxitv","2rvdf4t5qnx5hqjj29bojcc","stj9lq0lxhfuk5ntomiozz0","gvdyfgvq0z08fcfaqzmhtjo","2rvclk21kfedpvxuzjpizi7","dcwgamgyghrlyau1avlh6ug","432qdutuo1i8h5pcuh39ytt","2npxodkvs5jk6p1eksi551b","h81rw16zzgh9kix8ti1mbam","lco50o42dfeph5i5f2k981w","46d1odkovrpdi6g16992phy","sw67lr6069gwhqmdym2l9na","s9gzk7nphtjzmpdqvk5y4vj","82ra6p4ykf814hp8yfw4wp6","hpnaglyhnb48vuiniqecnqf","y7nk7xmiht44neo0q7cl5cs","2cxr093kvrg4jojokwgqrbj","8vfu5h3617jbzy78xr2hlo1","w75krbmkkvla3hwd66hn5bh","40po5od17ekcr1e77dluxao","4pqppog2u66rx1tkc8jy5v9","ektni5nfulyro7dkrbtek7j","vfsp2aci6vy7kg2jsyy8tzu","0wm4geq40t6nscn88rcwu47","ib4jmxy1x3l1r0ewe6hln4j","0h57aw0be2jnc3dxcpn3ajn","4789z8f1dqdh5k3nmgr1m4z","p5dszyuhj1klgje0brtv0xj","sk4m9gq7vz2t9phcxlxvqpw","43p60vv8btyhaclugl93jok","zhc9hhpaobkbo4e2votv6wr","ylulfzi7ra5yv6ja7j78t6e","wj0i9czxvt4v0b674nb8501","ovslc641d0h00s16tf6kl8w","4zmlbmcp6q4q69ycvhavzr6","59ftsVxFXXM9bB43vfKwK","nmnpsy2e1rwqnqgurogi2u6","yi9sq691cas9eyjfx8x7atd","hmn2egle6t4foxe01xup7xt","3yysbx5aor30qd48lqaulbt","nq0iph4a21h5alnuip05j6z","y4t7h534eugai0bjr3mgfjn","zlbfl274tfdx3ix844jt5bm","ulasj276ktykjhdco456wan","au21tj497d981l8pdsily19","8zdzqjzai32lw7xbn30khlt","rjq88ar936t5kn7i86dnfb2","q1yxhdq1jqazej8hq8qzqrb","9mwhjkgi6lx9icrry5qwcg7","3j65st8vcb7mztobso4xk1m","t4z6dnhqmj5axvc2d1esbnn","quvftc4ygczckg0vfltkxbb","jka9lkt701hkbxyfs0qujnx","ivro3wr1xttk7fh7ikp0mvx","alwx9pow583s15xgx2gecjv"],"parent":null,"data":{},"body":"\n![](/assets/images/allard-lab.jpg)\n\nWelcome the the COMMONS Lab Open Dendron !\n\nIn the [COMMONS Lab](https://www.unifr.ch/bio/en/groups/allard/) we intent to follow the [Open Notebook Science](https://en.wikipedia.org/wiki/Open-notebook_science) approach to document our research.\n\nFor this we use the [Dendron](https://www.dendron.so/) system as a mean to efficiently capture notes and publish them.\n\n## What is this note\n\nThis note is a succinct tutorial note aiming to get you started in the use of the COMMONS Lab Dendron.\n\n## Tutorial\n\n### Dendron. \n\n#### What is Dendron ?\n\n> Dendron is an open-source, local-first, markdown-based, note-taking tool. Think of it as a cache for everything that you care about - if you've spent more then five minutes solving a problem, you should never spent any more time solving the same exact problem.\n> \n> Dendron is a knowledge base built by and for developers and integrates natively with IDEs like VS Code and VSCodium.\n\n#### Where to get more info on Dendron ?\n\n- You can get more information in the Dendron system at the official website www.dendron.so\n- All the Dendron documentation is hosted here https://wiki.dendron.so/. It is, obviously, a Dendron itself.\n\n#### Concrete steps to access and contribute to the DBGI Dendron\n\n1. Install [VSCode](https://code.visualstudio.com/download)\n2. Install [Dendron](https://marketplace.visualstudio.com/items?itemName=dendron.dendron) from the VSCode marketplace \n3. Clone the COMMONS Dendron repo\n\n    In your terminal\n    ```\n    git clone https://github.com/commons-research/commons-dws-public.git\n    ```\n4. In VSCode open (File/Open) the cloned repository.\n5. Voila ! You should now be in the COMMONS Lab Open Dendron.\n\nFeel free to explore and contribute.\nA first, important step could be to configure VSCode so that you can easily add a daily note. See steps described at [[open-notebook.commons.setup]]\n\n\n## Questions, comments, suggestions ?\n\nFeel free to contribute here https://github.com/orgs/commons-research/discussions\n\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"vaultSelectionModeOnCreate":"smart","fuzzThreshold":0.2}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.112.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"assetsPrefix":"/commons-dws-public","copyAssets":true,"siteHierarchies":["root"],"enableSiteLastModified":true,"siteRootDir":"docs","siteUrl":"https://commons-research.github.io","enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"writeStubs":false,"seo":{"title":"COMMONS DWS Public","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Click here to edit this page on Github !","editBranch":"main","editViewMode":"edit","editRepository":"https://github.com/commons-research/commons-dws-public"},"enablePrettyLinks":true,"enableTaskNotes":true,"siteFaviconPath":"favicon.ico","siteIndex":"root","searchMode":"lookup"}}},"__N_SSG":true}