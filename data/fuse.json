{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title","getFn":null},{"path":["body"],"id":"body","weight":1,"src":"body","getFn":null}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"Welcome to the COMMONS Lab Open Dendron","n":0.378},"1":{"v":"\n![](/assets/images/allard-lab.jpg)\n\nWelcome the the COMMONS Lab Open Dendron !\n\nIn the [COMMONS Lab](https://www.unifr.ch/bio/en/groups/allard/) we intent to follow the [Open Notebook Science](https://en.wikipedia.org/wiki/Open-notebook_science) approach to document our research.\n\nFor this we use the [Dendron](https://www.dendron.so/) system as a mean to efficiently capture notes and publish them.\n\n## What is this note\n\nThis note is a succinct tutorial note aiming to get you started in the use of the COMMONS Lab Dendron.\n\n## Tutorial\n\n### Dendron. \n\n#### What is Dendron ?\n\n> Dendron is an open-source, local-first, markdown-based, note-taking tool. Think of it as a cache for everything that you care about - if you've spent more then five minutes solving a problem, you should never spent any more time solving the same exact problem.\n> \n> Dendron is a knowledge base built by and for developers and integrates natively with IDEs like VS Code and VSCodium.\n\n#### Where to get more info on Dendron ?\n\n- You can get more information in the Dendron system at the official website www.dendron.so\n- All the Dendron documentation is hosted here https://wiki.dendron.so/. It is, obviously, a Dendron itself.\n\n#### Concrete steps to access and contribute to the DBGI Dendron\n\n1. Install [VSCode](https://code.visualstudio.com/download)\n2. Install [Dendron](https://marketplace.visualstudio.com/items?itemName=dendron.dendron) from the VSCode marketplace \n3. Clone the COMMONS Dendron repo\n\n    In your terminal\n    ```\n    git clone https://github.com/commons-research/commons-dws-public.git\n    ```\n4. In VSCode open (File/Open) the cloned repository.\n5. Voila ! You should now be in the COMMONS Lab Open Dendron.\n\nFeel free to explore and contribute.\nA first, important step could be to configure VSCode so that you can easily add a daily note. See steps described at [[open-notebook.commons.setup]]\n\n\n## Questions, comments, suggestions ?\n\nFeel free to contribute here https://github.com/orgs/commons-research/discussions\n\n","n":0.062}}},{"i":2,"$":{"0":{"v":"Daily","n":1}}},{"i":3,"$":{"0":{"v":"Notebook","n":1}}},{"i":4,"$":{"0":{"v":"Pma","n":1}}},{"i":5,"$":{"0":{"v":"2023","n":1}}},{"i":6,"$":{"0":{"v":"02","n":1}}},{"i":7,"$":{"0":{"v":"2023-02-09","n":1},"1":{"v":"\n# This is PMA's daily notebook.\n\nToday is 2023.02.09\n\n## Todo today\n\n###\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n\n### Meeting Marco Visani \n\n[[people.marco-visani]]\n\nWill work on the [[project.commons-private.anticipated-lotus]] \n\nhttps://openmolecules.org/datawarrior/\nhttps://www.dendron.so/\n\nhttps://www.dbgi.org/dendron-dbgi/notes/tofizf0eb38rduuw6ffnzba/\n\nLOTUS outputs\nhttps://zenodo.org/communities/the-lotus-initiative/?page=1&size=20\n\n\nhttps://zenodo.org/record/7534071#.Y-S2QJOZP8Y\n\n\nSome links https://www.dbgi.org/dendron-dbgi/notes/inakqagsydtih7ls65eh3nb/\n\nhttps://www.sib.swiss/training/upcoming-training-courses\n\n\nhttps://www.irradiatedsoftware.com/sizeup/\n\n\n\n## Notes\n\n## Todo tomorrow\n\n###\n###\n###\n\n## Today I learned that\n\n- ","n":0.177}}},{"i":8,"$":{"0":{"v":"2022","n":1}}},{"i":9,"$":{"0":{"v":"11","n":1}}},{"i":10,"$":{"0":{"v":"2022-11-25","n":1},"1":{"v":"\n# This is PMA's daily notebook.\n\nToday is 2022.11.25\n\n## Todo today\n\n###\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n### Formation HPLC Friday 25 November 2022\n\n[[hplc]]\n\n\n\n## Todo tomorrow\n\n###\n###\n###\n\n## Today I learned that\n\n- ","n":0.196}}},{"i":11,"$":{"0":{"v":"08","n":1}}},{"i":12,"$":{"0":{"v":"2022-08-14","n":1},"1":{"v":"\n# This is PMA's daily notebook.\n\nToday is 2022.08.14\n\n## Todo today\n\n- [ ] \n- [ ] \n- [ ] \n\n## Doing \n\n- \n- \n- \n\n## Done\n\n-\n-\n-\n\n## Notes\n\n- This morning I am wanting to use a docker image which is supposed to run on localhost:8080\nHowver this one is allready used \nsee\n![](/assets/images/2022-08-14-08-02-02.png)\n\nI need to find which process is using this and stop it \n\n\nSolution one. Use findanyfile and search for \"It works!\" string \nNot working \n\nFound https://www.maketecheasier.com/setup-local-web-server-all-platforms/\n\ncd /Library/WebServer/Documents/\n\nSo sudo apachectl stop  should be OK now\n\nTrying to run Rhizomer https://rhizomer.rhizomik.net/about\n\n\nhttps://graph.metabomaps.com/repositories/ENPKG?query=PREFIX%20enpkg%3A%20%3Chttps%3A%2F%2Fwww.sinergiawolfender.org%2Fjlw%2F%3E%20PREFIX%20rdf%3A%20%3Chttp%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%3E%20%20SELECT%20%3Factive_extract%20WHERE%20%7B%20%3Factive_extract%20rdf%3Atype%20enpkg%3ALabExtract%20.%20%3Factive_extract%20enpkg%3Ahas_bioassay_results%20%3Fbiores%20.%20%3Factive_extract%20enpkg%3Ahas_bioassay_results%20%3Ftoxres%20.%20%3Fbiores%20rdf%3Atype%20enpkg%3ATcruzi_10ugml%20.%20%3Ftoxres%20rdf%3Atype%20enpkg%3AL6_10ugml%20.%20%3Fbiores%20enpkg%3Ainhibition_percentage%20%3Ftc_inhib%20.%20%3Ftoxres%20enpkg%3Ainhibition_percentage%20%3Fl6_inhib%20.%20FILTER((%3Ftc_inhib%20%3E%2080)%20%26%26%20(%3Fl6_inhib%20%3C%2050))%20%7D&queryLn=sparql\n\n\nhttps://dbgikg.commons-lab.org/repositories/DBGI-KG?query=PREFIX%20enpkg%3A%20%3Chttps%3A%2F%2Fenpkg.commons-lab.org%2Fkg%2F%3E%0Aselect%20%3Fdbgi_sample%20%3Fsubmitted_taxon%20where%20%7B%20%0A%09%3Fextract%20enpkg%3Ahas_lab_process%20%3Fdbgi_sample%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20enpkg%3Asubmitted_taxon%20%3Fsubmitted_taxon%20.%0A%7D%0A=sparql\n\nhttps://dbgikg.commons-lab.org/sparql?name=dbgi_plants&infer=true&sameAs=true&query=PREFIX%20enpkg%3A%20%3Chttps%3A%2F%2Fenpkg.commons-lab.org%2Fkg%2F%3E%0Aselect%20%3Fdbgi_sample%20%3Fsubmitted_taxon%20where%20%7B%20%0A%09%3Fextract%20enpkg%3Ahas_lab_process%20%3Fdbgi_sample%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20enpkg%3Asubmitted_taxon%20%3Fsubmitted_taxon%20.%0A%7D%0A\n\nhttps://dbgikg.commons-lab.org/repositories/DBGI-KG?query=PREFIX%20enpkg%3A%20%3Chttps%3A%2F%2Fenpkg.commons-lab.org%2Fkg%2F%3E%20select%20%3Fdbgi_sample%20%3Fsubmitted_taxon%20where%20%7B%20%20%09%3Fextract%20enpkg%3Ahas_lab_process%20%3Fdbgi_sample%20%3B%20%20%20%20%20%20%20%20%20%20%20%20%20%20enpkg%3Asubmitted_taxon%20%3Fsubmitted_taxon%20.%20%7D&queryLn=sparql\n\n\n\nhttps://graph.metabomaps.com/repositories\n\nhttps://graph.metabomaps.com/sparql\n\n\nMade a wikidata dump https://wdumps.toolforge.org/dumps?last=2569\n\n\n\n- \n- \n\n## Todo tomorrow\n\n- [ ] \n- [ ] \n- [ ] \n\n\n## Today I learned that \n\n- ","n":0.096}}},{"i":13,"$":{"0":{"v":"Open Notebook Commons","n":0.577}}},{"i":14,"$":{"0":{"v":"Srerat","n":1}}},{"i":15,"$":{"0":{"v":"2025","n":1}}},{"i":16,"$":{"0":{"v":"04","n":1}}},{"i":17,"$":{"0":{"v":"2025-04-11","n":1},"1":{"v":"\n\n# This is Simon's COMMONS Lab daily Open Notebook.\n\nToday is 2025.04.11\nAll the gymnosperms (except one) north of the system have been sampled.\nI believe I have more than 50 specimens collected by now. I will then reduce the sampling to only 1 day a week (friday) and use the others to prepare the samples for the lc-ms.\nNext step in the collection process:\n  - Check if there are any new flowering trees\n  - Start the arboretum\n\nDONT FORGET: NEEDLES NEED DISC BEADS.\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.096}}},{"i":18,"$":{"0":{"v":"2025-04-09","n":1},"1":{"v":"\n\n# This is Simon's COMMONS Lab daily Open Notebook.\n\nToday is 2025.04.09\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\nIMPORTANT NEWS:\nThe sample collected until now by me (tree stuff), and Jade and Héloïse (geophytes) are all mixed up in tube racks. That is problematic because its complicated to differenciate them even by using the database. They should be separated before entering the lc-ms to be placed in different libraries. My samples will go in a dedicated library (tree) where they could be compared. As Jade's one will go together. This will allow us to have a picture representing all of our work for the presentation.\nWether the separation can be done before creating the aliquots or later in the extraction process is unknown.\n=> I will have to ask Edouard\nThats a bit annoying for I already weighted some geophytes. \nMaybe I could ask Héloïse or Jade to weight some samples or prepare alicots (+-40 samples on their side?)\n\nNew QR codes must be installed in due place of the old \"specimen\" ones. The way it was made makes it easier to follow the progression of the sampling of the organs of a speciment or a species. Much more readable than my sign system.\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.067}}},{"i":19,"$":{"0":{"v":"03","n":1}}},{"i":20,"$":{"0":{"v":"2025-03-27","n":1},"1":{"v":"\n\n# This is Simon's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.27\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\nContinued with the collect. It took me 2 hours to almost completely sample 2 trees. By following this logic, I have around 138 hours (18 office days=>6 weeks if 3 days a week) of collect to fit in the semester.\nIt appears working late and during the week-end isn't an option anymore. \nIt is mandatory.\nSome python.\nSticking the legend of the signs on the nitrogen box might be a good way to avoid having a flying sheet in the collect bag.\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.092}}},{"i":21,"$":{"0":{"v":"2025-03-26","n":1},"1":{"v":"\n\n# This is Simon's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.26\n\n## Todo today\nContinuing with the research of a definition for \"tree\":\nSelon \"Le glossaire illustré pour la botanique de terrain\" de Kozlowski, un arbre est une \"Plante ligneuse possédant un tronc (ce qui sépare les racines du houppier) et une couronne (nécessite des branches), de grande taille (généralement plus de 7m lorsqu'il est âgé)\n\nUn arbrisseau est une \"Plante ligneuse sans tige principale (tronc), ramifié dès sa souche. Les bourgeons apparaissant à la base de la plante engendrent de nouvelles tiges tout au long de sa vie. Mesure souvent moins de 4m\"\n\nArbuste: \"Plante ligneuse possédant généralement un tron (contrairement à l'arbrisseau, qui est ramifié dès sa souche) et mesurant jusqu'à 7m de hauteur, à morphologie intermédiaire entre l'arbre et l'arbrisseau\nCf. tableau 33 du bouquin\n\nDie Wald- und Parkbäume Europas : ein Bestimmungsbuch für Dendrologen und Naturfreunde\nMitchell, Alan (créateur_trice)\nHamburg [etc.] : P. Parey\n[1975]; © 1975\n\"Ein Baum ist eine holzige, ausdauernde Pflanze, die wenigstens eine Höhe von etwa 6m erreicht; der Stamm kann sich schon sehr weit unten verzweigen, jedoch mus dies oberhalb des Bodens erfolgen. Soweit die Definition. In diesem Werk wurden Gattungen dann vollständig, d.h. mit allen wichtigen Arten, aufgenomzählt. So gehört der Weissdorn hierher, obwohl er hierzulande fast stet als niedriger, vielstämmiger Strauch zu sehen ist. Es gibt von ihm nämlich einige Arten, die über 10m hoch werden. Die Hasel stellt einen Grenzfall dar, während Holunder und Hartiriegl einwandfrei.\nDiese Definition trifft für einige Kultivare (Sorten) von Koniferen nicht zu. Wenn diese trotzdem aufgenommen wurden, so deshalb, weil sie Formen \"echter\" Bäume darstellen und aus diesem Grunde dazu gehören.\"\nIn english:\n\"A tree is a woody, perennial plant that reaches a height of at least about 6 metres; the trunk can branch very far down, but this must be above the ground. So much for the definition. In this work, genera were then listed in full, i.e. with all important species. Hawthorn, for example, belongs here, although in this country it is almost always seen as a low, multi-stemmed shrub. There are some species of hawthorn that grow to over 10 metres in height. The hazel is a borderline case, while the elderberry and the dogwood are perfect.\nThis definition does not apply to some cultivars (varieties) of conifers. If these are included anyway, it is because they are forms of ‘real’ trees and therefore belong here.\"\nTranslated with DeepL.com (free version)\n\nAs there are no universal description of what a tree is, I will propose a first definition for this bachelor work.\nA plant referred to as a tree is perennial, is lignified, has a trunk. Encompasses palms, cycadales, conifers, arbres standards, bonsais. But excludes banana trees, papaya trees, shrubs\n\nhttps://doi.org/10.1016/j.cub.2007.01.041:\nIt is quite philosophical as there is a general idea of what a tree is, but no clear botanical description. We could say that \"tree\" refers to the classical oak style plant. But tree-like growth forms appeared more than once in the evolution of land plants (lepidodendron, ferns, sphenopsides calamites, seed plants), different emergences in monocotyledons (dragon trees, palms)\n\nDefinitions of 'tree' and 'shrub'\nSeptember 2015\nDOI:10.13140/RG.2.1.4103.9848:\nAu moins 249 définitions différentes du mot \"arbre\" et 23 de \"buisson\"\nVarie selon le domaine, l'Etat, la loi\nEléments qui reviennent: plante pérenne, tige(s) avec ramification au bout, ligneux, grande taille\n\nSéparation arbre/buisson semble pour le moins arbitraire\n\nArbre vient du latin \"arbor\" (https://www.littre.org/definition/arbre) et qui veut dire \"arbre\" (https://en.wiktionary.org/wiki/arbor)\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\nI forgot to do yesterday's log. So here it is.\nThe sampling of trees finally started (yay!).\nIt is regular sampling, but an additionnal picture of the specimen QR-code must be taken and added to the comment section of the second \"onglet\" (maybe ecological metadata?).\nI made a sign code (![alt text](IMG_6220.JPG)) to determine which organs have already been collected and what's left to sample. A will post a picture of it if I remember to.\nHowever, the category bark, and maybe branch are missing. Maybe the branch category is redundant, as a branch is a secondary stem. We will see.\nI should ask Edouard to add them if possible.\n\n## Paused\n\n## Done\n\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n[]Ask Edouard to add the categories \"bark\", and \"branch\" to the sample type.\n[] Demander à Kozlowski ce qu'il pense ce qu'est un arbre\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.038}}},{"i":22,"$":{"0":{"v":"2025-03-25","n":1},"1":{"v":"\n\n# This is Simon's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.26\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.158}}},{"i":23,"$":{"0":{"v":"2025-03-21","n":1},"1":{"v":"\n\n# This is Simon's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.21\n\n## Todo today\nWriting the methodology for the sampling\nAs I don't know how to create new files in my bachelor work's dendron.\nI will start writing the methodology here and paste it in the dendron later.\nOf course, it will be heavily inspired by what Héloïse and Edouard already did\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\nMy methotodology for the tree extractions so far:\nMy project will focus on the extraction of tree metaboloms and the continuation, and hopefully the end, of the DBGI project in Fribourg. Unlike,the majority of plants already sampled, trees are perennial and tend to present harder parts (bark, trunk, ...). This presents a first challenge for the already tested DBGI method. As of now, the method defines each sample as being its own unit. In the case of trees, this simplification is somewhat limiting as the different organs (which might be quite numerous) can't all be linked to a single individual through the already established informatical system.\nThe hardness of the tissues could also cause a problem by not breaking properly with the metal beads. However, this issue might be overcome by the use of disc shaped beads that should slice right through.\n\nAll the (remaining) trees in the botanical garden need to be sampled for this bachelor's work. They are scattered all over the garden, with a greater concentration in the arboretum, and near the fences as hedges. They tend to come from all over the world with local species (Picea abies) aswell as tropical ones (Persea americana). \nHow are they placed in the garden ? Taxonomic/usefulness reasons? Remains of the old organisation of the garden ?\n\n- Sampling\n\n  The classical DBGI methodology was mostly applied to collect the different organs. The main difference being the use of ladders, and telescopic cutting tools.\n  For each sample, the geographical position of the specimen will be marked down on a QField map. Additional data, such as photos:\n  1) the identification panel\n  2) the identification panel with the number of the sample\n  3)  photo of the whole specimen\n  4) a detailled photo of the leaves/flowers/seeds/fruits, \n  5) the sampled zone \n  6) Additional photo, if judged necessary\n  will be taken.\n\n  The photos, and the location will then be imported on iNaturalist for receving further confirmation of the species. This, in term, should allow the identification of sampled species in the wild without having to take an expert in the field\n  A branch will be cutted down. From the fallen branch, leaves/needles, bark, twigs, flowers, fruits will be collected. => this will need to be rewritten after the first samplings.\n  After the cut, the organ is wrapped in a brown coffee filter, and shoved in a falcon tube closed with a perforated cap. Each tube is pre-labeled with a unique QR-code that will allow to identify and track the sample through the extraction process and the storage.\n  The tube are then dunked in liquid nitrogen. They will finally be put to rest in the freezer (-80C), if they can't be freeze-dryed immediately. The freeze-drying process needs to be at least 72 hours long to make sure the samples is absolutely dry. \n  Directly after the freeze-drying process, all the perforated caps need to be switched out with standard, desinfected, non-perforated caps. The falcon tubes are then stored in a labeled rack. They need to be scanned to allow the system to track them.\n \n\n- Extraction \n\n  The first step of the extraction process is weighing out 50 milligrams (!!0.0500 g sur la machine!!) of each sample. An error of 5% (+-2,5mg) was accepted. The matter is weigthed in a 2 ml Eppendorf with a rounded bottom. Depending on the weight, metal beads are added. Less than 20mg =1; between 20mg-50mg = 2beads, around 50mg= 3 beads(this may change with the new discoid beads).\n  => shape of beads depends on type of sample.\n\n  The samples go in the MM400 Retsch machine for 2.5 minutes at 25Hz. Then, 1,5ml(why not the same as Héloïse and Edouard's protocol ?) of the classic DBGI extraction solution. It is a mix of 80% methanol, 20% distilled water, and 0,1% formic acid. The newly rehydrated samples go back in the Retsch machine with the same settings.\n  The tubes are then taking a turn in a centrifugation machine for 2 minutes at 13'000 RPM to separate the supernatant from the plant deposit.\n  Finally, as much of the supernatant (usually 1,4 ml) is collected and pipetted in a glass vial with a hermetically sealed cap (the red ones).\n  The vial need to be labelled and associated to a container ensuring the tracking of the sample from the garden to the MS.\n  This final step needs to be performed under a bench.\n  The vials container is then stored in the freezer (-80C), and is ready for MS and further analysis.\n\n- Analysis ?\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n[] Start the collect of differents tree organs (bark if possible, leaves, seeds, flowers/reproductive organs, buds, twigs/small branches)\n[]Continue with sample preparation\n[] Download Zotero ?\n[] Check the list of plants, and trees of the garden\n[] Find a way to automatically copy/paste what is in the to do list of the previous entry into the newest log\n[] When grinding woody parts for the first time, check if they need to rest a longer time in the extraction solution (cells not well enough broken). Or if the extraction process can follow up directly.\n[] Check the list of trees on the BGUNIFR Botalista\n[] Need to book the freeze-dryer for friday 28\n[] Notify Edouard that I might have fucked up on the units announced in the vial app\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.032}}},{"i":24,"$":{"0":{"v":"2025-03-20","n":1},"1":{"v":"\n\n# This is Simon's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.20\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n- Researching what is a tree:\n  Wikipedia says that there are no precise definition, botanically or in common language, of what a tree is. It is a plant with a trunk and a certain height (if its too small, it is refered as a shrub or \"arbuste\"). The trunk can be lignified, but is not always the case (banana, papaya). It doesn't refer to a monophyletic group as angiosperms, gymnosperms, and even some ferns do grow a trunk. Perennial\n\n  https://knowablemagazine.org/content/article/living-world/2018/what-makes-tree-tree:\n  This news article claims it is the absence of programmed senescence that makes a tree, even more than its woodiness\n\n  https://web.archive.org/web/20140420004648/http://www.as.miami.edu/qr/arboretum/what_is_a_tree.html:\n  No unversally agreed botanical definition\n  Multiple trunks equaly developed \n  Trunk not necessarly made of wood\n\n  Wilson, Philip. (2014). The meaning of 'tree'. The Arb Magazine: Newsletter of the Arboricultural Association. 166. 32-33. :\n  A tree is: ‘A perennial woody plant growing to a considerable height and size, with a self-supporting main stem and usually developing branches at some distance from the ground’\n  Idea of size, species (woody perennial), and form (main stem + usually branches at some distance of the ground), a \"ideal tree\" would tick all thoses boxes, but some individuals only tick two (bonsai, palms, ...)\n\n  https://wikibotanica.net/glossary:\n  (a woody plant at least 5 metres high, with a main axis the lower part of which is usually unbranched)   \n\n  https://en.wikipedia.org/wiki/Glossary_of_botanical_terms:\n  A woody plant, usually with a single distinct trunk and generally more than 2–3 metres (6.6–9.8 ft) tall.\n\n\n\n## Paused\n\n## Done\nLearned more details about the DBGI project\n\n## Notes\nMy bachelor work will be about trees. Approximately 140 trees and their different organs (leaves, bark, seeds, flowers, fruits, twigs, and buds) will have to be sampled.\nThis will multiply the number of total samples by a factor of 3-4 depending on how I feel it, and the availability of the organ.\n\n## Todo tomorrow, one day ... or never \n[x]Ask the seretaries for an access key to the building and the garden\n[x] Take a stroll in the garden to see where a QR code could be attached to a specimen (use big plastified sheets, a string, roll that string around the nails in the trees)\n[x] => Ask Alain if it is okay. He will call me back on monday\n[] Start the collect of differents tree organs (bark if possible, leaves, seeds, flowers/reproductive organs, buds, twigs/small branches)\n[]Continue with sample preparation\n[] Download Zotero ?\n[] Check what BotaLista and BotaVista is\n[] Check the list of plants, and trees of the garden\n\n\n\n###\n###\n\n\n## Today I learned that\n  It is not trivial to describe what a tree is\n\n- ","n":0.047}}},{"i":25,"$":{"0":{"v":"2025-03-19","n":1},"1":{"v":"\n\n# This is Simon's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.19\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\nSome reading about bark extraction\nThis article seems nice: https://pmc.ncbi.nlm.nih.gov/articles/PMC5905184/ 10.1186/s13020-018-0177-x\n- What kind of method do we use to extract ?  liquid chromatography-mass spectrometry, is it talked about in the document ? Not sure. Is it simply maceration or sublimation ? \n- Maybe the method of extraction is sublimation/maceration, and the LC is the method of separation. If this is the case, another article should be found, for this one doesn't include sublimation.\n\nhttps://www.researchgate.net/publication/232089322_Isolation_identification_and_purification_of_cinnamaldehyde_from_Cinnamomum_zeylanicum_bark_oil_An_antibacterial_study\n- Extraction of a very specific bark component in the tree Cinnamomum zelyanicum\n- Use of steam distillation in a Clevenger-type apparatus for 8h to extract the essential oils. Maybe this is a method proper to essential oils extraction, but unfit for all bark components ? Would it be mass-spec friendly ?\n\nRichard, B., Bénard, A., Dumarçay, S. et al. Wood, knots and bark extractives for oak, beech and Douglas fir: a dataset based on a review of the scientific literature. Annals of Forest Science 81, 9 (2024). https://doi.org/10.1186/s13595-024-01223-0\n- Have a very similar project of mapping the metabolome of a few species (Quercus robur L., Quercus petraea Liebl., Fagus sylvatica L. and Pseudotsuga menziesii ) in France, and in the whole organism.\n- Wood_db-chemistry database, EXTRAFOR_EST scientific project\n- Database is available\n- Used 12 different extraction techniques, are note described in the paper cuz it is a metaanalysis\n- Many links to papers and their method of extraction (https://entrepot.recherche.data.gouv.fr/dataset.xhtml?persistentId=doi:10.57745/QZYPUA) => need to take a look later \n\nhttps://www.researchgate.net/publication/230771042_Handbook_Of_Wood_Chemistry_And_Wood_Composites. https://doi.org/10.1201/b12487\n- Introduction book on wood/bark chemistry, and their extractives\n- chemical constituents of bark can be classified into four major groups: polysaccharides (cellulose, hemicellulose, and pectic materials); lignin and polyphenols; hydroxy acid complexes (suberin); and extractives (fats, oils, phytosterols, resin acids, waxes, tannins, terpenes, phlobaphenes, and flavonoids). \n- The analysis methods developed for wood cannot be used for bark directly. - There are many compounds in bark that are not found in wood that interfere with these analysis methods. Because of the interference of the extractives in polysaccharide and lignin analysis, procedures for elucidation of the chemical composition of bark begin with an extraction protocol that consists \nof sequential extraction solvents of increasing polarity. A common protocol begins with a diethyl ether extraction step that yields waxes, fatty acids, fats, resin acids, phytosterols, and terpenes. This is followed by an ethyl alcohol extraction step that yields condensed tannins, flavonoids, and phenolics. The third step uses hot water, and yields condensed tannins and water-soluble carbohydrates. To release phenolic acids, hemicelluloses, and suberin monomers from the residue from the third step, 1% aqueous sodium hydroxide is used (Holloway and Deas 1973, Kolattukudy 1984). The extract fractions from the above-mentioned steps are then subjected to further workup to separate each into easy-to-analyze mixtures of compounds. For example, partitioning the diethyl ether fraction against aqueous sodium bicarbonate separates the fatty acids and resin acids from the neutral components, tannins, terpenes, and flavonoids. The neutral fraction is then \nsaponified to give the alcohols and salts of fatty acids, dicarboxylic, hydroxy-fatty, and ferulic acids. Ethanol extraction followed by hot water extraction of the insoluble ether fraction yields soluble simple sugars and condensed tannins. Sodium hydroxide extraction of the insoluble residue gives soluble suberin monomers, phenolic acids, and hemicelluloses. Sulfuric acid treatment of the insoluble fraction yields lignin (Chang and Mitchell 1955, Hemingway 1981, Laks 1991).\n- Why no use of MS ? Is it a very recent tech ?\n- Procedure for extraction varies between labs. No comparison between data is thus possible.\n\nTanase C, Coșarcă S, Muntean D-L. A Critical Review of Phenolic Compounds Extracted from the Bark of Woody Vascular Plants and Their Potential Biological Activity. Molecules. 2019; 24(6):1182. https://doi.org/10.3390/molecules24061182\n- Extraction of phenolic compounds only\n- Description of many different methods (ultrasounds, microwaves, ...) with their pros and cons\n\nZidorn, C. Seasonal variation of natural products in European trees. Phytochem Rev 17, 923–935 (2018). https://doi.org/10.1007/s11101-018-9570-4\n- Interesting in the case of variability of the metabolome through the year\n- Big bias towards study of leaves and phenolics. Other compounds are understudied.\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \nTake a look at many wood extraction methods (https://entrepot.recherche.data.gouv.fr/dataset.xhtml?persistentId=doi:10.57745/QZYPUA) \n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.038}}},{"i":26,"$":{"0":{"v":"2025-03-13","n":1},"1":{"v":"\n\n# This is Simon's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.13\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\nLearned the step following the weighting: extraction\nDon't be fooled, it's not the MS's part yet.\n\nA peculiar solution must be prepared in order to proceed. It is composed of 80% methanol (99,8%), 20% distilled water, and 0,1% formic acid. All the components can be found in the orange safe closet, in the machine room.\nEloïse recommended to prepare a total volume of 200ml for easier calculation=> 160ml methanol, 40ml water, 0.2ml formic acid. Thats smart.\nIt is not always necessary to prepare such solution. If some is left, it is still possible to use it.\nFor each new solution, a blank must be prepared. It should allow to detect the molecular noise present in the tubes and vials\n\nNext step is the shaker room.\nHere, the plants in the tubes will be pulverised by the super-shaker. Be sure to screw the screws all the way.\nBeat the shit out of the shaked tubes to make the dust fall off the inner portion of the lid.\nAfter the beating, go in the \"chapelle\" add 1,5ml of the peculiar solution in the individual tubes. Be wary not the touch the tube with the pump to avoid contaminations.\nAfter being filled with the liquid, the tubes must go back for another shaking.\n\nThey must now go for a 2 minutes/13'000 rounds in the centrifuge.\n\nNow, prepare the small glass vials, a square container, take the tablet and the printer and go to a chapelle. \nThere, transfer the liquid part of the tubes in the glass vials. Avoid taking any solid parts.\nDO NOT FORGET TO PRINT THE LABELS !\nThe square containers must be left in the super freezer downstairs at the end of the day. It is possible the software will indicate that the container aint full even though it is. Its because the blanks can't be registered for now.\n\nNow the samples should be finally ready for MS (hurray)\n\n## Notes\n\n## Todo tomorrow, one day ... or never \nNotify someone that i might have fucked up concerning the volume of solution in the small glass vials (1,5ml instead of 150ml). Before starting pipeting the solution in the vials, it is necessary to indicate the volume, type of vial, container, ...\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.051}}},{"i":27,"$":{"0":{"v":"2025-03-10","n":1},"1":{"v":"\n\n# This is Simon's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.10\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\nLearned the processing step following the use of the lyophilisator:\n- Take the rack of falcon tubes, the bottle of small metal bolls, tweezers, gloves in the lab next to the balance.\n- Scan the falcon tube of the sample with the tablet\n- Put +-500 micrograms of a semple in the very small tube. Confirm the weight on the tablet. It should print out an etiquette\n- Add 3 metal balls in the tube. Be wary of not contaminating the tweezers by touching the tube\n- Close the tube. Stick the etiquette onto it. \n- Disinfect the gloves, and the tweezers\n- Rinse and repeat\nBe weary of cross-contaminations\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.084}}},{"i":28,"$":{"0":{"v":"2025-03-06","n":1},"1":{"v":"\n\n# This is Simon's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.06\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\nCut my thummb open while sampling a stupid date palm.\nAlmost all plants in the orangerie have been sampled.\nOnly the last row, and the a few pots in the middle of the first row are still left.\nMixed up an empty tube with a full one => should pay a pint to Jade for cleaning up\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.104}}},{"i":29,"$":{"0":{"v":"2025-03-05","n":1},"1":{"v":"\n\n# This is Simon's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.05\nFirst day doing some sampling for the project.\n\nLearned how to sample:\n -  Geolocalise the position of the sample through the QField app.\n - Take pictures of the whole plant, typical organs/allowing hints for identification, the panel, the panel and the serial number of the falcon tube.\n - Do the cutting\n - Put the plant matter in a filter, shove the package in the tube, get the tube in liquid nitrogen\n - Repeat for a different organ (leaves, stem, flower, fruit, whole plant) on the same species, or change species\n\nWhen done with the sampling, go to the big freezer. Take the tubes out of the nitrogen, and put them in a plastic bag (20 per bag).\n\nAs of now, we should ask Stefanie Ranf for permission to use the lyophylisation machine. Ironically, the  machine needs to be warmed up before use. It needs up to 3 days to do its work.\n\nThe sampling of the plants in the orangerie is still in progress. However, something like 1/3 of the plants have been sampled already. The first eastern rows are completed.\n\n\n## Todo today\n\n# trite\n## sous-titre\n\n### sous-sous-titre\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n[X] Sampling the orangerie\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.067}}},{"i":30,"$":{"0":{"v":"02","n":1}}},{"i":31,"$":{"0":{"v":"2025-02-10","n":1},"1":{"v":"\n\n# This is Simon's COMMONS Lab daily Open Notebook.\n\nToday is 2025.02.10\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\nMy first dendron note\n\n## Paused\n\n## Done\n\n\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\nHave a look at https://www.dendron.so\n\n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.146}}},{"i":32,"$":{"0":{"v":"Templates","n":1}}},{"i":33,"$":{"0":{"v":"Open Notebook","n":0.707}}},{"i":34,"$":{"0":{"v":"Commons","n":1}}},{"i":35,"$":{"0":{"v":"Vgrosso","n":1},"1":{"v":"\n\n# This is Vincenzo's COMMONS Lab daily Open Notebook.\n\nToday is {{ CURRENT_YEAR }}.{{ CURRENT_MONTH }}.{{ CURRENT_DAY }}\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.147}}},{"i":36,"$":{"0":{"v":"Srerat","n":1},"1":{"v":"\n\n# This is Simon's COMMONS Lab daily Open Notebook.\n\nToday is {{ CURRENT_YEAR }}.{{ CURRENT_MONTH }}.{{ CURRENT_DAY }}\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.147}}},{"i":37,"$":{"0":{"v":"Sguetchueng","n":1},"1":{"v":"# This is Stephanie's daily open-notebook.\n\nToday is {{ CURRENT_YEAR }}.{{ CURRENT_MONTH }}.{{ CURRENT_DAY }}\n\n## Todo today\n\n### Have a look at the DBGI discussion forum\n    - https://github.com/orgs/digital-botanical-gardens-initiative/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.167}}},{"i":38,"$":{"0":{"v":"Rouchene","n":1},"1":{"v":"\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is {{ CURRENT_YEAR }}.{{ CURRENT_MONTH }}.{{ CURRENT_DAY }}\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.137}}},{"i":39,"$":{"0":{"v":"Pmallard","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is {{ CURRENT_YEAR }}.{{ CURRENT_MONTH }}.{{ CURRENT_DAY }}\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.13}}},{"i":40,"$":{"0":{"v":"Pamrein","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.218}}},{"i":41,"$":{"0":{"v":"Open Notebook Mvisan","n":0.577},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is {{ CURRENT_YEAR }}.{{ CURRENT_MONTH }}.{{ CURRENT_DAY }}\n\n\n## Notes\n\n## Todo today\n* \n\n## Doing\n\n\n## Done\n* \n\n\n## Todo tomorrow\n ","n":0.209}}},{"i":42,"$":{"0":{"v":"Jdandois","n":1},"1":{"v":"\n# This is Jade's COMMONS Lab daily Open Notebook.\n\nToday is {{ CURRENT_YEAR }}.{{ CURRENT_MONTH }}.{{ CURRENT_DAY }}\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n## Today I learned that\n\n- ","n":0.147}}},{"i":43,"$":{"0":{"v":"Shared","n":1}}},{"i":44,"$":{"0":{"v":"Laure Weisskopf","n":0.707}}},{"i":45,"$":{"0":{"v":"Np_determination","n":1},"1":{"v":"\nPasted from [[project.commons-private.laure-weisskopf.np_determination]] for sharing purposes.\nTime stamp screenshot \n\n![](/assets/images/2024-03-18-09-24-02.png)\n\n----\n\n\nEliane indicated that they are working n the structural determnination of a potentially novel NP form Streptomyces coelicolor.\n\n> Salut Pierre-Marie\n> \n> Les analyses Masses sont sur le serveur : V:\\Biol\\_Vegetale\\Eliane\n> \n> Le nom de la bactérie la plus proche est\n> \n> Streptomyces coelicolor\n> \n> J’espère que ce n’est pas des sphyngolipids\n> \n> Merci pour ton aide\n> Eliane\n> \n\n> MW 812\n> C42H68O15\n> MW 826\n> C43H70O15\n> \n> Ce que je peux voir tres claire par la RMN c’est\n> \n> • Proton : 70\n> • Carbon : 43 ou 42 (1 CO, 1COO, 3 quaternary, 20 CH, 5 CH2, 11 CH3)\n> • Oxygen : 10 (including 1 CO, 2 for ester COO)\n\nekg\nWe try to launch a SPARQL query https://w.wiki/3$J7\n\nHowever it returns a timeout error.\n\nThis ones looks better https://w.wiki/3$Jy\n\nhttp://www.wikidata.org/entity/Q105280358\nhttp://www.wikidata.org/entity/Q105168596\nhttp://www.wikidata.org/entity/Q105168602\n\n wd:Q105280358\tavermectin\tC₄₄H₆₆O₁₄\t\t wd:Q2355919\tStreptomyces coelicolor\n\n\n C43H64O14\n\nCould be a derivative of avermectin\nLets try a proton NMR prediction\n\nO=C1OC2CC(OC3(OCC(C)CC3)C2)CC=C(C)C(OC4OC(C)C(OC5OC(C)C(O)C(OC)C5)C(OC)C4)C(C=CC=C6COC7C(O)C(=CC1C67O)C)C\n\n```smiles\nO=C1OC2CC(OC3(OCC(C)CC3)C2)CC=C(C)C(OC4OC(C)C(OC5OC(C)C(O)C(OC)C5)C(OC)C4)C(C=CC=C6COC7C(O)C(=CC1C67O)C)C\n```\n\n![](/assets/images/2021-09-03-11-44-58.png)\n\n\n![](/assets/images/2021-09-03-12-11-06.png)\n\n\n![](/assets/images/2021-09-03-12-17-48.png)\n\nAccording to the MS I would head more for a molecular ion at 805\n\nC45H72O12\nOlygomycin simulation \n\n41-demethylhomooligomycin B\n\n```smiles\nCC[C@@H](CC[C@H]([C@H](C)[C@@H]([C@H]1C)OC(/C=C/[C@@H](C)[C@@H]([C@@H](C)C([C@@H](C)[C@@H]([C@@H](C)C([C@@]2(C)O)=O)O)=O)O)=O)O[C@]11O[C@H](C[C@H](C)O)[C@H](C)CC1=O)/C=C/C=C/C[C@H](C)[C@H]2O\n```\n\n\n![](/assets/images/2021-09-03-12-20-30.png)","n":0.079}}},{"i":46,"$":{"0":{"v":"Reproducibility","n":1}}},{"i":47,"$":{"0":{"v":"Templates","n":1}}},{"i":48,"$":{"0":{"v":"Cookie Cutter","n":0.707},"1":{"v":"\nTired of having non consistent folder for MAPP Metabolomics reports.\nLooking into cookie cutter (for data science) as a possible template to start with and have more consistency across these repos.\n\n\nhttps://towardsdatascience.com/automate-the-structure-of-your-data-science-projects-with-cookiecutter-937b244114d8\n\nUsing the github template is allready a good start maybe https://levelup.gitconnected.com/quick-setup-of-data-science-github-repositories-647b111b3c5f\n\nHaving a look at https://www.youtube.com/watch?v=HM56wCNxCnQ\n\nStop at 1:04:00 and workinh here /Users/pma/Dropbox/git_repos/mapp-metabolomics-unit/cookie_cut_project\n\n\nhttps://cruft.github.io/cruft/\n\ncruft create https://github.com/mapp-metabolomics-unit/mapp-repo-cookiecutter.git --overwrite-if-existscruft create https://github.com/mapp-metabolomics-unit/mapp-repo-cookiecutter.git --overwrite-if-exists\n\nYou can check a project \n\ncruft check\n\n","n":0.127}}},{"i":49,"$":{"0":{"v":"Open Notebook","n":0.707}}},{"i":50,"$":{"0":{"v":"Mapp","n":1}}},{"i":51,"$":{"0":{"v":"Pmallard","n":1}}},{"i":52,"$":{"0":{"v":"2025","n":1}}},{"i":53,"$":{"0":{"v":"02","n":1}}},{"i":54,"$":{"0":{"v":"2025-02-27","n":1},"1":{"v":"\n\n# This is PMA's MAPP Metabolomics daily Open Notebook.\n\nToday is 2025.02.27\n\n## Todo today\n\n### Have a look at the MAPP Metabolomics discussion forum\n    - https://github.com/orgs/mapp-metabolomics-unit/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n\nhttps://www.postgresql.org/docs/current/ddl-constraints.html#DDL-CONSTRAINTS-CHECK-CONSTRAINTS\n\n\n\n\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n-","n":0.171}}},{"i":55,"$":{"0":{"v":"Commons","n":1}}},{"i":56,"$":{"0":{"v":"Vgrosso","n":1}}},{"i":57,"$":{"0":{"v":"2025","n":1}}},{"i":58,"$":{"0":{"v":"11","n":1}}},{"i":59,"$":{"0":{"v":"2025-11-04","n":1},"1":{"v":"\n\n\n# This is Vincenzo's COMMONS Lab daily Open Notebook.\n\nToday is 2025.11.04\n\n## Todo today\nSPE with honey samples \n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n\n## Doing\nPage 15 from 2 lab notebook\n## Paused\nVials altemis transition + Waiting from Mr.Woodford for the cryoracks\n## Done\nHoney samples preparation + SPE protocol \n## Notes\nThe cartridge should never be dry during the preparation with MeOH + MeOH/H20 1:1 + H2O + Samples\n## Todo tomorrow, one day ... or never \nLaunch the MS of the samples in vials\n###\n###\n\n\n## Today I learned that\nHow to do a SPE with C18 cartridge\n- ","n":0.103}}},{"i":60,"$":{"0":{"v":"10","n":1}}},{"i":61,"$":{"0":{"v":"2025-10-27","n":1},"1":{"v":"\n\n\n# This is Vincenzo's COMMONS Lab daily Open Notebook.\n\nToday is 2025.10.27\n\n## Todo today\nPreparation of sample for MS \n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n\n## Doing\nSample preparation\n## Paused\nAltemis transition\n## Done\n27 samples from yeast for the analysis of AA \nPage 13 of the second lab notebook\nContact with Mr Woodfoord for cryo racks\n## Notes\n\n## Todo tomorrow, one day ... or never \nAnother sample preparation \n###\n###\n\n\n## Today I learned that\nAll the process from the sample to the MS \nLabelling vials and preparing mixtures for MS\nThe MS is complex to launch, but it's very interesting\n- ","n":0.103}}},{"i":62,"$":{"0":{"v":"2025-10-03","n":1},"1":{"v":"\n\n\n# This is Vincenzo's COMMONS Lab daily Open Notebook.\n\nToday is 2025.10.03\n\n## Todo today\nStart of the pairing\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n\n## Doing\nTransition to SBS matrix tubes with direct pairing\n## Paused\n\n## Done\n2 new box paired\nContact with Mr Mulic, awaiting his reply \n## Notes\nTotal of 7 box paired\n## Todo tomorrow, one day ... or never \nCheck of the code for the pairing of new SBS tubes\nContinuation of the transition on Monday (03.10)\n###\n###\n\n\n## Today I learned that\nwhen everything works perfectly, it is very satisfying \n\n- ","n":0.107}}},{"i":63,"$":{"0":{"v":"09","n":1}}},{"i":64,"$":{"0":{"v":"2025-09-29","n":1},"1":{"v":"\n\n# This is Vincenzo's COMMONS Lab daily Open Notebook.\n\nToday is 2025.09.29\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n\n## Doing\nAltemis transition\n## Paused\n\n## Done\n4 racks completed\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.152}}},{"i":65,"$":{"0":{"v":"2025-09-22","n":1},"1":{"v":"\n\n# This is Vincenzo's COMMONS Lab daily Open Notebook.\n\nToday is 2025.09.22\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n\n## Doing\n\n- overview of the Dendron note taking ecosystem\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.146}}},{"i":66,"$":{"0":{"v":"Sguetchueng","n":1}}},{"i":67,"$":{"0":{"v":"2023","n":1}}},{"i":68,"$":{"0":{"v":"03","n":1}}},{"i":69,"$":{"0":{"v":"2023-03-20","n":1},"1":{"v":"\n# This is Stephanie's daily open-notebook.\n\nToday is 2023.03.20\n\n## Todo today\n\n### Have a look at the DBGI discussion forum\n    - https://github.com/orgs/digital-botanical-gardens-initiative/discussions\n###\n###\nsample code\n\nblank STG03\nQC anacardia\nQC Pseudos\nQC KLA\nSTG-01-01C\nSTG-01-02C\nSTG-01-03C\nSTG-01-04C\nSTG-01-05C\nSTG-01-06C\nSTG-01-07C\nSTG-01-08C\nSTG-01-09C\nSTG-01-10C\nSTG-01-11C\nSTG-01-12C\nSTG-01-13C\nSTG-01-14C\nSTG-01-15C\nSTG-01-16C\nSTG-01-17C\nSTG-01-18C\nSTG-01-19C\nSTG-01-20C\nSTG-01-21C\nSTG-01-22C\nSTG-01-23C\nSTG-01-24C\nSTG-01-13A\nSTG-01-14A\nSTG-01-15A\nSTG-01-16A\nSTG-01-13B\nSTG-01-14B\nSTG-01-15B\nSTG-01-16B\nSTG-01-025\nSTG-01-026\nSTG-01-027\nSTG-01-028\nSTG-01-029\nSTG-01-030\nSTG-01-031\nSTG-01-032\nSTG-01-033\nSTG-01-034\nSTG-01-035\nSTG-01-036\nSTG-01-037\n\n\n## Doing\n\n## Paused\n\n## Done\n* on 17/03/2023 I orked with Eliane on the Agilent 1260 HC-DAD to develop a method to analyse the anacardiaceae samples. we took as a basis a method I previously used to analyse the leaves extracts of P. microcarpa. After several attempts we adopted the method below which gave rise to a better separation\n-T= 0 min 30% B 70% A\n-T= 1 min 30% B 70% A\n-T= 25 min 60 % B 40% A\n-T= 28 min 100% B 0% A\n-T= 33 Min 100% B 0% A\n-T= 38 min 30% B 70 % A for a Total run time 45 min\nwhere B is methanol containg 0.1 % TFA and A is water containing 0.1 % TFA. injection volume 10 Ul flow rate 0.2 mL/min DAD dectector at 360nm, 275 nm, 245 nm and 307 nm.\n\nI have prepare the injection list for the batch odf sample to be analysed.\n\n\n## Notes\nWe used the method above to analyse pseudopondias samples 11 samples + seven *pure* compounds previously isolated from the leaves of Pseudospondias.\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.071}}},{"i":70,"$":{"0":{"v":"2023-03-03","n":1},"1":{"v":"\n# This is Stephanie's daily open-notebook.\n\nToday is 2023.03.03\n\n## Todo today\n\n### Have a look at the DBGI discussion forum\n    - https://github.com/orgs/digital-botanical-gardens-initiative/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\nremoved samples from the freeze dyer\nsample dbgi_1105 need to be redry. the cap used on tube was not appropiate for the freeze dyer.\ncncentrate Methanol samples of batch 1\n## Notes\n\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.132}}},{"i":71,"$":{"0":{"v":"02","n":1}}},{"i":72,"$":{"0":{"v":"02","n":1}}},{"i":73,"$":{"0":{"v":"2023-02-28","n":1},"1":{"v":"# This is Stephanie's daily open-notebook.\n\nToday is 2023.02.28\n\n## Todo today\n\n### Have a look at the DBGI discussion forum\n    - https://github.com/orgs/digital-botanical-gardens-initiative/discussions\n###\n###\n\n## Doing\n\nTesting the git upload\n\n## Paused\n\n## Done\n-check why I can commit on github\n-make a little plan of what I would like to do\n-work with Pierre-Marie to fix the issue on git hub\n-work with Edouard on inaturalist\n-sample extraction first batch 12 samples\n## Notes\ni have to run visualcode as administrator\nthere is a possibility to write notes even after the date\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.11}}},{"i":74,"$":{"0":{"v":"2023-02-27","n":1},"1":{"v":"\n# This is Stephanie's daily open-notebook.\n\nToday is 2023.02.27\n\n## Todo today\ndry samples collected\n### Have a look at the DBGI discussion forum\n    - https://github.com/orgs/digital-botanical-gardens-initiative/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\ni was not ble to kook the freeze dryer by myself. However I discussed with Edouard and we will do it together on wednesday.\nI have collected a total of 32 samples from the garden including 18 Acer species, 4 Citrus and 2 Ruta\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.116}}},{"i":75,"$":{"0":{"v":"2023-02-23","n":1},"1":{"v":"\n# This is Stephanie's daily open-notebook.\n\nToday is 2023.02.23\n\n## Todo today\n\n### Have a look at the DBGI discussion forum\n    - https://github.com/orgs/digital-botanical-gardens-initiative/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.183}}},{"i":76,"$":{"0":{"v":"20","n":1}}},{"i":77,"$":{"0":{"v":"2023-02-15","n":1},"1":{"v":"\n# This is Stephanie's daily open-notebook.\n\nToday is 2023.02.15\n\n## Todo today\n\n### Have a look at the DBGI discussion forum\n    - https://github.com/orgs/digital-botanical-gardens-initiative/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.183}}},{"i":78,"$":{"0":{"v":"2023-02-07","n":1},"1":{"v":"# This is Stephanie's daily open-notebook.\n\nToday is 2023.02.07\n\n## Todo today\nfresh plant material collection and processing, 4 species from Anacardiaceae\ndocumentation on GNPS\nread two papers\nwork on the malaria project\n### Have a look at the DBGI discussion forum\n    - https://github.com/orgs/digital-botanical-gardens-initiative/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.146}}},{"i":79,"$":{"0":{"v":"2023-02-06","n":1},"1":{"v":"# This is Stephanie's daily open-notebook.\n\nToday is 2023.02.06\n\n## Todo today\nextraction  of plant sample using DBGI extraction Protocol \ncheck the metabolite profile of selected anacardiaceae\ndendron Tuto\n### Have a look at the DBGI discussion forum\n    - https://github.com/orgs/digital-botanical-gardens-initiative/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\nextraction of plant sample with the help of Edouard\ndendron, VScodium  tutorials with pierre Marie\n## Notes\n\n- \n## Todo tomorrow\nPlant collection from the botanical garden and the processing prior to extraction\nworking on the malaria project\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.116}}},{"i":80,"$":{"0":{"v":"Rouchene","n":1}}},{"i":81,"$":{"0":{"v":"2025","n":1}}},{"i":82,"$":{"0":{"v":"01","n":1}}},{"i":83,"$":{"0":{"v":"2025-01-07","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2025.01.07\n\n## Todo today\nChecker les boîtes.\nPrendre contact avec PMA.\nRelancer Deutz.\nContacter le service de promotion de la recherche.\nRegarder P21 Antismash.\n\n\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.127}}},{"i":84,"$":{"0":{"v":"2024","n":1}}},{"i":85,"$":{"0":{"v":"12","n":1}}},{"i":86,"$":{"0":{"v":"2024-12-16","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.12.16\n\n## Todo today\n- meeting with Kuhner technology about Duetz system at 2pm!\n- read this ActinoMation: a literate programming approach for medium-throughput robotic conjugation of Streptomyces spp.\n- \n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n- read on Deutz for actino \n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\nla réduction d'échelle conduit inévitablement à des perturbations dans le développement du phénotype https://link.springer.com/article/10.1186/s12934-024-024. \n\n- ","n":0.105}}},{"i":87,"$":{"0":{"v":"2024-12-13","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.12.13\n\n## Todo today\n Mzmine webinaires.\n Demo mass spectro for proteomics this afternoon. \n Test bio on red phenol results and pictures. \n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.123}}},{"i":88,"$":{"0":{"v":"2024-12-11","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.12.11\n\n## Todo today\n- Clean al liquid culture. \n- practice MZmine4. \n- write on my lab Notebook. \n- contact kuhner.com for Duetz System. \n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.122}}},{"i":89,"$":{"0":{"v":"11","n":1}}},{"i":90,"$":{"0":{"v":"2024-11-28","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.11.28\n\n## Todo today\nculture V1 i find an contaminated bacillus.\nMeeting PMA: we have discussed on my sampling point.\n\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n### Litterature\n1. la méthode SMIRC :\nLa méthode SMIRC (capture de résine in situ de petites molécules) est une approche indépendante de la culture qui permet de capturer des produits naturels directement à partir des environnements où les microbes les produisent, sans avoir besoin de cultiver ces microbes en laboratoire (https://www.nature.com/articles/s41467-024-49367-x).\nhttps://www.mdpi.com/2076-3417/11/20/9418  \n\n\n###\n\n## Doing\nRead the papers send by PMA:  Molecules to Ecosystems: Actinomycete Natural Products In situ. Chemical ecology of antibiotic production by actinomycetes. \n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.087}}},{"i":91,"$":{"0":{"v":"2024-11-27","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.11.27\n\n## Todo today\n\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.146}}},{"i":92,"$":{"0":{"v":"2024-11-26","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.11.26\n\n## Todo today\n- Isolation of new strains.\n- Prepare meniral media.\n- Preparation of SCA. \n- Read how to isolate endophytic actinobacteria. \n\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\nGoog paper: describe a compound-first approach to natural product discovery in which adsorbent resins capture compounds directly from the environments in which they are produced. Using this technique, which we call SMIRC, natural products were captured and purified from a marine deployment site in sufficient quantities to elucidate the structures of cabrillostatin (1) and the halogenated polyketides cabrillospirals A and B (2-3), which represent two new carbon skeletons https://www.nature.com/articles/s41467-024-49367-x.\n\n## \n\n\n## Done\nprotocol of endophytic bacteria isolation.\nI didn't sampled yet.\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.085}}},{"i":93,"$":{"0":{"v":"2024-11-25","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.11.25\n\n## Todo today\nAsk PMA questions.\nPrepare A4 media for new screening.\nPrepare solutions for inactivation of V1.\nRead Mzmine 4 instructions. \n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that to clone git repo\n1. ouvrir le terminal.\n2. Vérifier que Git est installé 'git'\n3. Lister les fichiers et répertoires dans le terminal avec ls ou dir 'ls'.\n4. Créer un dossier appelé git_repos avec \"mkdir\".\n5. Se déplacer dans ce dossier avec 'cd'.\n6. Cloner un dépôt Git depuis GitHub avec git clone git clone \"https://github.com/mapp-metabolomics-unit/swiss-soil-microbials.git\" (this path from ghithub code you will find dit). \n7. Se déplacer dans le répertoire cloné avec cd.\n8. Ouvrir le projet dans Visual Studio Code avec code ..\n\n- ","n":0.084}}},{"i":94,"$":{"0":{"v":"2024-11-23","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.11.23\n\n## Todo today\nLiterature screening methods \nIn situ captured antibacterial action of membrane-incising peptide lamellae \n\n1. cette étude explore de nouvelles approches pour combattre la résistance aux antibiotiques en utilisant des peptides qui se forment en structures actives lorsqu'ils rencontrent la surface bactérienne, perturbant ainsi la membrane et tuant les bactéries, tout en étant visuellement observés via des techniques avancées https://www.nature.com/articles/s41467-024-47708-4. \n2. Methods for in vitro evaluating antimicrobial activity: A review (classicmethodes) https://doi.org/10.1016/j.jpha.2015.11.005.\n3. Production of inactivated gram-positive and gram-negative species with preserved cellular morphology and integrity: une étude comparative des différentes méthodes utilisées pour inactiver des bactéries, c'est-à-dire les rendre métaboliquement mortes tout en conservant leur intégrité cellulaire. Cela signifie que les bactéries doivent être inactivées de manière à ce que leur structure cellulaire, notamment la paroi et la membrane, soit préservée, tout en minimisant la fuite de protéines et d'ADN intracellulaires. Ce type de bactéries inactivées est essentiel pour des applications spécifiques, telles que l'étude des signaux déclenchés par des récepteurs ou l’analyse des interactions bactérie-cellule qui nécessitent de longues périodes d'incubation. Bacterial inactivation with ethanol, formalin, NaOH, UV-C and BPL results in 100% inactivation efficacy. (https://doi.org/10.1016/j.mimet.2021.106208).  \n## Protocol inscaativation: \n1. Bacterial strains and growth conditions\nEight strains of bacteria from five phyla were selected as representatives for the structural differences in bacterial cell walls of Gram-positive and Gram-negative strains to evaluate the inactivation efficacy of each method (Table 1). The anaerobic bacteria Bacteroides fragilis 9343 NTBF, Parabacteroides distasonis 3999B T(B)4, Fusobacterium nucleatum patient isolate NTB17 (from the Radboudumc strain collection), Akkermansia muciniphila ATCC BAA-835 were cultured in an anaerobic jar using sachets (Thermo Fisher Scientific, USA) in Brain-Heart-Infusion (BHI) broth (Sigma-Aldrich, USA) supplemented with L-cysteine (Sigma-Aldrich, USA), yeast extract (BD, USA), hemin (Sigma-Aldrich, USA), vitamin K1 (Sigma-Aldrich, USA) for 48 h at 37 °C. Facultative aerobic strains such as Salmonella enterica serovar Typhimurium NTB6 (Kortman et al., 2014) (further designated as S. typhimurium), Streptococcus gallolyticus subsp. gallolyticus UCN34 (further designated as S. gallolyticus), Escherichia coli NC101 and Lactococcus lactis IL1403 were cultured aerobically in BHI broth overnight at 37 °C with 5% CO2.\n2. Following incubation, optical density at 620 nm was measured in the microplate reader Infinite F50 (Tecan, Switzerland) and samples were centrifuged at maximum speed (16,100 x g) for 10 min. Supernatants were discarded and OD620 was adjusted to 1.0 in 0.9% sodium chloride buffer (B Braun Melsungen AG, Germany) for treatments with BPL (Acros Organics, Thermo Fisher Scientific, USA) and pasteurization. For NaOH, ethanol (all from Merck, Germany) and formalin (formaldehyde solution about 37%, Merck, Germany) treatments, pellets were resuspended at OD620 of 1.0 in NaOH, ethanol and formalin, respectively.\n2.2.2. NaOH, ethanol and formalin treatments\nBacterial pellets (Table 1) were resuspended in 6 mg/ml (0.15 M) NaOH solution (Rabi et al., 2018; Vinod et al., 2014), 70% ethanol (Morton, 1950), or formalin (McDonnell and Russell, 1999), and incubated at room temperature for 5 min.(https://doi.org/10.1016/j.mimet.2021.106208).\n\n## How to proced?\n1. Culture des bactéries :\n•\tBactéries anaérobies : Cultiver des souches comme Bacteroides fragilis, Parabacteroides distasonis, Fusobacterium nucleatum, et Akkermansia muciniphila dans une boîte à anaérobiose à 37 °C pendant 48 heures en utilisant du milieu Brain-Heart-Infusion (BHI) enrichi de L-cystéine, extrait de levure, hémine et vitamine K1.\n•\tBactéries aérobies facultatives : Cultiver des souches comme Salmonella enterica, Streptococcus gallolyticus, Escherichia coli et Lactococcus lactis en milieu BHI à 37 °C avec 5 % de CO2 pendant 16-18 heures. \n2. Mesure de la densité optique :\n•\tAprès incubation, mesurer la densité optique (DO) des cultures à 620 nm (OD620) à l'aide d'un lecteur de microplaque (par exemple, Tecan Infinite F50).\n•\tCentrifuger les échantillons à 16 100 x g pendant 10 minutes pour récupérer les pellets de bactéries.\n•\tJeter les surnageants et ajuster les pellets de bactéries à OD620 = 1.0 dans une solution saline à 0.9% de NaCl (solution tampon saline, B Braun Melsungen AG).\n3. Traitement avec NaOH, éthanol ou formol :\n•\tPréparer les solutions :\no\tNaOH : 6 mg/ml (0.15 M).\no\tÉthanol : 70 %.\no\tFormol : solution de formaldéhyde à 37 %.\n•\tInactivation :\no\tRésuspendre les pellets de bactéries dans l'une de ces solutions (NaOH, éthanol ou formol) à OD620 = 1.0.\no\tIncuber les bactéries à température ambiante pendant 5 minutes dans ces solutions.\no\tCette incubation permet l'inactivation des bactéries tout en perturbant leurs fonctions métaboliques sans détruire totalement leur structure cellulaire.\n4. Étape finale :\n•\tAprès l'incubation, vous pouvez procéder à des étapes supplémentaires comme la culture des bactéries traitées pour vérifier leur inactivation, ou effectuer des tests pour évaluer l'intégrité de leur paroi cellulaire (par exemple, mesure de la libération d'ADN ou coloration avec des marqueurs fluorescents).\nPour préparer 200 mL de solution de NaCl à 0,9%, vous devez dissoudre 1,8 g de NaCl dans de l'eau distillée et compléter jusqu'à un volume total de 200 mL.\nPour préparer 200 mL NaOH: Vous devez dissoudre 1,2 g de NaOH dans de l'eau distillée et compléter à 200 mL pour obtenir une solution à 6 mg/mL (0,15 M) de NaOH.  \n\n\nNotes:  L’inactivation bactérienne avec de l’éthanol, du formol, du NaOH, des UV-C et du BPL donne une efficacité d’inactivation de 100 %.\n•\tLa pasteurisation a entraîné une inactivation incomplète étant donné que de multiples souches bactériennes proviennent d'espèces différentes.\n•\tL’éthanol et le BPL entraînent une fuite minimale d’ADN, ce qui suggère un effet minimal sur l’intégrité cellulaire.\n•\tLe BPL et le formol ont largement maintenu l'intégrité cellulaire d' E. coli , S. gallolyticus , L. lactis et A. muciniphila .\n\n\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.033}}},{"i":95,"$":{"0":{"v":"2024-11-22","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.11.22\n\n## Todo today\nMeeting PMA 9-12 am\nclaen the hood, run UV. \n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.135}}},{"i":96,"$":{"0":{"v":"2024-11-20","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.11.20\n\n## Todo today\ncompleting the CSV table.\ncleans fungi cultures\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.139}}},{"i":97,"$":{"0":{"v":"2024-11-19","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.11.19\n\n## Todo today\n CSV table with all project data.\n Semminair gut microbiota 11h30.\n\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.132}}},{"i":98,"$":{"0":{"v":"18","n":1},"1":{"v":"on---\nid: 8mpdyp5uvho24ngupmg4wz6\ntitle: '2024-11-18'\ndesc: ''\nupdated: 1731953868706\ncreated: 1731937282182\ntraitIds:\n  - open-notebook-commons-rouchene\n---\n\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.11.18\n\n## Todo today\nmeeting PMA.\n\nCreate a table with the following headers\n\n\ninternal code | species name| wikidataQID of the species |blast job link|comments|wikidata query link for individual compounds|wikidata query link with refs | scholia link | pathogenicity (list of refs with doi)||\n-|-|-\n\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\nprepare SCV table for all data collection.\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n this evening clean fungi collection, everything should be strerilized. \n\n## Paused\n\n## Done \nPMA mettenig: for the moment we keep the strains after metabolomics we will see.\n\n## Notes\n\n\n## Todo tomorrow, one day ... or never \n\nTomorrow: all results sshould be in the same table.\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.088}}},{"i":99,"$":{"0":{"v":"2024-11-11","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.11.11\n\n## Todo today\nPutification of V1 DNA.\nPreparation of PDB.\nInformation on CH4's pathogenicity.\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\nLitterature on my species! \n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \ncomplet table of strains.\nLitterature on my species!  \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.123}}},{"i":100,"$":{"0":{"v":"2024-11-08","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.11.08\n\n## Todo today\nAgarose gel for V1 DNA extracted with the kit. I want to decrease the migration time to 20 minutes to observe the results.\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n### for DNA identification i need \nladder 1kb for bacteria and 800 pb for fungi.\nprimers 27F and 1492R \nSolifast \n\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.107}}},{"i":101,"$":{"0":{"v":"2024-11-07","n":1},"1":{"v":"\n\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2024.11.07\n\n## Todo today\nPCR and purification of V and CH44S DNA \n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project \n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n\n\n###\n\n## Doing\nDNA purification with kit this afternoon.\n\n## Paused\n\n## Done\nPCR and gel migration.\n\n## Notes\ni get beautiful band for CH4 and bad one of V1. \n\n## Todo tomorrow, one day ... or never \n\n\n\n###\n###\n\n\n## Today I learned that\nEven though I have good DNA, it doesn't mean that sequencing is guaranteed. \nIf the sequencing doesn't work with the forward primer, we can try the reverse primer, if our DNA is well amplified. \n\n- By doing ctrl+o ctrl+n I can open a daily note ","n":0.092}}},{"i":102,"$":{"0":{"v":"2023","n":1}}},{"i":103,"$":{"0":{"v":"11","n":1}}},{"i":104,"$":{"0":{"v":"2023-11-14","n":1},"1":{"v":"\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2023.11.14\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\ndfkfhdkhkdj\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.146}}},{"i":105,"$":{"0":{"v":"10","n":1}}},{"i":106,"$":{"0":{"v":"2023-10-31","n":1},"1":{"v":"\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2023.10.31\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n### today 31-10-2023\n- I prepared NL 148sb agar \n- I i cultred the strains of VW.\n- I will isolate from a culture soil of 21 days. \n- ","n":0.117}}},{"i":107,"$":{"0":{"v":"2023-10-13","n":1},"1":{"v":"\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2023.10.13\n\n## Todo today\n\n- Isolation of some strains \n- read ecoplate papers \n- \n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n- Read about ecoplate.\n-isolation of strains this afternoon.\n- \n\n\n#### Next week\n - 17-10-2023 Redrego conf \n - 18-10-2023 go to the University of Neuchâtel with PMA for the collaboration.\n - 19-10-2023 visit thun city.\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.105}}},{"i":108,"$":{"0":{"v":"2023-10-12","n":1},"1":{"v":"\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2023.10.12\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.146}}},{"i":109,"$":{"0":{"v":"2023-10-11","n":1},"1":{"v":"\n\n# This is Rimas's COMMONS Lab daily Open Notebook.\n\nToday is 2023.10.11\n\n## Todo today\nGetting started with Dandron with PMA\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Microcosmics project\n\nSee [[projects.commons-public.microcosmics]]\n\n\n### Lab work \n\n\n09-10-23\n\nI carried out the first sampling at the botanical garden. I took a horizon of 3- 12 cm.\nSee pic [[![Alt text](image-5.png)]]\n[[![Alt text](image-6.png)]]\n[[![Alt text](image-7.png)]]\n![](/assets/images/2023-10-12-10-01-08.png)\n![](/assets/images/2023-10-12-10-01-36.png)\n![](/assets/images/2023-10-12-10-04-27.png)\n\n\n10-10-2023 Check the inoculated plates.  \n\nLook pic [[![Alt text](image-1.png)]]\n[[![Alt text](image-2.png)]]\n[[![Alt text](image-3.png)]]\n[[![Alt text](image-4.png)]]\n\n![](/assets/images/2023-10-12-09-58-57.png)\n![](/assets/images/2023-10-12-09-59-28.png)\n![](/assets/images/2023-10-12-09-59-51.png)\n![](/assets/images/2023-10-12-10-00-21.png)\n\n\n\n###\n\n## Doing\n\nWorking on the eerimental design off the roject.\nCollecting infos and pdf and woring at [[projects.commons-public.microcosmics.experimental-design]]. \n\n\n\n## Paused\n\n## Done\n\nHow to write note in Dendron and to sync with public commons web.\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n###\n###\n\n## Today I learned that\n\n- using ctrl+O+N i can creat a dialy note \n- ctrl+s to save my modification  \n- ctrl+L search or create note \n- share picture [[link]]\nctrl+shift+P show![](/assets/images/2023-10-12-08-57-45.png) pallette\n\n#### Setting up of the Microcosmics project \n\n### Literature \n\n_Useful before setting up the microcosmis system_\n \n ## Microcosm incubation\n12-h photoperiod: Columbia View orchard soil was passed through a 4-mm sieve and 100 g samples were placed into 487 mL microcosms (glass jars). Jar lids were perforated to make a 1 cm diameter hole into which a rubber septum was inserted. The experiment consisted of two treatments; ASD amended with rice bran (RB) and a no-carbon input ASD control (ASD-NA), seven time points; day 0, 1, 2, 3, 7, 11, and 15, with four samples per treatment at each incubation duration point. In total, across all treatments and time points, 56 samples analyzed. For the purposes of this study, RB soil amendment treatment was not included as pathogen suppression (e.g., F. oxysporum f. sp. fragariae) was not realized under such conditions (Figure 1). In addition, RB soil incorporation does not yield an anaerobic environment (Mazzola et al., 2018), nor result in amplification of target microbial populations commonly associated with ASD-induced disease suppression, such as Clostridium spp. For the ASD treatment, 1.57 g of RB (equivalent to 20 Mg per ha per 15 cm depth in the field) was homogeneously mixed into soil. Estimated nutrient concentration of RB was C = 47.8%, N = 2.49%, P = 1.53%, K = 1.60%, S = 0.18%, C:N ratio = 19:1, pH = 6.2 (Soiltest Farm Consultants, Inc., Moses Lake, WA, United States). For both treatments, 25 mL of distilled water was added to saturate the soil pore spaces. The headspace volume over the microcosms was 409 mL. Jars were incubated in an environmental growth chamber for 15 days at 24/18°C with 12-h photoperiod. Photosynthetically active radiation (PAR, 400–700 nm) just above the jars was 226 μmol m–2 sec–2. Immediately after initiating the experiment, headspace volatiles were extracted, and a representative soil sample was collected using a #3 cork borer (7 cores from each microcosm). Soil samples were placed in a chilled sample cup, followed by immediate immersion in liquid nitrogen and stored at −80°C. This procedure was followed for soil sampling at all incubation duration points. Frozen soil cores were cryogenically milled to a fine powder and stored again at −80°C before use for metabolite analysis. For day 0 and day 1 time points, headspace O2 and CO2 composition was analyzed every 4 h and once for the remaining incubation duration points as described below (https://www.frontiersin.org/articles/10.3389/fmicb.2019.02365/full).\n\n## LC/MS analysis ( soil metabolomics)\nExtraction of the metabolome and LC-MS analysis:\nMethod 1. Extracellular metabolites were extracted from 2 g of wet soil from each sample (with five technical replicates) using 10 ml of deionized water. The samples were shaken on a mechanical shaker for 12 hours at 4°C, then centrifuged at 2,500 x g for 15 minutes at 4°C, and finally filtered through 0.2 µm polyethersulfone membrane filters (Pall Corporation, New York, NY, USA). Polar metabolites were completely dried using a rapid vacuum concentrator, then chemically derivatized and analyzed by gas chromatography-mass spectrometry (GC-MS) (https://www.mdpi.com/2076-2607/10/8/1653].\n\nMethod 2. Biocrust soil water samples (1.5 mL) were lyophilized and resuspended in methanol (200 μL) containing internal standards (2–10 μg/mL) and filtered through 96-well Millipore filter plates (0.2 μm PVDF) by centrifuging at 1500 × g for 2 min. Samples were analyzed using normal-phase LC/MS with a ZIC-pHILIC column (150 × 2.1 mm, 3.5 μm 200 Å, Merck Sequant, Darmstadt, Germany) using an Agilent 1290 series UHPLC (Agilent Technologies, Santa Clara, California, USA)(https://www.nature.com/articles/s41467-017-02356-9).\n\nMethod 3. (Soil non-targeted metabolomic detection and analysis) Twelve rhizosphere soil samples were sent to Majorbio (Shanghai, China) on dry ice for metabolite extraction, detection, and analysis. In detail, 1,000-mg soil aliquot of each sample was homogenized with 1,000 µL methanol/water (4:1, v/v) solution, including 0.02 mg/mL internal standard (L-2-chlorophenylamine acid) for 6 min at −10 °C and 50 kHz using a Geno-grinder 2,000 (SPEX, Metuchen, NJ, USA) and spun down for 30 min at 5 °C and 40 kHz. After resting for 30 min at −20 °C, each material was centrifuged at 13,000 g (relative centrifugal force) for 15 min at 4 °C, then the supernatant was transferred and concentrated by a Termovap Sample Concentrator (DC-24, Anpel Laboratory Technologies, Shanghai, China). The dry residue was derivatized by adding 50 µL acetonitrile/water (1:1), homogenized for 30 s at 5 °C and 40 kHz, and centrifuged at 13,000 g (relative centrifugal force) for 10 min at 4 °C. Finally, the supernatant was subjected to LC-tandem MS (MS/MS) analysis; 20 µL supernatant of each sample was mixed for the quality control sample.\nThe UHPLC-Triple TOF system (AB Sciex, Foster City, CA, USA) equipped with an ACQUITY UPLC HSS T3 (100 mm × 2.1 mm i.d., 1.8 µm; Waters, Milford, CT, USA) was applied to chromatographic separating the metabolites with two mobile phases, phase A (95% water and 5% acetonitrile (with 0.1% formic acid)) and phase B (5% water (with 0.1% formic acid), 47.5% acetonitrile, and 47.5% isopropanol). The whole system was integrated to a quadrupole time-of-flight mass spectrometer (Triple TOFTM 5600th; AB Sciex, Foster City, CA, USA) equipped with an electrospray ionization source and operated in positive and negative modes [doi: 10.7717/peerj.13254](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8995024/).\n\nMethod 4. The 45 collected soil samples, and 5 blank samples containing no soil, were lyophilized on an Edwards Super Modulyo freeze-drier (SciQuip Ltd., Shropshire, UK) for 7 d. Subsequently, these were ground in a Retsch MM200 stainless steel ball mill (Retsch GmbH, Haan, Germany) at a frequency of 20 Hz to aid recovery of metabolites from the microbial biomass (Fiehn et al., 2002; Wang et al., 2015). The samples were then stored in individual sterile glass vials at −80 °C to minimize changes in metabolites (Wellerdiek et al., 2009). The soils were extracted using 3:3:2 (v/v/v) acetonitrile-isopropanol-water, vortexed for 15 s, shaken at 4 °C for 5 min, centrifuged at 1400 rpm for 2 min, and dried using a CentriVap Benchtop Centrifugal Concentrator (Labconco Corp., Kansas City, MO) (Barupal et al., 2019; Fu et al., 2019). Non-targeted primary metabolism analysis was performed using a Gerstel Automated Linear Exchange-Cold Injection System (ALEX-CIS) with Agilent gas chromatograph (GC) and Leco Pegasus IV Time Of Flight (TOF) MS at the UC Davis West Coast Metabolomics Facility using the method of Fiehn (2016). Briefly, 0.5 μl of each sample was injected onto a Rtx-5Sil MS capillary column (30 m length × 0.25 m i.d with 10 m integrated guard column; 0.25 μm 95% dimethylsiloxane/5% diphenylpolysiloxane coating; Restek Corp., Bellefonte, PA). Using a He mobile phase, the GC thermal programme was 50 °C for 1 min, ramped to 330 °C at 20 °C min−1 and finally held at 330 °C for 5 min. Upon elution, samples were injected into a Pegasus IV GC-time of flight mass spectrometer (Leco Corp., St Joseph, MI), using mass resolution of 17 spectra s−1, from 80 to 500 Da, at −70 eV ionization energy and 1800 V detector voltage with a 230 °C transfer line and 250 °C ion source (https://www.sciencedirect.com/science/article/pii/S0038071720300559).\nMethod 5 (3 methods in the same paper): Soil Sample Extractions for NMR and MS Analyses\nExtraction in DMSO\nAntarctic soil (2 g) was suspended in 10 mL of DMSO, sonicated at 37 kHz, pulse, 100 pw, 30 min, 30–60 °C (Elmasonic P 30 H, Elma Schmidbauer GmbH, Singen, Germany). Each sample was centrifuged (Beckman Avanti J-20 Centrifuge, Beckman Coulter, Indianapolis, IN, USA) at 20,000× g for 15 min, 4 °C. The supernatant was collected and freeze-dried (Christ Alpha 1-2 LD plus, Martin Christ Gefriertrocknungsanlagen GmbH, Osterode am Harz, Germany). The extraction yield was calculated for each sample. Lyophilized samples were stored at −20 °C.\nExtraction in H2O/CH3OH 1:1\nAntarctic soil (2 g) was suspended in 10 mL of MilliQ water/CH3OH 1:1 with 50 µL NaN3 0.3 M to obtain NaN3 1.5 mM (0.01%), sonicated and centrifuged as described above. The supernatant was collected and CH3OH evaporated under reduced pressure at 40 °C (Heidolph Rotary Evaporator, Laborota 4000, Heidolph Instruments GmbH & Co. KG, Schwabach, Germany). The water phase was transferred in flask and freeze-dried as above. The extraction yield was calculated for each sample. Lyophilized samples were stored at −20 °C.\nExtraction in H2O/CH3CN 7:3\nAntarctic soil (2 g) was suspended in 10 mL of MilliQ water/CH3CN 7:3 with 50 µL NaN3 0.3 M to obtain NaN3 1.5 mM (0.01%) sonicated at 37 kHz, pulse, 100 pw, 60 min, 30–60 °C, and centrifuged as described above. The extraction was repeated with 10 mL of fresh extraction solution. The supernatants were transferred in a flask and freeze-dried as above. The extraction yield was calculated for each sample. Lyophilized samples were stored at −20 °C (https://www.mdpi.com/1422-0067/24/15/12340).\nMethod 5 (+ ammonium bicarbonate) 5 g of lyophilized soil were placed in a 25 ml centrifuge tube equipped with a Teflon-lined screw cap and 4 ml of 0.25 M aqueous ammonium bicarbonate, 10 ml methanol, and 5 ml chloroform containing the internal standards for NLFA and PLFA analysis (trinonadecanoin glyceride, Nu-Chek Prep, Inc., Elysian, MN, USA; 19:0 phosphatidylcholine, Avanti Polar Lipids, Alabaster, AL), were added. The contents of the centrifuge tubes were then sonicated 10 min in a water bath sonicator at room temperature, incubated at room temperature with end-over-end mixing for 2 h, and centrifuged 10 min at 1710 G. The liquid phase was transferred to a 30 ml test tube with a Teflon-lined screw cap, 5 ml each of water and chloroform were added, and the sample mixed by vigorous shaking. After centrifuging for 10 min at 1710 G, 2 layers were formed. The top layer (aqueous phase) contained the water-soluble metabolites while the bottom layer (organic phase) contained the lipids. Each phase was transferred into a separate test tube and evaporated in vacuo using a centrifugal evaporator. The organic phase was evaporated to dryness for NLFA and PLFA analyses while the aqueous phase was evaporated to approximately one-quarter of the original volume for metabolomic analysis. Samples were stored at −80 °C until further processing (https://www.sciencedirect.com/science/article/pii/S0929139318309958?casa_token=Ke9s59BsPbMAAAAA:m0W7-gJGUad-_iMOcfnUumQW_JYGiiW9exCDR7bVKgGh0JTUPbzVJq_X2I94sHOyuGtfys5Ftw).\nMethod 7. methanol–chloroform–water method [DOI: 10.1002/etc.2418].\n\n## Determination of Soil Microbial Biodiversity\nThrough amplicon sequencing (Illumina MiSeq):\nThe diversity of soil bacteria and fungi was analyzed through amplicon sequencing (Illumina MiSeq). A total of 10 g of frozen soil samples were cooled using liquid nitrogen and ground using a mortar and pestle. Soil DNA (n = 435) was extracted using a DNA Isolation Kit (Powersoil, MoBio Laboratories, Carlsbad, CA, USA). A portion of the bacterial 16S and eukaryotic 18S rRNA genes were sequenced using the 515F/806R and Euk1391f/EukBr primer sets, respectively (https://doi.org/10.1038/s41396-021-00906-0.\n\n## Relevance of biolog plates\nECOPLATE : The EcoPlate contains 31 carbon sources that are useful for community analysis. These 31 carbon sources are repeated 3 times to give the scientist more replicates of the data. Communities of microorganisms will give a characteristic reaction pattern called a metabolic fingerprint. From a single EcoPlate, these fingerprint reaction patterns rapidly and easily characterize the community (https://sci-hub.se/https://doi.org/10.1016/j.apsoil.2015.06.007).\nL’Eco-plate est une microplaque de 96 puits dans lesquels se trouvent un substrat carboné et un colorant. Cette plaque doit être inoculée par une solution environnementale contenant une communauté microbienne provenant notamment du sol. Elle regroupe 3 réplicas d’une série de 31 substrats carbonés et un contrôle négatif (eau). Ces substrats représentent 6 classes différentes de composés carbonés : amines/amides, hydrates de carbone, polymères de carbone, acides carboxyliques, acides aminés, phosphates organiques (Preston-Mafham et al., 2002) (Annexe 1). Ils représentent les sources de carbone les plus retrouvés dans l’environnement terrestre, la majorité d’entre eux étant issus de matière végétale (exemple : D-Xylose). Ce choix de substrats a été déterminé ainsi pour apporter des informations suffisantes et pertinentes dans le cas d’étude des populations bactériennes de l’environnement. Par ailleurs, chaque puits contient aussi un sel de tétrazolium qui sert d’indicateur coloré positif. En effet ce sel va jouer le rôle d’accepteurs d’électron artificiel dans la chaine respiratoire des bactéries. Ainsi, lorsque les bactéries métabolisent le substrat, ce sel est réduit de manière irréversible en un composé violet insoluble : le formazan (Tachon et al., 2009). La production de formazan est alors quantifiée par mesure de la densité optique à 590 nm (OD590nm). L’OD590nm est alors proportionnelle à la consommation du substrat (chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://www.secure.mg/sites/default/files/2019-01/Ecoplate-Version-Courte.pdf).\nThe limitations: Le principal reproche fait à l’Eco-Plate est que ses conditions d’incubations ne sont pas celles du sol. Il se peut que ce métabolisme ne puisse pas s’exprimer dans le contexte naturel. De plus, l’apport d’une seule source de carbone à la fois induit en effet une pression de sélection vis-à-vis du substrat en faveur de celles ayant un métabolisme rapide supportant une forte concentration en un seul nutriment (Garland et al., 1997 ; Preston-Mafham et al., 2002 ; Muñiz et al., 2014). Le CLPP pourrait donc ne refléter que la capacité d’une communauté bactérienne à supporter les conditions de la plaque : des bactéries capables d’intégrer ce sel de tétrazolium dans leur chaine respiratoire, qu’elles soient cultivables ou non, mais ayant un métabolisme rapide et aérobie, (Winding et al., 1997 ; Preston-Mafham et al., 2002). D’un puits à l’autre, la diversité n’est donc pas la même et elle diminue par rapport à la communauté inoculée (Garland et al., 1997). De plus, alors qu’ils représentent des organismes très actifs dans les sols, les champignons ne sont pas représentés dans les Eco-Plates car ce sel de tétrazolium n’est pas adapté à leur métabolisme. Il existe cependant la plaque Biolog FF adaptée pour les étudier (Preston-Mafham et al., 2002 (chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://www.secure.mg/sites/default/files/2019-01/Ecoplate-Version-Courte.pdf)\n\n## isolation of soil microrganisms\n\n- **Isolation of Fungal Strains** from Soil Samples: Solid potato dextrose agar (PDA) media were used for the isolation and identification of fungal strains. The inoculum prepared from soil samples was spread on PDA medium, and incubation was carried out at 28 ± 2°C for 5 to 7 days. After incubation, the morphology of the colonies was recorded to identify the specific fungus collected in each sample (ref) [https://www.mdpi.com/2304-8158/10/6/1280].\nFor bacteria: Starch casien agar(https://www.nature.com/articles/202928a0).\nWe prepared a mineral solution composed of 2 g/L (NH4)2SO4, 4 g/L KH2PO4, 6 g/L Na2HPO4, 0.05 g/L CaCl.2H2O,\n0.2 g/L MgSO4.7H2O, and 0.01 g/L FeSO4.7H2O (https://link.springer.com/article/10.1007/s11270-016-2789-z).\n\n\n### Ecoplate \nAccording to So et al., the EcoPlates™ test, especially when applied to soil, can be challenging to replicate and standardize due to the lack of detailed procedures and protocols. The main issues with this technique primarily concern soil preparation, bacterial inoculum densities, and the correct definition of the reference value (blank) when calculating diversity indices. Based on our previous research in agricultural soils, we propose a standardized and precise step-by-step method for assessing the functional diversity of a soil bacterial community using Biolog® EcoPlates (https://www.mdpi.com/2076-3417/9/19/4035).\n\nWe prepared 1:100 dilutions from 10 g subsamples, inoculated the EcoPlate with these diluted subsamples, incubated the plates at in situ temperature, and made measurements on Days 0, 1, 3, 5, 7, 10, and 14. The first step was to inoculate samples into an EcoPlate, either as aqueous samples or after suspension. The utilization of each carbon source during incubation was coupled to the conversion of triphenyl tetrazolium chloride to triphenyl formazan (TPF), so that carbon utilization could be quantified by the color density of TPF in each well using the optical density at 590 nm with a microplate reader (iMark; Bio-Rad Laboratories). Detailed information on EcoPlate, including the 31 carbon substrates, is available at https://www.biolog.com/wp-content/uploads/2020/05/00A-012-rD-EcoPlate-IFU.pdf (last accessed on November 9, 2021). [Correction added on 3 March 2022, after first online publication: information about the microplate reader was amended in the preceding paragraph]\n\nDue to its small volume (100 μl/well), the community size can be less than 10,000 individuals/well, which is a nonnegligible source of stochasticity in the initial species composition among the 96 wells in a plate. This could result in variation in color density among identical substrates within a plate (Zhou et al., 2013). To reduce the stochastic effect, three repeated sets of 31 different response wells were conducted for each plot (https://esj-journals.onlinelibrary.wiley.com/doi/full/10.1111/1440-1703.12293). \n\n_Protocol _ \n\n1.\tMeasure 10 g of the soil sample.\n2.\tAdd 10 ml of distilled water and gently shake the flask.\"\n3.\tInoculate the ecoplate with 100 µL for each well.\"\n4.\tIncubate plates at 37°C.\"\n5.\tRead at 590 nm on days 0, 1, 3, 5, 7, 10, and 14.\n\n\n\n\n### Experimental design of microcosmics project \n\nMaterials and Methods\n\n\n\n- Preliminary microcosm optimization step\n\n_Preparation of Microcosms\n_We do not have data on the lab's microcosm resistance duration. Therefore, we have created three different batches of 200 grams of soil. The first batch (control) consists of soil sterilized in an autoclave at 121 °C for one hour. The second microcosm, called the natural microcosm, underwent no modifications. The last type is the microcosm enriched with a mineral solution to maintain the basic metabolism of the microcosm and promote the growth of slow-growing microorganisms, as shown in the experimental plan in Figure 1. Each of these three types of microcosms will be replicated four times, giving us a total of twelve microcosms for measurements after 1 week, 15 days, 21 days, and 30 days. All microcosms were incubated at 28 °C. All components used for the microcosms were sterilized in an autoclave for 30 minutes at 121 C.\n\n_Sterilization of soil_ \n\nSoil is autoclaved at 121°C during 1h (https://www.sciencedirect.com/science/article/abs/pii/0167701296008433)\n_Samling site _\nhttps://maps.app.goo.gl/Ch9ccDJaAidT1GxR8\n\n\n\n- First screening of extraction methods\n\nIn the first step, we optimized the soil metabolome extraction protocol. To achieve this, we extracted 5 grams of soil using five extraction methods: M1, M2, M3, M4, and M5. Subsequently, the mixtures were allowed to rest for 2 hours, after which they underwent sonication at 37 kHz with a 100-pulse wave for 30 minutes at a temperature range of 30-60°C. Following this, the samples were centrifuged at 20,000× g for 15 minutes at 4°C. The supernatants were collected and stored at -20°C for further analysis.\nMethod 1: 100% methanol.\nMethod 2: 80%,20%, 0.01% (Methanol/ H2O/Formic acid).\nMethod 3: 100% DMSO.\nMethod 4: 4ml of ammonium bicarbonate + 10 ml methanol+ 5ml of chloroform.\nMethod 5: 4ml of ammonium bicarbonate + 10 ml ethyl acetate.\nAll the extractions have a final volume of 15 ml with 5 g of soil.\nAdditionally, 0.5 grams of the sample were diluted in 4 milliliters of sterile distilled water and vigorously shaken. A volume of 100 μL of the diluted sample was inoculated onto various culture media, including SCA supplemented with antimicrobials (nalidixic acid, cycloheximide, and nystatin), PDA, nutrient agar, and A4. The plates were incubated at 28°C, except for those inoculated on nutrient agar, which were incubated at 37°C.\n\n##### comments after applying\n\nthe five methods are not coonslusive - the search for other methods is essential. Weak profiles\n\n     - Others etraction methods: \n\n1. The 45 collected soil samples, and 5 blank samples containing no\nsoil, were lyophilized on an Edwards Super Modulyo freeze-drier (SciQuip Ltd., Shropshire, UK) for 7 d. Subsequently, these were ground in a Retsch MM200 stainless steel ball mill (Retsch GmbH, Haan, Germany)\nat a frequency of 20 Hz to aid recovery of metabolites from the microbial biomass (Fiehn et al., 2002; Wang et al., 2015). The samples were then stored in individual sterile glass vials at  -80°C to minimize changes in metabolites (Wellerdiek et al., 2009). The soils were extracted using 3:3:2 (v/v/v) acetonitrile-isopropanol-water, vortexed for 15 s, shakenat 4° C for 5 min, centrifuged at 1400 rpm for 2 min, and dried using a CentriVap Benchtop Centrifugal Concentrator (Labconco Corp., Kansas City, MO) (Barupal et al., 2019; Fu et al., 2019). Non-targeted primary metabolism analysis was performed using a Gerstel Automated Linear Exchange-Cold Injection System (ALEX-CIS) with Agilent gas chromatograph (GC) and Leco Pegasus IV Time Of Flight (TOF) MS at the UC Davis West Coast Metabolomics Facility using the method of Fiehn (2016). Briefly, 0.5 μl of each sample was injected onto a Rtx-5Sil MS capillary column (30 m length ° 0.25 m i.d with 10 m integrated guard column; 0.25 μm 95% dimethylsiloxane/5% diphenylpolysiloxane coating; Restek Corp., Bellefonte, PA). Using a He mobile phase, the GC thermal programme was 50 °C for 1 min, ramped to 330°C at 20° C min 1 and finally held at 330 °C for 5 min. Upon elution, samples were injected into a Pegasus IV GC-time of flight mass spectrometer (Leco Corp., St Joseph, MI), using mass resolution of 17 spectra s1 , from 80 to 500 Da, at  70 eV ionization energy and 1800 V detector voltage with a 230 °C transfer line and 250°C ion source [[https://doi.org/10.1016/j.soilbio.2020.107758]].\n\n    -- _Protocol steps_\n     - Lyophilization of the samples for 7 days.\n     -Grinding in a stainless steel ball mill Retsch at a frequency of 20 Hz.\n     -The samples were then stored in individual sterile glass vials at -80°C.\n     -The soils were extracted using a 3:3:2 (v/v/v) acetonitrile-isopropanol-water solution. The mixture was vortexed for 15 seconds, shaken at 4°C for 5 minutes, and then centrifuged at 1400 rpm for 2 minutes. Finally, the samples were dried using a CentriVap Benchtop CentriVap.\n2. Prior to use, all glassware was acid-washed (5% HCl, > 24 h) to remove chemical residues, rinsed in HPLC-grade water three times, and subsequently dry heat sterilised (150 °C, 2.5 h) (Jain et al., 2020). All equipment used to process the soil (e.g., tweezers and spatulas) were thoroughly cleaned both before and between samples with deionised water and 70% industrial methylated spirit (IMS) to prevent cross-contamination. Nutrients in the concentrations described in section 2.2 were added by pipette in 1 ml of HPLC-plus grade water (Sigma-Aldrich, Munich, Germany) evenly distributed across the surface of **10 g fresh weight of soil** in 240 ml polypropylene sample containers (Snap-Seal®; Corning, NY, USA). This type of container was used to ensure even coverage of the soil surface with the nutrient solution (soil depth ca. 10 mm). Five independent soil replicates (n = 5) were set up per treatment. Samples were subsequently incubated as described in Section 2.2. At the end of the incubation period, the **soil samples were immediately transferred to 20 ml glass vials and fumigated with ethanol-free chloroform for 24 h** to lyse microbial cells, to increase metabolite yield (Swenson et al., 2015) and limit microbial processing of metabolites, using the method of Vance et al. (1987). After fumigation, samples **were immediately frozen (−80 °C) to quench any residual metabolic and enzymatic activity** (Wellerdiek et al., 2009). From this point onwards, all samples were stored at −80 °C, unless otherwise stated and while being processed (i.e. out of the freezer), samples were kept on ice (4 °C). L**yophilisation of samples (>24 h) was then performed** using a Modulyo Freeze Dryer (ThermoFisher Corp, Waltham, MA) equipped with an RV vacuum pump (Edwards Ltd., Crawley, UK). S**amples were then mechanically ground using a Retsch MM200** stainless steel ball mill (Retsch GmbH, Haan, Germany) **for 60 s at a frequency of 20 Hz** to aid in cell lysis and metabolite recovery and to increase sample homogeneity (Wang et al., 2015; Withers et al., 2020). The ball mill was cleaned thoroughly between samples with HPLC-grade water followed by 70% IMS, to avoid contamination.\nThe following extraction method is based on the hybridised methods of Swenson et al. (2015) and Fiehn et al. (2008). Briefly, we used the extraction method from Swenson et al. (2015) and the solvent makeup (3:3:2) from Fiehn et al. (2008), to ensure broad metabolite coverage, with the recovery of both polar and non-polar metabolite classes. Further, the weight of soil extracted was increased in order to maximise the volume of supernatant available for lyophilisation and subsequent analysis. A pre-experiment was used to compare the efficiency of the metabolite extraction method proposed here to that of the Swenson et al. (2015) method (the results are summarised in supplementary information Section S1).\n\nUpon soil extraction, **6 g of each fumigated, lyophilised**, **ground soil sample was weighed into a 35 ml glass centrifuge tub**e (Kimax®; DWK Life Sciences, Stoke-on-Trent, UK), **to which 24 ml of pre-cooled (−20 °C) acetonitrile (MeCN)/isopropyl alcohol (IPA)/HPLC-plus grade water (H2O) (3:3:2 v/v/v) extractant was added**, using a glass pipette. Samples were then **horizontally shaken on ice (4 °C) at a frequency of 200 Hz for 1 h**, and then c**entrifuged at 3320×g for 15 min** (Swenson et al., 2015). S**upernatants were then transferred**, using glass pipettes, into **20 ml glass vials and stored at −20 °C** (to ensure metabolic activity was quenched but the supernatant was not frozen). Samples were left unfiltered due to the potential of contamination from dissolution of contaminants from the filter paper and plastic housing. **The supernatant was lyophilised in 2 ml glass vials** using a Modulyo Freeze Dryer with RV pump attached to a SpeedVac vacuum concentrator (Savant; ThermoFisher Corp.). **The vials were periodically topped up with the supernatant, taking note of the quantity added (∼15 ml total) and lyophilised to complete dryness.** Samples **were then shipped on dry ice (−78.5 °C)** to Metabolon Inc. (Morrisville, North Carolina, USA) for untargeted LC-MS metabolomic analysis. Upon analysis, **samples were dissolved in methanol:water (4:1 v/v) and subjected to the standard Metabolon sample preparation procedure.** Ultrahigh Performance Liquid Chromatography-Tandem Mass Spectroscopy (UPLC-MS/MS) analysis parameters, bioinformatics, compound ID and data curation are summarised in Supplementary information Section S2 [[https://www.sciencedirect.com/science/article/pii/S003807172200236X]].\n\n\n\n\n\n\n### Composition of culture media, prepared solution supplemented, and chemicals used in the experimental section \n\n_Culture media and solutions_\nStarch casein agar\nsoluble starch: 10 g\n K2HPO4: 2 g\n KNO3: 2 g\nCasein: 0.3 g, \nMgSO4.7H2O 0.05 g\n CaCO3: 0.02 g\n FeSO4.7H2O: 0.01 g\nAgar: 15 g \n_Mineral medium (g/L)_\n(NH)2SO4:  \nKH2PO4, 4\nNa2HPO4:  6;\nMgSO4. 7H2O: 0.2\nCaC12 .2H2O: 0.001 \nFeSO4 - 7 H2O: 0.001\npH 7.5.\n\n\n### you have to do tomorrow \n\n1. Prepare blanks for LC-MS analysis.\n2. check plates. \n3. looking for a protocol to manipulate ecoplate\n\n\n\n### Rima note 12-10-23\n\n\n# I learned how to share image with Dendronn\nctrl+shift+p ![](/assets/images/2023-10-12-09-19-51.png)\n\n\n### Done \n-praparation of blancks for LC-MS analysis \n-boites checked \nToday I observed the appearance of the first actinomycete spores on SCA + ATB plates and a fungus on PDA medium. \n###  Doing\n\nliterature  \n\n\n### ASk PMA\n\norganise a doodle with the soil team \n\n### to do tomorow \n \n -check plates.\n - isolation of same strains with diferent aspects in particular actino and fungi.\n \n #### Today is 13-10-2023 \n   \n   ### To do \n   - Isolation of some strains \n   - read ecoplat papers \n   \n \n\n  ### Done \n  \n  I have isolated actinomycetes on SCA, named S1-S8 (B1, B2 or B3 means they come from the same isolation plate).\n  I've isolated 2 fungi (ch1,Ch2) of different aspect on PDA.   \n\n  ### Program next week\n\n  - LC-MS analysis of the first extraction 9-10-2023.\n  - after the fisrt LC-MS, second extractin with the best prtocol.\n\n  - 17-10-2023 Redrego conf.\n  - 19-10-2023.\n  -18-10-2023 going to the University of Neuchâtel with PMA for collaboration.\n  - Visit Thun city.\n\n  ### Today 16-10-2023\n\n  ## To do \n\n  - LC-MS run with PMA \n  - check plates \n\n\n   ### Done \n   - We submitted the samples containing the blanks from RO_01_07_01 to RO_01_07_10 for LC-MS analysis. However, the profiles obtained are inconclusive. Therefore, the search for other extraction protocols is essential.\n   - I have also isolated two other strains of fungi.\n   - Édouard showed me his DBGI extraction method.\n\n   ### Today 20-10-23\n   - write in the lab notebook\n   - ask PMA if we can launch the vials extracted on 17-10-23\n   - check the strains if further purification is needed   \n### Done \n-Plates sheked\n-transplantation of isolated strains\n  \n\n\n\n\n","n":0.015}}},{"i":110,"$":{"0":{"v":"Pmallard","n":1}}},{"i":111,"$":{"0":{"v":"2025","n":1}}},{"i":112,"$":{"0":{"v":"11","n":1}}},{"i":113,"$":{"0":{"v":"2025-11-05","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2025.11.05\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.137}}},{"i":114,"$":{"0":{"v":"09","n":1}}},{"i":115,"$":{"0":{"v":"2025-09-30","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2025.09.30\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n\nOpen Science workshop at Unifr\n\nTuesday 30 September 2025\n\nhttps://www.unifr.ch/research/fr/openscience/\nhttps://www.openscience.uzh.ch/en/open-science-at-uzh.html\n\nhttps://zenodo.org/records/10066199\n\nhttps://www.unesco.org/en/open-science\n\nhttps://www.unesco.org/en/open-science/toolkit?hub=686\n\nhttps://peercommunityin.org/\n\n\n\nhttps://inveniosoftware.org/\n\n\nhttps://www.rero.ch/produits/sonar\n\nhttps://folia.unifr.ch/\n\n\narks can be nested\n\nhttps://arks.org/\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.126}}},{"i":116,"$":{"0":{"v":"07","n":1}}},{"i":117,"$":{"0":{"v":"2025-07-01","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2025.07.01\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- \n\n### Chat with Scorfi \n\nhttp://www.metabolomexchange.org/site/\n\nhttps://masswiki.metabolomics.us/aOC06HM\n\n\n- Get in touch with MetabolomExchange \n\n- INSDC (https://www.insdc.org/) wants to go [[metabolomics]] -> MetaboBank (https://www.ddbj.nig.ac.jp/metabobank/index-e.html) ... IDF: Investigation Description Format... MAF: metabolite assignment file (https://www.ddbj.nig.ac.jp/metabobank/datafile-e.html#maf)\n\n- [[Thomas Hankemeier]] hankemeier@lacdr.leidenuniv.nl\n\nhttps://www.nature.com/articles/s42255-025-01239-4/figures/1\n\nhttps://github.com/elixir-europe/biohackathon-projects-2025/blob/main/14.md\n\nhttps://github.com/elixir-europe/biohackathon-projects-2025/blob/main/18.md\n\n","n":0.108}}},{"i":118,"$":{"0":{"v":"03","n":1}}},{"i":119,"$":{"0":{"v":"2025-03-10","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.10\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n-","n":0.139}}},{"i":120,"$":{"0":{"v":"2025-03-06","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.06\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\nTrying to fetch Zenodo archive through curl\n\ncurl  https://zenodo.org/api/records/5213015\n\n\ncurl  https://zenodo.org/api/records/10284416\n\nwget https://zenodo.org/api/records/10284416/files/MSV000087728_VGF142_H08_merged_graph_d223bb13f553fb3acd54fe6bcdb44420.ttl.gz/content\n\n\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.127}}},{"i":121,"$":{"0":{"v":"02","n":1}}},{"i":122,"$":{"0":{"v":"2025-02-21","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2025.02.21\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nChat wioth Javier on Scholia\nPossibility to establisha DB of NP isolated in Chili with their geographical occurences.\n\n\nWe start with the example of https://scholia.toolforge.org/chemical/Q82866929\n\nhttps://scholia.toolforge.org/taxon/Q15513067#metabolome\n\nThis one is connected to the GBIF id https://www.gbif.org/species/5343387\n\n\nWe manually created the taxon ranmge properties for this one\n\nhttps://www.wikidata.org/wiki/Q15513067\n\n\nSo now we can check for molecules found in the Astragalus genera for which the taxon range includes Chile.\nhttps://w.wiki/D9aT\n\nWe can observe that few taxa have in fact Chile as a taxonrang https://w.wiki/D9an\n\n\nWe started with Tiago's http://tiago.bio.br/gbif_range_to_wikidata/\n\nLets see how we can use / adapt this for our use case\n\nhttps://api.gbif.org/v1/occurrence/search?taxonKey=212&continent=africa&limit=0&facet=speciesKey&facetMincount=10&facetLimit=5000\n\nFor countries, the url should be encoded\n\nhttps://api.gbif.org/v1/occurrence/search?taxonKey=212&country=CL&limit=0&facet=speciesKey&facetMincount=10&facetLimit=5000\n\n\nWe started to investigate the possibility to map traditional uses from taxon to indegeneous peoples\n\nhttps://www.wikidata.org/wiki/Q158780\n\n\nDiscussing about ethopharmocological KG \n\nhttps://ieeexplore.ieee.org/abstract/document/10443268\nhttps://www.nature.com/articles/s41597-023-02757-0\nhttps://gitub.u-bordeaux.fr/erias/oregano\n\n\n### Directus/Qfield\nWe try to set up a EMI project for Javier (temporary while we have the EMI data portal up and running)\n\n\nWe could create both a qfieldcloud and directus username\nHowever we are stuck at the stage of Project creation (https://emi-collection.unifr.ch/qfieldcloud/admin/core/project/add/) as we cannot setup the owner.\nTo be checked with Edouard.\n\nThis , https://emi-collection.unifr.ch/qfieldcloud/admin/auditlog/logentry/ , for example returns a 500 \n![](/assets/images/2025-02-21-15-03-35.png)\n\n\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.067}}},{"i":123,"$":{"0":{"v":"2025-02-12","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2025.02.12\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\nAlison Bender's Matser thesis presentation\n\nConcept of [eusociality](https://en.wikipedia.org/wiki/Eusociality \"Eusociality \\(Greek εὖ eu \"good\" and social\\) is the highest level of organization of sociality. It is defined by the following characteristics: cooperative brood care \\(including care of offspring from other individuals\\), overlapping generations within a colony of adults, and a division of labor into reproductive and non-reproductive groups. The division of labor creates specialized behavioral groups within an animal society, sometimes called castes. Eusociality is distinguished from all other social systems because individuals of at least one caste usually lose the ability to perform behaviors characteristic of individuals in another caste. Eusocial colonies can be viewed as superorganisms.\nEusociality has evolved among the insects, crustaceans, trematoda and mammals. It is most widespread in the Hymenoptera \\(ants, bees, and wasps\\) and in Blattodea \\(termites\\). A colony has caste differences: queens and reproductive males take the roles of the sole reproducers, while soldiers and workers work together to create and maintain a living situation favorable for the brood. Queens produce multiple queen pheromones to create and maintain the eusocial state in their colonies; they may also eat eggs laid by other females or exert dominance by fighting. There are two eusocial rodents: the naked mole-rat and the Damaraland mole-rat. Some shrimps, such as Synalpheus regalis, are eusocial. E. O. Wilson and others have claimed that humans have evolved a weak form of eusociality. It has been suggested that the colonial and epiphytic staghorn fern, too, may make use of a primitively eusocial division of labor.\")\n\n\n- Do honeypots ants only occur in desert-like environments ?\n\n- You show metabolomics and proteomics differneces on the replete types.\nAre they any behaviour / time differnces. E.g. do clear become amber ?\n\n- Are the replete feeding themselves or are they \"filled\" by others ?\n\n\n\"Label-free metabolite annotation\"\n\nTriglycerides --- long term energy storage\n\n\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.053}}},{"i":124,"$":{"0":{"v":"2024","n":1}}},{"i":125,"$":{"0":{"v":"11","n":1}}},{"i":126,"$":{"0":{"v":"2024-11-28","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.11.28\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n- Meeting with Daniel Probst\n\n### Junction Tree Variational Autoencoder for Molecular Graph Generation\nhttps://arxiv.org/pdf/1802.04364\n\n### Rxn-INSIGHT: fast chemical reaction analysis using bond-electron matrices\nhttps://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00834-z\n\n## Todo tomorrow, one day ... or never \n\n\n### BigSMARTS: A Topologically Aware Query Language and Substructure Search Algorithm for Polymer Chemical Structures\nhttps://pubs.acs.org/doi/10.1021/acs.jcim.3c00978\n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.107}}},{"i":127,"$":{"0":{"v":"10","n":1}}},{"i":128,"$":{"0":{"v":"2024-10-09","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.10.09\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nPreparation of meeting with Chris Steinbeck.\n\nAdriano, Jo.\n\nMain aim of this meeting is to discuss th integration of LOTUS in COCONUT and or the establishment of LOTUS under the revamped .naturalproducts.net domain.\n\nhttps://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/66dee5e212ff75c3a1dbfd54/original/coconut-2-0-a-comprehensive-overhaul-and-curation-of-the-collection-of-open-natural-products-database.pdf\n\nNO mention of the LOTUS project in the paper. Were do the occurence data come from ?\n\nBioschemas ?\nhttps://coconut.naturalproducts.net/api/schemas/bioschemas/CNP0606256.0\n\nThe report compounds / request changes is unclear\n\n![](/assets/images/2024-10-09-14-02-20.png)\n\nhttps://coconut.naturalproducts.net/compounds/CNP0342695.0\n\nCreated one reported for this misspelled species name \nhttps://coconut.naturalproducts.net/dashboard/reports/12\n\n\n\n\n### Previous meeting with Jo \n\nLOTUS data \n\nWe keep a RAW LOTUS composed of \n\n- Wikidata QID for chemical structures\n- Wikidata QID for biological entities\n- Wikidata QID for references\n\nWe extract one item per WD QID.\n\n- Isomeric SMILES for chemical structures\n- Taxon name for biological entities\n- DOI for references\n\nWe rely on COCONUT enrichers to do the rest of the job for chemical structures.\n\nWe bring our workflow for biological entities and references.\n\nWe need all entities to be linked to Wikidata.\n\n\nTwo solutions :\n\n- Or we have a https://coconut.naturalproducts.net and a https://lotus.naturalproducts.net but if they are no taxonomical info in the COCONUT part.\n\n- Or we have a single https://coconut.naturalproducts.net with all the info, including the taxonomical info. But in this case no https://lotus.naturalproducts.net\n\n- In both cases we benefit from the edit/update mechanisms of COCONUT and use these to further edit WD.\n\n\n\n\n\n## Paused\n\n## Done\n\nPushed small script to fetch LOTUS info https://github.com/lotusnprod/wd-lotus-scripts\n\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.062}}},{"i":129,"$":{"0":{"v":"04","n":1}}},{"i":130,"$":{"0":{"v":"2024-04-30","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.04.30\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nMeeting with Pascal on the hypothetical structures generation\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.129}}},{"i":131,"$":{"0":{"v":"2024-04-11","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.04.11\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n\nPresentation by Marco on AI\n\nThree types of ML\n\n- Supervised\n- Unsupervised\n- Reinforcement\n\n### Supervised learning \n\n- Regression\n\nYour output is a continuous value\n\n- Classification\n\n### Reinforcement learning\n\nLearn from mistakes\n\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.114}}},{"i":132,"$":{"0":{"v":"2024-04-04","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.04.04\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nsirius -i /home/allardpm/git_repos/mapp-metabolomics/laure-weisskopf-group/docs/mapp_project_00016/mapp_batch_00060/results/mzmine/mapp_batch_00060_sirius.mgf --output /home/allardpm/git_repos/mapp-metabolomics/laure-weisskopf-group/docs/mapp_project_00016/mapp_batch_00060/results/sirius/mapp_batch_00060 --maxmz 800  config --IsotopeSettings.filter=true --FormulaSearchDB=BIO --Timeout.secondsPerTree=0 --FormulaSettings.enforced=HCNOP --Timeout.secondsPerInstance=0 --AdductSettings.detectable=[[M+H3N+H]+,[M+Na]+,[M-H4O2+H]+,[M+K]+,[M-H2O+H]+,[M+H]+] --UseHeuristic.mzToUseHeuristicOnly=650 --AlgorithmProfile=orbitrap --IsotopeMs2Settings=IGNORE --MS2MassDeviation.allowedMassDeviation=5.0ppm --NumberOfCandidatesPerIon=1 --UseHeuristic.mzToUseHeuristic=300 --FormulaSettings.detectable=Cl,Br,S --NumberOfCandidates=10 --ZodiacNumberOfConsideredCandidatesAt300Mz=10 --ZodiacRunInTwoSteps=true --ZodiacEdgeFilterThresholds.minLocalConnections=10 --ZodiacEdgeFilterThresholds.thresholdFilter=0.95 --ZodiacEpochs.burnInPeriod=2000 --ZodiacEpochs.numberOfMarkovChains=10 --ZodiacNumberOfConsideredCandidatesAt800Mz=50 --ZodiacEpochs.iterations=20000 --AdductSettings.enforced=, --AdductSettings.fallback=[[M+Na]+,[M+K]+,[M-H2O+H]+,[M+H]+] --FormulaResultThreshold=true --InjectElGordoCompounds=true --StructureSearchDB=BIO --RecomputeResults=false formula zodiac fingerprint structure canopus write-summaries\n\nRelaunching with\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.103}}},{"i":133,"$":{"0":{"v":"03","n":1}}},{"i":134,"$":{"0":{"v":"2024-03-29","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.03.29\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nStruglling to serialize a .yaml, hash the contents, and save the hash + serialized contents to  a tsv file.\n\nLets work with minimal examples\n\n```yaml\nmapp_project : mapp_project_00017\n\noptions:\n  gnps_column_for_boxplots : \n    factor_name : 'process'\n\nfilter_sample_type :\n  mode : 'include'\n  factor_name : 'sample_type'\n  levels :\n   - 'BK' \n   - 'BLANK'\n```\n\n\n```yaml\nmapp_project : mapp_project_00017\n\noptions:\n  gnps_column_for_boxplots : \n    factor_name : 'process'\n\nfilter_sample_type :\n  mode : 'include'\n  factor_name : 'sample_type'\n  levels :\n   - 'BK' \n   - 'QC'\n```\n\nShould yield as tsv\n\nmapp_project\toptions.gnps_column_for_boxplots.factor_name\tfilter_sample_type.mode\tfilter_sample_type.factor_name\tfilter_sample_type.levels\thash\nmapp_project_00017\tprocess\tinclude\tsample_type\tBK, BLANK\t<hash>\nmapp_project_00017\tprocess\tinclude\tsample_type\tBK, QC\t<hash>\n\nPlease propose me a mechansim in R to do this.\n\n```r\n\nlibrary(yaml)\nlibrary(digest)\n\n# Read the yaml files\n\nyaml1 <- yaml::read_yaml('file1.yaml')\nyaml2 <- yaml::read_yaml('file2.yaml')\n\n# Serialize the yaml files\n\nyaml1_serialized <- yaml::as.yaml(yaml1)\nyaml2_serialized <- yaml::as.yaml(yaml2)\n\n# Hash the serialized yaml files\n\nhash1 <- digest::digest(yaml1_serialized)\nhash2 <- digest::digest(yaml2_serialized)\n\n# Save the hash and the serialized yaml files to a tsv\n\n\n \n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.077}}},{"i":135,"$":{"0":{"v":"2024-03-26","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.03.26\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nChecking [[people.marco-visani]] experiment text at [[fundings.experiment.mvisani]]\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.131}}},{"i":136,"$":{"0":{"v":"2024-03-25","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.03.25\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n- Conversation Regine Maritz (Open Research Data enquiry)\n\n- small workshop within UniFr\n\n- Landscape of OS practice in UniFr. What is done yet ? What are the needs ?\nWhat are the different approaches across fields \n\nhttps://www.unifr.ch/research/en/news-events/news/30479/?utm_source=news&utm_medium=&utm_campaign=redirection_from_homehttp%3A%2F%2Fwww.unifr.ch%2Fresearch%2Fen%2F\n\n- 3 hours workshop\n\nShe will recontact us with a doodle, possibly between mid may and end of may\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.098}}},{"i":137,"$":{"0":{"v":"2024-03-20","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.03.20\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nTroubleshooting the broken login and ssh connection to the server after NVIDIA drivers update\n\nWe get help from chatGPT \n\nhttps://chat.openai.com/share/c937af37-28e4-4d35-a337-563a19987a71\n\n\n\nhttps://askubuntu.com/questions/1491769/ubuntu-22-04-freezing-in-login-screen-after-graphic-drivers-change-attempt\n\n\nThis saved us !!!\nhttps://chat.openai.com/share/4852d834-0918-4f10-b366-c748bc468368\n\n\nsudo systemctl status zfs-import-cache\nsudo systemctl status zfs-import.target\n\nsudo systemctl start zfs-import-cache\nsudo systemctl start zfs-import.target\n\nsudo zpool import\n\n\nsudo zpool import [pool_name]\n\nin our case (DATA)\n\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.103}}},{"i":138,"$":{"0":{"v":"2024-03-19","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.03.19\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nPoint [[people.pascal-amrein]]\n\n- LOTUS subset extractor\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.132}}},{"i":139,"$":{"0":{"v":"2024-03-18","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.03.18\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n-","n":0.139}}},{"i":140,"$":{"0":{"v":"2024-03-17","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.03.17\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\nlooking for a way to copy very large dir (with a high number of files and nested dir) efficiently\n\nInstalled rust-based  cpz https://github.com/SUPERCILEX/fuc\n\n\nhttps://basila.medium.com/fastest-way-to-copy-a-directory-in-linux-40611d2c5aa4\n\ncd /path/to/SOURCE_FOLDER; tar cf - . | (cd /path/to/DESTINATION_FOLDER; tar xvf -)\n\nProgress bars are good for mental sanity in these cases ...\n\n\ncp -r ./pf1600_sub ./pf_1600_test | pv -lep -s $(du -sb ./pf1600_sub | awk '{print $1}') >/dev/null\n\ncp -r /path/to/source /path/to/destination | bar\n\nrsync -aP ./pf1600_sub ./pf_1600_test\n\ntime rsync -avh --progress VGF157 VGF157_test_rsync\n\n\n\ntime cpz VGF157/ VGF157_test_it\n\n\ntar -cf - ./pf1600_raw | pv -s $(du -sb ./pf1600_raw | awk '{print $1}') | gzip > pf1600_raw.tar.gz\n\n\n\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.084}}},{"i":141,"$":{"0":{"v":"2024-03-08","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.03.08\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nMeeting Marco\n\n- Nextflow within the metabocore-igniter\nhttps://github.com/nf-core/metaboigniter/tree/2.0.0\n\n- Textes funding pour experiment.com\n\n\n- News prediction and streamlit anticipated LOTUS ()\nhttp://134.21.20.118:8501/\n\n\nWe start from https://pubs.acs.org/doi/epdf/10.1021/acs.jnatprod.3c00838\nhttps://decimer.ai/\n\nDisplay probabilities of the putative molecules as a barplot on a phylogenetic tree\n\nSee https://tb-gen.streamlit.app/~/+/ \n\nMaybe it will require to use Dash \nhttps://dash.plotly.com/cytoscape/biopython\n\nAdd filter in headers possibility https://discuss.streamlit.io/t/filtering-columns-by-header-name/5946\n\n\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.102}}},{"i":142,"$":{"0":{"v":"2024-03-05","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.03.05\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nSetting up the Vinesh bioblitz with Donat\nhttps://zenodo.org/communities/taxodros/records?q=&l=list&p=1&s=10\n\nDonat \nDonat dit:\nhttps://zenodo.org/communities/taxodros/records?q=&l=list&p=1&s=10\n \nDonat dit: Hans-Peter Wymann < wymann.hp@gmail.com > \n\nJacqueline \n\nUrs Shafner\n\n1. Maker sure to have a pdf of all interesting paper\n\n2. \n\nhttps://zenodo.org/records/10730668\n\nDonat dit: willi egloff (Vice Director in Plazi) \n\nWilli Egloff < egloff_bader@bluewin.ch >\n\nAdriano mentionned https://scholar.archive.org/\n\nhttps://guide.fatcat.wiki/welcome.html\n\n\n\n\n\n### Fundings\n\nDaniel proposed that we apply to https://novartisgrants.smapply.io/protected/r/FkmBTc_C-GJ6iD28zx8OmMze2keciHs_lu3rFRwX-rYsg6IyK42CanVr8_ihr91kWQSp6rJHDLKb4xWFPTXiZw==/FreeNovation_2024_Call_English.pdf\n\nTo the roots: Mathematics to address biology\n\nCheck what are the implication of a Novartis funding.\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.092}}},{"i":143,"$":{"0":{"v":"2024-03-04","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.03.04\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n### Launching Sirius on Ola's dataset\n\n- Not sure what the duplicated feature id problem was again or where it came from.\nRelaunching the biostat tool box to double check.\n\nTypical command would be \n\n```bash\nsirius -i tests/data/input_sirius.mgf --output tests/data/output_sirius --maxmz 800 config --IsotopeSettings.filter=true --FormulaSearchDB=BIO --Timeout.secondsPerTree=0 --FormulaSettings.enforced=HCNOP --Timeout.secondsPerInstance=0 --AdductSettings.detectable='[[M+H]+,[M-H4O2+H]+,[M+Na]+,[M+K]+,[M+H3N+H]+,[M-H2O+H]+]' --UseHeuristic.mzToUseHeuristicOnly=650 --AlgorithmProfile=orbitrap --IsotopeMs2Settings=IGNORE --MS2MassDeviation.allowedMassDeviation=5.0ppm --NumberOfCandidatesPerIon=1 --UseHeuristic.mzToUseHeuristic=300 --FormulaSettings.detectable=B,Cl,Br,Se,S --NumberOfCandidates=10 --ZodiacNumberOfConsideredCandidatesAt300Mz=10 --ZodiacRunInTwoSteps=true --ZodiacEdgeFilterThresholds.minLocalConnections=10 --ZodiacEdgeFilterThresholds.thresholdFilter=0.95 --ZodiacEpochs.burnInPeriod=2000 --ZodiacEpochs.numberOfMarkovChains=10 --ZodiacNumberOfConsideredCandidatesAt800Mz=50 --ZodiacEpochs.iterations=20000 --AdductSettings.enforced=, --AdductSettings.fallback='[[M+H]+,[M+Na]+,[M+K]+]' --FormulaResultThreshold=true --InjectElGordoCompounds=true --StructureSearchDB=BIO --RecomputeResults=false formula zodiac fingerprint structure canopus write-summaries\n```\n\n\nFirst we make sure to log via \n\nsirius login --user-env SIRIUS_USERNAME --password-env SIRIUS_PASSWORD\n\n\nsirius -i /home/allardpm/git_repos/mapp-metabolomics/laure-weisskopf-group/docs/mapp_project_00016/mapp_batch_00060/results/mzmine/mapp_batch_00060_sirius.mgf --output /home/allardpm/git_repos/mapp-metabolomics/laure-weisskopf-group/docs/mapp_project_00016/mapp_batch_00060/results/sirius/mapp_batch_00060 --maxmz 800  config --IsotopeSettings.filter=true --FormulaSearchDB=BIO --Timeout.secondsPerTree=0 --FormulaSettings.enforced=HCNOP --Timeout.secondsPerInstance=0 --AdductSettings.detectable=[[M+H3N+H]+,[M+Na]+,[M-H4O2+H]+,[M+K]+,[M-H2O+H]+,[M+H]+] --UseHeuristic.mzToUseHeuristicOnly=650 --AlgorithmProfile=orbitrap --IsotopeMs2Settings=IGNORE --MS2MassDeviation.allowedMassDeviation=5.0ppm --NumberOfCandidatesPerIon=1 --UseHeuristic.mzToUseHeuristic=300 --FormulaSettings.detectable=Cl,Br,S --NumberOfCandidates=10 --ZodiacNumberOfConsideredCandidatesAt300Mz=10 --ZodiacRunInTwoSteps=true --ZodiacEdgeFilterThresholds.minLocalConnections=10 --ZodiacEdgeFilterThresholds.thresholdFilter=0.95 --ZodiacEpochs.burnInPeriod=2000 --ZodiacEpochs.numberOfMarkovChains=10 --ZodiacNumberOfConsideredCandidatesAt800Mz=50 --ZodiacEpochs.iterations=20000 --AdductSettings.enforced=, --AdductSettings.fallback=[[M+Na]+,[M+K]+,[M-H2O+H]+,[M+H]+] --FormulaResultThreshold=true --InjectElGordoCompounds=true --StructureSearchDB=BIO --RecomputeResults=false formula zodiac fingerprint structure canopus write-summaries\n\nWriting the command I realize that initially I might have `sirius -i /home/allardpm/git_repos/mapp-metabolomics/laure-weisskopf-group/docs/mapp_project_00016/mapp_batch_00060/results/mzmine`, thereby specifying a whole directory instead of a file. This might be the source of the problem. I will relaunch the command with the correct input file. `sirius -i /home/allardpm/git_repos/mapp-metabolomics/laure-weisskopf-group/docs/mapp_project_00016/mapp_batch_00060/results/mzmine/mapp_batch_00060_sirius.mgf`\n\n\nI also realized another thing. The --RecomputeResults=false will only be effective if the input is changed to the previously computed directory. It seams obvious now that I think about it but since the commond doesnt throws an exception I didn't realize it. See https://github.com/boecker-lab/sirius/issues/69#issuecomment-1098053079\n\nWe had some awk commands which we cant find again.\n\nMooved to [[awk]]\n\ncanopus_compound_summary.tsv > prefixed_canopus_compound_summary.tsv\n\n\nawk -F'\\t' 'BEGIN {OFS=\"\\t\"} NR==1 {for (i=1; i<=NF; i++) $i = \"canopus_\" $i} {print}' canopus_compound_summary.tsv > prefixed_canopus_compound_summary.tsv\n\nawk -F'\\t' 'BEGIN {OFS=\"\\t\"} NR==1 {for (i=1; i<=NF; i++) $i = \"sirius_\" $i} {print}' compound_identifications.tsv > prefixed_compound_identifications.tsv\n\nawk -F'\\t' 'BEGIN {OFS=\"\\t\"} NR==1 {for (i=1; i<=NF; i++) $i = \"dbresults_gnps_\" $i} {print}' e18c64bf354f457bb534c513821f7426.tsv > e18c64bf354f457bb534c513821f7426_prefixed.tsv\n\n\nawk -F'\\t' 'BEGIN {OFS=\"\\t\"} NR==1 {for (i=1; i<=NF; i++) $i = \"gnps_\" $i} {print}' 0735059ee1034ad58a3861c2630e593f.tsv > 0735059ee1034ad58a3861c2630e593f_prefixed.tsv\n\nawk -F'\\t' 'BEGIN {OFS=\"\\t\"} NR==1 {for (i=1; i<=NF; i++) $i = \"met_annot_enhancer_\" $i} {print}' mapp_batch_00060_spectral_match_results_repond.tsv > mapp_batch_00060_spectral_match_results_repond_prefixed.tsv\n\n\n### Meeting Eliane Garo\n\nMalik and Eliane\n\nInfo Orbitrap\n\n- QE HF-X\n\n2576 extracts\n\nMeOH \n\nSplitter UHPLC with UV\n\nWaters 50 mm \n\n\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.052}}},{"i":144,"$":{"0":{"v":"02","n":1}}},{"i":145,"$":{"0":{"v":"2024-02-20","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.02.20\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n### Training Pascal\nDendron training with [[people.pascal-amrein]]\n\nShared https://doi.org/10.5281/zenodo.8137605\n\nWe'll work at https://github.com/orgs/commons-research/projects/2\n\n\n\n\n### MIBIG workshop\n\nMiBIG workshop \nMIBIG started in 2015 \nhttps://mibig.secondarymetabolites.org/\n\nApparently had some notes over there [[projects.commons-public.wikidata.mibig]]\n\nInteroperable with\n\n- npatlas\n- GNPS\n- Rhea\n\nLaunching MiBIG 4.0 \n3 annotathon rounds\n\nSubstantial contribution : actively participating in at least 2-hour annotathon sessions or equivalent (reviewing entries, writing)\n\n\nMiBIG organization team\nCoordinators\nInterest groups\n\nMIBIG 4.0 Data Standard\n\n- separate between biosynthesis vs. compound classification\n- use controlled vocabulary where possible\n- keep citations close to claims\n- keep related data points together\n- make parts of the schema reusable elsewhere \n\n- More DB cross links (e.g. MITE db) https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2376-y\n\n[operon](https://en.wikipedia.org/wiki/Operon \"In genetics, an operon is a functioning unit of DNA containing a cluster of genes under the control of a single promoter. The genes are transcribed together into an mRNA strand and either translated together in the cytoplasm, or undergo splicing to create monocistronic mRNAs that are translated separately, i.e. several strands of mRNA that each encode a single gene product. The result of this is that the genes contained in the operon are either expressed together or not at all. Several genes must be co-transcribed to define an operon.Originally, operons were thought to exist solely in prokaryotes \\(which includes organelles like plastids that are derived from bacteria\\), but their discovery in eukaryotes was shown in the early 1990s, and are considered to be rare. In general, expression of prokaryotic operons leads to the generation of polycistronic mRNAs, while eukaryotic operons lead to monocistronic mRNAs.\nOperons are also found in viruses such as bacteriophages. For example, T7 phages have two operons. The first operon codes for various products, including a special T7 RNA polymerase which can bind to and transcribe the second operon. The second operon includes a lysis gene meant to cause the host cell to burst.\")\n\n\nMITE minimum information about a tailoring enzyme/maturase\n\n\nDuring this meeting, we will inform you about the scope and focus of the annotathons, some organizational improvements, and our upcoming MIBiG Online Submission system. We will also discuss the new roles of Coordinators and Reviewers in detail. Make sure to tune in!\n\nWe also want to announce the dates of the annotathons. Please bear in mind that for co-authorship on the next MIBiG publication, participation in at least two 3-hour annotathon sessions (or an equivalent contribution) is necessary. The MIBiG annotathon dates are:\n\n    • March 19th 7 am – 10 pm and 4 pm – 7 pm (GMT)\n    • April 23rd 7 am – 10 pm and 4 pm – 7 pm (GMT)\n    • May 14th 7 am – 10 pm and 4 pm – 7 pm (GMT)\n\nFurther, we want to make a call for contributions to our MIBiG Literature table (http://tinyurl.com/mibig-literature). In this table, we are collecting recent publications on biosynthetic gene cluster that are currently missing in the MIBiG database, but also publications that report additional information on already existing MIBiG entries. This collection of publications will be used as a starting point during the annotathons. If you have publications that you want to see covered during the annotathons, please feel free to add them to the table. We have prepared an explanatory document in case of any uncertainties (http://tinyurl.com/mibig-literature-explanation). \n\nColleagues who have indicated to be interested in acting as Coordinators or Reviewers will receive an additional email about these roles in the next few days.\n\nWe are looking forward to welcome you at the Kickoff meetings!\n\nKind regards, \n\nMarnix Medema, Mitja Zdouc, and the MIBiG team\n\n\nThey mention the https://www.contributor-covenant.org/\n\n\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.04}}},{"i":146,"$":{"0":{"v":"2024-02-19","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.02.19\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- Cmd+shift+L flags/un-flags an mail in Mail (MacOS)\n- https://github.com/mikefarah/yq is a lightweight and portable command-line YAML, JSON and XML processor. yq uses jq like syntax but works with yaml files as well as json, xml, properties, csv and tsv. It doesn't yet support everything jq does - but it does support the most common operations and functions, and more is being added continuously.","n":0.094}}},{"i":147,"$":{"0":{"v":"2024-02-16","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.02.16\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n(shifting to the commons-open-notebook by default ...)\nExpect to find passwords to bank account and other surprises here ... #.env \n\nAssisting https://www.spettrometriadimassa.it/Congressi/4MSNatMed/index.html\n\n\nInstitute of biomolecular chenmistry\n\nDirector [Institute of biomolecular chemistry](https://www4.na.icb.cnr.it/en/) (Prof. ANGELO FONTANA Professore di Chimica Organica) is presenting\nMarine Nat prod chemist\n\n\n- https://www.toscanalifesciences.org/it/\n\n\n\n\n\nhttps://www4.na.icb.cnr.it/en/research/research-activities/nature-and-environment/\n\nSulfavant A\nhttps://www.unicampus.it/en/research-project/sulfavant-aa-new-marine-derived-compound-for-targeting-neuroinflammation-in-alzheimer%27s-disease/\n\nhttps://link.springer.com/article/10.1007/s00018-022-04297-z\n\n\n![](/assets/images/2024-02-16-10-12-52.png)\n\n\nNo wikipedia nor wikidata entry for this.\nhttps://www.mdpi.com/1660-3397/15/9/288 (uploaded to decimer)\n\n\nDecimer returns GDDVJRRNJOLGDY-KCJHKMSFSA-M\n\nCCCCCCCCCCCCCCCCCC(=O)OCC(CO[C@H]1C([C@H]([C@H](C(CS(=O)(=O)[O-])O1)O)O)O)OC(=O)CCCCCCCCCCCCCCCCC\n\nhttps://pubchem.ncbi.nlm.nih.gov/#query=GDDVJRRNJOLGDY-KCJHKMSFSA-M\n\nYields no results\n\nhttps://www.chemspider.com/InChI.asmx?op=SMILESToInChI\n\nInChI=1S/C45H86O12S/c1-3-5-7-9-11-13-15-17-19-21-23-25-27-29-31-33-40(46)54-35-38(36-55-45-44(50)43(49)42(48)39(57-45)37-58(51,52)53)56-41(47)34-32-30-28-26-24-22-20-18-16-14-12-10-8-6-4-2/h38-39,42-45,48-50H,3-37H2,1-2H3,(H,51,52,53)/p-1/t38?,39?,42-,43-,44?,45+/m0/s1\n\nGDDVJRRNJOLGDY-KCJHKMSFSA-M\n\n\n\n\n## Notes\n\n\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.097}}},{"i":148,"$":{"0":{"v":"2024-02-15","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.02.15\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n\nAdpating tutorial at[[ressources.datasette]] to an inat exported data set\n\nsqlite-utils insert inat.db locations \\\n  2024_02_14_inat_output.csv --csv -d\n\n\nsqlite-utils schema inat.db\n\nsqlite-utils tables inat.db --counts\n\nsqlite-utils tables inat.db --counts -t\n\n\nsqlite-utils inat.db \"select * from locations limit 4\"\n\nsqlite-utils inat.db \"select * from observations limit 1\"\n\nsqlite-utils inat.db -t \\\n  \"select id, captive, uri, location from observations limit 10\"\n\nsqlite-utils convert inat.db observations location \\\n'bits = value.split(\",\")\nreturn {\n  \"latitude\": float(bits[0]),\n  \"longitude\": float(bits[1]),\n}' --multi\n\n\n## Paused\n\n## Done\n\n## Notes\n\nhttps://simonwillison.net/2023/Jun/18/symbex/\n\n\nCreated [[resources.datasette]]\n\n\nAssisting https://www.spettrometriadimassa.it/Congressi/4MSNatMed/index.html\n\nPresented https://doi.org/10.5281/zenodo.10663625\n\nNotes : \n\n\n- Valorisation of tomato leaves phytochemicals\nThey use a \"Natural products workflow\" from Compound Discoverer, this apparently comes with FoodDB included \n\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- https://llm.datasette.io/en/stable/index.html allows you to run LLM locally \n\nSee ex :\n\n```\ncat inat_fetcher.py | llm summarize\n```\n\n- https://kagi.com/ is a mind-blowing search engine\n\n- https://book.mwmbl.org/page/progress/ they are building the best search engine in the world .... and they are 1.2134 % task completed ! Thk Adriano  @adafede (checking what happens if I mention a github user from a Dendron note .... most likely nothing) for the pointer\n\n- https://tapas.knowledgepixels.com/tapas.html?api=knowledgepixels/nanopub-query-api&op=/get-subj-refs&autosubmit=on&param_subj=https://doi.org/10.1038/sdata.2016.18\n\nhttps://tapas.knowledgepixels.com/tapas.html?api=knowledgepixels/nanopub-query-api","n":0.07}}},{"i":149,"$":{"0":{"v":"2024-02-14","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.02.14\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n- looking at the way to define synonymy across taxa in WD\n- looking at the way to push a paper from its DOI to WD\n\n- checking BAM paper https://www.biorxiv.org/content/10.1101/2024.02.04.578795.abstract\n\n## Paused\n\n## Done\n\n- created the https://www.wikidata.org/wiki/Q124533285\n\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- https://sourcemd.toolforge.org/ is the tool to add a scientific paper to WD (had lost this one)\n- The Old version is the working one https://sourcemd.toolforge.org/index_old.php \n- Copy pasting one DOI in Scholia is also a way (Thnaks Adriano !)\n\n- Its possible to suggest functions at https://www.wikifunctions.org/wiki/Wikifunctions:Suggest_a_function\n\n","n":0.089}}},{"i":150,"$":{"0":{"v":"2024-02-06","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.02.06\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.137}}},{"i":151,"$":{"0":{"v":"01","n":1}}},{"i":152,"$":{"0":{"v":"2024-01-22","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.01.22\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nSome procrastination on https://gothenburgbitfactory.github.io/taskserver-setup/\n\n\nBy default, Taskserver uses port 53589. You can choose any port you wish, provided it is unused. If you choose a port number that is under 1024, then Taskserver must run as root, which is not recommended.\n\nCreating a new user and group on the COMMONS server for taskserver\n\n\ntaskd add user 'Public' 'First Last' (doesnt works)\nsudo taskd add user 'Public' 'First Last' --data /var/taskd (works)\n\ntask_server_user@biolpc045600:~$ sudo taskd add user 'Public' 'First Last' --data /var/taskd\nNew user key: 6240d660-30d9-4ab8-bdbe-d3d6b91f1944\nCreated user 'First Last' for organization 'Public'\n\ntask config taskd.credentials -- Public/First Last/6240d660-30d9-4ab8-bdbe-d3d6b91f1944\n\n\n\nhttps://github.com/ogarcia/docker-taskd\n\n\ndocker run -d \\\n  --name=taskd \\\n  -e CERT_BITS=4096 \\\n  -e CERT_EXPIRATION_DAYS=365 \\\n  -e CERT_ORGANIZATION=\"COMMONS Lab Task server\" \\\n  -e CERT_CN=localhost \\\n  -e CERT_COUNTRY=CH \\\n  -e CERT_STATE=\"Fribourg\" \\\n  -e CERT_LOCALITY=\"Fribourg\" \\\n  -p 53589:53589 \\\n  -v /home/task_server_user/taskd:/var/taskd \\\n  ghcr.io/connectical/taskd\n\n\ndocker exec -t -i \\\n  86d94d29ed51c8c6230bc29bc0b2754297233e6a9d76c7dd3fd67813e2f82044 sh\n  \n\nNew user key: ae500061-a550-4dae-9b74-fa6a2b012c91\nCreated user 'First Last' for organization 'Public'\n\ntask config taskd.credentials -- Public/First Last/ae500061-a550-4dae-9b74-fa6a2b012c91\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.071}}},{"i":153,"$":{"0":{"v":"2024-01-16","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2024.01.16\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\nPeeking into another resource than the Rustlings https://rust-book.cs.brown.edu/\n\n\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.13}}},{"i":154,"$":{"0":{"v":"2023","n":1}}},{"i":155,"$":{"0":{"v":"11","n":1}}},{"i":156,"$":{"0":{"v":"2023-11-27","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.11.27\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- o","n":0.137}}},{"i":157,"$":{"0":{"v":"09","n":1}}},{"i":158,"$":{"0":{"v":"2023-09-28","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.09.28\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nhttps://www.thuenen.de/en/institutes/climate-smart-agriculture/laboratory-department/microcosm-facility\nin [[projects.commons-public.microcosmics.ressources]]\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.137}}},{"i":159,"$":{"0":{"v":"2023-09-26","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.09.26\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nChat with Rima\n[[projects.commons-public.microcosmics]]\n\n[[projects.commons-public.microcosmics.historic]]\n\n## Paused\n\n\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.136}}},{"i":160,"$":{"0":{"v":"2023-09-22","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.09.22\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nDiscussion with Rima on the [[projects.commons-public.microcosmics]] project\n\nRima found a paper on continuous flow cultivation systems.\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.123}}},{"i":161,"$":{"0":{"v":"2023-09-20","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.09.20\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nMeeting with Rima and setting up the next task to tackle in the frame of the [[projects.commons-public.microcosmics]]\n\nI have set up a Github projects in order to centralize tasks in the frame oif this project https://github.com/orgs/commons-research/projects/1\n\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.108}}},{"i":162,"$":{"0":{"v":"2023-09-02","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.09.02\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n2023-09-02 07:27\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.137}}},{"i":163,"$":{"0":{"v":"08","n":1}}},{"i":164,"$":{"0":{"v":"2023-08-29","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.08.29\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\nscratch_nt\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- \n\n","n":0.137}}},{"i":165,"$":{"0":{"v":"2023-08-22","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.08.22\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\nReading [[people.rima-ouchene]] proposition.\nRima will join the lab starting September for a 3 months internship. The idea was to work on the somewhat archived (for now) Mircocosmics projects.\nAnd for her to get familiar with open science and metabo/computational metabolomics approaches.\n\nStarting a Micrcocosmics project. Over here [[project.microcosmics]].\n\nRima proposed some ideas to think about https://docs.google.com/document/d/1Sub8ccgML1JCPGMOg2srQmUXQMBdrnj5/edit\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.099}}},{"i":166,"$":{"0":{"v":"07","n":1}}},{"i":167,"$":{"0":{"v":"2023-07-29","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.07.29\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n2023-07-29 11:29\n\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.137}}},{"i":168,"$":{"0":{"v":"2023-07-28","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.07.28\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.139}}},{"i":169,"$":{"0":{"v":"2023-07-25","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.07.25\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n2023-07-25 09:06\n\n\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.137}}},{"i":170,"$":{"0":{"v":"2023-07-08","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.07.08\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n2023-07-08 08:16\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.137}}},{"i":171,"$":{"0":{"v":"2023-07-05","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.07.05\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.139}}},{"i":172,"$":{"0":{"v":"2023-07-04","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.07.04\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n2023-07-04 08:11\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.137}}},{"i":173,"$":{"0":{"v":"2023-07-01","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.07.01\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n2023-07-01 17:50\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.137}}},{"i":174,"$":{"0":{"v":"06","n":1}}},{"i":175,"$":{"0":{"v":"2023-06-27","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.06.27\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n2023-06-27 18:16\n2023-06-27 18:34\n\n\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.136}}},{"i":176,"$":{"0":{"v":"2023-06-26","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.06.26\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n2023-06-26 21:59\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.137}}},{"i":177,"$":{"0":{"v":"2023-06-24","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.06.24\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\n2023-06-24 18:52\n2023-06-24 19:09\n\n\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.136}}},{"i":178,"$":{"0":{"v":"2023-06-23","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.06.23\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n### Daily work on the Open Science for natural products research Viewpoint\n\nSee [[viewpoint]]\n\nStarted at 2023-06-23 15:11\nFinished at 2023-06-23 15:28\n\n\n\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.131}}},{"i":179,"$":{"0":{"v":"2023-06-22","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.06.22\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\n### \n2023-06-22 07:34\n\nI have been contacted by an editor of Natural Products Reports proposing to write a Viewpoint paper on Open Science in natural products research.\nI am interested but have some fear in committing to yet another project given the current list of running tasks.\n\nI have decide to give it a try but following this method.\nI'll work on this project by small chunks of 15 min daily. No more, no less. This will also be a methodological experiment.\n\nGot inspired by this article in Science (find ref)\n\n### Plan\n\nToday I'll set up the template for note taking for this project and will answer the email of the editor.\nActually I might not need to create yet another daily template. And will keep notes in this one.\n\nDrafting notes there [[viewpoint]].\n\nEmail sent.\n\n2023-06-22 07:44\n\n\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.077}}},{"i":180,"$":{"0":{"v":"2023-06-13","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.06.13\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- Remove last chracter from excel cell\n\n=LEFT(C2,LEN(C2)-1)\n\nTo keep just the first character\n\n =LEFT(A2,4)","n":0.139}}},{"i":181,"$":{"0":{"v":"2023-06-02","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.06.02\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\nPoint Arnaud ENPKG\n\n- batch dl of git repos\n- batch upload to Zenodo\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.14}}},{"i":182,"$":{"0":{"v":"05","n":1}}},{"i":183,"$":{"0":{"v":"2023-05-30","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.05.30\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\nActivity report and was browsing Marco's note.\nWent for some papers on image reconstructiuon from partial inputs \n\n\nImage reconstruction from partial subband images and its application in packet video transmission\nhttps://doi.org/10.1016/0923-5965(91)90010-Y\n\nhttps://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-020-06892-5\n\nPhylogenetic imputation of plant functional trait databases\nhttps://onlinelibrary.wiley.com/doi/abs/10.1111/j.1600-0587.2013.00528.x\nCheck citing articles https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1600-0587.2013.00528.x\n\n\nhttps://digitalcommons.aaru.edu.jo/cgi/viewcontent.cgi?article=1019&context=fej\n\nhttps://arxiv.org/pdf/2303.11396.pdf\n\nA real data-driven simulation strategy to select an imputation method for mixed-type trait data\nhttps://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010154\n\nUsing phylogenetic information to impute missing functional trait values in ecological databases\nhttps://www.sciencedirect.com/science/article/pii/S1574954121001060\n\n\nMachine learning based imputation techniques for estimating phylogenetic trees from incomplete distance matrices\nhttps://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-020-06892-5\n\nA General Method for Simultaneously Accounting for Phylogenetic and Species Sampling Uncertainty via Rubin’s Rules in Comparative Analysis \n https://doi.org/10.1093/sysbio/syy089\n\nHandling missing values in trait data\n https://onlinelibrary.wiley.com/doi/pdf/10.1111/geb.13185\n\nmbImpute: an accurate and robust imputation method for microbiome data\nhttps://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02400-4\nhttps://github.com/ruochenj/mbImpute\n\n\n## ChatGPT exchanges leading to the previous selected papers\n\n\nWhat are the methods to construct (infer or expand) a full image from partial inputs (bits of the big picture). These methods should not involve automated learning.\nChatGPT\nConstructing or inferring a full image from partial inputs without involving automated learning can be challenging, as it typically requires complex computational algorithms or manual interventions. However, there are a few methods that can be used to reconstruct or expand a full image from partial inputs without relying on automated learning. Here are a few approaches:\n\nPatch-based methods: In this approach, the partial inputs or patches are analyzed individually, and then these patches are combined or stitched together to form the full image. This method requires a prior understanding of the spatial relationships between patches. Various algorithms, such as graph cuts or seam carving, can be used to combine the patches effectively.\n\nImage inpainting techniques: Image inpainting aims to fill in missing or occluded regions in an image. By applying inpainting algorithms, you can reconstruct the missing parts of the image based on the surrounding information or by propagating the existing image content. Techniques like texture synthesis, diffusion-based methods, or exemplar-based approaches can be used for image inpainting.\n\nStructure-from-Motion (SfM): SfM is a technique used to reconstruct 3D scenes from 2D image sequences. If you have partial inputs from different viewpoints or angles, you can use SfM algorithms to estimate the camera poses and 3D structure of the scene. By combining the reconstructed 3D information, you can generate a full image or a more complete representation of the scene.\n\nImage completion with manual interventions: If automated learning is not allowed, manual interventions can be used to complete or expand an image from partial inputs. This approach involves human interaction or expertise to fill in missing details or to infer the complete image based on the available information. Tools like image editing software can be employed to manually paint or draw missing parts of the image.\n\nIt's important to note that these methods may require some level of computational algorithms or techniques, but they do not rely on automated learning specifically. Instead, they involve manual interventions or computational procedures that do not involve training on large datasets.\n\n\n\nLet's say that this patchy dataset is a table of occurence of molecules within living organisms. We thus have phylogenetic relationshsips across the organisms and chemical class taxonomy across the molecules. What approch would you propose to reconstruct a full dataset from a patchy dataset ?\nChatGPT\nIn the case of a patchy dataset representing the occurrence of molecules within living organisms, where phylogenetic relationships across organisms and chemical class taxonomy across molecules are known, you can leverage these relationships to reconstruct a more complete dataset. Here's an approach you can consider:\n\nPhylogenetic imputation: Given the phylogenetic relationships among organisms, you can utilize this information to infer missing values in the dataset. This approach assumes that closely related organisms have similar characteristics, including the occurrence of molecules. You can estimate missing values by propagating the observed data from closely related organisms to fill in the gaps in less studied or missing organisms.\n\nChemical class-based imputation: If you have a taxonomy of chemical classes for the molecules, you can use this information to infer missing values. Explore the chemical classes present in the dataset and their relationships to impute missing occurrences based on the patterns observed within each class. This could involve considering the distribution of occurrences within a chemical class or using statistical measures within specific chemical class groups.\n\nCross-validation: To enhance the reliability of the reconstructed dataset, you can perform cross-validation techniques. Split the available data into training and testing sets and use the known data to impute the missing values in the testing set. Then compare the imputed values with the actual values to evaluate the accuracy and adjust the imputation method if necessary.\n\nExpert validation: Given the complexity and domain-specific nature of the dataset, it is valuable to involve experts in the field. Experts can provide insights, validate the reconstructed dataset, and refine the imputation process based on their knowledge of the organisms, molecules, and their interactions.\n\nIt's important to note that imputation methods rely on assumptions and might introduce some level of uncertainty. The quality and accuracy of the reconstructed dataset will depend on the availability and quality of the existing data, the accuracy of the phylogenetic relationships and chemical class taxonomy, and the effectiveness of the imputation methods employed.\n\nOverall, combining phylogenetic relationships, chemical class taxonomy, statistical imputation, and expert input can help you reconstruct a more complete dataset of molecule occurrences within living organisms.\n\n\n\nGreat. Would their be an approach that could combine both the Phylogenetic imputation and the Chemical class-based imputation ? That is a method which would exploit the structure on both dimension of the datset for the inputation \nChatGPT\nYes, it is indeed possible to combine both phylogenetic imputation and chemical class-based imputation to exploit the structure on both dimensions of the dataset for imputation. Here's an approach that combines these two methods:\n\nPhylogenetic imputation: Use the phylogenetic relationships among organisms to propagate information and impute missing values. Start by identifying closely related organisms with available data. For each missing value, find the closest related organisms with observed data and use their values as a basis for imputation. This imputation process takes into account the assumption that closely related organisms share similar characteristics, including the occurrence of molecules.\n\nChemical class-based imputation: Leverage the chemical class taxonomy to further refine the imputation process. Within each chemical class, observe the distribution of occurrences and utilize statistical measures such as mean, median, or mode to estimate missing values. Consider the patterns and tendencies within each chemical class while imputing missing values.\n\nCombination and refinement: Combine the imputed values from the phylogenetic imputation and chemical class-based imputation approaches. This can be achieved by assigning weights or merging the imputed values based on the confidence or reliability of each approach. You can also consider using statistical techniques such as ensemble methods or weighted averaging to combine the imputations effectively.\n\nExpert validation: As mentioned before, involving domain experts in the validation process is crucial. Experts can provide insights on the reliability and biological plausibility of the imputed values. They can also suggest adjustments or refinements to the imputation process based on their knowledge of the organisms, molecules, and their relationships.\n\nBy combining phylogenetic imputation with chemical class-based imputation, you leverage both the phylogenetic relationships among organisms and the chemical class taxonomy of molecules to impute missing values. This approach takes advantage of the structural information present in both dimensions of the dataset, resulting in a more comprehensive and accurate imputation process.\n\n\n\n\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.028}}},{"i":184,"$":{"0":{"v":"2023-05-12","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.05.12\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- To open a new instance of chromium I need to\nhttps://askubuntu.com/a/35414\n\nchromium --user-data-dir=$(mktemp -d)","n":0.139}}},{"i":185,"$":{"0":{"v":"2023-05-08","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.05.08\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n### Getting more info on the recurrent ‘Solving environment: failed with initial frozen solve. Retrying with flexible solve’ issue\n\nhttps://medium.com/floppy-disk-f/linux-ubuntu-how-to-fix-solving-environment-failed-with-initial-frozen-solve-27c53c6de32a\n\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.131}}},{"i":186,"$":{"0":{"v":"2023-05-02","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.05.02\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.158}}},{"i":187,"$":{"0":{"v":"04","n":1}}},{"i":188,"$":{"0":{"v":"2023-04-27","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.04.27\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\n### ENPKG work in Lausanne\n\n# For the extract specified in the BIND() clause below,\n# retrive the chromatogram info (RT,M/Z, peak area) and \n# formula. Only features with very high confidence \n# formula are shown. To be completed\n#\nPREFIX enpkg: <https://enpkg.commons-lab.org/kg/> .\nPREFIX foaf: <http://xmlns.com/foaf/0.1/> .\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\nPREFIX wd: <http://www.wikidata.org/entity/> .\n\nSELECT ?feature ?MZ ?RT ?string ?score ?area\nWHERE{\n    BIND( enpkg:VGF142_F07 AS ?sample ) .\n    ?formula enpkg:has_SIRIUS_formula_string ?string ;\n             enpkg:has_SIRIUS_formula_score  ?score  .\n    ?feature enpkg:has_SIRIUS_formula ?formula ;\n             enpkg:has_MZmine_MZ ?MZ           ;\n             enpkg:has_MZmine_RT ?RT           .\n    ?chromatogram enpkg:has_MZmine_feature               ?feature .\n\t?sample       enpkg:has_MZmine_chromatogram\t\t   ?chromatogram .\n    << ?chromatogram enpkg:has_MZmine_feature ?feature >> enpkg:has_MZMine_peak_area ?area\n    FILTER( ?score >= 0.98 )\n}\nORDER BY ?RT\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.085}}},{"i":189,"$":{"0":{"v":"2023-04-25","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\n\nToday is 2023.04.25\n\n## Todo today\n\n| Project | Description                                             | Due Date   | Tags     |\n| ------- | ------------------------------------------------------- | ---------- | -------- |\n| null     | - [ ] call Buchi guy regarding pressure regulator        | 2023-04-30 | #mapp    |\n| null     | - [ ] Email WSS EMI consortium                           | 2023-04-24 | #emi     |\n\n\n## Doing\n\n### Customizing website\n\nhttps://github.com/wowchemy/wowchemy-hugo-themes/issues/147\n\n## Call Antonio\n\n\n\n\n\n## Paused\n| null     | - [ ] point Lendita                                      | 2023-04-25 | #commons, #dbgi |\n\n@Lendita \n\n- Manubot for report handling\nRead : https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007128\nExplore : https://manubot.org/\nRead : Tree, maps and theorems\n\n@oolonek\n\nClone the https://github.com/digital-botanical-gardens-initiative/dbgi-green-paper and make it a template for reports\n\nhttps://docs.github.com/en/repositories/creating-and-managing-repositories/duplicating-a-repository\n\nActually it could be a bad idea to duplicate a manubot repo and maybe the best way to go it to follow the establishment of a new repo.\nWill create one for Lendita report\nAnd think of a tuto is the instructions on manubot's website are not clear enough\nhttps://github.com/manubot/rootstock/blob/main/SETUP.md\n\n\n\nPreparaing SBL.20004 2023 course material [[teaching.master.SBL20004.2023]]\n## Done\n\nPoint Audrey.\nCreating a git repo in commons\nand moving data from the commons server to local pc\n## Notes\n\n## Todo tomorrow, another day ... or never !\n###\n###\n###\n\n## Today I learned that\n\n- \n\n📖 Comment what should be commented and pass this daily Notebook to it's Open Notebook counterpart\n\n\n\n\nmkdir -p pos/{metadata/{original,treated},results/{cytoscape,met_annot_enhancer,metaboanalyst,mzmine,stats,sirius,tmp},src} && touch pos/{metadata/{original/.gitignore,treated/.gitignore},results/{cytoscape/.gitignore,met_annot_enhancer/.gitignore,metaboanalyst/{.gitignore,placeholder.out},mzmine/{.gitignore,placeholder.out},stats/.gitignore,sirius/{.gitignore,placeholder.out},tmp/.gitignore},src/.gitignore}\n\n","n":0.07}}},{"i":190,"$":{"0":{"v":"2023-04-23","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.04.23\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\nFollowing Writing Reusable, Reproducible Python: Documentation, Packaging, Continuous Integration, and Beyond\n\nhttps://www.youtube.com/watch?v=lo_g-GbYtaA&ab_channel=CoronaWhy\n\nSemantic Versioning 2.0.0\nhttps://semver.org/\n\n\nimport this >>> \n\nThe Zen of Python, by Tim Peters\n\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nFlat is better than nested.\nSparse is better than dense.\nReadability counts.\nSpecial cases aren't special enough to break the rules.\nAlthough practicality beats purity.\nErrors should never pass silently.\nUnless explicitly silenced.\nIn the face of ambiguity, refuse the temptation to guess.\nThere should be one-- and preferably only one --obvious way to do it.\nAlthough that way may not be obvious at first unless you're Dutch.\nNow is better than never.\nAlthough never is often better than *right* now.\nIf the implementation is hard to explain, it's a bad idea.\nIf the implementation is easy to explain, it may be a good idea.\nNamespaces are one honking great idea -- let's do more of those!\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.075}}},{"i":191,"$":{"0":{"v":"2023-04-22","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.04.22\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\nWorked on https://github.com/enpkg/enpkg_mn_isdb_taxo/pull/4\n\nReading and following https://cthoyt.com/2020/06/03/how-to-code-with-me-organization.html\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \nFollow https://www.youtube.com/watch?v=lo_g-GbYtaA&ab_channel=CoronaWhy\n\n\n###\n###\n\n\n## Today I learned that\n\n- In a nano text editor you can jump to the end of the file by ctrl+W (opens a search field) and ctrl+v\n(re)discovered https://beta.briefideas.org/ideas/27deb8bb6d86c83d29f53320f02a22a5\nSupported https://beta.briefideas.org/ideas/cab8754c68b586c2713deee4f1079ddb\n\n\n\n\n","n":0.12}}},{"i":192,"$":{"0":{"v":"2023-04-13","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.04.13\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\n### Metabolite annotation Audrey and Stephanie\n\nAnnotation with https://github.com/mandelbrot-project/met_annot_enhancer\n\nhttps://github.com/digital-botanical-gardens-initiative/emi_anacardiaceae/tree/main\n\nWorking on the emi_batch_00001 (Anacardiaceae) we found two interesting clusters in Pseudospondias extracts\n\n![](/assets/images/2023-04-13-18-34-37.png)\n\nhttps://pubchem.ncbi.nlm.nih.gov/compound/21581584\nOhchinolide B derivatives possibly.\n\n[Melia azedarach](https://en.wikipedia.org/wiki/Melia_azedarach \"Melia azedarach, commonly known as the chinaberry tree, pride of India, bead-tree, Cape lilac, syringa berrytree, Persian lilac,  Indian lilac, or white cedar, is a species of deciduous tree in the mahogany family, Meliaceae, that is native to Indomalaya and Australasia.\")\n\nhttps://academic.oup.com/femsle/article/120/3/267/520869\n\n\n## Paused\n\n## Done\n\n## Notes\n\nMid Thesis presentation Audrey le Cabbec\n\n- worked on insects metabolites in Rennes (ynsect)\n- worked with P Coulerie in New Caledonia\n\nICOA\n\nAnalytical, Affinity and Bioactive Strategies\nCosmetic valley (Tours, Blois, Rouen)\nOrlean area of high horticultural prod\n\n## Eclipta alba\n\n\n- Culture of non native plants ([Eclipta alba](https://en.wikipedia.org/wiki/Eclipta_prostrata \"Eclipta prostrata, commonly known as false daisy, yerba de tago, Gunta kalagaraku\\/Gunta galagaraku, Karisalankanni, and bhringraj, is a species of plant in the family Asteraceae. It is widespread across much of the world.This plant has cylindrical, grayish roots. Solid, circular, purplish stems with white fine hairs 0.8m. Leaves arranged in opposite pairs, hairy in two-sided, lanceolate, serrated 2–12.5 cm long, 5-35 mm wide.\nThe solitary flower heads are 6–8 mm \\(0.24–0.31 in\\) in diameter, with white florets. The bumpy achenes are compressed and narrowly winged. This species grows commonly in moist places in warm temperate to tropical areas worldwide. It is widely distributed throughout India, Nepal, China, Thailand,Bangladesh and Brazil.\"))\n\n\n\nPresence of [coumestan](https://en.wikipedia.org/wiki/Coumestan \"Coumestan is a heterocyclic organic compound.  Coumestan forms the central core of a variety of natural compounds known collectively as coumestans.  Coumestans are oxidation products of pterocarpan that are similar to coumarin.  Coumestans, including coumestrol, a phytoestrogen, are found in a variety of plants. Food sources high in coumestans include split peas, pinto beans, lima beans, and especially alfalfa and clover sprouts.Coumestrol has about the same binding affinity for the ER-β estrogen receptor as 17β-estradiol, but much less affinity than 17α-estradiol, although the estrogenic potency of coumestrol at both receptors is much less than that of 17β-estradiol.Because of the estrogenic activity of some coumestans, a variety of syntheses have been developed that allow the preparation of coumestans so that their pharmacological effects can be explored.\") \n\n\n5 enzymatic test (COX, elastase, ROS etc.)\n\nQ : why such difference in the raw extracts conc used for testing ?\nQ : can you explain the heatmap again ?\nQ : stats significative diff \nQ : how did you annotate the compounds ? Which software ? Which DB ?\n\n\n\n## C forskohlii \n\n[Coleus forskohlii](https://en.wikipedia.org/wiki/Coleus_barbatus \"Coleus barbatus, also known by the synonyms Plectranthus barbatus and incorrectly Coleus forskalaei \\(and other spellings of this epithet\\), is a tropical perennial plant related to the typical coleus species.  It produces forskolin, an extract useful for pharmaceutical preparations and research in cell biology. \")\n\n[forskolin](https://en.wikipedia.org/wiki/Forskolin \"Forskolin \\(coleonol\\) is a labdane diterpene produced by the plant Coleus barbatus \\(Blue Spur Flower\\). Other names include pashanabhedi, Indian coleus, makandi, HL-362, mao hou qiao rui hua. As with other members of the large diterpene class of plant metabolites, forskolin is derived from geranylgeranyl pyrophosphate \\(GGPP\\). Forskolin contains some unique functional elements, including the presence of a tetrahydropyran-derived heterocyclic ring. Forskolin is commonly used in laboratory research to increase levels of \n\nwhich gave the name to the plant ?\n\nHow do you quantify forskolin iteratively ?\n\n\n### Conclusion \n\nexplore the coumestan biosynthetic pathway.\nWhy exactly ?\n\n\n### Perspectives and collab in UniFr\n\n- [Clematis](https://en.wikipedia.org/wiki/Clematis \"Clematis is a genus of about 380 species within the buttercup family, Ranunculaceae. Their garden hybrids and cultivars have been popular among gardeners, beginning with Clematis 'Jackmanii', a garden standby since 1862; more cultivars are being produced constantly. They are mainly of Chinese and Japanese origin. Most species are known as clematis in English, while some are also known as traveller's joy, a name invented for the sole British native, C. vitalba, by the herbalist John Gerard; virgin's bower for C. terniflora, C. virginiana, and C. viticella; old man's beard, applied to several with prominent seedheads; leather flower for those with fleshy petals; or vase vine for the North American Clematis viorna.\")\n\n- Lonicera\n- Euonymus\n\n\n\n\n\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.038}}},{"i":193,"$":{"0":{"v":"03","n":1}}},{"i":194,"$":{"0":{"v":"2023-03-15","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.03.15\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n#### Presnetation Edourad\n\n\n- precise that their is no taxonomical focus\n\n- not category of plants ! (ways to access biodiversity)\n\nSay that DBGI is a Pilot\n\n\n- some numbers regarding the diversity of BG\n\nWhat is a Knowledge Graph ?\nWhat is an Ontology ?\n\n- make a precision regarding the Open Science aspects (not only at the publication step but really Open Notebook Science)\n\n\n- Phylogeny /should be taxonomy\n\n- A small transition sentence.\nNow I am going to talk you about what I started doing in my Bachelor work and what I am currently doing in my master\n\n- Why ? do you make maps ?\n\n- Explain very quickly what are the layers for \n\n- You say you take a picture of the QR code and this updates the code automatically (explain why this is interesting)\n- Community curation : here also explain quickly why this is nice !\n\n- API what is that ??? You should explain to people how dont use computer\n- 12 Euros ... maybe not required +\n\n- More than a collection tool its a set of tools or framework\n\n\n- \"unknowing\" system\n\n\n\n\n\n\n\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.068}}},{"i":195,"$":{"0":{"v":"2023-03-12","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.03.13\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- \n\n- I could (or couldn't) tune the wikipedia hyperlinker to link wd entries\n\nSee [erythromycin](https://en.wikipedia.org/wiki/Erythromycin \"Erythromycin is an antibiotic used for the treatment of a number of bacterial infections. This includes respiratory tract infections, skin infections, chlamydia infections, pelvic inflammatory disease, and syphilis. It may also be used during pregnancy to prevent Group B streptococcal infection in the newborn, as well as to improve delayed stomach emptying. It can be given intravenously and by mouth. An eye ointment is routinely recommended after delivery to prevent eye infections in the newborn.Common side effects include abdominal cramps, vomiting, and diarrhea. More serious side effects may include Clostridium difficile colitis, liver problems, prolonged QT, and allergic reactions. It is generally safe in those who are allergic to penicillin. Erythromycin also appears to be safe to use during pregnancy. While generally regarded as safe during breastfeeding, its use by the mother during the first two weeks of life may increase the risk of pyloric stenosis in the baby. This risk also applies if taken directly by the baby during this age. It is in the macrolide family of antibiotics and works by decreasing bacterial protein production.Erythromycin was first isolated in 1952 from the bacteria Saccharopolyspora erythraea. It is on the World Health Organization's List of Essential Medicines. In 2020, it was the 225th most commonly prescribed medication in the United States, with more than 2 million prescriptions.\")\n\n\n\n\n[France](Q142 \"Q142\")\n\n\n[Erythromycin](Q213511 \"Q213511\")\n\n\n[Aspirin](Q18216 \"medication used to treat pain and decrease the risk of heart disease\")\n\n[Salix alba](Q156918 \"species of plant\")\n\n\n\n[Salix alba](https://www.wikidata.org/wiki/Q156918 \"species of plant\")\n\nQ1\n\nQ1\n\nuniverse\n\nTrying to adapt the wikipedia VScode extension so it handles wd also\n\n## Original url\n\nhttps://www.wikidata.org/w/api.php?action=wbgetentities&sites=enwiki&titles=Erythromycin&props=descriptions&languages=en&format=json\n\n\n\nhttps://en.wikipedia.org/w/api.php?format=json&action=query&prop=info|extracts&exintro&explaintext&&inprop=url&redirects=1&titles=Erythromycin\n\n## Modified\n\nhttps://www.wikidata.org/w/api.php?format=json&action=query&prop=info|extracts&exintro&explaintext&&inprop=url&redirects=1&titles=Erythromycin\n\n\nhttps://www.wikidata.org/w/api.php?format=json&action=query&prop=info|extracts&exintro&explaintext&&inprop=url&redirects=1&titles=keanumycin\n\nhttps://www.wikidata.org/w/api.php?action=wbgetentities&sites=enwiki&titles=Erythromycin&props=descriptions&languages=en&format=json\n\n\n\n[Keanumycin](https://www.wikidata.org/wiki/Q116980169 \"class of chemical compounds\")\n\n\n[Keanumycin](https://www.wikidata.org/wiki/Q116980169 \"class of chemical compounds\") A\n\nQ116980169\n\n\n[Keanumycin](https://www.wikidata.org/wiki/Q116980169 \"class of chemical compounds\")n](https://www.wikidata.org/wiki/Q116980169 \"class of chemical compounds\")\n\n\n[aspirin](https://en.wikipedia.org/wiki/Aspirin \"Aspirin, also known as acetylsalicylic acid \\(ASA\\), is a nonsteroidal anti-inflammatory drug \\(NSAID\\) used to reduce pain, fever, and\\/or inflammation, and as an antithrombotic. Specific inflammatory conditions which aspirin is used to treat include Kawasaki disease, pericarditis, and rheumatic fever.Aspirin is also used long-term to help prevent further heart attacks, ischaemic strokes, and blood clots in people at high risk. For pain or fever, effects typically begin within 30 minutes. Aspirin works similarly to other NSAIDs but also suppresses the normal functioning of platelets.One common adverse effect is an upset stomach. More significant side effects include stomach ulcers, stomach bleeding, and worsening asthma. Bleeding risk is greater among those who are older, drink alcohol, take other NSAIDs, or are on other blood thinners. Aspirin is not recommended in the last part of pregnancy. It is not generally recommended in children with infections because of the risk of Reye syndrome. High doses may result in ringing in the ears.A precursor to aspirin found in the bark of the willow tree \\(genus Salix\\) has been used for its health effects for at least 2,400 years. In 1853, chemist Charles Frédéric Gerhardt treated the medicine sodium salicylate with acetyl chloride to produce acetylsalicylic acid for the first time. Over the next 50 years, other chemists established the chemical structure and devised more efficient production methods.: 69–75 Aspirin is available without medical prescription as a proprietary or generic medication in most jurisdictions. It is one of the most widely used medications globally, with an estimated 40,000 tonnes \\(44,000 tons\\) \\(50 to 120 billion pills\\) consumed each year, and is on the World Health Organization's List of Essential Medicines. In 2020, it was the 36th most commonly prescribed medication in the United States, with more than 17 million prescriptions.\")\n\n[Aspirin](https://www.wikidata.org/wiki/Q18216 \"medication used to treat pain and decrease the risk of heart disease\")\n\n\n[Keanumycin](https://www.wikidata.org/wiki/Q116980169 \"class of chemical compounds\")\n\n\n[Q18216](https://www.wikidata.org/wiki/Q257106 \"Q257106\")\n\n\n[Q18216](https://www.wikidata.org/wiki/Q257106,Q1856114,Q177932 \"Q257106\")\n\n\n[Q18216](https://www.wikidata.org/wiki/Q257106)\n[Q18216](https://www.wikidata.org/wiki/Q1856114)\n[Q18216](https://www.wikidata.org/wiki/Q177932)\n\n\n\nQ18216\n\nCryptocarya chartacea\n\nhttps://www.wikidata.org/w/api.php?action=wbsearchentities&search=Q156918&language=en\n\n\nhttps://www.wikidata.org/w/api.php\n\n[](../../../Dropbox/git_repos/random/vscode-wikipedia-hyperlink/)\n\n\nhttps://www.wikidata.org/w/api.php?action=wbgetentities&props=claims&ids=Q116980169&format=json\n\nhttps://www.wikidata.org/w/api.php?action=wbgetentities&props=claims&ids=Q213511&format=json\n\n\n\nfound%&in%&taxon\n\n\"found in taxon\"\n\n\nWorked at https://github.com/oolonek/vscode-wikipedia-hyperlink","n":0.04}}},{"i":196,"$":{"0":{"v":"2023-03-05","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.03.05\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\nThere is a whole website to learn wb https://learningwikibase.com/\nCreated a first Wb instance at https://dbgi-sandbox.wikibase.cloud/wiki/Main_Page\n\n\n\n\nDe Candolle's archives\n\nhttps://www.biodiversitylibrary.org/item/196369#page/12/mode/1up\n\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.134}}},{"i":197,"$":{"0":{"v":"02","n":1}}},{"i":198,"$":{"0":{"v":"2023-02-24","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.02.24\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n### Upload the SI of James Lever paper to Wikidata\nhttps://www.mdpi.com/1660-3397/20/9/554\n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.143}}},{"i":199,"$":{"0":{"v":"2023-02-16","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.02.16\n\n## Todo today\n\n### Have a look at the XXXX discussion forum\n    - https://github.com/orgs/XXXXX/discussions\n###\n###\n\n## Doing\n\n### 4th and last day of the #swat4hcls\n\nProgram is here \n\nhttps://www.swat4ls.org/workshops/basel2023/hackathon/\n\n\n# Hacking Scholia for custom SPARQL endpoints discord\n\nhttps://github.com/SWAT4HCLS/Biohackathon-SWAT4HCLS-2023/issues/4\nThis hack project is following up efforts of other to repurpose the Scholia platform for other SPARQL endpoints, like custom Wikibase installations or Wikidata subsets. In this project we will explore how we can make the Scholia code base configurable for the aspects to show, and which panels to show.\nIf the project is successful, we have a custom Scholia instance around any of the existing public SPARQL endpoints (e.g. ChEMBL, UniProt/NextProt, etc).\n\nExpertise needed\nSPARQL coding, and/or\nPython coding (Flask experience particularly welcome)\n\nhttps://en.wikipedia.org/wiki/Flask_(web_framework)\n\n\nhttps://github.com/wdscholia/scholia\n\nLeyla Jael Castro\n\nhttp://guide.biohackrxiv.org/\n\nhttps://nanopub.net/\n\nhttps://linkml.io/\n\nhttps://www.semantic-web-journal.net/content/onegraph-vision-challenges-breaking-graph-model-lock-0\n\n\nCheck in WikiBase\n\n\n\nhttp://guide.biohackrxiv.org/\n\n\n\n\n\n\n\n\nFrom Egon\n> good morning. I am finishing some teaching before we start around 9am CET\n> hacking ideas for this project include:\n> 1. global configurable SPARQL endpoint URL\n> 2. configurable subset of aspects to run\n> 3. mappings between Wikibase properties and classes with Wikidata equivalents (so that SPARQL can be in the \"Wikidata language\" but translated to the \"Wikibase language\" before being run)\n> 4. extract mapping of Wikidata classes (Q-ids) to Scholia aspects into a config file\n> \n\noh, and yes, this project will write a BioHackrXiv report\nhttps://biohackrxiv.org/\n\n\n\n\n\n\n\n# Creating life science fom WD\n\n\n### Discussion with Tarcisio, Ana & Marco\n\n- small sized RDF (see PCM molecules) are a thing to investigate\n- check into Wikibase installs\n- have a RDF with no GraphDB dependenat specification (should easily go to GraphDb and Virtuoso for ex)\n- nonopubs website changed its now at https://nanopub.net/\nhttps://arxiv.org/pdf/2203.01608.pdf\n\nA startup is beeing build Knowledge Pixels\nhttps://knowledgepixels.com/\n\n\nKnowledge Space\nhttps://gist.github.com/tkuhn/a3842683b810f1e0dbc72a021083ea31\n\nPeta Pico https://github.com/peta-pico\n\n\n# This is my nanopub intro page\nhttps://np.petapico.org/RAo1CRf-4uDsGEhblzPIAYJrAiFGfJ20ST6hhIWsns0Go\n\nAnd my first nanopub ! I know J. Bisson http://purl.org/np/RAn2gGIzaJ21w72ZGbA92_p50iyomQ-Kb_a8etfmIKZyo\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.059}}},{"i":200,"$":{"0":{"v":"2023-02-14","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\nToday is 2023.02.14\n\n## Todo today\n\n### Set a meeting with [[people.marco-visani]]\n### Work on the biostats_toolbox\n\n- graphml generation step.\nFind a way to merge a df (or several) to a graph object in a smoother way\n\n###\n\n## Doing\n\n### Qual comparison\n\nmapp_project_00020\nmapp_batch_00036\nmapp_01_39_x\n\n[[mapp_project_00020.mapp_batch_00036]]\n\n### Updating DBGI program\n\n[[communication.meetings.2023.02.22.program]]\n\n## Paused\n\n## Done\n\n## Notes\n\n### Ressource for taxa illustration\n\n#taxa #silhouettes\nhttps://www.phylopic.org/\n\n\n### SWAT4HCLS Hackaton is on Friday \n#swat4hcls\n\nHere is the prog https://www.swat4ls.org/workshops/basel2023/hackathon/\n\nhttps://github.com/SWAT4HCLS/Biohackathon-SWAT4HCLS-2023/issues/4\n\n### Day 2 of SWAT4HCLS\nhttps://www.swat4ls.org/workshops/basel2023/livestream/\n\n\n#### The SPHN (Swiss Personalized Health Network)\nHave been funded for 135M CHF \n\nSemantics standards not common in healthcare\n\n> Standards don't send you money now, they send you money later\n> \nG. Grieve\n\nQ: Hi Katrin. Thanks for the talk ! On one slide you mentioned the importance of efforts regarding integration of omics data within the SPHN KG.\nAre these future tasks or are they currently undertaken ? I am particularly interested to know wether they are concrete things done on the integration of metabolomics data.\nWhat are the challenges here according to you ?\n\nNational Data streams.\n\nIntegration of genomics + other omics\nTwo of them integrate metabolomics data Partners on the data stream. Curated with an expert team in Zurich\n\nWho are these teams ?\n\nInteroperability framework. Sabine Oesterle \nLed by https://www.sib.swiss/directory?cn=sabine%20oesterle\n\n#### Visualapps\n\nGerhard Kober \ngerhard.kober@visuapps.com\n\nFIHR Stores http://hl7.org/fhir/\nRuleML https://en.wikipedia.org/wiki/RuleML\n\n\n#### Privacy preserving dashboards\n\n\nVarsha Gouthamchand\nMaastro (ND)\n\nTriplifier (JS based) converts and relational DB to RDF \n\n#### Problems of AI in Drug Discovery\n\n\n#### BenchSci\n\n![](/assets/images/2023-02-14-15-32-28.png)\n\n\n![](/assets/images/2023-02-14-16-20-08.png)\n\n\n![](/assets/images/2023-02-14-17-05-28.png)\n\n\n![](/assets/images/2023-02-14-17-07-02.png)\n\n\n### Check how to setup granular autorization on a git organizations\n\n### Discussion with Marco\n\nWhy should molecules be normaly distributed  ?\nHave a look why object in Nature are usually normally distributed ? Are they exceptions ? \n\nnear field NMR ?\nhttps://academic.oup.com/gigascience/article/doi/10.1093/gigascience/giac124/6980761\nhttps://github.com/mandelbrot-project/pf_1600_datanote\n\ntodo PM : \n- prepare the 1600 pf dataset \n- prepare DBGI\n\nMS paper Marco\n\n### ENPKG\n\n- have the 1600 pf dataset ind files uploaded on Zenodo\n- Think about a structure for individual \"capsule\" per profile. \nIt would include all required metdata, raw files and resulting individual RDF\nCould be uploaded to Zenop using their API. \nEach profiled sample wpould thus benefit from its individual doi\n\nQ: what wouldn't fit in such a capsule ?\n\n\n\n\n## Todo tomorrow, another day ... or never !\n### Mechanism to copy assets\nWhen transfering daily notes from notebook.xxxx. to open-notebook.xxxx the assets stay in the orignal vault where they were pasted. This leads to broken link. \n\n###\n###\n\n## Today I learned that\n\n- \n```R \nglimpse(df)\n```\nis a great way to peak into a df\n\nAdded to [[R]]\n\n\n","n":0.051}}},{"i":201,"$":{"0":{"v":"2023-02-13","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily Open Notebook.\n\n\nToday is 2023.02.13\n\n## Todo today\n\n### SWAT4HCLS\n\nTutorials can be found here https://www.swat4ls.org/workshops/basel2023/tutorials/\n\nThose which are organized as interactive you can find the zoom links here. \nTrack A https://zoom.us/j/98544172437\nTrack B https://us02web.zoom.us/j/85986933013\nTrack C https://zoom.us/j/99286755590\n\n\n\nThe other sessions will be streamed on the website. \nFor Q&A please use Discord channel https://discord.gg/WC6qanWj\n\n\nThe final programme of the conference days  can be found here https://www.swat4ls.org/workshops/basel2023/scientific-programme-2023/\nAll sessions will be streamed at the conference website. \nFor Q&A please use Discord channel  https://discord.gg/BRwbWWjDaE\n\n\nInformation about BioHackathon can be found here https://www.swat4ls.org/workshops/basel2023/scientific-programme-2023/\n\n\nWe work at https://cocalc.com/projects/\n\nOntology at the Topo\nData on the bottom (**instances** of the ontology)\n\nPrefix is simply a declaration of an IRI abbreviation\n\n\n# Remember that in the turtle data above we can see:\n#\n# 'ttr:John a dbo:Person'\n#\n# 'a' can also be used instead of 'rdf:type'\n# 'a' is a synonym of 'rdf:type'\n\n\nIf you dont know what is your data. Dont fill it in \n\n\nhttps://sparql.rhea-db.org/\n\n\n# Put your code here\n\n\n\nchebi = '18059'\n\n```SQL\n#endpoint:https://sparql.rhea-db.org/sparql\n#query Q9: Select Rhea reactions using CHEBI:31488 (N-acylsphinganine) or one of its descendant as reaction participant\n\nPREFIX rh:<http://rdf.rhea-db.org/>\nPREFIX CHEBI:<http://purl.obolibrary.org/obo/CHEBI_>\nPREFIX up:<http://purl.uniprot.org/core/>\n\nSELECT distinct ?chebi ?chebiUniprotName ?rhea ?equation \nWHERE {\n  ?rhea rdfs:subClassOf rh:Reaction .\n  ?rhea rh:equation ?equation .\n  ?rhea rh:side/rh:contains/rh:compound/rh:chebi ?chebi .\n  ?chebi rdfs:subClassOf/rdfs:subClassOf/rdfs:subClassOf CHEBI:\"\"\" + chebi + \"\"\" .\n  ?chebi up:name ?chebiUniprotName .\n}\nORDER BY ?chebi\n```\n\nNote : \n\nTo fetch exactly one level:\n`?chebi rdfs:subClassOf CHEBI:\"\"\" + chebi + \"\"\" .`\n\nTo fetch exactly all level:\n`?chebi rdfs:subClassOf* CHEBI:\"\"\" + chebi + \"\"\" .`\n\nTo fetch exactly one to three levels:\n`?chebi rdfs:subClassOf/rdfs:subClassOf/rdfs:subClassOf CHEBI:\"\"\" + chebi + \"\"\" .`\n\n\n\nprint(sparql_QEx4)\n\n\nSPARQL is 1 based\n\nWhen one queries the Uniprot KB (or other massive source) one can work 2step wise.\n\n1 get a subset of the graph\n\n```SQL\n\nP05067ttl = \"\"\"base <http://purl.uniprot.org/uniprot/>  \nprefix up: <http://purl.uniprot.org/core/>\nprefix taxon: <http://purl.uniprot.org/taxonomy/>\n\n<P05067> a up:Protein ;\n         up:organism taxon:9606 .\n\"\"\"\n\nP05067=Graph().parse(format='ttl', data=P05067ttl)\n\nfor subj, pred, obj in P05067:\n   print(subj, pred, obj)\n\n```\n\nAnd then query this subgraph\n\n```SQL\nqres=P05067.query(\"\"\"\nPREFIX up: <http://purl.uniprot.org/core/> \nPREFIX uniprotkb: <http://purl.uniprot.org/uniprot/>\nPREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n\nSELECT ?protein ?taxon\nWHERE {\n  ?protein a up:Protein ;\n           up:organism ?taxon .\n}\"\"\")\n\nfor row in qres:\n    print(\"The taxon (organism id) of %s is %s\" % row)\n```\n\n2023-02-13 13:34\n\nEric Neumann\n\n\n\n2023-02-13 14:05\n\nHi, this is the link to the slides: https://docs.google.com/presentation/d/10bVN0e5wFSKxbi8l6KCvfGxRSkWLi1eXmeIaY4Szo7w/edit?usp=sharing\n\n\nThis is a link to the github repo: https://github.com/kg-subsetting/tutorial-swat4hcl23\n\n\nProperty graphs.\nSimilar to RDF + some flavor\ne.g. Neo4j\nNodes and relations can be qualified\n\nWikibase supporting WD\nCan go further than traditional Property graphs.\n\nWhy would you create KG subset ?\n\n- Reproducibility !\n\n\nMost advances in WD subsetting were done through Hackatons (Andra, Jose etc.)\n\n\nSparkWDSub\nGraph traversal (Pregel)\nJose Emilio Labra Gayo\n\nKGTK \nKypher language\nJSON dump > SQLite \n(Dump processed on a laptop)\n\n\nZenodo \nWikibase\nHDT triple store\n\nShEX Shape Expression\nConcise and Human readable\n\nsheXer can extract ShEx schemas from RDF data\n\n![](/assets/images/2023-02-13-15-53-41.png)\n\n\nEric Neumann\n\nProperty Graph are syntactic sugar https://en.wikipedia.org/wiki/Syntactic_sugar\nHyperedges Hypergraphs\n\nMathematical tools \n\nFunctors \n\nSpivak Category Theory for the Sciences.\nA database is a Functor\n\nSHACL and SHEx are Functors\n\nNotion of Simplices\n\n\n\n![](/assets/images/2023-02-13-16-30-52.png)\n\nThey are nested subsets. A simplex contains all lower simplices \n\n\n![](/assets/images/2023-02-13-16-33-32.png)\n\nDedekind Numbers\n\n![](/assets/images/2023-02-13-16-56-35.png)\n\n\n## Doing\n\n## Paused\n\n## Done\n### Send DBGI 22nd program\n\nWorking on [[communication.meetings.2023.02.22.program]] and \n### Send MAPP Activity report\n\n## Notes\n\n## Todo tomorrow, another day ... or never !\n###\n###\n###\n\n## Today I learned that\n\n- \n\n📖 Comment what should be commented and pass this daily Notebook to it's Open Notebook counterpart","n":0.045}}},{"i":202,"$":{"0":{"v":"2023-02-12","n":1},"1":{"v":"\n# This is PMA's daily notebook.\n\nToday is 2023.02.12\n\n## Todo today\n\n\n\n\n## Doing\n\n\n### Program 22nd DBGI\n\nWorking at [[communication.meetings.2023.02.22.program]]\n\n### Peeking into Quarto\nhttps://quarto.org/\n\nLooks pretty much like the Knitr and Rmd format but also suited for python.\nMaybe to keep in mind for MAPP reports [[2022.platform.communication and reports]]\n\n\n## Paused\n\n## Done\n### MAPP Activity Report\n\n## Notes\n\n- followed\nhttps://towardsdatascience.com/managing-project-specific-environments-with-conda-406365a539ab\nTrying to better grasp the .env and location of env with mamba\n\n\n\n- Created notebook-commons-pmallard.js\nShould reflect the ON on the commons side.\n\n\n## Todo tomorrow, another day ... or never !\n\n### Will need to find a way to clean the huge mess within my conda environments at one point\n\n### Think of a way to incentivate passage from daily Notebook to Open Notebooks at the end of the day\nMost likely through the templates notes first  [[templates.notebook.commons.pmallard]]\n\nAdding a \n` 📖 Comment what should be commented and pass this daily Notebook to it's Open Notebook counterpart`\n\n- `cmd+A` on local Notebook (without frontmatter)\n- `cmd+o cmd+c` to open new daily Open Notebook (in COMMONS)\n- `cmd+v` to paste \n- remove/comment if needed\n- post\n\nThat's some lines for now and will try redirecting to Open Notebook (in MAPP, COMMONS and DBGI) as much as possible. Will not port old notes ...too much of a burden\n\n\n\n## Today I learned that\n\n- I can output selectively a text (and not only code) depending on knitting as pdf or html. Note the `results='asis'` to render as text.\n\n```R\n```{r, echo=FALSE, results='asis'}\nif (knitr::is_latex_output()) {\n  cat(\"This text will only be rendered in PDF.\")\n}\nif (knitr::is_html_output()) {\n  cat(\"This text will only be rendered in HTML.\")\n}\n```\n```\n\n- Just lost a lot of time since I wrote the MAPP activity report having in mind that I could share the Airtbale dashboard (they call this an interface) as a public link. Turns out it's not possible https://community.airtable.com/t5/other-questions/how-to-make-link-to-interface-public/td-p/81008\nAnother good reason to keep on digging in the NocoDB/Directus direction. Should have checked before.","n":0.058}}},{"i":203,"$":{"0":{"v":"2023-02-11","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily open-notebook.\n\nToday is 2023.02.11\n\n## Todo today\n\n### Have a look at the XXXX discussion forum\n    - https://github.com/orgs/XXXXX/discussions\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n- Have a look into Livemark from Frictionless to establish the MAPP report https://livemark.frictionlessdata.io/\n\n\n## Todo tomorrow\n\n###\n###\n###\n\n## Todo someday\n\n### Have the equivalent of open-notebook.commons.pmallard for mapp\n\n\n\n## Today I learned that\n\n- ","n":0.136}}},{"i":204,"$":{"0":{"v":"2023-02-10","n":1},"1":{"v":"\n# This is PMAS's COMMONS Lab daily open-notebook.\n\nToday is 2023.02.10\n\n## Todo today\n\n### Have a look at the XXXX discussion forum\n    - https://github.com/orgs/XXXXX/discussions\n###\n###\n\n## Doing\n\n- refactoring traits and templates so as to have the possibility to generate daily open-notebooks notes across all public and private Dendrons. \nLet's see if the fact to have a common `open-notebook.`hierarchy cross Dendron workspace doesn't leads to conflicts.\n\nApparently this implies to copy individual Dendron's Note traits to the Multiworkspace Dendron but shortcuts can be shared.\n\n\n\n\n## Paused\n\n## Done\n\n## Notes\n\n- Checked the GNPS + metabolite annotation with Stephanie this morning.\n\nIt would be good to have a list of Anacardiaceae metabolites.\n\n1.  Download - Datawarrior (https://openmolecules.org/datawarrior/)\n2. Download and uncompress - https://zenodo.org/record/7534071#.Y-YjcZOZP8Y 230106_frozen_metadata.csv.gz\n3. load 230106_frozen_metadata.csv.gz in DW\n4. save as .dwar\n5. search and filter for Anacardiaceae\n6. search and filter for each of your plants\n\n\n\n\n\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.085}}},{"i":205,"$":{"0":{"v":"Mvisani","n":1}}},{"i":206,"$":{"0":{"v":"2024","n":1}}},{"i":207,"$":{"0":{"v":"03","n":1}}},{"i":208,"$":{"0":{"v":"2024-03-08","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2024.03.08\n\n\n## Notes\nTalk with PMA\n### Nextflow\n\n### Text for experiment.com\n**about this project** : , we want to predict the molecules of life. No introduction to EMI. \nSee [[writing.scientific_paper]]\nSee https://docs.google.com/document/d/1M2tU1GmtFWkD05RSsxgKfchrQRhUnmf_q77IV8wyBMk/edit\n\n### Anticipated LOTUS new predictions\nTodo : add a display of probabilites \nstrangly the model predicts all species to be around 0.8 at minimum. \nCall Luca to discuss this ! --> TODO today\n\ninvestigate interactive phylogenetic plots \n\n## Todo today\n* \n\n## Doing\n\n\n## Done\n* \n\n\n## Todo tomorrow\n ","n":0.114}}},{"i":209,"$":{"0":{"v":"2024-03-04","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2024.03.04\n\n\n## Notes\n\n## Todo today\n* \n\n## Doing\n\n\n## Done\n* \n\n\n## Todo tomorrow\n ","n":0.243}}},{"i":210,"$":{"0":{"v":"2023","n":1}}},{"i":211,"$":{"0":{"v":"07","n":1}}},{"i":212,"$":{"0":{"v":"12","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.07.12\n\n\n## Notes\n### DBGI workshop\n\n\n\n## Todo today\n* \n\n## Doing\n\n\n## Done\n* \n\n\n## Todo tomorrow\n ","n":0.229}}},{"i":213,"$":{"0":{"v":"05","n":1}}},{"i":214,"$":{"0":{"v":"2023-05-17","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.05.17\n\n\n## Notes\n### Markov random fields\nIf we have a tree structure we can do either do \"loopy belief propagation\" which is updating all node one at a time. This is garanteed to converge to correct marginals but it is wasteful. There is an other way : \"collect and distribute schedule\". The idea is to pick one node as the \"root\" fo the tree, find all the leaves of the graph and compute messages to their parents. Continue until you reach the root. **If the graph is a tree, any node can be a root.** We then backpropagate back to the leaves. Advantage : we only do one update per message.  See explanation [here](https://www.youtube.com/watch?v=meBWAboEWQk) at 11min34sec. This is very similar to an HMM and its forward-backward algorithm. \n\nNow the problem for our model is that we have to combine two trees. The one from species and the one from molecules. We could think of each node as a combination of each molecule with each species. \n## Todo today\n* look definition of loopy back propagation. \n* Check out [this blog](https://medium.com/@philipyunsoocho/image-denoising-by-gibbs-sampling-67d1ad3d7344). For more explanations. I think this new approach could really work for our case. \n* [Here](https://towardsdatascience.com/image-denoising-with-gibbs-sampling-mcmc-concepts-and-code-implementation-11d42a90e153) is an implementation on an image. Could this be applied to our model ?\n* \n## Doing\n\n\n## Done\n* \n\n\n## Todo tomorrow\n ","n":0.067}}},{"i":215,"$":{"0":{"v":"04","n":1}}},{"i":216,"$":{"0":{"v":"2023-04-25","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.04.25\n\n\n## Changes to implement in the model\nWe made a mistake in the variance covariance matrix. In fact, we should have a product between the values of the covariances matrices and not a sum. For example, if I take two species that have 0 correlation and one molecule. Does having that molecule in one of the species give me any additional information about the presence of that molecule in the other species ? Other than the average presence $\\mu$ NO we can't have any other information ! \n\nWe thus have $$cov(\\epsilon_c, \\epsilon_{c'}) = \\prod_t \\prod_{f=1}^{F_t} \\sigma_{tf}(\\tau_t(c), \\tau_t(c')^{\\alpha_{tf}})$$\n\nFurthermore, in order to reduce the variance covariance matrix, we first assume that a lot of molecules and a lot of species share no correlation. This, in theory, would allow us to split the data **before** creating the cov matrix of molecules and the cov matrix of species. This would imply to assume that some molecules and some species share 0 covariance.\n\n![image](assets/images/2023-04-24-17-14-46.jpg)\n\n## Todo today\n* \n\n## Doing\n\n\n## Done\n* \n\n\n## Todo tomorrow\n ","n":0.076}}},{"i":217,"$":{"0":{"v":"2023-04-24","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.04.24\n\n\n## Notes\n\n## Todo today\n* \n\n## Doing\n\n\n## Done\n* Discussion with Daniel about new approach. For now we still keep the old model but we adapt the variance covariance matrix to reduce it's size. \n\n![image](assets/images/2023-04-24-17-14-46.jpg)\n\n\n## Todo tomorrow\n ","n":0.154}}},{"i":218,"$":{"0":{"v":"2023-04-06","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.04.06\n\n\n## Notes\nI think the model we have can work quite nicely with the Lotus database. I have generated some fake data and am trying to predict the parameters given to the model. It looks like it works pretty well. \n\nAlso we performed Gibbs sampling for trying to predict X given $\\mu$ and $\\epsilon_c$ it seems like it is able to find X fast and accurately !\n\n## Todo today\n* \n\n## Doing\n\n\n## Done\n* Finished implementing MCMC for predicting both gamma, delta and X. Works like a charm !\n\n\n## Todo tomorrow\nHoliday","n":0.103}}},{"i":219,"$":{"0":{"v":"03","n":1}}},{"i":220,"$":{"0":{"v":"2023-03-28","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.03.28\n\n\n## Notes\n\n## Todo \n* simulate $\\epsilon_c$ from multivariate normal distribution with mean = 0 and cov `prob_sigma`\n* from x simulate Lotus from x and P and Q --> R \n* from R draw Bernoulli with P = R\n* --> simulated data\n* from simulated data try to do the opposite :\n  * try to infer $\\gamma$ and $\\delta$ from MCMC --> should find our $\\delta$ and $\\gamma$\n\n## Doing\n\n\n## Done\n* \n\n\n## Todo tomorrow\n ","n":0.113}}},{"i":221,"$":{"0":{"v":"2023-03-22","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.03.22\n\n\n## Notes\n### Maëlle's presentation\nGNPS dashboard. \n\n## Todo today\n* \n\n## Doing\n\n\n## Done\n* \n\n\n## Todo tomorrow\n ","n":0.218}}},{"i":222,"$":{"0":{"v":"2023-03-17","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.03.17\n\n\n## Notes\n* read paper [*Can phylogeny predict chemical diversity and potential medicinal activity of plants? A case study of amaryllidaceae*](https://doi.org/10.1186/1471-2148-12-182)\n  * from that paper they say that there is a **lack** of congruence between specialized chemistry and phylogeny may be caused by several different phenomena. One of them is convergent evolution. $\\rightarrow$ we need to take this into account in our model. \n\n\n* [*Combining Evolutionary Inference and Metabolomics to Identify Plants With Medicinal Potential*](https://doi.org/10.3389/fevo.2019.00267) \n  * \"Recent research on plant phylogeny coupled with metabolomics, which is the comprehensive analysis of metabolite profiles, has identified that related taxa produce similar secondary metabolites, **although correlations are dependent also on environmental factors.** \"\n  * interesting article stating that there is a need for creating a model such as what we are doing. We shouldn't forget to include environmental variable. It seems crucial. \n\n## Todo today\n\n\n## Doing\n\n\n## Done\n* \n\n\n## Todo tomorrow\n ","n":0.081}}},{"i":223,"$":{"0":{"v":"2023-03-16","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.03.16\n\n\n## Notes\n\n## Todo today\n* continue learning `statools` and try some things \n\n## Doing\n\n\n## Done\n* \n\n\n## Todo tomorrow\n ","n":0.204}}},{"i":224,"$":{"0":{"v":"2023-03-15","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.03.15\n\n## Edouard's presentation\nDBGI is part of Earth metabolome initiative. Edouard is mainly in the wet lab part. \n\n* Right now they are transitioning from DBGI to Earth metabolome initiative (EMI). \n\n## Notes\n\n## Todo today\n* \n\n## Doing\n\n\n## Done\n* Learned Snakemake. It's actually super easy and it's super powerful to create reproducible workflows.\n\n\n## Todo tomorrow\n ","n":0.129}}},{"i":225,"$":{"0":{"v":"2023-03-09","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.03.09\n\n## Women in Data Science Geneva event 2023\n![image](assets/images/2023-03-09-13-19-36.jpg)\n### Buidling a data practice from scratch for cheap \n*Christelle Marfaing, Head of Data, May*\n#### How to build your stack \n* define and model your target \n  * Ingestion and processing frameworks\n  * technical monitoring\n  * data quality\n  * docs\n  * analysis tools\n* build and model a road map\n\n#### How to build a team\n* decentralize \n* data mesh\n* don't decentralize for nothing or reorganize all the time.\n* learn to let people go. \n\n### Graph neural networks \n*Nadya Chernyavskaya, Senior Reasearcher, CERN*\n\n#### What is a graph\n* a set of nodes and edges with some features\n* directed/undirected, connected/disconnected, sel-loops, \n* they offer much more flexibility\n\n#### What are they for ? \n* node level: predict a property of a node \n* edge, link level : predict links between two nodes \n* subgraph level: detect if nodes form a community (for ex: diagnostics) \n* graph level : molecule property prediction for example \n\n#### How to implement and represent a graph neural network\n* create adjacency matrix, or edge list, or adjacency list \n* a graph can then be implemented into a feature matrix and adjacency matrix \n* each node has to keep its own local information, take new information into account and update it's state based on the previous two. \n\n#### impact ?\nexample Google maps:\n* nodes: road segments\n* edges : connectivity between road segments\n* prediction: time of arrival\n\n#### Conclusion\n* **When ?** Graph neural networks is a very powerful tool for complex and sparse data\n* **What for ?** They can be successfully applied to a variety of different tasks such as node classification, graph classfication, edge prediction, etc...\n* **How ?** We learned how to convert graph into ML read representation and build GNN\n\n\n## Lab meeting of today\n\n\n## Notes\n\n## Todo today\n* \n\n## Doing\n\n\n## Done\n* \n\n\n## Todo tomorrow\n ","n":0.057}}},{"i":226,"$":{"0":{"v":"2023-03-08","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.03.08\n\n\n## Notes\n\n## Todo today\n* find a good nomenclature for n dimensional data\n\n## Doing\n\n\n## Done\n* Hastings ratio for $\\alpha$ and $\\mu$\n\n\n## Todo tomorrow\n* check ratios with Daniel","n":0.174}}},{"i":227,"$":{"0":{"v":"2023-03-03","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.03.03\n\n\n## Notes\n* After long discussion with Pierre-Marie and Daniel, we agreed on:\n  * 2 main properties are \"molecules\" and \"species\"\n  * Adding another dimension like \"tissue\" or \"environment\" is important\n    * Finding which one to add is not of our concern for now.\n  * We could increase to how many properties as we want but what is the scientific relevance of doing that ? For now it would make sense just to keep the tissue\n\n\n## Todo today\n* Continue on generalization of the model, find a way to increase properties to an infinite number of dimensions\n* Correct nomenclature and keep the same for the rest of the model. \n* Try to write Hastings ratio to update our parameters\n\n## Doing\n* continue on the \"upper\" part of the model\n\n\n## Done\n\n\n\n## Todo tomorrow\n","n":0.086}}},{"i":228,"$":{"0":{"v":"02","n":1}}},{"i":229,"$":{"0":{"v":"2023-02-28","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.02.28\n\n\n## Notes\n### Watched Madleina's presentation on presentation about sex determination\nlet us denote $n_{ic}$ the number of reads in individual i in contig c. We have :\n\n$$\nn_{ic} \\propto Multinomial(N_i, \\pi_{ic}) \\\\\n\n\\tilde{\\pi_{ic}} = \\gamma_c (p_{ic} + \\epsilon) \\\\\n\n\\tilde{\\pi_{ic}} = \\frac{\\tilde{\\pi_{ic}}}{\\sum_{c=1}^c \\tilde{\\pi_{ic}}}\n$$\n\n\n\n## Todo today\n* \n\n## Doing\n\n\n## Done\n* \n\n\n## Todo tomorrow\n* meeting with Pierre-Marie\n ","n":0.132}}},{"i":230,"$":{"0":{"v":"2023-02-21","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.02.21\n\n\n## Notes\n\n## Todo today\n* Find more littereture and read it \n* Formlize discussion with Daniel\n\n\n## Doing\n* C++ lessons\n\n\n## Done\n* machine learning assignment\n* discuss with Daniel details and following of the project.\n\n\n\n## Todo tomorrow\n* discuss with Pierre-Marie about \"new\" model and see if it could work with MS data that we have. \n ","n":0.13}}},{"i":231,"$":{"0":{"v":"2023-02-15","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.02.15\n\n## Todo today\n* read some papers about Bayesian approaches for our project\n* continue C++ lessons \n\n## Doing\n\n## Paused\n\n## Done\n* Finished learning polymorphisms in C++\n* Finished concept of `static` and \"friend\" in C++\n* Finished chapter about containers and iterators in C++\n* Finished chapter functors C++\n* \n\n## Notes\n\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.13}}},{"i":232,"$":{"0":{"v":"2023-02-14","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.02.14\n\n## Todo today\n* still publish PDF online because images and DAGs don't work.\n* change DAG to split MS data and lotus\n\n###\n###\n\n## Doing\n* Trying to create multiple DAG and see which one is correct for our model.\n\n## Paused\n\n## Done\n* Used `pandoc` to convert latex file into markdown and then passed it into \n\nDiscussion with Pierre-Marie about the structure of MS and what could be used to implement the model. \n\n![image](assets/images/2023-02-14-15-17-40.jpg)\n\nWe shouldn't forget that our model will likely not be on a 3D molecular level but a 2D since mass spec is not able to make the difference between enantiomers. \n \n## Notes\nSirius and ISDB = info to molecular level \nCANOPUS info to NPC (NP classifier class)\n\n* $y_{sm}$ is the probability of having a molecule in a species\n* $\\mu_{m}$ is the average presence of *one molecule* across all species. \n* $y_{sm}$ is then the average presence across all species *plus* an error $\\epsilon$. And that is why we assume that **error** is normally distributed across the mean $\\mu$.\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.075}}},{"i":233,"$":{"0":{"v":"2023-02-13","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.02.13\n\n## Todo today\n* try to write out complete model (try to be as general as possible )\n* continue C++ courses \n* figure out a way to add the LaTex mathematical model in Dendron in order for people to access it\n\n![[A]]\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n* ask how to access MS data and how to pass to to the 1 and 0 matrix\n## Notes\n\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.116}}},{"i":234,"$":{"0":{"v":"2023-02-10","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.02.10\n\n## Todo today\n\n## Theory and ideas of the project\nWe seek to infer the presence or absence of $M$ metabolites in $S$ species. We denote by $x_{sm}$ whether metabolite $m=1,\\ldots,M$ is present ($x_{sm}=1$) or absent ($x_{sm}=0$) in species $s=1,\\ldots,S$. To infer the full vector $\\bm{x}=(x_{11}, \\ldots, x_{1M},\\ldots,x_{SM})$, we assume that related species share a similar set of metabolites and that metabolites related in their synthesis share a similar distribution across species. \nLet ${\\mathbb P}(x_{sm}=1|y_{sm})=y_{sm}$ be the probability with which metabolite $m$ is present in species $s$. We then assume that\n\n$$\nlogit \\space y_{sm} = log \\frac{y_{sm}}{1-y_{sm}} = \\mu_m + \\epsilon_{sm}\n$$\n\nwhere $\\mu$ is a metabolite-specific intercept and $\\epsilon_{sm}$ is normally distributed with mean 0 and co-variance $cov(\\epsilon_{sm},\\epsilon_{s'm'})=\\alpha \\sigma_{ss'} + \\beta \\sigma_{mm'}$ between each combination of species and metabolite. Here, $\\sigma_{ss'}$ and $\\sigma_{mm'}$ are known measures of covariance between species $s$ and $s'$ and between metabolites $m$ and $m'$, respectively, and $\\alpha$ and $\\beta$ are positive scalars.\n\nWe consider two sets of data informative about $\\bm{x}$: i) Presence-absence data obtained with mass-spectrometry and ii) presence-only reports of specific metabolites in specific specie. Let $\\bm{d_{sj}}=(d_{sj1}, \\ldots, d_{sjM})$ be the presence-absence vector of each metabolite $m$ obtained with mass-spectrometry run $j=1,\\ldots,J_s$ performed on species $s$. Assuming a false-positive and false-negative error rates $\\epsilon_{01}$ and $\\epsilon_{10}$, respectively, we have\n\n$$\n{\\mathbb P}(\\bm{d_{sj}}|\\bm{x}, \\epsilon_{01}, \\epsilon_{10}) = \\prod_m \\left[ x_{sm}\\left(\\epsilon_{10}^{1-d_{sjm}}(1-\\epsilon_{10})^{d_{sjm}}\\right) + (1-x_{sm})\\left( \\epsilon_{01}^{d_{sjm}}(1-\\epsilon_{01})^{1-d_{sjm}}\\right)\\right].\n$$\n\nTo model the presence only data, it must be put in relation to the expected research effort. Let $p_{sm}$ denote the known number of presence-only reports for metabolite $m$ in species $s$ and $n_{sm}$ the unknown number of research projects that aimed at discovering metabolite $m$ in species $s$. Assuming a false-positive and false-negative error rates $\\pi_{01}$ and $\\pi_{10}$, respectively, we have\n\n$$\n{\\mathbb P}(p_{sm}|n_{sm}, \\pi_{01}, \\pi_{10}) = ...\n$$\n\n\nProduct of cov ?! and not the sum ? \n### Images\nHere are the first ideas of the discussion we had with Daniel and Pierre-Marie:\n\n![image](assets/images/2023-01-30-14-53-54.jpg)\n\n![image](assets/images/2023-01-30-14-53-55.jpg)\n### Ideas \nSee forum discussion [here](https://github.com/anticipated-lotus/forum/discussions/3)\n* The probability of occurence of a given chemical class (i.e of a pseudo absence being indeed pseudo an not a real absence) could be formulated as the sum of probability of this occurence given the : chemical research effort context, phylogenetic context, covariance of other chemical classes. \n* This last term was discussed: study of the covariance of chemical classes within a given taxa could be informative. \n###\n\n## Doing\n\n## Paused\n\n## Done\nChange `prepare_pseudoabsence_tables.R` in order to have a csv table and not a space separated data. \n\n## Notes\n\"ref/noref, children/nochildren\" mean if you take into account multiple reference (and children) or not.\n\nSo, for example: 2 articles report amarogentin in *Gentiana lutea*, 3 (of which 1 is the same) in *Gentiana acaulis*.\n\nThen, for the pair amarogentin in *Gentiana*:\n* `ref_child` : 5 &rarr; Gives the number of occurences were we find amarogentin related with a *Gentiana* species.\n* `ref_nochild`: 4 &rarr; Gives how many **different** papers there are that talk about amarogentin in the species *Gentiana*\n* `noref_child` : 2 &rarr; Gives how many children of that species were found with at least one reference (in that case : *Gentiana    \n  lutea* and *Gentiana acaulis*)\n* `noref_nochild`: 1 &rarr; Will only be either 0 or 1. Gives if it there is at least one reference that talks about that molecule \n  in the species *Gentiana*\n\n**ATTENTION** tables are grouped also chemically. So child also refers to the \"chemical children\", so exactly same principle as for *Gentiana* and *G. lutea* but this for Terpenoids > Monoterpenoids > Secoiridoids (> Amarogentin)... \n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.042}}},{"i":235,"$":{"0":{"v":"2023-02-09","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2023.02.09\n\n## Todo today\n\n### Have a look at the DBGI discussion forum\n* https://github.com/orgs/digital-botanical-gardens-initiative/discussions\n\n\n###\n###\n\n## Doing\n* comment code from https://github.com/anticipated-lotus/elotus-trees\n  * `prepare_pseudoabsence_tables.R`\n  * `prettyStructuresTable.R`\n  * `prettyTree.R`\n\n## Paused\n\n## Done\nCommented code from https://github.com/anticipated-lotus/elotus-trees : \n* `count_npclasses.R`\n* `papers_taxa_correlation.R`\n\n## Notes\n### Scripts descrition\nI think the most important script for us is `prepare_pseudoabsence_tables.R`. It generates presence and absence tables\nof chemical compounds based on the Order. The Order could be changed to then have tables based on Family, Subfamily, Genus, etc... \n\nThis will have to be discussed: \n* At what level of taxonomy do we want to work ?\n* At what level of *chemical* taxonomy should we work ? \n* Should we try all the levels ?\n### Links to look at \nhttps://openmolecules.org/datawarrior/\nhttps://www.dendron.so/\n\nhttps://www.dbgi.org/dendron-dbgi/notes/tofizf0eb38rduuw6ffnzba/\n\nLOTUS outputs\nhttps://zenodo.org/communities/the-lotus-initiative/?page=1&size=20\n\n\nhttps://zenodo.org/record/7534071#.Y-S2QJOZP8Y\n\n\nSome links https://www.dbgi.org/dendron-dbgi/notes/inakqagsydtih7ls65eh3nb/\n\nhttps://www.sib.swiss/training/upcoming-training-courses\n\n\nhttps://www.irradiatedsoftware.com/sizeup/\n\n## Todo tomorrow\n\n###\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.088}}},{"i":236,"$":{"0":{"v":"Jdandois","n":1}}},{"i":237,"$":{"0":{"v":"2025","n":1}}},{"i":238,"$":{"0":{"v":"04","n":1}}},{"i":239,"$":{"0":{"v":"2025-04-17","n":1},"1":{"v":"\n# This is Jade's COMMONS Lab daily Open Notebook.\n\nToday is 2025.04.17\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\nPlate 3, Rg 1, dilution in DMSO \n\n## Notes\n1A-H : 100 uM (1uL sample + 99uL DMSO)\n2A-H : 10 uM (10 uL sample 1 + 90 uL DMSO)\n3A-H : 1 uM (10 uL sample 2 + 90 uL DMSO)\n4A-H : blank, only DMSO \n\n## Todo tomorrow, one day ... or never \n\n## Today I learned that\n\n- ","n":0.11}}},{"i":240,"$":{"0":{"v":"2025-04-07","n":1},"1":{"v":"\n# This is Jade's COMMONS Lab daily Open Notebook.\n\nToday is 2025.04.07\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n* for datacleaning, totally failed : ['Bacitracin', 'Colistin Sulfate', 'Glucosyl-vitexin']\n\n\n## Todo tomorrow, one day ... or never \n\n## Today I learned that\n\n- ","n":0.143}}},{"i":241,"$":{"0":{"v":"2025-04-04","n":1},"1":{"v":"\n# This is Jade's COMMONS Lab daily Open Notebook.\n\nToday is 2025.04.04\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n## Today I learned that\n\n- ","n":0.158}}},{"i":242,"$":{"0":{"v":"03","n":1}}},{"i":243,"$":{"0":{"v":"2025-03-21","n":1},"1":{"v":"\n# This is Jade's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.21\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\nHaversted some geophytes \n* Galanthus nivalis L. \n* Scilla mischtschenkoana Grossh. \n* Scilla bifolia L. \n* Muscari botryoides (L.) Mill. \n* Narcissus albicans (Haw.) Spreng \n* Crocus flavus Weston \n* Puschkinia scilloides Adams \n* Scilla sardensis (Barr & Sayden) Speta \n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n## Today I learned that\n\n- ","n":0.112}}},{"i":244,"$":{"0":{"v":"2025-03-18","n":1},"1":{"v":"\n# This is Jade's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.18\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n![](assets/images/chromato.png)\n\n\n\n\n## Doing\n\nLearning Python [^1] and citing [^2]\n\n## Paused\n\n## Done\n\n## Notes\n\n\n## Todo tomorrow, one day ... or never \n\n## Today I learned that\n\n\n----\n# References\n\n[^1] https://codefinity.com/get-started/spa/v8_new_brl?utm_source=google&utm_medium=cpc&utm_campaign=21435973810&utm_content=163793080723&utm_term=learning%20python&dki=Learning%20Python&gad_source=1&gad_campaignid=21435973810&gbraid=0AAAAABTeUgTiJp_rfgOunPW09KksdE-PH&gclid=EAIaIQobChMIq9v_0YmyjQMVzamDBx2LOB7TEAAYAiAAEgLMHvD_BwE\n\n[^2] Allard, P.-M. (2023). The Digital Botanical Gardens Initiative repository. https://doi.org/10.5281/zenodo.7662428\n","n":0.132}}},{"i":245,"$":{"0":{"v":"2025-03-17","n":1},"1":{"v":"\n# This is Jade's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.17\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n## To do ASAP \n\n- [ ] Learn python \n- [ ] Import excel data & script python \n\n## Doing\n* learning coding with git & gitub \n\n## Done\n\n## Notes\n* Isolating SMILES, MF & Name from the excel list \n\n## Todo tomorrow, one day ... or never \n\n### Ligne de Commande \n- [X] Check https://openclassrooms.com/fr/courses/6173491-apprenez-a-utiliser-la-ligne-de-commande-dans-un-terminal \n- [X] Check https://fribash.netlify.ap \n\n\n### git et Github \n[] Check https://openclassrooms.com/fr/courses/7162856-gerez-du-code-avec-git-et-github\n[] Check https://carpentries-incubator.github.io/git-novice-branch-pr/\n\n### python \n[] Check https://openclassrooms.com/fr/courses/7168871-apprenez-les-bases-du-langage-python \n[] Check https://realpython.com/python-first-steps/ \n\n### Linux \n[] Check https://openclassrooms.com/fr/courses/7170491-initiez-vous-a-linux/7251641-tirez-un-maximum-de-ce-cours-22 \n\n## Today I learned that\n\n- ","n":0.097}}},{"i":246,"$":{"0":{"v":"2025-03-15","n":1},"1":{"v":"\n# This is Jade's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.15\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n### Ligne de Commande \n[X]Check https://openclassrooms.com/fr/courses/6173491-apprenez-a-utiliser-la-ligne-de-commande-dans-un-terminal \n[X] Check https://fribash.netlify.ap \n[] Check https://www.codecademy.com/learn/learn-the-command-line \n--> Site payant ? \n\n### git et Github \n[] Check https://openclassrooms.com/fr/courses/7162856-gerez-du-code-avec-git-et-github\n[] Check https://carpentries-incubator.github.io/git-novice-branch-pr/\n\n### python \n[] Check https://openclassrooms.com/fr/courses/7168871-apprenez-les-bases-du-langage-python \n[] Check https://realpython.com/python-first-steps/ \n\n## Today I learned that\n\n- ","n":0.118}}},{"i":247,"$":{"0":{"v":"2025-03-13","n":1},"1":{"v":"\n# This is Jade's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.13\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\nRead 3 the 3 first chapters of BashCourse \n\n## Notes\n\n## Todo tomorrow, one day ... or never \n\n### Ligne de Commande \n[]Check https://openclassrooms.com/fr/courses/6173491-apprenez-a-utiliser-la-ligne-de-commande-dans-un-terminal \n[X] Check https://fribash.netlify.ap \n[] Check https://www.codecademy.com/learn/learn-the-command-line \n\n### git et Github \n[] Check https://openclassrooms.com/fr/courses/7162856-gerez-du-code-avec-git-et-github\n[] Check https://carpentries-incubator.github.io/git-novice-branch-pr/\n\n### python \n[] Check https://openclassrooms.com/fr/courses/7168871-apprenez-les-bases-du-langage-python \n[] Check https://realpython.com/python-first-steps/ \n\n## Today I learned that\n\n- ","n":0.115}}},{"i":248,"$":{"0":{"v":"2025-03-05","n":1},"1":{"v":"\n# This is Jade's COMMONS Lab daily Open Notebook.\n\nToday is 2025.03.05\n\n## Todo today\nrecolt \nunderstand dendron \n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n###\n\n## Doing\n\n## Paused\n\n## Done\n\n## Notes\n\n\n## Todo tomorrow, one day ... or never \n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.152}}},{"i":249,"$":{"0":{"v":"02","n":1}}},{"i":250,"$":{"0":{"v":"2025-02-10","n":1},"1":{"v":"\n# This is Jade's COMMONS Lab daily Open Notebook.\n\nToday is 2025.02.10\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n###\n\n###\n\n## Doing\ntest \n\nCreating my first note in dendron \n\n## Paused\n\n## Done\n\n## Notes\n\n## Todo tomorrow, one day ... or never \ncheck https://www.dendron.so\n\n\n\n\n###\n###\n\n\n## Today I learned that\n\n- ","n":0.144}}},{"i":251,"$":{"0":{"v":"jdandois-2025-checklist","n":1},"1":{"v":"\n# This is Jade's COMMONS Lab checklist \n\n## Bachelor project \n- [] Learn python \n- [] Make python script with excel list (550 molecules)\n- [] Isolating Name of the molecule, SMILES & Molecular Formule \n\n### Have a look at the COMMONS research discussion forum\n- [X] https://github.com/orgs/commons-research/discussions\n\n### Ligne de Commande \n- [X] Check https://openclassrooms.com/fr/courses/6173491-apprenez-a-utiliser-la-ligne-de-commande-dans-un-terminal \n- [X] Check https://fribash.netlify.ap \n\n\n### git et Github \n- [X] Check https://openclassrooms.com/fr/courses/7162856-gerez-du-code-avec-git-et-github\n- [X] Check https://carpentries-incubator.github.io/git-novice-branch-pr/\n\n### python \n- [] Check https://openclassrooms.com/fr/courses/7168871-apprenez-les-bases-du-langage-python \n- [] Check https://realpython.com/python-first-steps/ \n\n### Linux \n- [] Check https://openclassrooms.com/fr/courses/7170491-initiez-vous-a-linux/7251641-tirez-un-maximum-de-ce-cours-22 \n\n","n":0.109}}},{"i":252,"$":{"0":{"v":"Pamrein","n":1}}},{"i":253,"$":{"0":{"v":"2024","n":1}}},{"i":254,"$":{"0":{"v":"07","n":1}}},{"i":255,"$":{"0":{"v":"2024-07-18","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n\nPerformance Tips for DuckDB\nUse Wildcards and Directories:\nDuckDB supports using wildcards and directories for loading multiple Parquet files, which can simplify the process and improve performance by enabling parallel file reads.\n\nPredicate Pushdown:\nDuckDB supports predicate pushdown, which means it can push filter conditions (like WHERE clauses) down to the Parquet file scan level. This reduces the amount of data read and processed.\n\nIndexing:\nWhile DuckDB itself doesn't require traditional indexing, ensuring your Parquet files are partitioned appropriately based on the columns you frequently query can improve performance.\n\nEfficient Storage:\nEnsure your Parquet files are optimized for storage, using appropriate compression (like Snappy or ZSTD) and columnar storage formats.\n\nMemory Management:\nDuckDB operates in-memory, so ensure your system has sufficient RAM to handle the dataset. If your dataset is too large to fit into memory, consider processing it in chunks.\n\n\n\nexplanation of rules:\npkr0000001\t\t(1) http://www.wikidata.org/entity/Q278809[c0].(1) PHOSPHATE_ACCEPTOR_CoF[c0].(1) Pi[c0]>>(1) pkc0000111[c0].(1) pkc0000312[c0].(1) PYROPHOSPHATE_DONOR_CoF[c0]\tC=C(C)C1CC=C(C)CC1.O=P(O)(O)O.Nc1ncnc2c1ncn2C1OC(COP(=O)(O)OP(=O)(O)O)C(O)C1O>>C.C=C(O)C1CC=C(C)CC1.Nc1ncnc2c1ncn2C1OC(COP(=O)(O)OP(=O)(O)OP(=O)(O)O)C(O)C1O\tR0018d5c11a521de93fc329868fe7e99b660898ffef935a146d044e31a2d9d40e\trule0402\n\nrule0402\tAny;PHOSPHATE_ACCEPTOR_CoF;Pi\t[#6:1]-[#6:2].[#8:3].[#8:4]-[#15:5]>>[#6:1].[#6:2]-[#8:4].[#8:3]-[#15:5]\tAny;Any;PHOSPHATE_DONOR_CoF\tA4YD22;A4YD23;A4YGI1;A9WEI4;A9WKJ2;O17732;O24789;O27179;O27939;O30019;O93918;P05165;P05166;P07633;P11154;P11498;P14882;P32327;P34385;P52873;P53002;P53003;P54541;P63408;P78992;P79384;P81185;P95127;P9WQH4;P9WQH5;P9WQH6;P9WQH7;Q05920;Q06101;Q0CLK1;Q16921;Q19842;Q20676;Q29RK2;Q2QMG2;Q2TBR0;Q3J4D9;Q3J4E3;Q3ULD5;Q40121;Q42523;Q42777;Q54KE6;Q58626;Q58628;Q5I0C3;Q5XIT9;Q612F5;Q6M0D0;Q6M0D1;Q877I3;Q877I4;Q877I5;Q8T2J9;Q8X1T3;Q91ZA3;Q96CX0;Q96RQ3;Q99MN9;Q99MR8;Q9CHQ7;Q9F843;Q9HCC0;Q9HES8;Q9I297;Q9KWU4;Q9LDD8;Q9PNQ4;Q9PP00;Q9UUE1;Q9V9A7;Q9XBJ1\n\nSMART reaction:\nC-C + O* + P-O >> C + O-C + P-O*\n\n1 limonen + Phoshate_acceptor_CoF + pi >> pkc0000111 + pkc0000312 + PYROPHOSPHATE_DONOR_CoF\nC10H16   + C10H16N5O13P3 + H3O4P >> CH4 + C9H14O + C10H16N5O13P3\n\n(1)Q278809 + (1) PHOSPHATE_ACCEPTOR_CoF + (1) Pi>>(1) pkc0000111 + (1) pkc0000312 + (1) PYROPHOSPHATE_DONOR_CoF\nC=C(C)C1CC=C(C)CC1 + O=P(O)(O)O + Nc1ncnc2c1ncn2C1OC(COP(=O)(O)OP(=O)(O)O)C(O)C1O >> C + C=C(O)C1CC=C(C)CC1 + Nc1ncnc2c1ncn2C1OC(COP(=O)(O)OP(=O)(O)OP(=O)(O)O)C(O)C1O\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.068}}},{"i":256,"$":{"0":{"v":"2024-07-17","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nStorage vs. rows (what changes with removing duplicates):\n\noriginal\trenamed\t\n52402\t49875\t0.951776649746193\n48531\t45710\t0.94187220539449\n71354\t68697\t0.962763124702189\n    \n    \nrenamed\tcleaned\t\n49875\t\t\n45710\t44294\t0.969022095821483\n68697\t67320\t0.979955456570156\n\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.183}}},{"i":257,"$":{"0":{"v":"2024-07-15","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n\n\n\n## Future perspective\nToday I checked the script for cleaning. It was not worth to do it. \nMaybe I also did a mistake in the script. \n\noriginal reaction rows: 1_209_846_743\noriginal compound rows: 1_066_531_079\ncleaned reaction rows: 1_209_846_743 (not one removed line)\ncleaned compound rows: 1_014_766_986 (95% of original compounds)\n\n\noriginal files\n---reactions---\namount of files:        45\ntotal size (byte):      134_415_376_995\naverage size (byte):    2_987_008_378\n------\n---compounds---\namount of files:        45\ntotal size (byte):      57_967_518_441\naverage size (byte):    1_288_167_076\n------\n\ncleaned files\n---reactions---\namount of files:        45\ntotal size (byte):      135_488_568_545\naverage size (byte):    3_010_857_079\n------\n---compounds---\namount of files:        45\ntotal size (byte):      55_868_259_143\naverage size (byte):    1_241_516_870\n------\n\n\n\nAlso I looked at the reactions to see, if some rules appears more often than others. Witout separating multiple rules, I got this results:\n┌───────────────────────────────────────────────────────┬───────────┬────────────┐\n│ Reaction rules                                        ┆ count     ┆ frequency  │\n│ ---                                                   ┆ ---       ┆ ---        │\n│ str                                                   ┆ u32       ┆ f64        │\n╞═══════════════════════════════════════════════════════╪═══════════╪════════════╡\n│ rule0822                                              ┆ 187090387 ┆ 0.15464    │\n│ rule0028                                              ┆ 125538598 ┆ 0.103764   │\n│ rule0126                                              ┆ 68651569  ┆ 0.056744   │\n│ rule0918                                              ┆ 34774787  ┆ 0.028743   │\n│ rule0264                                              ┆ 28080779  ┆ 0.02321    │\n│ …                                                     ┆ …         ┆ …          │\n│ rule0124;rule0006;rule0604;rule0029;rule0001;rule1088 ┆ 1         ┆ 8.2655e-10 │\n\n\nhttps://smarts.plus/ we can analyse the reaction, which appears most often:\nrule0822\tAny;WATER\t([#6:1]-[#6:2].[#6:3]-[#6:4]).[#8:5]>>([#6:1].[#6:2]-[#6:3].[#6:4]-[#8:5])\tAny\t\n\n\nfrom: 2938937046\nto:   2955526557\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.071}}},{"i":258,"$":{"0":{"v":"2024-07-11","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nInstall Snakemake: <https://snakemake.readthedocs.io/en/stable/getting_started/installation.html>  \nI used the command: 'micromamba install -c conda-forge bioconda::snakemake'\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.177}}},{"i":259,"$":{"0":{"v":"2024-07-03","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nI tried to generate a graph based database with neo and I failed. \nJust to understand the basics is hard... (https://console.neo4j.io/)\n\n!! Learn how to use scratch on the cluster\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.143}}},{"i":260,"$":{"0":{"v":"2024-07-02","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nSpark with Polars:\nhttps://medium.com/@arkimetrix.analytics/polars-and-spark-100-million-row-dataset-18fd29f46d2c\n\nFalquet told me about two plattforms to upload chemical structures.\nhttps://www.ebi.ac.uk/\nhttps://pubchem.ncbi.nlm.nih.gov/\n\nI think it is not, what we want...\n\n\nrelational database (RDBMS), specifically MySQL (we later switched to Postgres).\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.144}}},{"i":261,"$":{"0":{"v":"2024-07-01","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n\n1. unique counts of columns\n- 10 files:\ntotal row = (241'488'958, 6)\nunique rows = 241'488'852\nInChIKey and ID = 241'488'852\nID = 24'744'991\nType = 1\nGeneration = 1\nFormula = 892'458\nInChIKey = 216'477'652\nSMILES = 216'481'182\nFormula & InChIKey = 216'477'652\nSMILES & InChIKey = 216'481'182\nFormula & SMILES & InChIKey = 216'481'182\n\n\n- all files [2min 32s]\ntotal rows = shape(1'066'311'368, 6)\nID = 25'095'950\nType = 1\nGeneration = 1\nFormula = 1'905'057\nInChIKey = 718'107'716\nSMILES = 718'267'621\nCPU times: user 25min 7s, sys: 4min 18s, total: 29min 26s\nWall time: 29min 23s\n\nFormula & SMILES & InChIKey = \n\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.099}}},{"i":262,"$":{"0":{"v":"06","n":1}}},{"i":263,"$":{"0":{"v":"2024-06-25","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nTodo: how many entries exist in the parquet files and how many in the db. (full?)\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.167}}},{"i":264,"$":{"0":{"v":"2024-06-24","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\nToday I will try to setup duckdb to search the database.\n\n\n\n## Daily report (What did I learn?)\nthe tests for duckDB\n\nsrun --partition=pibu_el8 --cpus-per-task=6 --mem=600G --time=10:00:00 --pty /bin/bash\n\nThe worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.  \n\nBecause of this error, the memory and cpu was increased to cpus-per-task=10 and mem=900G\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.122}}},{"i":265,"$":{"0":{"v":"2024-06-21","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n          || visible in terminal ||   visible in file   || existing\n  Syntax  ||  StdOut  |  StdErr  ||  StdOut  |  StdErr  ||   file   \n==========++==========+==========++==========+==========++===========\n    >     ||    no    |   yes    ||   yes    |    no    || overwrite\n    >>    ||    no    |   yes    ||   yes    |    no    ||  append\n          ||          |          ||          |          ||\n   2>     ||   yes    |    no    ||    no    |   yes    || overwrite\n   2>>    ||   yes    |    no    ||    no    |   yes    ||  append\n          ||          |          ||          |          ||\n   &>     ||    no    |    no    ||   yes    |   yes    || overwrite\n   &>>    ||    no    |    no    ||   yes    |   yes    ||  append\n          ||          |          ||          |          ||\n | tee    ||   yes    |   yes    ||   yes    |    no    || overwrite\n | tee -a ||   yes    |   yes    ||   yes    |    no    ||  append\n          ||          |          ||          |          ||\n n.e. (*) ||   yes    |   yes    ||    no    |   yes    || overwrite\n n.e. (*) ||   yes    |   yes    ||    no    |   yes    ||  append\n          ||          |          ||          |          ||\n|& tee    ||   yes    |   yes    ||   yes    |   yes    || overwrite\n|& tee -a ||   yes    |   yes    ||   yes    |   yes    ||  append\n\n\n\ntest:\n--RAY--\n(read-MINEs) [pamrein@login8 read-MINE-results]$ srun --partition=pibu_el8 --cpus-per-task=5 --mem=800G --time=10:00:00 --pty /bin/bash\n2024-06-21 09:42:33,117\tINFO worker.py:1770 -- Started a local Ray instance.\nshape: (0, 8)\n┌─────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n│ ID  ┆ predicted_r ┆ predicted_r ┆ predicted_r ┆ predicted_r ┆ predicted_c ┆ predicted_c ┆ predicted_c │\n│ --- ┆ eaction_ID  ┆ eaction_SMI ┆ eaction_Rxn ┆ eaction_Rea ┆ ompounds_Fo ┆ ompounds_In ┆ ompounds_SM │\n│ str ┆ equation    ┆ LES equa…   ┆ hash        ┆ ction ru…   ┆ rmula       ┆ ChIKey      ┆ ILES        │\n│     ┆ ---         ┆ ---         ┆ ---         ┆ ---         ┆ ---         ┆ ---         ┆ ---         │\n│     ┆ str         ┆ str         ┆ str         ┆ str         ┆ str         ┆ str         ┆ str         │\n╞═════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n└─────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘\ntime used: \nread_in_and_processed_time: 1218.27sec \tshow_time: 1.72sec\n\nsecond try:\ngenerated tabel: shape: (1_827, 8)\nread_in_and_processed_time: 1503.29sec (25min) \tshow_time: 1.72sec\n\n\n--DASK--\n1. srun --partition=pibu_el8 --cpus-per-task=5 --mem=200G --time=5:00:00 --pty /bin/bash\nread_in_time: 0.14sec   filtered_time: 0.01sec  show_time: 1992.17sec (33min)\n\n2. srun --partition=pibu_el8 --cpus-per-task=5 --mem=400G --time=5:00:00 --pty /bin/bash\nread_in_time: 0.07sec   filtered_time: 0.00sec  show_time: 1976.15sec\n\n3. srun --partition=pibu_el8 --cpus-per-task=5 --mem=800G --time=5:00:00 --pty /bin/bash\nread_in_time: 0.11sec   filtered_time: 0.01sec  show_time: 1923.53sec\n\nall the results where empty tables. So something with the ID went wrong...\n\n\nsecond try:\n1. srun --partition=pibu_el8 --cpus-per-task=5 --mem=200G --time=5:00:00 --pty /bin/bash\nrread_in_time: 0.02sec   filtered_time: 0.00sec  show_time: 3381.82sec (56min)\n\n2. srun --partition=pibu_el8 --cpus-per-task=5 --mem=400G --time=5:00:00 --pty /bin/bash\nread_in_time: 0.02sec   filtered_time: 0.00sec  show_time: 3622.37sec (60min)\n\n3. srun --partition=pibu_el8 --cpus-per-task=5 --mem=800G --time=5:00:00 --pty /bin/bash\nread_in_time: 0.01sec   filtered_time: 0.00sec  show_time: 3524.00sec (42min)\n\n\n\nwe can see, that It can takes at least 25 min for searching for a specific ID. This is very long, specially when you like to use it as a service. The way to go is using a DB (database), which can generate indexes and use them. This has the advantage to be faster in finding a specific word, but will increase the memorysize. In this case it is also important, to be able to work parallel. Because the big ammount of data can end up in a oom (out of memory) error.\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.045}}},{"i":266,"$":{"0":{"v":"2024-06-20","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nToday I asked again the question, how should I store the database and how could be accessible (what is the need of it?)\n\n> Which fileformat is the best?\nsource: https://www.reddit.com/r/learnpython/comments/omhsl5/pandas_saving_a_large_data_frame_efficiently/\nThey say, that the parquet file would be the best way to go. It is possible to reduce 50 Gb to 6 Gb.\nThe thing about *.parquet is, that it is binary (not human readable) and my dates are with the parquet file format still ~120 Gb togheter.\nEven with streaming and loading this huge datasets with the berner cluster (IBU) I run in \"kill\", which result in a OOM (out of memory).\n\nparquet: column oriented storage with a self-describing header (metadata). It was introduced 2013 by <https://parquet.apache.org/> which   is an opensource project.\n          compression is done columne wise and can be stored as a binary. It uses also RLE (Run length encoding) which saves multiple occurences of words only ones with a index.\n          parquet format can be read from multiple dataanalytic tools and is not only smaller in storagespace, but also in read & save speed.\n          good to know: Parquet files can be a zip bomb. so be carefull to read in parquet files (if possible, set max limits.)\n\n- DuckDB can use parquet files. (https://duckdb.org/2024/03/26/42-parquet-a-zip-bomb-for-the-big-data-age.html)\n\nfor big data processing they speak from dask or spark. Dask is in general less heavy and faster. It get public 2014 and spark 2010. ^uapatuqa2w46\n\n\n> Which are the \"intresting questions\" for this dataset?\nMy interpretation of the questions who can be answered with this datset, if the possibility exist, that a specific molecule exist in a choosen organism.\nFor example: If we analyse bacetrias thuringensis and we found in the MS spectra an unknown peak (untargeted). When we kind of can reconstruct the molecule, so we can search in our database and try to find it. If yes, we can check, in which organism it is known...\n\n\n\n\ntest run 1#:\npolars: shape: (7_431, 8)\nstart time: 1718883014.44sec    read_in_time: 0.05sec   filtered_time: 0.01sec         show_time: 516.50sec\n\ntest run 2#:\npolars: shape: (14_862, 8)\nread_in_time: 4.60sec   filtered_time: 1718883699.48sec         show_time: 4849.37sec\n\nI had a small error in my script. But what we can see, that the time to show it takes the longest...\nThe show time for the second run (full dataset) took over an 1h and 20min.\n\n\ntest run 2b# (corrected version of time):\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.051}}},{"i":267,"$":{"0":{"v":"2024-06-19","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nTmux - allow to work in one terminal parallel.\n<https://tmuxcheatsheet.com/>\n\ntmux ls - check all running terminals\ntmux new -t *progname*\ntmux kill-server - all terminals closed\ntmux a -t mysession\n\ntmux new -s mysession -n mywindow \n\n\nctr + b + %\nctr + b + \"\nctr + b + q *windowsnumber [0...]*\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.123}}},{"i":268,"$":{"0":{"v":"2024-06-18","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nAgain I have problems with storage. I can have about 900GB memory per task. If I read in all the *.parquet files, it is not enough.\nEven all the *.parquet files are only about 180GB, the compressed format will explode through the read in.  \nI am looking for parallising this step, which can be maybe possible with \"use_legacy_dataset=False\" (https://stackoverflow.com/questions/74236493/why-reading-a-parquet-dataset-requires-much-more-memory-than-the-size-of-the-dat). \n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.113}}},{"i":269,"$":{"0":{"v":"2024-06-14","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nscontrol show partition - Check the hardware and possible cpus / memory...\n\nsacct -j 12820165 --format=JobID,JobName%30,MaxRSS,Elapsed    - will check the memory and cpu use of a running job\nseff 12820165                                                 - more comprehensive description of memory and cpu use of this job-id \n\n\nThe size of all the predicted files (n45) is arround 771.22Gb. Because of storage problems after taking out the important columns (all columns) I have to reduce storage.\nThe main idea was to make a gzip command. \n\nBut for comparison reason, I will do ones a *.gzip and ones a *.paquet (polats binary) file.\n\nFilename: compounds_1_generalized_230106_frozen_metadata_for_MINES_split_14.csv_85718.53_\nshape: (24_035_930, 6)\n*.tsv:      4.7G\n*.gzip:     1.4G\n*.parquet:  1.3G\n\nFilename: reactions_1_generalized_230106_frozen_metadata_for_MINES_split_14.csv_85718.53_\n*.tsv:      13G\n*.gzip:     3.1G\n*.parquet:  2.9G\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.09}}},{"i":270,"$":{"0":{"v":"2024-06-12","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n-\n\n\n## Daily report (What did I learn?)\nToday I looked into the new complet predicted table. \nThe dataframe has 1_185_136_695 rows and 3 columns ('ID', 'Reaction rules', 'predicted_SMILES').\n\nI maybe see a problem with the rules. I am not 100% sure how unique they are. For example, if I concatenate them, that they have two different rules with the same name. \nStupid... I provided a file with all the rules. So all the information comes from one file. This is good. :)\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.104}}},{"i":271,"$":{"0":{"v":"2024-06-06","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nThe last file now started to run. The file n41 from the n45 folder runned for over 3 days and didn't succeed. \n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.152}}},{"i":272,"$":{"0":{"v":"05","n":1}}},{"i":273,"$":{"0":{"v":"2024-05-28","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n-\n\n\n## Daily report (What did I learn?)\nThe splitted files runned for ca. 1 day. It generated 620 GB of \"compounds and reactions\".\n\nAfter combining the compounds and reactions I have got 160GB of resultlist. \nI also realised, that some parts are missing. After checking the mails, I saw that some of the job run out of memory...\n\nthe cachedecorater saves the results between some steps. So you don't have to rerun it...\n\nTODO: - Read the dock for lazyframes\n\n### bash commands\n`du -h` - check the foldersize as humanreadable thing.\n\n`lsquota` - check the available size\n`du -h . | sort -rh`- ckeck the foldersize and sort them.\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.093}}},{"i":274,"$":{"0":{"v":"2024-05-23","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nbash commands:\n\ndelet all files in the current folder which are older then the given date (if problems with the date, run `date`)\n`find . -type f ! -newermt 'Thu May 23 15:00:14 CEST 2024' -exec rm -f {} \\;`\n\ncount files in a folder with specification:\n`ls -1q log* | wc -l`\n\ntoday I finished the script to join the ID with the reaction and predicted compounds.\nBut because I am running stuff parallel, I should also join this things at one point.\nFor this I will do tomorrow another script.\n\n\n## Future perspective\nNext I want to handle the compounds with specific rules.  \nSo the final dataframe should have added columns with the rules and the produced compounds of this rule.\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.087}}},{"i":275,"$":{"0":{"v":"2024-05-21","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\nI was running over the weekend the first generation for the full dataset LOTUS.\nThe job failes because of \"OUT_OF_MEMORY\". \nAlso I had the following error message:  \n[23:59:30] Maximum product count hit 10000, stopping reaction early...  \n[23:59:47] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.  \n\n\n\n## Daily report (What did I learn?)\n\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.118}}},{"i":276,"$":{"0":{"v":"2024-05-16","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nToday I like to write the first part of the masterthesis. \nI also have planned to start to run some more SMILES with the mongodb. Just to see how it works and how I can control / quality check it.\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.129}}},{"i":277,"$":{"0":{"v":"2024-05-15","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nToday I tried to produce MS spectras out of some SMILES.\nI tried RDkit, openbabel and cfmid. None of them worked in the first try.\nUntil now, I am not sure if I am supposed to do it. But at least I try. \n\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.127}}},{"i":278,"$":{"0":{"v":"2024-05-14","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n-\n\n\n## Daily report (What did I learn?)\n(Meeting in Davos)[https://worldbiodiversityforum2024.org/], which our groupe will join. \n\ncache decorator - use a function to save it on storage.\n\npickle : datathing in python (4bits). \n\n\nI've got the feeling, that the masterthesis is about to make Mines more efficient. We can run it and the choosen rules works finde, but in the beginning he tries for almost a minute to run tensorflow (or checking it). Also to parallel stuff doesn't work properly.\n\nI also have now problems to run it localy... this is amazing!!!\n\nI tried to rerun my pickaxe script on my laptop, which gives me errors because a module \"lxml\" is not installed. \nI reinstalled it with linuxbrew. Doesn't help. I run ´pip install lxml´ and then it worked... this is scaring me.\n\nlxml: it is a tool to handle html and xml in python. It is used to parse and manipulate XML and HTML documents. It provides a Pythonic API for processing XML and HTML documents.\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.076}}},{"i":279,"$":{"0":{"v":"2024-05-03","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\npubchem.ncbi.nlm.nih.gov - website for visualize smiles\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.196}}},{"i":280,"$":{"0":{"v":"2024-05-02","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nToday I started to run the different rulesets with pickaxe and tried to compare their differences.\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.167}}},{"i":281,"$":{"0":{"v":"04","n":1}}},{"i":282,"$":{"0":{"v":"2024-04-30","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nPierre Marie tried to register for an account on BNICE.\n\n\nWe started againg mongodb and I had some problems.\nI had to change authorisation for some files. <https://askubuntu.com/questions/823288/mongodb-loads-but-breaks-returning-status-14>\n\n\n\nhow to recover git commited files:\n1. clone the repo (so nothing bad can happen)\n2. get the hash - commit file\n```bash\ngit log -S cfm_id\ngit log --all --full-history -- <path_to_script>\ngit show <commit_hash>\n```\n3. recover it\n```bash\ngit revert <commit_hash>\n```\n\ncfm is a module to transfer SMILES into a spectra file.\n\n\n## Future perspective\n- different fraction 0.1, 0.2, 0.5\n- save files as datawarior file\n- script to calculate overlap between different datavases or different fractions with \n- upset plot (optional)\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.094}}},{"i":283,"$":{"0":{"v":"2024-04-26","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nI've got a Mail from Lisa Jeske (Brenda Database). \n\n1. take the structure file (molfile) from Brenda\n2. Convert it to a SMART (https://docs.chemaxon.com/display/docs/molconvert_index.md)\n3. annotate it with the organism\n\nI wanted to find out, how the mines database is build (where is the code?).\nThe paper <https://doi.org/10.1186/s13321-015-0087-1> provides some information about it. \nAlso a Github account is given: <https://github.com/JamesJeffryes/MINE-API>.\nBut it is not possible to find the code, how they put the reactions togheter. \nIt looks like they are working with the BNICE methode (database?) which is comming from the University of Lausanne.\n\nTo get access to the BNICE database, you have to sign up. This you can only do, if you are a professor.\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.088}}},{"i":284,"$":{"0":{"v":"2024-04-25","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nEC-Number: classification of enzym reactions. If different enzymes make the same reactions, it will be the same EC-number. <https://de.wikipedia.org/wiki/EC-Nummer>\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.16}}},{"i":285,"$":{"0":{"v":"2024-04-24","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nToday I received an answer from the BRENDA database: \n\nvielen Dank dass du BRENDA verwendest! Aktuell gibt es keine Möglichkeit die Reaktionen in BRENDA als SMARTS darzustellen/runterzuladen. Eine einfach Lösung für dein Problem sehe ich aktuell nicht. Für die Zukunft ist geplant eine umfangreichere API anzubieten, die mehr Informationen bereitstellt.\n\nFolgendes könnte ich mir allerdings vorstellen: Jeder Ligand hat eine spezifische Seite (z.B. https://brenda-enzymes.org/ligand.php?ligand_name=heme+b), wo es auch die Mol Files zum Download gibt. Diese Mol Files könnten verwendet werden um SMILES zu generieren (z.B. mit RDKit) um daraus dann die SMARTS zu generieren. Allerdings wäre es dazu nötig die BRENDA Webseite zu parsen um die  Mol Files zu erhalten.\n\nparsen: analysieren, bzw. in Teile zerlegen\n\n\n\n> Molfile: https://de.wikipedia.org/wiki/Molfile\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.086}}},{"i":286,"$":{"0":{"v":"2024-04-19","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n10:15 - shortly exchange with PMA -> I should have a look to Brenda.\nMaybe also other databases can be interesting, for example Uniprot. \nWe are looking for rules (SMARTS), which are known from an taxonomy.\n\n\n## Daily report (What did I learn?)\n\n### Brenda\nDatabase for enzyme information: <https://www.brenda-enzymes.org/download.php>\n\nhttps://web.archive.org/web/20150502012049/http://www.brenda-enzymes.org/index.php\n\n\n\n## Future perspective\nBerlese-Trichter : Bodenbakterien testen\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.126}}},{"i":287,"$":{"0":{"v":"2024-04-18","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n\n**How to use JupyterLab on the cluster**  \n1. start the correct environment and jupyter lab (Maybe you want also activate a specific environment with `poetry shell`)\n```bash\nsrun --partition=pibu_el8 --cpus-per-task=10 --mem=30G --time=10:00:00 --pty /bin/bashun\nmicromamba activate jup_lab\njupyter lab --no-browser --ip=0.0.0.0 --port=8879\n```\n\n2. start a new ssh connection from your pc\n```bash\nssh -N -f -L localhost:4000:binfservas22:8879 pamrein@login8.hpc.binf.unibe.ch\n```\n\n3. login with a browser (localhost:4000). The first time, you will be asked for a token. This you can find on the terminal (cluster), where the \"server\" is running. [my current password: jupyterlab]\n\n\n4. close jupyter-lab\n```bash\nlsof -ti:4000 | xargs kill -9   #for the pc-terminal\n```\nWith `Ctrl + C` you can close the jupyter-lab session on the cluster.\n\n\ntotal generelized rules: 1224\ntotal indermediate: 7358\nintermediat with underline: 6746\nIntermediat without underline should be: 612\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.085}}},{"i":288,"$":{"0":{"v":"2024-04-17","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n\nChange from website to ssh (for this you need a ssh key and also saved it on github):\n1. git remote -w      # check if remote is set to https\n2. git remote set-url origin <repository>\n\n\n\nFurther analysisi of ./MINE-Database/mine_database/data/metacyc_rules/\nmetacyc_intermediate_rules.tsv - 7359 lines \nmetacyc_generalized_rules.tsv - 1225 lines \n\n```bash\ncomm -12 metacyc_generalized_rules_sorted.tsv metacyc_intermediate_rules_sorted.tsv | wc\n    426     852    8896\ncomm -31 metacyc_generalized_rules_sorted.tsv metacyc_intermediate_rules_sorted.tsv | wc\n   6933   13866  171744\ncomm -23 metacyc_generalized_rules_sorted.tsv metacyc_intermediate_rules_sorted.tsv | wc\n    799    1598   16695\ncomm -3 metacyc_generalized_rules_sorted.tsv metacyc_intermediate_rules_sorted.tsv | wc\n   7732   15464  195372\n``` \n-1     suppress column 1 (lines unique to FILE1)\n-2     suppress column 2 (lines unique to FILE2)\n-3     suppress column 3 (lines that appear in both files)\n\nunique in **generalized** rules: 799 \nunique in **intermediate** rules: 6933\nunique entries total: 7732 \nfound in both files:  426\n\n\nTo check further, I asked for the rulename and the \"reactioncomment\":\n- Because it had some rulenames with underscore, I was wondering what this could be\n```bash\ncut -f1,5 metacyc_intermediate_rules.tsv | grep -v -E \"[a-z]*_[a-zA-Z0-9]*\" | wc\n```\nHe found **91 lines** with this rulename and following structure (example):\nrule0945\tmetacyc:RXN-17975;metacyc:RXN-17988  \nrule0906\tkegg:R07039;kegg:R07043;metacyc:RXN-14948;metacyc:RXN-14952 \nrule0323\tRXN-17679;RXN-527;RXN-7686;RXN-7687;RXN-8379;RXN-8450;RXN1F-93  \nrule1260\tN-ACETYLHEXOSAMINE-1-DEHYDROGENASE-RXN  \n\nIt looks like, that almost all the time \"RXN\" is involved. To check that:\n```bash\ncut -f1,5 metacyc_intermediate_rules.tsv | grep \":RXN-\" | wc*\" | wc\n# 3598 lines\n```\n\n```bash\ncut -f1,5 metacyc_intermediate_rules.tsv | grep \"metacyc:RXN-\" | wc\n# 3598 lines\n```\n\n```bash\ncut -f1,5 metacyc_intermediate_rules.tsv | grep \"RXN\" | wc\n# 5291 lines\n```\n\nOther Databases are followed distributed:\n(exp.: `cut -f1,5 metacyc_intermediate_rules.tsv | grep \"kegg\" | grep \"metacyc\" -c`)\n\nKegg: 4198\nBrenda: 5656\nmetacyc: 5258\nKegg & Brenda: 3250\nKegg & metacyc: 3783\nBrenda & metacyc: 3756\nBrenda & metacyc & Kegg: 3002\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.062}}},{"i":289,"$":{"0":{"v":"2024-04-16","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nToday I got the advice to look for the rules (general and intermediat). The goal is to change the rules, depending on the organism.\n\nSo for the moment I didn't dig more into the feasibility filter. I stopped by the \"_choose_items_to_filter\" function, which was correct, but somehow the filtering still doesn't work. I should look into it a little bit more maybe later.\n\nFor the reaction rules I found following information:\n./MINE-Database/mine_database/data/metacyc_rules/\nmetacyc_intermediate_rules.tsv - 7359 lines ()\nmetacyc_generalized_rules.tsv - 1225 lines (JN1224min from <https://doi.org/10.1016/j.ymben.2021.02.006>)\n\nthe loaded rules in pickaxe is the generalized_rules (./MINE-Database/mine_database/rules.py).\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.097}}},{"i":290,"$":{"0":{"v":"2024-04-15","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nNew start in the week with some motivation.\nToday I like to see the feastibility filter with expected results.\n\npycirclize : Package for circular diagram generation in Python. Marco likes to have that for his PHD for predicting Molecules in a species.\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.129}}},{"i":291,"$":{"0":{"v":"2024-04-12","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nNumba: Python package for \"in time\" compyling.\n\nmicromamba is an environment control program, which I am using for the cluster in bern. \n<https://mamba.readthedocs.io/en/latest/user_guide/micromamba.html>. \nThis is the way, how I am able to run different python versions.\nI tried also conda, which didn't worked...\n\nIf srun: use --partition=pibu_el8\n\nfile xxx : gives you the format of the file xxx\nlsquota: gives you the disk usage info of your project/group\n\nBecause of ibu cluster problems, I ve got the advice from bertier to reinstall conda, pyenv and ....\nI deleted Conda, pyenv and micromamba. Poetry (I guess) was in an environment and also deleted.\n\nThe reinstalling process is still going on.\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.091}}},{"i":292,"$":{"0":{"v":"2024-04-11","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nMCC, Matthews correlation coefficient\nSEN, sensitivity \nSPE, specificity\nPPV, positive predictive value \nNPV, negative predictive value\n\nfeasibility filter had some problems. He couldn't find any possible reaction, which is a little bit weired. \n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.14}}},{"i":293,"$":{"0":{"v":"2024-04-09","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n- Installed Zotero (<https://github.com/retorquere/zotero-deb>)\n  ```bash\nwget -qO- https://raw.githubusercontent.com/retorquere/zotero-deb/master/install.sh | sudo bash\nsudo apt update\nsudo apt install zotero\n```\n\nIt is recommended to do an account on Zotero, so you are able to store the links. \nBy the syncing settings, you shouldn't download the PDFs, because you only have 300 MB.  \n\n\npartial: command in python. <https://docs.python.org/3/library/functools.html>\n\n## pickaxe journal\n1. similarity and sampler filter  \na) set generation similarity to [0.0, 0.2]\n\n\nb) 10 targets; 10 Input; 0.2 reactions (fraction_coverage)\n10 compounds loaded...\n(9 after removing stereochemistry)\n10 target compounds loaded\n\nOverall run took 0.55 seconds. \n    0 new compounds & 0 new reactions\n\nc) 0 targets; 10 Input; 0.2 reactions (fraction_coverage)\n10 compounds loaded...\n(9 after removing stereochemistry)\n0 target compounds loaded\n\nGeneration 1 finished in 2.840805768966675 s and contains:\n\t\t946 new compounds\n\t\t916 new reactions\n\n- Because of the similarity filter couldn't work, it seems it didn't applied the filter.\n\n\nd) 0 targets; 10 Input; 0.5 reactions (fraction_coverage)\n10 compounds loaded...\n(9 after removing stereochemistry)\n0 target compounds loaded\n\nGeneration 1 finished in 9.916597843170166 s and contains:\n\t\t1429 new compounds\n\t\t1442 new reactions\n\nd) 10 targets; 10 Input; 0.5 reactions (fraction_coverage)\n10 compounds loaded...\n(9 after removing stereochemistry)\n10 target compounds loaded\n\n\n\n## Goal's\n- [ ] run MINEs on the cluster with poetry\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.07}}},{"i":294,"$":{"0":{"v":"2024-04-05","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n9:45 - 12:00 - Filters in Pickaxe (how use the filters)\n13:00 - 14:00 - work in Cluster (Bern)\n13:30 - 15:00 - update extractor-dataset\n\n\n\n## Daily report (What did I learn?)\n\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.152}}},{"i":295,"$":{"0":{"v":"2024-04-04","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n- [ x ] print the pickaxe paper and read it!\n- [ ] start with the filters\n\nTomatine (<https://en.wikipedia.org/wiki/Tomatine>): is a glykoalkaloid found in tomatoplants. Defense molecule.\n\n**virtual screening**: Virtual screening is an in silico method that consists of screening large small-molecule databases for bioactive molecules.\n\n![alt text](image-10.png)\n\ntoday I read the paper and started with the filters again. I am still confused about the options.\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.11}}},{"i":296,"$":{"0":{"v":"2024-04-03","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n~13:00 PM was in the office\n\n\n\n\n## Daily report (What did I learn?)\nI installed **Data warrior** (<https://openmolecules.org/datawarrior/download.html>), which is a tool developped for looking at molecules. It's written in Java and can show the molecules as a 2D or 3D structure. The helppage is quiet big.\n\nTomorrow I will have to read again the paper and try again the different filters. \n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.116}}},{"i":297,"$":{"0":{"v":"2024-04-02","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[] \n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\nToday I will try to do a little package to calculate predicted next molecules.\n\n\nMultiprocessing package (from pyhton):\n\nToday helped me Marco Visani a lot. We tried out the minedataset module, what should be my masterthesis.\nWe did some different filters and run in problems, which was a little bit unexpected.\nFor example: \n- I was working in the fork folder with my script, which isn't the smartest idea.\n- I was working in the forkfolder and had additionaly installed **minedatabase** as a package in poetry. This doesn't make any sense, because I want to work in the forkfolder (copy of minedatabase)...\n- with the command `poetry add git+<website>` it is possible to add packages, which are not from pip. This what we have to do with our fork. \n- Somehow, it didn't worked. The solution was to rename the mainfolder minedatabase -> mine_database. Additionaly we had to run `poetry build` in the folder, to make kind of a package out of it. With poetry show, we could see it added the package which was not from pipy. \n- I realised, when I installing packages, they will be also available for pyenv. Better said, poetry uses pyenv for this. The problem is, that I have multiple packages working on that pyenv... I have to find a solution.\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.066}}},{"i":298,"$":{"0":{"v":"03","n":1}}},{"i":299,"$":{"0":{"v":"2024-03-28","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n11:00 - xx:xx\n- Fibl (doc project - different technics over 40 years in 96 areas)\n- retrosynthesis -> retrobiosyntheses (Product to basic elements)\n- camb fingerprinting\n- enthology\n- maximum common substructure (MCS) <https://docs.chemaxon.com/display/docs/jklustor_maximum-common-substructure-mcs-search.md>\n\n## Daily report (What did I learn?)\n8:45 - | started with the university of mongodb\n\n- tqdm for processing overview is a robust and easly to implement tool: <https://tqdm.github.io/>\n\nfaisse : AI from facebook\n\nLuca Capalleti\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.115}}},{"i":300,"$":{"0":{"v":"2024-03-27","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n- made a new \"course\" entry about mongodb\n- learned about mongodb with pickaxe, that some how it can have problems when you generate images. It will not write in to the database, because of a system error.\n- I don't know, how to verify the output and even how I can looking for that. \n- [Mongo University](https://learn.mongodb.com/learning-paths/introduction-to-mongodb) maybe it's worth it to check it out.\n\n\n\n## Future perspective\n- try to understand pickaxe a little bit better (maybe reread the paper...)\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.102}}},{"i":301,"$":{"0":{"v":"2024-03-26","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\nNext Thursday at 11:00.\n\n\n## Daily report (What did I learn?)\nlearning about mongo db...\n\n### Mongo DB\n[Installation of mongodb](https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-ubuntu/#std-label-install-mdb-community-ubuntu)\n\nAfter the installation, the service has to be started.\n\n```bash\n# start service\nsudo systemctl start mongod\n\n# check status\nsudo systemctl status mongod\n\n# if problems accurese, try this\nsudo systemctl daemon-reload\n\n# stop service\nsudo systemctl stop mongod\n```\n\nto check the databases, we can use `mongosh`(=mongo shell).\nUse the help page for navigation.\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.116}}},{"i":302,"$":{"0":{"v":"2024-03-22","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n9:00 Pierre Maries Office\n\n- sort the downloads\n- file should be choosen directly too\n- add extension\n- come back\n\n\n## Daily report (What did I learn?)\nGithub actions had problems with publishing the website. So I tried to fix it and found out, that the action was failing because of a \"missing package: mkdocstring\". Even after adding it the action with the command `mkdocs gh-deploy` was failing.\n\n\"mkdocstrings\" is set as plugin in the mkdocs.yml file. Somehow he couldn't find a specific module. Even after adding the mkdocstrings package. It can be interesting to dive more in too. <https://mkdocstrings.github.io/>\nI also don't understand exactly how it works with sphynx <https://www.sphinx-doc.org/en/master/>, which I mostly can find...\n (pytkdocs)\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.09}}},{"i":303,"$":{"0":{"v":"2024-03-21","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n- I did the first running using version of the program. It is released as new version on github: https://github.com/commons-research/dataset-extractor-lotus/releases/tag/v1.1.\n\nMamba is another conda. Just a little bit better... ^^ <https://github.com/mamba-org/mamba>\n<https://mamba.readthedocs.io/en/latest/user_guide/micromamba.html>\n\nI have to dive into it...\n\n*SDF (Simple Data Format)* : Simple Data Format is a file format used by numerical modelers. It was invented by George H. Fisher of the Space Sciences Lab at UC Berkeley in 2007.  \nThe format's goal was to provide a way of reading and writing output data from numerical simulations that preserve full precision. Furthermore, the format is simple, easy to use, and supports files of several gigabytes.\n\n \n\nfor request commands like *GET and *POST we should always raise an error, if the status has some problems...\n`r.raise_for_status()`   \nThe *GET and *POST is for communication with a server. *GET is for requesting data from a server and *POST is for submitting data to a server. It exist more than just this twos, but they are mainly used. <https://www.w3schools.com/tags/ref_httpmethods.asp>\n\n\nWhen I searched for pickaxe (subtool of mine) I always came back to mine <https://pypi.org/project/minedatabase/>. \nIt includes pickAxe! --> Info <https://mine-database.readthedocs.io/en/develop/pickaxe_run.html>\nI tried to run the pickaxe_run.py (sample code), which couldn't be launched because of filterproblems...\n\n\n## Future perspective\nLook up, how to predict SMILES....\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.067}}},{"i":304,"$":{"0":{"v":"2024-03-20","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n-\n\n\n## Daily report (What did I learn?)\nToday I will try to finish my prog. \n\nFor better programming, I tried to install spyder and use it with poetry. \nI run in the problem, that spyder would have a problem to install dependencies on poetry with the command `poetry add spyder`. \n\n`dir(<package>)` : all the possible attribute and methods.\n\nI still tried out the same stuff like yesterday. \nThe function *.join() should do what I like to have. But I will get still some unusual results.\nfor example, if I do a subset of a dataframe and join it with *inner*, I will get nothing.\nThe return should be the same dataframe.\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.091}}},{"i":305,"$":{"0":{"v":"2024-03-19","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[] todays goal is to finish the prog and show it to mary-pierre...\n\n\n## Meetings\n- short look at the prog\n\n\n## Daily report (What did I learn?)\npolar used sphinx for the documentation <https://www.sphinx-doc.org/en/master/>.\n\n\ndf_remove = []\n    ...: for i in range(len(df1)):\n    ...:     for j in range(len(df)):\n    ...:         print(df1[i,:].equals(df[j,:]))\n    ...:         if df1[i,:].equals(df[j,:]):\n    ...:             df_remove.append(df1.row(i))\n    ...:             break;\n\nI am still not done with the programming part. The problem is one basic step and I just don't find a solution...\nOne solution could be change to pandas, but I like to do it with polars.\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.1}}},{"i":306,"$":{"0":{"v":"2024-03-15","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n\n### Docstrings (in Python)\nDocstring helps by the documentation of python modules. It can be added just under the function name with `\"\"\"`or `'''`.   \n\nIt can be called in two ways:\n\n```py\n# import your model\nimport zenodo_downloader as zd\n\n# using variable __doc__\nprint(\"Using __doc__:\")\nprint(zd.doi_info.__doc__)\n \n# using help function\nprint(\"Using help:\")\nhelp(zd.doi_info)\n```\n\nFor the documentation it exist different \"styles\" of docstring. One which I will prefer is google-style which is the following:\n```py\ndef multiply_numbers(a, b):\n    \"\"\"\n    Multiplies two numbers and returns the result.\n \n    Args:\n        a (int): The first number.\n        b (int): The second number.\n \n    Returns:\n        int: The product of a and b.\n    \"\"\"\n    return a * b\nprint(multiply_numbers(3,5))\n```\n\nNow I am working with the `pip install inquirerpy` package. It is a package for creating interactive command line interfaces.\n<https://inquirerpy.readthedocs.io/en/latest/pages/prompts/rawlist.html>.   \nAttention: It also exist 'pyinquirer` which is not the same!\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.082}}},{"i":307,"$":{"0":{"v":"2024-03-14","n":1},"1":{"v":"\n\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n[[courses.keyboardshortcuts]]\n\nConnect with the new cluster (Rocky Linux 8)\nssh pamrein@login8.hpc.binf.unibe.ch\n\nTUI: Textbased User Interfaces (to make the code more interactive)\n\nREPL: Read–eval–print loop <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>\n-> https://replit.com/signup\n\nHow to handle input arguments: <https://docs.python.org/3/library/getopt.html>\n\nToday I finished my fist module, which I like to use for the main.py. \nBut the main.py has still some difficulties, so I started to write a new main2.py, which should be released as next. \nThe goal is to finish tomorrow. \n\nI will also change the strategy, how to collect the samples. It would just take the taxa and amount to sample. If the output file exist, it will check for duplicates, drop them and add the new entries.\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.089}}},{"i":308,"$":{"0":{"v":"2024-03-12","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n\nZenodo is just used as a \"research google drive\". It will provide a DOI number and you can upload your data (without proofing it).\n\n### zenodo_client \nToday I tried out the package zenodo_client <https://github.com/cthoyt/zenodo-client>.\nFor this you need to make an API token to access the zenodo webpage.\nAPI tokens are used for authentication and authorization purposes in API (Application Programming Interface) requests.\nThis token has to be stored in the file `~/.config/zenodo.ini` ([.ini](https://en.wikipedia.org/wiki/INI_file)) with the following entry:\n```yaml\n[zenodo]\napi_token = <your_token>\n```\nUnfortunately, I was not able to download my data specificly. Somehow I have to provide a name of the file, but I don't get it, how I would get the filename without knowing it. If I try the querys directly in the browser, I can see there is only one file to download. The package also needs the API_token, which doesn't makes it userfriendly.\nI will try to find another solution for it. \n\n\n### Webscrapping\nIt didn't worked out with the zenodo_client, so I tried to do it with webscrapping. I used beautifulsoup4 and selenium to get the links.\nThe trick is, to open a webpage where all the versions are available, load them (javascript is activ what makes it more difficult to grap)\nand get the links for downloading. I tried to build my own package, but it didn't worked out until now. So I will do it in the next days.\n\nI learned a lot about webscrapping basics and some nice coding. I am looking forward to do my first package.\n\n## Future perspective\nAsk PM for more advice\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.061}}},{"i":309,"$":{"0":{"v":"2024-03-11","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learn?)\n- for documentation on github (Website): <https://pages.github.com/>\n- github workflows <https://docs.github.com/en/actions/learn-github-actions/understanding-github-actions>\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.183}}},{"i":310,"$":{"0":{"v":"2024-03-08","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[] try to get in touch with mkdocs\n\n\n## Meetings\nNone\n\n\n## Daily report (What did I learn?)\n\n### Mkdocs\nTool for documentation.\n\n1. Installation:\n```bash\npipx install mkdocs\n```\n\n2. Create mkdocs in the projectfolder\n```bash\nmkdocs new <project_directory>\n```\n\n3. Configurate the mkdocs.yml. In this file will be set all the settings and links.\n```bash\nvim mkdocs.yml\n```\n\nThe file can look like this (<https://www.mkdocs.org/user-guide/configuration/>):\n```bash\nThe file can look like this:\nsite_name: \"Dataset Extractor for LOTUS\"\nrepo_url: \"https://github.com/commons-research/dataset-extractor-lotus\"\nsite_author: \"Pascal Amrein\"\nsite_description: \"Python script to extract data from the LOTUS Database\"\ncopyright: \"commons-lab\"\nrepo_name: \"GitHub\"\nnav:\n  - Home: \"index.md\"\n  - About: \"about.md\"\nnot_in_nav:\ntheme: \"readthedocs\"\n```\n\n4. test your documentation\n```bash\nmkdocs serve\n```\n\n5. publish it to github (the output will show you the link for the documentation)\n```bash\nmkdocs gh-deploy\n```\n\nIt is recommended to ignore (.ignore file) the folder /site which will be the outputfile from mkdocs. It will inclute the *.html file, *.css and others.\n\n\nWith the gh-deploy the following webpage went online <https://commons-research.github.io/dataset-extractor-lotus/#information>.\n\n\n## Future perspective\nhow can it automatically include the functiondoc.\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.082}}},{"i":311,"$":{"0":{"v":"2024-03-07","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n## Meetings\nWith PM:\n- Readme is as much important then code <https://www.freecodecamp.org/news/how-to-write-a-good-readme-file/>\n- no hardcoded paths! Use this package <https://github.com/cthoyt/zenodo-client>\n- not only random sampeling. Also possibility to specify taxanomy...\n\n## Daily report (What did I learn?)\nToday I tried mkdocs. It is a cool and easy way to build a documentation. At least they claim that.\nI am not there now. MKDocs should have the possibility to read your code and automatically use this for documentation.\nIt can generates HTML sites, which can be used for publishing.\n\n## Future perspective\nI like to make a LOTUS module, for my code stuff. It works, but my 209 lines of code are not easly readable anymore. \n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.092}}},{"i":312,"$":{"0":{"v":"2024-03-06","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[] API with Pick-Axe\n\n\n## Meetings\n- short feedback for my first line of codes  \nI should make a readme for other people to know how to use it.\n[good practice](https://cthoyt.com/2020/06/03/how-to-code-with-me-organization.html)\n[good readme](https://www.freecodecamp.org/news/how-to-write-a-good-readme-file/)\n\n## Daily report (What did I learn?)\n\n### About Pick-axe\n- [Metacyc](https://metacyc.org/) has information about metabolic pathways database. It provides the \"JN1224min ruleset\" (1224 reaction rulset) for pick axe. For each reaction exist an UniProt entry for the specific Enzyms.\n- It has two *compound property filters*. One for molecularweight (MV) and one for atomic composition of an individual compound to determine if it should be removed\nfrom the network.\n- Pickaxe generates cemical fingerprints (bit vectores with the RDKit) for see similarities. It has a cutoff filter and sampling filter (weighted Tanimoto distribution)\n- With the Metabolomics filter needs as input a list of experimental mass-to-charge (m/z) values and a list of possible adducts.\n- Thermodynamics-based filter uses the Gibbs free energy. \n- Feasibility filter: Deep learning-based Reaction Feasibility Checker (Deep_RFC). It is incorporated into Pickaxe.\n- Outputs: generated networks in three different formats. Each format has information about the compounds: reactions, reactionrules and target molecules.\nResults can be stored in a MongoDB as a JSON format. It also supports Systems Biology Markup Language (SBML).\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded-np-chemspace.keywords]]\n","n":0.069}}},{"i":313,"$":{"0":{"v":"2024-03-05","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\nNone\n\n\n## Daily report (What did I learn?)\n- finished version one of the script for the toydataset.\n\n\nCtrl. + D : exit environment in Terminal\n\n### Autoformating for code\nVisual studio provides a package \"Black formatter\" for python, which will automatically reformat when you press `Ctrl. + Shift + I` (for Linux) or `Ctrl. + Shift + F` (for Windows).\nIf you change the file \"Open Users Settings (JSON)\" and you add the line `\"editor.formatOnSave\": true` into the barely brackets, it will format if you save the file. \n\n### Sparkl's\nWikidata questions\n[qlever](https://qlever.cs.uni-freiburg.de/wikidata) website for searching wikidata (much faster than [wikidata](https://query.wikidata.org/))\n\n\n### MINEs\nThe [Website](https://minedatabase.mcs.anl.gov/#/home) provides an [API](https://github.com/tyo-nu/MINE-Server/blob/master/docs/API%20Examples.ipynb) for searching the Metabolic In Silico Network Expansion Database. \n\n### LOTUS dataset\n\nThe columns will have following content:  \n**chemical information**\nstructure_wikidata,structure_inchikey,structure_inchi,structure_smiles,structure_molecular_formula,structure_exact_mass,\nstructure_xlogp,structure_smiles_2D,structure_cid,structure_nameIupac,structure_nameTraditional,structure_stereocenters_total,\nstructure_stereocenters_unspecified,  \n\n**npclassifier**\nstructure_taxonomy_npclassifier_01pathway,structure_taxonomy_npclassifier_02superclass,structure_taxonomy_npclassifier_03class,\n\n**classyfire - chemical taxonomy**\nstructure_taxonomy_classyfire_chemontid,structure_taxonomy_classyfire_01kingdom,structure_taxonomy_classyfire_02superclass,structure_taxonomy_classyfire_03class,structure_taxonomy_classyfire_04directparent,\n\n**organism information**\norganism_wikidata,organism_name,organism_taxonomy_gbifid,organism_taxonomy_ncbiid,\n\n**organism taxonomy**\norganism_taxonomy_ottid,organism_taxonomy_01domain,organism_taxonomy_02kingdom,organism_taxonomy_03phylum,organism_taxonomy_04class,organism_taxonomy_05order,organism_taxonomy_06family,organism_taxonomy_07tribe,organism_taxonomy_08genus,organism_taxonomy_09species,organism_taxonomy_10varietas,\n\nreference_wikidata,reference_doi,manual_validation\n\n\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.085}}},{"i":314,"$":{"0":{"v":"2024-03-01","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\nNone\n\n\n## Daily report (What did I learn?)\nWhich prog language is the best?  \nDoes it depends on the usage or other stuff? \nMarco showed me today rust. It looks very easy to use and they have a lot of implemented tools, which are very useful. \nLike Julia, it can also work with other packages which increases the possibilties of the language.\n[https://survey.stackoverflow.co/2023/](https://survey.stackoverflow.co/2023/)\n\npolars is a package for python. It is 30x faster than pandas for data wrangling and analysis. It is very useful for data science tasks like feature engineering, data cleaning, etc.\nBecause the LOTUS dataset is very big, the table of polar has to be increased too. `data = pl.read_csv(path_to_file, separator=\",\", infer_schema_length=1000000)`\n\n\nPickaxe removes stereochemistry by default.\nCompounds (SMILES) -> reaction rules (SMARTS - based on JN1224min) -> compounds, reactions, reaction rules, and target molecules (Systems Biology Markup Language (SBML)).\n\n### Poetry #program\npoetry show : shows all available packages in this environment\n\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.079}}},{"i":315,"$":{"0":{"v":"02","n":1}}},{"i":316,"$":{"0":{"v":"2024-02-29","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\n\n\n\n## Daily report (What did I learned?)\n[[courses.python-and-packages]]\n\nDendron refractor:\nhttps://wiki.dendron.so/notes/srajljj10V2dl19nCSFiC/\n\n\n### VSCode #program\n| **command**        \t| **description**          \t|\n|--------------------\t|--------------------------\t|\n| `Ctrl + Shift + P` \t| Open search for commands \t|\n|     `Ctrl + P`     \t| Open search for files.   \t|\n\n### Poetry #program\nChanges made in config file (`poetry config --list`):\n`virtualenvs.path = \"{cache-dir}/virtualenvs\"  # /home/popeye/.cache/pypoetry/virtualenvs` to\n`/home/popeye/.pyenv/versions`   \n\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.126}}},{"i":317,"$":{"0":{"v":"2024-02-28","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab)\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]write the script in python\n-[]try to translat it in rust code\n\n\n## Meetings\nNone\n\n\n## Daily report (What did I learned?)\n\nsnakemake\n\n### Poetry\nAdd a package:\n\n\n### shortcuts \n#### VScode\n`ctrl+shift+^` : open the new terminal\n\n### How Backup .bashrc\nBackup your current .bashrc file:\n```bash\ncp ~/.bashrc ~/.bashrc.bak\n```\n\nCopy the skeleton .bashrc file over yours:\n```bash\ncp /etc/skel/.bashrc ~/\n```\n\nAfterwards, load the new one:\n```bash\nsource ~/.bashrc\n```\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n\n","n":0.125}}},{"i":318,"$":{"0":{"v":"2024-02-27","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab) [2024.02.27]\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[] Cookiecutter install with poetry\n-[]Install Rust (with Packagemanager Cargo) and try to make a script\n\n\n## Meetings\nNone\n\n\n## Daily report (What did I learned?)\n[Tiobe](https://www.tiobe.com/tiobe-index/) makes the ranking for programmlanguages.\nNumber one is python followed by C, C++, Java and C#. Rust and Julia are not under the first 20 places.\n\nRust: Performance, Reliability (memory-safety and thread-safety), Productivity (specially because of cargo)\n\nJulia: High Performance (LLVM for numerical and scientific computing), Versatility (web development, game development, machine learning, data science, financial modeling, network security, and more), Ease of Use (like python), Interoperability (supports foreing functions), Growing Ecosystem (BioJulia, JuMP Dev, JuliaImages, QuantumBFS...). It has also an build in package and environment manager which is called \"pkg\".\n\nCookiecutter is using some called \"generators\", which helps to set up a specific structure for a project with some files.\nIt can be usefull to have a standard structure for projects. \n\nPoetry is a package and environment manager for python.\n\n\n## What I did today\nInstalled pipx: https://pipx.pypa.io/stable/\nIf pipx is installed in the terminal, you have to be sure it is added to the .bashrc and to reopen the terminal, so that the changes takes place.  \n'sudo apt update'  \n'sudo apt install pipx'  \n'pipx ensurepath'  \n\n\nInstalled cookiecutter: \npip install cookiecutter\n\nInstalled poetry: \n'pipx install poetry'\n'poetry init' or 'poetry new <projectname>'\n'poetry install'\n\npoetry show -v\n(Windows) $ poetry run python setup.py windows -s\n(macOS)   $ poetry run python setup.py macos -s\n(Linux)   $ poetry run python setup.py linux -s\npoetry build\n\npoetry shell /go into terminal mode - type \"exit\" to leave the shell\n\nTo run codium in a specific directory, write in the shell: 'codium .'\n \n\nInstalled [rust](https://www.rust-lang.org/tools/install)\n\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.061}}},{"i":319,"$":{"0":{"v":"2024-02-26","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab) [2024.02.26]\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[x]check out cookiecutter (with poetry)\n\n\n## Meetings\nNone\n\n\n## Daily report (What did I learned?)\n\n### [poetry](https://python-poetry.org/)\nPython packaging and dependency management tool. The *.toml is the managemant file.  \nThe installation can be done with pipx (install: pip install pipx)\n\ncookiecutter: \n\n\n\n\n## Future perspective\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]","n":0.141}}},{"i":320,"$":{"0":{"v":"2024-02-23","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab) [2024.02.23]\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\nNone\n\n\n## Daily report (What did I learned?)\n\n[[expanded-np-chemspace.information.papers]]\n\nmicromamba \npoetry\n\n## Future perspective\n\n\n","n":0.213}}},{"i":321,"$":{"0":{"v":"2024-02-22","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab) [2024.02.22]\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n-[]\n\n\n## Meetings\nNone\n\n\n## Daily report (What did I learned?)\nHow to work efficient? Maybe the [GTD](https://en.wikipedia.org/wiki/Getting_Things_Done) from David Allen can help.  \n\n[[expanded-np-chemspace.information.papers]]\n\n\n\n## Future perspective\n","n":0.174}}},{"i":322,"$":{"0":{"v":"2024-02-21","n":1},"1":{"v":"\n# PAMREIN's daily Open Notebook (COMMONS Lab) [2024.02.21]\n\n## Todo - [Check Github](https://github.com/orgs/commons-research/projects/2/views/1)\n- Read Paper's (find the subject of the thesis)\n\n\n## Daily report (What did I learned?)\n[[expanded-np-chemspace.information.papers]]\n\n\n## Future perspective\n[[open-notebook.commons.pamrein.questions]]","n":0.189}}},{"i":323,"$":{"0":{"v":"2024-02-20","n":1},"1":{"v":"\n# This is pamrein's COMMONS Lab daily Open Notebook.\n\nToday is 2024.02.20\n\n## Todo today\n\n### Have a look at the COMMONS research discussion forum\n    - https://github.com/orgs/commons-research/discussions\n\n\n## Doing\n- introduction to [dendron](https://www.dendron.so)\n  - Ctrl + L or daily lab book Ctrl + Shift + D\n  - Links are made with double brackets \"[[]]\"\n- info slides from PMA https://doi.org/10.5281/zenodo.8137605\n- Zulip for chatting https://commons-lab.zulipchat.com/\n- Mine, Smart and others (Datatypes for proteinstuff)\n- poetry (like conda but better)\n\n### Meeting Zoom - Annothons\nhttps://mibig.secondarymetabolites.org/\n\nMIBiG 1.0 (2015)\nMIBiG 3.0 (2022)\nMIBiG 4.0 (2024)\n\nseparate biosynthesis vs. compound classifications (Kai Blin)\n\nMITE - Minimum Informationabout at Tailoring Enzyme (database crosslinks - https://github.com/INTABiotechMJ/MITE-Tracker)\ndescribes reactions of molecules.\n\nTrello (Kanban boards for work coordinations) - Toyota is using it\n\nMIBiG Literature table (http://tinyurl.com/mibig-literature)\nhttp://tinyurl.com/mibig-literature-explanation\n\nLicensing: https://www.contributor-covenant.org/\n\n\n\n## Keywords\nPickaxe\n<<<<<<< HEAD\n=======\n\n\n## Today I learned that\n>>>>>>> f268f10 (update dendo daily report)\n","n":0.09}}},{"i":324,"$":{"0":{"v":"commons-pamrein-usefull_commands","n":1},"1":{"v":"\n# Usefull commands\n\n# Terminal - IBU Cluster\n\n\n## bash\n\n\n# python\n\n\n# R","n":0.316}}},{"i":325,"$":{"0":{"v":"Setup","n":1},"1":{"v":"\n\n\n### Defining a Note trait for daily logs\n\nThe idea is to be able to have a template and a note trait which can easily create note following the behaviors of a Daily Journal Note.\nFor this we followed https://wiki.dendron.so/notes/kwgbkl58xka0zsib8uhhkfw/ and https://wiki.dendron.so/notes/bdZhT3nF8Yz3WDzKp7hqh/\n\nI resume below the followed recipe.\n\n#### Set the Notes trait\n\n1. Create a new Note Trait\nRun the command `Dendron: Configure Note Traits`. Give your new trait a unique name. In this example, we'll call the trait `open-notebook-commons-pmallard`. Hit Enter and a `open-notebook-commons-pmallard.js` file will appear in your editor. This is where you define your custom trait logic.\n\n2. Add the trait behavior\nAdd in Javascript code to have custom settings when creating the note name and the note title.\n\nHere we used \n\n```js\nmodule.exports = {\n  OnWillCreate: {\n    /**\n     * This example sets a prefix of 'planning', and then adds a date hierarchy\n     * using the luxon module.\n     */\n    setNameModifier() {\n      // This example sets a prefix of 'planning', and then adds a date\n      // hierarchy using the luxon module.\n      return {\n        name: \"open-notebook.commons.pma.\" + luxon.DateTime.local().toFormat(\"yyyy.MM.dd\"),\n        promptUserForModification: true,\n      };\n    },\n  },\n  OnCreate: {\n    setTitle(props) {\n      // This example will use the currentNoteName property, extract the\n      // yyyy.MM.dd date portion of the note name, and then reformat it with\n      // dashes.\n      return props.currentNoteName.split(\".\").slice(-3).join(\"-\");\n    },\n    /**\n     * Apply a template to each note. NOTE: If you want to use this code, you\n     * will need a note file called `templates.planning-template.md` in your\n     * Dendron workspace.\n     */\n    setTemplate: () => {\n      return \"templates.open-notebook.commons.pmallard\";\n    },\n  },\n};\n```\n\n#### Edit the template.\n\nYou can (optionally) have a template for your journal notes.\nHere I used the following [[templates.open-notebook.commons.pmallard]]. \nThis template can be modified according to your needs.\n\n#### Set a keyboard shortcut\n\nI added a keyboard shortcut for it. But this needs to be done locally in your VSCode preferences (its not part of the published Dendron)\nFor this you can\n\n1. Run the VSCode Command `Preferences: Open Keyboard Shortcuts (JSON)` (Cmd+Shift + P)\n2. Add the following entry to the bottom of your keybindings.json file, with the shortcut key combo of your choice:\n\n```json\n  {\n    \"key\": \"cmd+o cmd+n\",\n    \"command\": \"dendron.customCommand.open-notebook-commons-pmallard\"\n  }\n```\n\nFor example :\n\n- open-notebook-commons-pmallard.js\n\nAdapt your keyboard shortcuts so that it leads to your own note traits.","n":0.053}}},{"i":326,"$":{"0":{"v":"Metabolinkai","n":1}}},{"i":327,"$":{"0":{"v":"Communications","n":1}}},{"i":328,"$":{"0":{"v":"Adriano","n":1},"1":{"v":"\n### Chat with Scorfi \n\nhttp://www.metabolomexchange.org/site/\n\nhttps://masswiki.metabolomics.us/aOC06HM\n\n\n- Get in touch with MetabolomExchange \n\n- INSDC (https://www.insdc.org/) wants to go [[metabolomics]] -> MetaboBank (https://www.ddbj.nig.ac.jp/metabobank/index-e.html) ... IDF: Investigation Description Format... MAF: metabolite assignment file (https://www.ddbj.nig.ac.jp/metabobank/datafile-e.html#maf)\n\n- [[Thomas Hankemeier]] hankemeier@lacdr.leidenuniv.nl\n\nhttps://www.nature.com/articles/s42255-025-01239-4/figures/1\n\nhttps://github.com/elixir-europe/biohackathon-projects-2025/blob/main/14.md\n\nhttps://github.com/elixir-europe/biohackathon-projects-2025/blob/main/18.md\n\n","n":0.174}}},{"i":329,"$":{"0":{"v":"Writing","n":1}}},{"i":330,"$":{"0":{"v":"Scientific_paper","n":1},"1":{"v":"\n# Scientific Papers\n\n(https://www.nature.com/scitable/topicpage/scientific-papers-13815490/)\n\n\n\nScientific papers are for sharing your own original research work with other scientists or for reviewing the research conducted by others. As such, they are critical to the evolution of modern science, in which the work of one scientist builds upon that of others. To reach their goal, papers must aim to inform, not impress. They must be highly readable — that is, clear, accurate, and concise. They are more likely to be cited by other scientists if they are helpful rather than cryptic or self-centered.\n\nScientific papers typically have two audiences: first, the referees, who help the journal editor decide whether a paper is suitable for publication; and second, the journal readers themselves, who may be more or less knowledgeable about the topic addressed in the paper. To be accepted by referees and cited by readers, papers must do more than simply present a chronological account of the research work. Rather, they must convince their audience that the research presented is important, valid, and relevant to other scientists in the same field. To this end, they must emphasize both the motivation for the work and the outcome of it, and they must include just enough evidence to establish the validity of this outcome.\n\nPapers that report experimental work are often structured chronologically in five sections: first, Introduction; then Materials and Methods, Results, and Discussion (together, these three sections make up the paper's body); and finally, Conclusion.\n\nThe Introduction section clarifies the motivation for the work presented and prepares readers for the structure of the paper.\nThe Materials and Methods section provides sufficient detail for other scientists to reproduce the experiments presented in the paper. In some journals, this information is placed in an appendix, because it is not what most readers want to know first.\nThe Results and Discussion sections present and discuss the research results, respectively. They are often usefully combined into one section, however, because readers can seldom make sense of results alone without accompanying interpretation — they need to be told what the results mean.\nThe Conclusion section presents the outcome of the work by interpreting the findings at a higher level of abstraction than the Discussion and by relating these findings to the motivation stated in the Introduction.\n(Papers reporting something other than experiments, such as a new method or technology, typically have different sections in their body, but they include the same Introduction and Conclusion sections as described above.)\n\nAlthough the above structure reflects the progression of most research projects, effective papers typically break the chronology in at least three ways to present their content in the order in which the audience will most likely want to read it. First and foremost, they summarize the motivation for, and the outcome of, the work in an abstract, located before the Introduction. In a sense, they reveal the beginning and end of the story — briefly — before providing the full story. Second, they move the more detailed, less important parts of the body to the end of the paper in one or more appendices so that these parts do not stand in the readers' way. Finally, they structure the content in the body in theorem-proof fashion, stating first what readers must remember (for example, as the first sentence of a paragraph) and then presenting evidence to support this statement.\n\n## The introduction\n\n\n View Full-Size Image An effective introduction for a paper\n\nThe introduction reproduced here exhibits the four components that readers find useful as they begin to read a paper.\nIn the Introduction section, state the motivation for the work presented in your paper and prepare readers for the structure of the paper. Write four components, probably (but not necessarily) in four paragraphs: context, need, task, and object of the document.\n* First, provide some context to orient those readers who are less familiar with your topic and to establish the importance of your work.\n* Second, state the need for your work, as an opposition between what the scientific community currently has and what it wants.\n* Third, indicate what you have done in an effort to address the need (this is the task).\n* Finally, preview the remainder of the paper to mentally prepare readers for its structure, in the object of the document.\n\n### Context and need\n\nAt the beginning of the Introduction section, the context and need work together as a funnel: They start broad and progressively narrow down to the issue addressed in the paper. To spark interest among your audience — referees and journal readers alike — provide a compelling motivation for the work presented in your paper: The fact that a phenomenon has never been studied before is not, in and of itself, a reason to study that phenomenon.\n\nWrite the context in a way that appeals to a broad range of readers and leads into the need. Do not include context for the sake of including context: Rather, provide only what will help readers better understand the need and, especially, its importance. Consider anchoring the context in time, using phrases such as recently, in the past 10 years, or since the early 1990s. You may also want to anchor your context in space (either geographically or within a given research field).\n\nConvey the need for the work as an opposition between actual and desired situations. Start by stating the actual situation (what we have) as a direct continuation of the context. If you feel you must explain recent achievements in much detail — say, in more than one or two paragraphs — consider moving the details to a section titled State of the art (or something similar) after the Introduction, but do provide a brief idea of the actual situation in the Introduction. Next, state the desired situation (what we want). Emphasize the contrast between the actual and desired situations with such words as but, however, or unfortunately.\n\nOne elegant way to express the desired part of the need is to combine it with the task in a single sentence. This sentence expresses first the objective, then the action undertaken to reach this objective, thus creating a strong and elegant connection between need and task. Here are three examples of such a combination:\n\n* To confirm this assumption, we studied the effects of a range of inhibitors of connexin channels . . . on . . .\n\n* To assess whether such multiple-coil sensors perform better than single-signal ones, we tested two of them — the DuoPXK and the GEMM3 — in a field where . . .\n\n* To form a better view of the global distribution and infectiousness of this pathogen, we examined 1645 postmetamorphic and adult amphibians collected from 27 countries between 1984 and 2006 for the presence of . . .\n\n### Task and object\nAn Introduction is usually clearer and more logical when it separates what the authors have done (the task) from what the paper itself attempts or covers (the object of the document). In other words, the task clarifies your contribution as a scientist, whereas the object of the document prepares readers for the structure of the paper, thus allowing focused or selective reading.\n\nFor the task,\n\n* use whoever did the work (normally, you and your colleagues) as the subject of the sentence: we or perhaps the authors;\n* use a verb expressing a research action: measured, calculated, etc.;\n* set that verb in the past tense.\n\nThe three examples below are well-formed tasks.\n\n* To confirm this assumption, we studied the effects of a range of inhibitors of connexin channels, such as the connexin mimetic peptides Gap26 and Gap27 and anti-peptide antibodies, on calcium signaling in cardiac cells and HeLa cells expressing connexins.\n\n* During controlled experiments, we investigated the influence of the HMP boundary conditions on liver flows.\n\n* To tackle this problem, we developed a new software verification technique called oblivious hashing, which calculates the hash values based on the actual execution of the program.\n\nThe list below provides examples of verbs that express research actions:\n\napply \nWe applied Laklöter's principle to . . . \nassess\tWe assessed the effects of larger doses of . . .\ncalculate \nWe calculated the photoluminescence spectrum of . . . \ncompare\tWe compared the effects of . . . to those of . . .\ncompute\tWe computed the velocity predicted by . . .\nderive\tWe derived a new set of rules for . . .\ndesign\tWe designed a series of experiments to . . .\ndetermine\tWe determined the complete nucleotide sequence of . . . \ndevelop\tWe developed a new algorithm to . . .\nevaluate\tWe evaluated the efficacy and biocompatibility of . . .\nexplore\tWe explored the relationship between . . .\nimplement\tWe implemented a genetic algorithm for . . .\ninvestigate\tWe investigated the behavior of . . .\nmeasure\tWe measured the concentration of cadmium in . . .\nmodel\tWe modeled the diffraction behavior of . . .\nFor the object of the document,\n\nuse the document itself as the subject of the sentence: this paper, this letter, etc.;\nuse a verb expressing a communication action: presents, summarizes, etc.;\nset the verb in the present tense.\nThe three examples below are suitable objects of the document for the three tasks shown above, respectively.\n\nThis paper clarifies the role of CxHc on calcium oscillations in neonatal cardiac myocytes and calcium transients induced by ATP in HL-cells originated from cardiac atrium and in HeLa cells expressing connexin 43 or 26.\n\nThis paper presents the flow effects induced by increasing the hepatic-artery pressure and by obstructing the vena cava inferior.\n\nThis paper discusses the theory behind oblivious hashing and shows how this approach can be applied for local software tamper resistance and remote code authentication.\n\nThe list below provides examples of verbs that express communication actions:\n\nclarify \nThis paper clarifies the role of soils in . . .\ndescribe\tThis paper describes the mechanism by which . . .\ndetail\tThis paper details the algorithm used for . . .\ndiscuss\tThis paper discusses the influence of acidity on . . .\nexplain\tThis paper explains how the new encoding scheme . . .\noffer\tThis paper offers four recommendations for . . .\npresent\tThis paper presents the results of . . .\nproposes\tThis paper proposes a set of guidelines for . . .\nprovide\tThis paper provides the complete framework and . . .\nreport\tThis paper reports on our progress so far . . .\nsummarize\tThis paper summarizes our results for 27 patients with . . .\nThe body\nEven the most logical structure is of little use if readers do not see and understand it as they progress through a paper. Thus, as you organize the body of your paper into sections and perhaps subsections, remember to prepare your readers for the structure ahead at all levels. You already do so for the overall structure of the body (the sections) in the object of the document at the end of the Introduction. You can similarly prepare your readers for an upcoming division into subsections by introducing a global paragraph between the heading of a section and the heading of its first subsection. This paragraph can contain any information relating to the section as a whole rather than particular subsections, but it should at least announce the subsections, whether explicitly or implicitly. An explicit preview would be phrased much like the object of the document: \"This section first . . . , then . . . , and finally . . . \"\n\nAlthough papers can be organized into sections in many ways, those reporting experimental work typically include Materials and Methods, Results, and Discussion in their body. In any case, the paragraphs in these sections should begin with a topic sentence to prepare readers for their contents, allow selective reading, and — ideally — get a message across.\n\n## Materials and methods\n\n\nThis paragraph of materials and methods expresses the main idea first, in a topic sentence, so readers immediately know what it is about.\nMost Materials and Methods sections are boring to read, yet they need not be. To make this section interesting, explain the choices you made in your experimental procedure: What justifies using a given compound, concentration, or dimension? What is special, unexpected, or different in your approach? Mention these things early in your paragraph, ideally in the first sentence. If you use a standard or usual procedure, mention that upfront, too. Do not make readers guess: Make sure the paragraph's first sentence gives them a clear idea of what the entire paragraph is about. If you feel you cannot or need not do more than list items, consider using a table or perhaps a schematic diagram rather than a paragraph of text.\n\n## Results and discussion\n\n\nThis paragraph of results and discussion (above) can easily be rewritten (below) to convey the message first, not last.\nThe traditional Results and Discussion sections are best combined because results make little sense to most readers without interpretation.\nWhen reporting and discussing your results, do not force your readers to go through everything you went through in chronological order. Instead, state the message of each paragraph upfront: Convey in the first sentence what you want readers to remember from the paragraph as a whole. Focus on what happened, not on the fact that you observed it. Then develop your message in the remainder of the paragraph, including only that information you think you need to convince your audience.\n\n## The conclusion\n\n\nThis paragraph of results and discussion (above) can easily be rewritten (below) to convey the message first, not last.\nIn the Conclusion section, state the most important outcome of your work. Do not simply summarize the points already made in the body — instead, interpret your findings at a higher level of abstraction. Show whether, or to what extent, you have succeeded in addressing the need stated in the Introduction. At the same time, do not focus on yourself (for example, by restating everything you did). Rather, show what your findings mean to readers. Make the Conclusion interesting and memorable for them.\nAt the end of your Conclusion, consider including perspectives — that is, an idea of what could or should still be done in relation to the issue addressed in the paper. If you include perspectives, clarify whether you are referring to firm plans for yourself and your colleagues (\"In the coming months, we will . . . \") or to an invitation to readers (\"One remaining question is . . . \").\n\nIf your paper includes a well-structured Introduction and an effective abstract, you need not repeat any of the Introduction in the Conclusion. In particular, do not restate what you have done or what the paper does. Instead, focus on what you have found and, especially, on what your findings mean. Do not be afraid to write a short Conclusion section: If you can conclude in just a few sentences given the rich discussion in the body of the paper, then do so. (In other words, resist the temptation to repeat material from the Introduction just to make the Conclusion longer under the false belief that a longer Conclusion will seem more impressive.)\n\n## The abstract\n\n\nIn just under 200 words, the abstract reproduced here conveys the motivation for and the outcome of the work with some accuracy but without intimidating readers by its length.\nThe readers of a scientific paper read the abstract for two purposes: to decide whether they want to (acquire and) read the full paper, and to prepare themselves for the details presented in that paper. An effective abstract helps readers achieve these two purposes. In particular, because it is typically read before the full paper, the abstract should present what the readers are primarily interested in; that is, what they want to know first of all and most of all.\nTypically, readers are primarily interested in the information presented in a paper's Introduction and Conclusion sections. Primarily, they want to know the motivation for the work presented and the outcome of this work. Then (and only then) the most specialized among them might want to know the details of the work. Thus, an effective abstract focuses on motivation and outcome; in doing so, it parallels the paper's Introduction and Conclusion.\n\nAccordingly, you can think of an abstract as having two distinct parts — motivation and outcome — even if it is typeset as a single paragraph. For the first part, follow the same structure as the Introduction section of the paper: State the context, the need, the task, and the object of the document. For the second part, mention your findings (the what) and, especially, your conclusion (the so what — that is, the interpretation of your findings); if appropriate, end with perspectives, as in the Conclusion section of your paper.\n\nAlthough the structure of the abstract parallels the Introduction and Conclusion sections, it differs from these sections in the audience it addresses. The abstract is read by many different readers, from the most specialized to the least specialized among the target audience. In a sense, it should be the least specialized part of the paper. Any scientist reading it should be able to understand why the work was carried out and why it is important (context and need), what the authors did (task) and what the paper reports about this work (object of the document), what the authors found (findings), what these findings mean (the conclusion), and possibly what the next steps are (perspectives). In contrast, the full paper is typically read by specialists only; its Introduction and Conclusion are more detailed (that is, longer and more specialized) than the abstract.\n\nAn effective abstract stands on its own — it can be understood fully even when made available without the full paper. To this end, avoid referring to figures or the bibliography in the abstract. Also, introduce any acronyms the first time you use them in the abstract (if needed), and do so again in the full paper (see Mechanics: Using abbreviations).\n\n\n\n-----\n\n## Snippet\n\nUse the ctno snippet (type ctno and tab or auto complete to have a predefined structure)\n\n# Title\n\n## Context (of the paper/doc/note/paragraph)\nFirst, provide some context to orient those readers who are less familiar with your topic and to establish the importance of your work.\n## Need (of the paper/doc/note/paragraph)\nSecond, state the need for your work, as an opposition between what the scientific community currently has and what it wants.\n## Task (of the paper/doc/note/paragraph)\nThird, indicate what you have done in an effort to address the need (this is the task).\n## Object (of the paper/doc/note/paragraph)\nFinally, preview the remainder of the paper to mentally prepare readers for its structure, in the object of the document.\n\n\n# Title \ntime\n## Context\nFirst, provide some context to orient you/readers/your grandma who are less familiar with your topic and to establish the importance of this note/paragraph/text/paper/project.\n## Need\nSecond, state the need for your note/paragraph/text/paper/project, as an opposition between what you/others/the scientific community/your grandma currently has and what it wants.\n## Task (of the note/paragraph/text/paper/project)\nThird, indicate what you have done in an effort to address the need (this is the task).\n- [ ] did this\n- [ ] did that\n- [ ] oh and this also\n## Object (of the note/paragraph/text/paper/project)\nFinally, preview the remainder of the paper to mentally prepare you/readers for its structure, in the object of the document.","n":0.018}}},{"i":331,"$":{"0":{"v":"Notes","n":1},"1":{"v":"\n\n# Taking notes vs. making notes\n\n[[nesslabs]]\n\nhttps://nesslabs.com/from-note-taking-to-note-making?ck_subscriber_id=1121227337&utm_source=convertkit&utm_medium=email&utm_campaign=Creating+Habits+%F0%9F%A7%A4%20-%205117179\n\n\nhttps://www.scotthyoung.com/blog/2021/01/11/how-to-take-notes/\n\n\n# File over  app\n\nhttps://stephango.com/vault\n\n","n":0.333}}},{"i":332,"$":{"0":{"v":"Smart_notes","n":1},"1":{"v":"\n## Principles of Smart Notes \n\nhttps://takesmartnotes.com/\n\n## The four underlying principles\n\n1. Writing is the only thing that matters\n2. Simplicity is paramount\n3. Nobody ever starts from scratch\n4. Let the work carry you forward\n\n---\n\n\n\nhttps://jamesclear.com/deliberate-practice-theory #prodporn\n","n":0.177}}},{"i":333,"$":{"0":{"v":"Workshops","n":1}}},{"i":334,"$":{"0":{"v":"Kg Wur 2025","n":0.577},"1":{"v":"\n### Mondo: Integrating Disease Terminology Across Communities\nhttps://watermark02.silverchair.com/iyaf215.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAA3UwggNxBgkqhkiG9w0BBwagggNiMIIDXgIBADCCA1cGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMkgsBQcpgrywg4GO0AgEQgIIDKEAvwrFLbJtl-0XfMrDO6g6QoI-jN7DYswXci5Qd58Aae-H-psID_d7TQUqD0im-cl5IGxqERYGAzRYrFzPO5H6QXdcuALmQMhkLFPUJMxT6rvtGJiHeQdLWBeTwGfXKUWnPDmut9W4rrrDeph1a2xmSwZgaNNNlK-mhM4bnY3a_pQfAlSqJ-g6j-plDTRDubQOpRK5Yx1fykIT0nG-h4ndDnIggpndFaAHPD_IhpyL0gObsgtK7Y2w71WBqR3iJl535he7tHjU3WYYjLQixG3nzR9ycuaaZB8DwI78K4B7coo2rkB0LyKlYYCNIoEB5yaKw1HlzPZuH-ZiVDxt47yAvIPTOMbvv6lSuXtkiShhzrftl29wXH0WVcFP8U2mauSK77LPFPGGeWeM98vnZNx1LXgLaRZfRG4okKEyTLgazpFx8BUz4ZOd6qLRHDBj8-eNv96Xnxy4-rkfn5TAm4kAFdqoQWYZ6IvMrcdqTaF7-hB0aVElrp5OEejoqUyV9IoDFA_kFQBgnY4B1kVZNdcR5gxlhcxK0Xx5V0uti8Am1z6Kzz2XF4lIGz_HJ7G-NwKROzoPxPVOw5VJbL2_ItaV30IlOrE8SjK6cg3qANbypFgYqXrvdzPKg9V44hbGf5rROcihTpsgp6NyBJNjJ2HvwqogpsZyuDfncdGDKGKW1rzQO6h-IHbDdSrJZQK5LY4W9eJ2vwR38yZRk9dDJoyEgFLNPtuUtzBLMEyIbqVHJzGrv_n10h6SOCd3eTw9FLmmk50DGxefE6V8KCF7dL5n9t1QD_ipWriU4zK9TFHsUjdpVM1ncMgee-rKp7OeLj4Ny2ztKZCiZsDbtxwgdqty6RlarwYov9NnR_oFT9CsMLgaliR4wtyU4_GFIez8HTl73zeWvF4Ku1X6AGu79XYIL0XMEHv4QkkeoE-RCNbr4kGyaWDXrnLPRJbVUx6oFyW8fI_amkKtA23gsRDfkDf271PAa1BsFDub59058MCc06yc1VW3WFPUqa5JcOmemtN0u6jEpHWwBRRDksuMiboAlN-YdbUuHdh7-5R5IFDLu_EuUqQqNBaU\n\n### Scalable Table-to-Knowledge Graph Matching from Metadata using LLMs\nhttps://ceur-ws.org/Vol-3889/paper4.pdf\n\n### Fantastic Vince !\n\nhttps://github.com/MaastrichtU-IDS/build-a-kg-example\nhttps://rml.io/yarrrml/\nhttps://rml.io/yarrrml/tutorial/getting-started/\nhttps://openrefine.org/\n\n### Pre-brainstrom preparation\nhttps://docs.google.com/document/d/15J9CHluMGA2IqFc5C-PF6YFRhbDHEHFe0tTbf9sYd4U/edit?tab=t.0*heading=h.jpeytol3ffyt\n\n\n### Targeted brainstorm\n\nhttps://docs.google.com/document/d/15J9CHluMGA2IqFc5C-PF6YFRhbDHEHFe0tTbf9sYd4U/edit?tab=t.0#heading=h.dm212t949dr6\n\n\n\n\n### Ressources\n\nPlant Metabolic Network\nhttps://plantcyc.org/\n\nPanREDU \n\n\n### Denise Slender \nhttps://github.com/sec2pri\n\n### Egon Willigagaen\nhttps://www.ddbj.nig.ac.jp/metabobank/index-e.html\nhttps://www.wikipathways.org/\n\nAOP wiki\n\nhttps://chembl.gitbook.io/chembl-interface-documentation/about\n\nA protocol for adding knowledge to Wikidata: aligning resources on human coronaviruses\nhttps://doi.org/10.1186/s12915-020-00940-y\n\nWhats new in GPML2021\nhttps://pathvisio.org/documentation/Whats-New-GPML2021.html\n\n","n":0.147}}},{"i":335,"$":{"0":{"v":"Brainstorm","n":1},"1":{"v":"\n### Pre-brainstrom preparation\nhttps://docs.google.com/document/d/15J9CHluMGA2IqFc5C-PF6YFRhbDHEHFe0tTbf9sYd4U/edit?tab=t.0*heading=h.jpeytol3ffyt\n\n\n### Targeted brainstorm\n\nhttps://docs.google.com/document/d/15J9CHluMGA2IqFc5C-PF6YFRhbDHEHFe0tTbf9sYd4U/edit?tab=t.0#heading=h.dm212t949dr6\n\n\n### Ressources\n\nMention Chase Clark\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC11370487/\n\nhttps://pmn.plantcyc.org/pathway?orgid=WHEATD&id=PWY-2463\n\n\n","n":0.354}}},{"i":336,"$":{"0":{"v":"Brainstorm Felicia","n":0.707},"1":{"v":"\n### Large paired omics dataset\n\nsyntheny\n\nGenes that are placed in a similar order across species.\n\nhttps://www.orthodb.org/\n\nhttps://planteome.org/\n\nwfe\n\nhttps://try.orbopengraph.com/\n\n","n":0.267}}},{"i":337,"$":{"0":{"v":"Tools","n":1}}},{"i":338,"$":{"0":{"v":"Organization","n":1}}},{"i":339,"$":{"0":{"v":"Time","n":1},"1":{"v":"\nTuesday 03 August 2021\n\n> Most of us use our calendars all wrong: we don't schedule work; we schedule interruptions. Meetings get scheduled. Phone calls get scheduled. Doctor appointments get scheduled. You know what often doesn't get scheduled? Real work. All those other things are distractions. Often, they're other people's work. But they get dedicated blocks of time, and your real work becomes an orphan.\n\nPeek into time blocking.\n\nAs Roman Stoic philosopher Seneca once wrote:\n\n> “People are frugal in guarding their personal property; but as soon as it comes to squandering time, they are most wasteful of the one thing in which it is right to be stingy.”\n\n----\n\n\nHaving a look at the MyTime plugin (https://github.com/codicelq/mytime) because I wanted a time tracking solution and that this is currectly lacking from the excellent Todo+ plugin.\n\nCreated a snippet to directyl add current time \n\n```bash\n    \"now\": {\n        \"prefix\": \"now\",\n        \"scope\": \"markdown,yaml\",\n        \"body\": \"- `$CURRENT_HOUR:$CURRENT_MINUTE` \",\n        \"description\": \"now in hour:min\"\n    }\n```\n\n\n- `20:00` Started work on machine A\n- `20:29` // Went to have a piss\n- `21:26` Started work on machine A\n- `23:26` // Went to have a piss\n- `23:45` Started work on machine B\n\n\n\n| Time span          | Task                      |\n| -----------------: | ------------------------- |\n|          `01:00`   | Started work on machine A |\n|          `00:15`   | Started work on machine B |\n|        **`01:15`** | **Total**                 |\n\n> _Last update 20:29_ / Lines [valid:3, comments:2, invalid:0]\n\n\n| Time span          | Task                      |\n| -----------------: | ------------------------- |\n|          `01:00`   | Started work on machine A |\n|          `00:15`   | Started work on machine B |\n|          `02:30`   | Went to have a piss       |\n|        **`03:45`** | **Total**                 |\n\n> _Last update 20:28_ / Lines [valid:5, comments:0, invalid:0]\n\n---\n\nLet's see if this work with intricated sentences or objects \n\n\n\n- `20:00` Started work on machine A\n\nAnd this is the code I used for this time machine \n\n```bash\n    \"now\": {\n        \"prefix\": \"now\",\n        \"scope\": \"markdown,yaml\",\n        \"body\": \"- `$CURRENT_HOUR:$CURRENT_MINUTE` \",\n        \"description\": \"now in hour:min\"\n    }\n```\n- `20:29` // Went to have a piss\n\nIn my amazing bathroom\n\n- `21:26` Started work on machine A\n\nBlah\n\n- `23:26` // Went to have a piss\n\nOutside \n\n- `23:45` Started work on machine B\n\n\n\n| Time span          | Task                      |\n| -----------------: | ------------------------- |\n|          `01:00`   | Started work on machine A |\n|          `00:15`   | Started work on machine B |\n|        **`01:15`** | **Total**                 |\n\n> _Last update 20:34_ / Lines [valid:3, comments:2, invalid:12]\n\n\nWorking !!! That looks like a very nice option \nIts not working in the todo+ files\n\n  Luis_Molina seeds metabo:\n    ✔ grab back latest Mzmine project @started(21-01-03 13:40) @done(21-01-03 13:42) @lasted(2m26s)\n    - make MN:\n      ✔ make MN metadata file @started(21-01-03 13:42) @done(21-01-03 13:47) @lasted(5m16s)\n      ✔ upload stuff to GNPS @started(21-01-03 13:47) @done(21-01-03 15:06) @lasted(1h19m56s)\n      ✔ briefly check MN in cytoscape @15m @started(21-01-03 15:56) @done(21-01-03 16:06) @lasted(10m11s)\n      ✔ Run ISDB @1h @done(21-01-03 18:05)\n        ✔ upload mgf and attributes to x2go @15m @started(21-01-03 16:06) @done(21-01-03 16:37) @lasted(31m29s)\n        ssh allardp@x2go.epgl-geneve.org\n        cd Desktop/FARMAnetwork/RECHERCHE/COMMON\\ FASIE-FATHO/PMA/Ubuntu_VM_img/ISDB_DNP/results/\n        ✔ run isdb via command line (x2go not working)  @30m @started(21-01-03 16:37) @done(21-01-03 16:42) @lasted(5m50s)\n        ✔ get back top 50 locally @10m @started(21-01-03 16:42) @done(21-01-03 16:46) @lasted(4m31s)\n    ✔ run taxo reponderation using Arabidopsis @1h @1h @started(21-01-03 17:47) @done(21-01-03 18:05) @lasted(18m24s)\n        ✔ download latest version @started(21-01-03 14:30) @done(21-01-03 15:06) @lasted(36m54s)\n      ☐ script a metadata formatter that take a sample metadata and feature table and generates a sample metadat grouped feature table (for cytoscape display) @4h\n      stope here  /Users/pma/Dropbox/Research_UNIGE/git_repos/pf_project/src/peaklist_formatter.py\n    ☐ make report @1h\n    ☐ send it @10m\n\n----\n\nWhat if it runned over various days ?? \nDoesn't seem to take days shifts into account.\n\n\n## Sunday 03 January\n\n- `20:38` //_Good morning_\n- `20:39` Bricole_2\n- `22:00` Bricole_1\n## Monday 04 January\n\n- `07:45` //_Let's start_\n- `08:39` Bricole_2\n- `09:43` Bricole_3\n- `21:39` Bricole_1\n\n\n- `21:03` Mail\n\n## Timeis\n\nhttps://time.is/fr/\n\n\n## Modified eisenhower matrix\n\nhttps://www.theuncertaintyproject.org/tools/eisenhower-matrix","n":0.041}}},{"i":340,"$":{"0":{"v":"Taskwarrior","n":1},"1":{"v":"\n# Taskwarrior \n\nhttps://taskwarrior.org/docs/start.html\nhttps://randomgeekery.org/tags/taskwarrior/\n\nRestore a recently deleted task in twarrior\nhttps://taskwarrior.org/support/faq.html#q7\n\n\nTW commands \n\nhttps://taskwarrior.org/docs/commands/\nhttps://taskwarrior.org/docs/dates/\n\n## Filters \nhttps://taskwarrior.org/docs/filter/\n\n\n## Taskwarrior-tui \n\nTaskwarrior-tui keybinding\n\nhttps://kdheepak.com/taskwarrior-tui/keybindings/\n\nhttps://kdheepak.com/taskwarrior-tui/keybindings/\n\n\n\n\n\n\n\n\n# Timewarrior\n\nhttps://timewarrior.net/docs/tutorial/\n\nintegrated with timewarrior https://jrisch.medium.com/tracking-time-with-taskwarrior-and-timewarrior-6759f3542276\n\nhttps://iturbe.info/2017/10/the-command-line-productivity-triad-vimwiki-taskwarrior-timewarrior/\n\nTo shorten a task\n\ntimew summary :id\ntimew modify end @4 \"2021-04-09\"T14:30:00\n\n\n## alternatives\n\nhttps://traggo.net/\n\n\n\n\n# Calendars\n\nPeak into https://khal.readthedocs.io/en/latest/usage.html\n\nhttps://gitlab.com/BlackEdder/caldavwarrior\n\nLife Calendar Swift coded dont lnow how to install https://github.com/wvdk/Life-Calendar\n\nhttps://github.com/serhii-londar/open-source-mac-os-apps\n\n\nMonday 19 April 2021\n\nTrying to sync calendar app to khal\n\nhttps://forum.magicmirror.builders/topic/1980/synchronizing-private-icloud-calendar-with-magicmirror-a-workaround\n\nhttps://dianne.skoll.ca/projects/remind/\n\nhttps://inthe.am/\n\n\nhttps://useplaintext.email/#why-plaintext\n\n(fell in a rabithole)\n\nTuesday 03 August 2021\n\n🖐️ Fell in another rabithole while trying to set up the calcurse-caldav and vsyncserver apps \nFinally plain iCal app might still me the most convenient solution \n\n\n# Taskserver \n\n\nThe steup guidelines \n\nhttps://gothenburgbitfactory.github.io/taskserver-setup/\n\n\n\n# Taskopen\n\nIs great to annotate and link files to task\n\nhttps://github.com/jschlatow/taskopen\n\n```bash\ntask 15 annotate Hello\ntask 15 http://www.example.com\ntask 15 ~/path/to/file\n```\n\n```bash\ntaskopen 15\n```\n\n","n":0.098}}},{"i":341,"$":{"0":{"v":"Pkm","n":1},"1":{"v":"\n# Personal Knowledge Management\n\nhttps://pkm.dendron.so/\n\n\n# Link paper and digital\n\n(ZK imported)\n\nAnd also a first attempt to link paper and digital ZK #6_93_V (or dendron or whatever digital pkm system). So here in dendron tag would be [[6_93_V]]\n\nThe first digit correspond to the notebook number. The second one to the page number. Here Notebook 6 page 93. The letter corresponds to : \n- Live List (L)\n- The Vault (V)\n- Notes (N)\n\nNotebooks are following the strikethru system https://www.kickstarter.com/projects/chriskyle/strikethru-the-to-do-list-notebook-0\nI am on my 8th notebook using the stikethru system so I guess it's a match for me (lets see how it goes with dendron, the time you stick to a tool seems to be a good measure of it's usefulness. Sometimes you get pretty excited about flashy tools with all the bells and whistle be if you drop them after a week, you know they might not worth investing much more time)\n\n- [ ] investigate more on digital / analogue links in various domains (note taking, pkm). Maybe more widely also, explore links between these two whole \"worlds\". Thinking about it it is actually the very core definition of bioinformatics. A discipline which is by essence at the interface of analogue and digital worlds ... \n\n# Obsidian thread\n\nhttps://forum.obsidian.md/t/cataloging-classification-information-science-pkms-and-you/10071\n","n":0.071}}},{"i":342,"$":{"0":{"v":"Focus","n":1},"1":{"v":"\n(ZK imported)\n\nWhen reading an article on the internet it could be useful to have a plugin able to completely remove active links (so they dont atract the attention anymore.)\nThis should greatly enhance the readers attention by giving a \"book like\" feeling.\n\n2021-01-17\n\nAdded since some month the \"Decreased Productivity\" plugin on chromium browser https://chrome.google.com/webstore/detail/decreased-productivity/nlbpiflhmdcklcbihngeffpmoklbiooj\nProduced by https://www.andryou.com/\nIt has a bunch of options, however I found that at the end of the day I am not using it that often. There is still work to do on such plugins to have a better reading experience. \nVery interested in quick and convenient ways to pass from retro-lightened screen > e-ink/paper like reading exp. (apart from printing the pages)\n\nA plugin that I installed more recently but which I use more (because its automatically acting also ) is a tab limitator Nuff Tabs\nhttps://chrome.google.com/webstore/detail/nuff-tabs/kemeihccgedidlokcbfhdekcfojpjjmp\n","n":0.086}}},{"i":343,"$":{"0":{"v":"Eln","n":1},"1":{"v":"\n# https://www.mylabbook.org/index.php\n\nCheck in to drupal\n# Digital Lab Notebook\n \nhttp://culturalheritageimaging.org/Technologies/Digital_Lab_Notebook/index.html\n\n\n\n# Electronic Lab Notebooks Ressources\n\nLooking for strategies to uniquely identify and track samples in the lab.\n\n\nhttps://www.limswiki.org/index.php/Main_Page\n\n\nhttps://leaflims.github.io/docs/index.html\n\nhttp://www.sesame.wisc.edu/sesame_home.html\n\nhttps://muccg.github.io/mastr-ms/\n\n\nhttps://chemotion.net/\n(down to recheck later)\nInstall over here https://github.com/ComPlat/chemotion_ELN\n\n\n## Recipe SENAITE install\n\nhttps://www.senaite.com/docs/installation.html\n\n2021-01-21 18:58\nOn  X2GO server\n\nsudo adduser --home /home/farma.unige.ch/senaite --shell /bin/bash senaite\n\npwd : d-gvapltivsv-BD place entity characteristic \n\n$ wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh\n$ bash /home/senaite/Miniconda2-latest-Linux-x86_64.sh\n$ source /home/senaite/.bashrc\n\nmess \n\nMiniconda2 will now be installed into this location:\n/home/farma.unige.ch/senaite/miniconda2\n\n  - Press ENTER to confirm the location\n  - Press CTRL-C to abort the installation\n  - Or specify a different location below\n\n[/home/farma.unige.ch/senaite/miniconda2] >>> \nPREFIX=/home/farma.unige.ch/senaite/miniconda2\n\n\n(senaite) senaite@FARMA-NONMEM:~/Plone-4.3.19-UnifiedInstaller$ ./install.sh standalone --target=/home/farma.unige.ch/senaite --instance=senaitelims --password=admin\n\n\n\nSENAITE is a beautiful trigonal, oil-green to greenish black crystal, with almost the hardness of a diamond. Although the crystal is described with a complex formula, it still has clear and straight shapes. Therefore, it reflects nicely the complexity of the LIMS, while providing a modern, intuitive and friendly UI/ UX.\n\n\n\n","n":0.084}}},{"i":344,"$":{"0":{"v":"Digitalgardens","n":1},"1":{"v":"\n# Digital gardens, forest and more ...\n\nhttps://maggieappleton.com/garden-history\n\nThis image perfectly resumes the idea I have of a public dendron. \n\n![](assets/images/2021-01-04-21-52-56.png)\n","n":0.229}}},{"i":345,"$":{"0":{"v":"Hardware","n":1}}},{"i":346,"$":{"0":{"v":"Laptops","n":1},"1":{"v":"\nhttps://itsfoss.com/get-linux-laptops/\n\nhttps://www.tuxedocomputers.com/en/Linux-Hardware/Linux-Notebooks/15-16-inch/TUXEDO-Book-Pulse-15-Gen1.tuxedo#625,36792;699,35297;717,35315;1545,34086;1845,37944;1896,38187;2108,38766;2126,38783;2127,38784;2155,38775;2297,38365;2307,38737;2308,39199\n","n":1}}},{"i":347,"$":{"0":{"v":"Graphes","n":1}}},{"i":348,"$":{"0":{"v":"Grakn","n":1},"1":{"v":"\n# Grakn\n\nGrakn 2.0 is out https://github.com/graknlabs/grakn/releases\nHave a look at this version.\n\nLearn more about fundamentals of hypergraphs and graphs theory. https://en.wikipedia.org/wiki/Hypergraph Ex of hypergraphes (Venn, Upset plots etc .)\n\nPaste here all the old codes used with the previous Grakn version.\nTry to implement Lotus as grakn base.\n\n## Semantic Web Standards and Grakn\n\nhttp://dev.grakn.ai/docs/comparisons/semantic-web-and-grakn\n\n","n":0.141}}},{"i":349,"$":{"0":{"v":"Dendron","n":1}}},{"i":350,"$":{"0":{"v":"Tags","n":1},"1":{"v":"\n#course_material ~~check tag system in dendron ~~\n\nShortcut for tags is # \nso [[#tag|tag.tag]]\n\n\nCheck and explore tags / backlinks system in Dendron\n\n2021-01-10 21:59\n\nSo actually looking at https://dendron.so/notes/8bc9b3f1-8508-4d3a-a2de-be9f12ef1821.html it appears that the way to tag a note is just exactly the same as the way you would link it.\nLets try both with an existing tag/note and an unexisting on.\n\nExisting is [[tools.organization.digitalgardens]] and non existing is [[spatial.exploration]].\n\nPretty version [[#explo|spatial.explo]]\n\n\n ---\n\n //TODO Sublime ZK-like tag system. It would be really nice to have tag proposition and autocompletion\n Suggest or ask in dendron discord. \n\n","n":0.105}}},{"i":351,"$":{"0":{"v":"Spellcheck","n":1},"1":{"v":"\nThe shortcut for quick suggestions using the Code Spell Checker plugin is Cmd + .\n(or clicking on the light bulb which is often far away ....)\n","n":0.196}}},{"i":352,"$":{"0":{"v":"Screenshot","n":1},"1":{"v":"\nTo directly paste a screen shot (Mac)\n\nUse the Ctrl + Shift + Cmd + 4 combination and then Cmd + shift + P : Paste from the Dendron Paste Image menu (or opt + cmd + V)\n\n\n![](/assets/images/2021-01-02-16-44-09.png)\n","n":0.164}}},{"i":353,"$":{"0":{"v":"Multivault","n":1},"1":{"v":"\n\nTrying to implement a multivault setup after all because I would like to mange publishing and keep specific research project private or at least controled by pwd. For acces to specific collaborators wile other should be public.\n\nLet's try this.\n\nStarting here ... fell in a rabit hole.\nThe whole multivault and selective publication looks really tough ... for me at least.\nI remember now why I turned away from it several times.\n\nhttps://github.com/matteobrusa/Password-protection-for-static-pages\n\n\nSample multivault by kenvin\n\nhttps://github.com/dendronhq/sample-multivault-workspace\n\n\n\nTuesday 29 June 2021\n\nDigging this again.\n\nFollowing https://wiki.dendron.so/notes/45cfb9f2-46cf-4f67-a41e-834818fbd06e.html\n\n\nThe `Dendorn: Initialize MultiVault Workspace` is not available \nSo apparently this command is not existing anymore https://discord.com/channels/717965437182410783/735365126227493004/790801646581055508\n\nSo in fact its Vault add  from a preexisting vault\n\n\ntesting croos vault links\n\nhttps://wiki.dendron.so/notes/3472226a-ff3c-432d-bf5d-10926f39f6c2.html#cross-vault-links\n\n\nApparently they do not work when published\n\n\n\nSamedi 21 Août 2021\n\nthe multivault folder lives here '~/multivault_dendron/'\n\nDimanche 22 Août 2021\n\nnew vscode window\ncmd+shit+p \ndendron new workspace \n/Users/pma/dendron-ws-private\nblank\nthe default vault name is vault\n<!-- we rename it directly to make things clear ^pXHF3aqJs96A\nhttps://wiki.dendron.so/notes/401c5889-20ae-4b3a-8468-269def4b4865.html#renaming-a-vault -->\n\ngo to github a create a new private repo\nhttps://github.com/oolonek/dendron-ws-private.git\n\nat the ws level\ngit init\ngit add . \ngit commit -m 'initial commit'\ngit remote add origin https://github.com/oolonek/dendron-ws-private.git\ngit push -u origin main\n(complains)\ngit pull origin main  \ngit config pull.rebase true\ngit pull origin main  \ngit push -u origin main\n\nrepeat steps for ws-public\nhttps://github.com/oolonek/dendron-ws-public\n\nnow we publish both dendron\nhttps://wiki.dendron.so/notes/230d0ccf-5758-4a8f-b39b-3b68e1482e2b.html\n\nActually dont follow all the steps.\nWe head directly for github action powered publication.\n\nSo just change your dendron.yml  by adding\n\n    siteUrl: https://oolonek.github.io\n    assetsPrefix: dendron-ws-public\n\nThen we follow\n\nhttps://wiki.dendron.so/notes/877f4347-f013-43ba-aec4-87412b2e1bec.html\n\nto create the package.json at the ws roots we follow this.\n\nCreate a package.json at the root of your workspace\n\nnpm init -y\nnpm install @dendronhq/dendron-cli@latest\nnpm install @dendronhq/dendron-11ty@latest\n\n\n\n\nWe modify the dendron.yml to have the gh edit link\n\n    gh_edit_link: true\n    gh_edit_link_text: Click here to edit this page on Github !\n    gh_edit_repository: 'https://github.com/oolonek/dendron-ws-public'\n    gh_edit_branch: main\n    gh_edit_view_mode: edit\n    assetsPrefix: dendron-ws-public\n\nWe repeat for the private repo \n\n\nAll seems to be set up correctly\n[[\n\n|mapp.fundings.swissbiodata]]\nNow we will vault add the dendron-ws-public as a remote vault in the private ws\n\nthis should be done at the vault level (in the dendron-private-vault)\nWe cmd+shit+p vault add and enter https://github.com/oolonek/dendron-ws-public.git \nand two time enter this allows us to have the vault name changed to dendron-ws-public\n\n\n\nSaturday 28 August 2021\n\n\ntest duplicated note and multivault handlinh of duplicated content.\n\n[[dendron.multivault]]\n\n","n":0.054}}},{"i":354,"$":{"0":{"v":"Frontmatter","n":1},"1":{"v":"\nTo have the md preview export as html and the toc displayed add the folloing line to the Dendron notes\n\nhtml:\n  embed_local_images: true\n  embed_svg: true\n  offline: true\n  toc: true\nprint_background: false\nexport_on_save:\n  html: true\ntoc:\n  depth_from: 1\n  depth_to: 6\n  ordered: false\n---\n\n[TOC]\n\n","n":0.164}}},{"i":355,"$":{"0":{"v":"Chemistry","n":1},"1":{"v":"\nPossible to display chemical structure using the MathPix MD plugin https://github.com/mathpix/vscode-mathpix-markdown \n\n- Abscisic acid (ABA)\n\n```smiles\nOC(=O)\\C=C(\\C)/C=C/[C@@]1(O)C(C)=CC(=O)CC1(C)C\n```\n\n\n![](/assets/images/2021-01-02-16-42-20.png)\n\n\n(edit) at 2021-01-02 17:15 So the smiles code chunck will not get compiled by the 11tfty \n\n````\n`RenderError` was thrown\n> Unknown language: `smiles` is not registered\n        at node (root) (/home/runner/work/dendron/dendron/node_modules/unist-util-visit-parents/index.js:67:75)\n\n````\n\nSee https://github.com/oolonek/dendron/runs/1636940880\n\n\n\n\n","n":0.151}}},{"i":356,"$":{"0":{"v":"Biblio","n":1},"1":{"v":"# Bib integration in dendron\n\nMessing around with pandoc citer and trying to integrate bibliography management in dendron\n\nThe markender extension (<https://github.com/mjwsteenbergen/markender>) is causing conflict with pandoc citer for the autocompletion.\nDeactivate Markender\n\nConflict thrown  [[projects.tramadol]] \n\nError: Command failed: pandoc --from=markdown-raw_tex+tex_math_single_backslash --to=html --katex --filter pandoc-citeproc\nError reading bibliography /Users/pma/Documents/library_formatted.bib (line 60541, column 1):\nunexpected end of input\nexpecting \"}\", \"\\\\\" or \"{\"\nError running filter pandoc-citeproc:\nFilter returned error status 1\n\nNow trying to troubleshoot the file using bibdesk\n\n## Bib file formatting\n\nBib file formatting is required to avoid the previous error. This error is somehow misleading because it indicates that the error comes from the end of the file ... and it's not the case, rather a curly brace somewhere which is not closed.\n\nFrom the automatically sync .bib of Mendeley, make a copy and ctrl+F replace all { by \\\\'{ and all all } by \\\\'}\nThis should make the trick.\n\nSee [[tools.cli.sed_bash]] for the recipee.\n\nAnd here goes a Note reference \n\n((ref: [[tools.cli.sed_bash]]))\n\n//DONE check Amoeba splitting of notes (here is a typical application case ... Automatization and sed lines should go in separate notes as these can be used for other purposes than just the .bib reformating) 2021-01-02 17:30 checking .... and just splitted the above sed commands\n\n//TODO understand the way to have the bibliography display on the published version of dendron. Not the case at the moment see [[projects.tramadol]]\n\n//TODO set bibliography globally\n\n\n","n":0.067}}},{"i":357,"$":{"0":{"v":"Code","n":1}}},{"i":358,"$":{"0":{"v":"Python","n":1}}},{"i":359,"$":{"0":{"v":"Oop","n":1},"1":{"v":"# Object Oriented Programming\n\n\nVery instructive video on the basics of OOP.\nWhat is a Class, what is a method ?\nHow they can be of interest for : \n- encapsulation (need to see this part again)\n- inheritance\n- polymorphism\n\nGreat teacher. Look for additional tuto.\n\n\nhttps://www.youtube.com/watch?v=MikphENIrOo\n\n\n## DataClass\n\nhttps://www.geeksforgeeks.org/data-classes-in-python-an-introduction/\n\n\n\n## https://testdriven.io/blog/clean-code-python/\n\n\nhttps://www.pythontutorial.net/python-oop/python-abstract-class/\n\n\n\n\n##  Everything Is an Object in Python\n\nWe’ll tell you a secret: you’ve been using OOP all the time without noticing it.\n\nEven when using other paradigms in Python, you still use objects to do almost everything.\n\nThat’s because, in Python, everything is an object.","n":0.109}}},{"i":360,"$":{"0":{"v":"Mamba","n":1},"1":{"v":"\n# Create environment\n\nmamba create -n taxonomical-preparator\n\n","n":0.408}}},{"i":361,"$":{"0":{"v":"Conda","n":1},"1":{"v":"\n\n# The Definitive Guide to Conda Environments\n\n\nhttps://towardsdatascience.com/a-guide-to-conda-environments-bc6180fc533\n","n":0.378}}},{"i":362,"$":{"0":{"v":"CLI","n":1},"1":{"v":"\n# How to Code with Me - Making a CLI\n\nhttps://cthoyt.com/2020/06/11/click.html\n\n","n":0.316}}},{"i":363,"$":{"0":{"v":"Ts","n":1},"1":{"v":"\n## Typescript\n\nRead about it here https://www.typescriptlang.org/docs/handbook/typescript-from-scratch.html\n\n","n":0.408}}},{"i":364,"$":{"0":{"v":"Js","n":1},"1":{"v":"\n## Javascript\n\nhttps://developer.mozilla.org/fr/docs/Web/JavaScript/Guide\n\nhttps://www.codecademy.com/learn/introduction-to-javascript\n\n","n":0.707}}},{"i":365,"$":{"0":{"v":"CLI","n":1},"1":{"v":" ---\nid: 85f109b5-4c48-4a6a-8447-24d1228f0ba8\ntitle: CLI\ndesc: ''\nupdated: 1610889677922\ncreated: 1610889677922\nstub: false\n---\n\n","n":0.378}}},{"i":366,"$":{"0":{"v":"Xan","n":1},"1":{"v":"\n### Filter rows with empty or \"NA\" values in the ScientificName column\n\n\n`xan filter '(ScientificName eq \"NA\") or (len(trim(ScientificName)) eq 0)' taxon_name_gnverified_col.tsv`\n\n### Filter rows with empty TaxonomicName in kew-species-list.csv and save to a new file\n\n`xan filter !'(len(trim(TaxonomicName)) eq 0)' kew-species-list.csv > kew-species-list-nona.csv`\n\n### Select specific columns from a file\n\n`xan select TaxonomicName kew-species-list-nona.csv > taxon_names.csv`\n\n### (not a xan command) Use gnverifier\n\n`gnverifier -f csv -s 1 taxon_names.csv > taxon_name_gnverified_col.csv`\n\n### View some stats \n\nxan stats taxon_name_gnverified_col.csv | xan v\n\n#### Deduplicate rows based on ScientificName\n\nxan dedup -s ScientificName taxon_name_gnverified_col.csv > taxon_name_gnverified_col_deduped.csv\n\n### Left join two files on ScientificName\n\nxan join --left TaxonomicName kew-species-list-nona.csv ScientificName taxon_name_gnverified_col_deduped.csv > kew-species-list-nona-gnverified-col.csv\n\n### Standardize a date field\n\nxan map 'strftime(datetime(col(\"Last Seen On\"), \"%d-%m-%Y\"), \"%Y-%m-%d\")' LastSeenISO joined.csv > joined_standardized.csv\n\nxan map 'strftime(datetime(col(\"Last Seen On\"), \"%d-%m-%Y\"), \"%Y-%m-%d\")' \\\n  LastSeenISO kew-species-list-nona-gnverified-col.csv > joined.tmp && mv joined.tmp kew-species-list-nona-gnverified-col.csv\n\n\n### Script\n\n\n\n`xan filter !'(len(trim(TaxonomicName)) eq 0)' kew-species-list.csv > kew-species-list-nona.csv`\n\n`xan select TaxonomicName kew-species-list-nona.csv > taxon_names.csv`\n\n`gnverifier -f csv -s 1 taxon_names.csv > taxon_name_gnverified_col.csv`\n\nxan dedup -s ScientificName taxon_name_gnverified_col.csv > taxon_name_gnverified_col_deduped.csv\n\nxan join --left TaxonomicName kew-species-list-nona.csv ScientificName taxon_name_gnverified_col_deduped.csv > kew-species-list-nona-gnverified-col.csv\n\nxan map 'strftime(datetime(col(\"Last Seen On\"), \"%d-%m-%Y\"), \"%Y-%m-%d\")' \\\n  LastSeenISO kew-species-list-nona-gnverified-col.csv > joined.tmp && mv joined.tmp kew-species-list-nona-gnverified-col.csv\n\n","n":0.075}}},{"i":367,"$":{"0":{"v":"Rsync","n":1},"1":{"v":"\nNote : pasted from ZK sublime ()\n\nSub [[202002291826]] terminal and unix shortcuts\n\n\n# local > x2go \n\n```bash\nrsync -rvz -e 'ssh -p 80' --progress ./ allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/pybatchclassyfire/\nrsync -rvz -e 'ssh -p 80' --progress ./ allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/\npybatchclassyfire/\nrsync -rvz -e 'ssh' --progress ./ allardp@10.25.88.39:/home/EPGL.UNIGE.LOCAL/allardp/\nrsync -rvz -e 'ssh' --progress ./ allardp@10.25.88.39:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/data/interim/tables/3_curated/\n\nrsync -rvz -e 'ssh' --progress ./ allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/Desktop/FARMAnetwork/RECHERCHE/COMMON\\ FASIE-FATHO/PMA/Ubuntu_VM_img/ISDB_DNP/results\nrsync -rvz -e 'ssh' --progress ./ allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/Desktop/FARMAnetwork/RECHERCHE/COMMON\\ FASIE-FATHO/PF_project\nrsync -rvz -e 'ssh' --progress ./ allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/is_fragmentation/lotus_data\n```\n\n# local > baobab\n\n```bash\nrsync -rvz -e 'ssh' --progress ./opennpdb_tofrag allardp@baobab2.unige.ch:/home/allardp/data_to_frag/opennpdb/\nrsync -rvz -e 'ssh' --progress ./ allardp@baobab2.unige.ch:/home/allardp/bash_files/opennpdb_bash\n\nrsync -rvz -e 'ssh' --progress ./ allardp@baobab2.hpc.unige.ch:/home/allardp/bash_files/lotus_bash\nrsync -rvz -e 'ssh' --progress ./ allardp@baobab2.hpc.unige.ch:/home/allardp/data_to_frag/lotus/\n\n\nrsync -rvz -e 'ssh' --progress ./ allardp@baobab2.hpc.unige.ch:/home/allardp/is_fragmentation/lotus_data/\n\n```\n\n# local > beast\nnda\n```bash\nrsync -rvz -e 'ssh' --progress ./ allardpm@biolpc045600:/home/allardpm/data_to_frag/opennpdb/\nrsync -rvz -e 'ssh' --progress ./ allardpm@biolpc045600:/home/allardpm/cfm/bash_files\nrsync -rvz -e 'ssh' --progress ./Downloads/forticlient_vpn_7.0.7.0246_amd64.deb allardpm@biolpc045600:/home/allardpm/Downloads/\nrsync -rvz -e 'ssh' --progress ./Downloads/structures_metadata.db allardpm@biolpc045600:/home/ENPKG/data/structures_db/\n\nrsync -rvz -e 'ssh' --progress /Users/pma/Downloads/2025_03_mzML_data/pos allardpm@commons-server:/msdata/mapp_project_00055/mapp_batch_00153\n```\n\n\n\n# beast > local\n\n```bash\nrsync -rvz -e 'ssh' --progress allardpm@biolpc045600:/home/allardpm/sandbox/GNPS_output_Qemistree_set/*.qza ./ \n\nrsync -rvz -e 'ssh' --progress allardpm@biolpc045600:/home/allardpm/sandbox/GNPS_output_Qemistree_set/*.qza ./ \n\nrsync -rvz -e 'ssh' --progress allardpm@biolpc045600:/home/allardpm/Downloads/wetransfer_rhino_2022-01-10_0411.zip ./ \n\nrsync -rvz -e 'ssh' --progress allardpm@biolpc045600:/home/allardpm/graphdb-import ./graphdb-import \n\nrsync -rvz -e 'ssh' --progress allardpm@commons-server:/msdata/mapp_project_00051/mapp_batch_00169 ~/02_tmp/mapp_project_00051/mapp_batch_00169\n\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/kew-botanical-gardens/ \\\n  /Users/pma/QField/cloud/kew-botanical-gardens/DCIM/kew-botanical-gardens/\n\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/git_repos/cronjobs/qfieldcloud-fetcher/qfieldcloud_fetcher/exiftool/ \\\n   /Users/pma/02_tmp/qfieldcloud_fetcher/exiftool/\n\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/git_repos/cronjobs/inaturalist-import-bot/inaturalist_import_bot/exiftool/ \\\n   /Users/pma/02_tmp/inat_fetcher/exiftool/\n\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Iris_acutiloba_dbgi_008497_05.jpg \\\n   /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Aillium_hymenorrhizum_dbgi_008497_01.jpg \\\n   /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Aillium_hymenorrhizum_dbgi_008497_02.jpg \\\n   /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Aillium_hymenorrhizum_dbgi_008497_03.jpg \\\n    /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Aillium_hymenorrhizum_dbgi_008497_04.jpg \\\n    /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Aillium_hymenorrhizum_dbgi_* \\\n    /Users/pma/02_tmp/\n\n\n    \nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Thymus_nitens_dbgi_008450_01.jpg \\\n    /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Thymus_nitens_dbgi_008450_02.jpg \\\n    /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Thymus_nitens_dbgi_008450_03.jpg \\\n    /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Thymus_nitens_dbgi_008450_04.jpg \\\n    /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Thymus_nitens_dbgi_008450_05.jpg \\\n    /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Olearia_haastii_dbgi_008450_01.jpg \\\n    /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Olearia_haastii_dbgi_008450_02.jpg \\\n    /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Olearia_haastii_dbgi_008450_03.jpg \\\n    /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Olearia_haastii_dbgi_008450_04.jpg \\\n    /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Olearia_haastii_dbgi_008450_05.jpg \\\n\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Triticum_aevistum_dbgi_008505_02.jpg \\\n    /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Triticum_aevistum_dbgi_008505_03.jpg \\\n    /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Triticum_aevistum_dbgi_008505_04.jpg \\\n    /Users/pma/02_tmp/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/jbc/jbc/Triticum_aevistum_dbgi_008505_05.jpg \\\n    /Users/pma/02_tmp/\n\n\n\n# to fetch all file with a given extension. See https://stackoverflow.com/a/11111793 for details\n\nrsync -rvz -e 'ssh' --include=\"*/\" --include=\"*.qza\" --exclude=\"*\" --progress allardpm@biolpc045600:/home/allardpm/sandbox/GNPS_output_Qemistree_set/ ./\n\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/nextcloud_data/emi/files/output/pictures/kew-botanical-gardens/ \\\n  /Users/pma/QField/cloud/kew-botanical-gardens/DCIM/kew-botanical-gardens/\n\n\n## fetch all dir under /media/data/qfieldcloud_data/data/inat_pictures\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/qfieldcloud_data/data/inat_pictures/ \\\n  /Users/pma/02_tmp/inat_pictures/\n\n\n## fetch all files under /media/data/qfieldcloud_data/data/formatted_csv/jbc\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/qfieldcloud_data/data/formatted_csv/jbc/ \\\n  /Users/pma/02_tmp/jbc_formatted_csv/\n\n## fetch dir /media/data/qfieldcloud_data/data/inat_pictures/dbgi_008385 and dbgi_008572 and dbgi_001353 \n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/qfieldcloud_data/data/inat_pictures/dbgi_008385/ \\\n  /Users/pma/02_tmp/inat_pictures/dbgi_008385/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/qfieldcloud_data/data/inat_pictures/dbgi_008572/ \\\n  /Users/pma/02_tmp/inat_pictures/dbgi_008572/\n\nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/qfieldcloud_data/data/inat_pictures/dbgi_001353/ \\\n  /Users/pma/02_tmp/inat_pictures/dbgi_001353/\n\n  \nrsync -avz -e 'ssh' --progress \\\n  --rsync-path=\"sudo -n -u cronuser rsync\" \\\n  commons-server:/media/data/qfieldcloud_data/data/inat_pictures/ \\\n  /Users/pma/02_tmp/inat_pictures/\n```\n\n\n# x2go > local \n\n```bash\nrsync -rvz -e 'ssh -p 80' --progress allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/is_fragmentation/coconut_data/coconut_ISDB_pos.mgf /Users/pma/Dropbox/People/Swap_MS/ISDB_Coconut\nrsync -rvz -e 'ssh -p 80' --progress allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/1_databases/PLANTCYC/2_chemo/2_rdkit/PLANTCYC_chemo_rdkit_new_pm.tsv ./\nrsync -rvz -e 'ssh -p 80' --progress allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/1_databases/PLANTCYC/2_chemo/2_rdkit/PLANTCYC_chemo_rdkit_sanitized_pm.tsv ./\nrsync -rvz -e 'ssh -p 80' --progress allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/outputs/tables/3_curated/curated_tablesampled1000.tsv ./\nrsync -rvz -e 'ssh -p 80' --progress allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/outputs/tables/3_curated/curatedTable5000_shuffled_headed ./\nrsync -rvz -e 'ssh -p 80' --progress allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/qiime2_cscs_explo_remote/pfabre/cscs_PCoA.qzv ./\nrsync -rvz -e 'ssh' --progress allardp@10.25.88.39:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/data/interim/tables/1_translated/structure/unique.tsv ./\n\nrsync -rvz -e 'ssh' --progress allardp@10.25.88.39:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/data/interim/tables_min/3_curated/smiles.gz ./\n\nrsync -rvz -e 'ssh' --progress --include '*.txt' allardp@10.25.88.39:/home/EPGL.UNIGE.LOCAL/allardp/opennaturalproductsdb/data/interim/tables/3_curated/ ./\n\nrsync -rvz -e 'ssh -p 80' --progress allardp@x2go.epgl-geneve.org:/home/EPGL.UNIGE.LOCAL/allardp/Desktop/FARMAnetwork/RECHERCHE/COMMON\\ FASIE-FATHO/Workshop_Material/Data_annotation_Workshop_2019/190225_FullDNP_prot_deprot.csv ./\n\n\nrsync -rvz -e 'ssh' --progress \"allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/Desktop/FARMAnetwork/RECHERCHE/COMMON\\ FASIE-FATHO/PMA/Ubuntu_VM_img/ISDB_DNP/results/fbmn_lena_metabo_results_DNP_top50.out\" ./ \n\nrsync -rvz -e 'ssh' --progress \"allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/lotusProcessor/data/interim/tables/4_analysed/platinum.tsv.gz\" ./ \n\nrsync -rvz -e 'ssh' --progress \"allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/lotusProcessor/data/processed/lotus.sqlite\" ./ \n\nrsync -rvz -e 'ssh' --progress \"allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/Documents/Toy_Dataset_MN/GNPS_output_Toy_Dataset_MN/cscs_PCoA.qzv\" ./ \n\n\nrsync -rvz -e 'ssh' --progress \"allardp@x2go.epgl-geneve.org:/home/farma.unige.ch/allardp/Documents/PF_GNP3/GNPS_output_PF_GNP3/feature_table_for_biom.tsv\" ./ \n\n\n\n\n\n```\n\n\n# baobab > local \n\n```bash\nrsync -rvz -e 'ssh' --progress allardp@baobab2.unige.ch:/home/allardp/CFM_results/npatlas ./results\nrsync -rvz -e 'ssh' --progress allardp@baobab2.unige.ch:/home/allardp/CFM_results/npatlas ./results\nrsync -rvz -e 'ssh' --progress allardp@baobab2.unige.ch:/home/allardp/CFM_results/coconut ./ --apend\n```\n\n# metabomaps > local \n\n\n\nrsync -rvz -e 'ssh' --progress --rsync-path=\"sudo rsync\" ~/Downloads/wetransfer-27d788/210523_lotus_map4_2D.js pma@metabomaps.nprod.net:/srv/metabo-store/tmap\n\nrsync -rvz -e 'ssh' --progress  pma@metabomaps:/home/pma/.ssh ~/02_tmp/backup_metabomaps\nrsync -rvz -e 'ssh' --progress  --rsync-path=\"sudo rsync\" pma@metabomaps:/home/bjo/scrappers ~/02_tmp/backup_metabomaps\n\nrsync -rvz -e 'ssh' --progress pmallard@kimsufi:/home/pmallard/arxiv/gbif-20250501-occurrence-data.torrent ~/02_tmp/torrent\n\n\n# local > metabomaps\n\nrsync -rvz -e 'ssh' --progress --rsync-path=\"sudo rsync\" /Users/pma/Dropbox/UniFr/Projects/Ongoing/COMMONS/NPKB/004_rdf/pos pma@metabomaps.nprod.net:/home/pma/graphdb/home/graphdb-import\n\nrsync -rvz -e 'ssh' --progress /Users/pma/Dropbox/UniFr/Projects/Ongoing/COMMONS/NPKB/004_rdf/pos pma@metabomaps.nprod.net:/home/pma/graphdb-import\n\nrsync -rvz -e 'ssh' --progress /Users/pma/Downloads/ pma@metabomaps.nprod.net:/home/pma/Downloads\n\n\n\n\n\n\n\n\nrsync -rvz -e 'ssh' --progress /Volumes/COMMON\\ FASIE-FATHO/PF_project/Graph_organization/7_full_pos_neg ./01_large_files\n\n\nhttps://ostechnix.com/how-to-resume-partially-downloaded-or-transferred-files-using-rsync/\n\n\n# local > vmunifr (allardpm@svx-uo7630dbgi)\n\nI move /Users/pma/git_repos/COMMONS_Lab/EMI/earth-metabolome-initiative.github.io/assets/img/emi_round_gold_simple.svg to /var/www/kg.earthmetabolome.org/emi_round_gold_simple.svg\n\n\nrsync -rvz -e 'ssh' --progress /Users/pma/git_repos/COMMONS_Lab/EMI/earth-metabolome-initiative.github.io/assets/img/emi_round_gold_simple.svg allardpm@svx-uo7630dbgi:/var/www/kg.earthmetabolome.org/emi_round_gold_simple.svg","n":0.034}}},{"i":368,"$":{"0":{"v":"Bash","n":1},"1":{"v":"\n# Rename files\n\n```bash\nfor f in *.png; do echo mv \"$f\" \"${f/_*_/_}\"; done\n```\n\nRemove echo \n\nhttps://stackoverflow.com/a/24103055\n\n[[#tremendous|tag.tremendous]]\n\n# List all files and folder in a graphical tree in terminal\n\nYou need to \n`brew install tree`\n\nThen you can `tree` or `tree -lart`\n# List all files and their full path\n\nls -d -1 \"$PWD/\"*.*\n\n\n# bash upgrade on mac\n\nhttps://itnext.io/upgrading-bash-on-macos-7138bd1066ba\n\nHad some problem when running the build.sh script of manubot.\nBecause of this error \n\nbuild/build.sh: line 50: ${BUILD_PDF,,}: bad substitution\nTurns out that ,, are not \n\nhttps://stackoverflow.com/a/47815884\n\n\n# create a folder architecture\n\nmkdir -p adria-leboeuf-group/{docs/MAPP_project_00014/MAPP_batch_00019/{metadata,results},src/MAPP_project_00014/MAPP_batch_00019/}\n\n\nmkdir -p {metadata,results/{cytoscape,met_annot_enhancer,metaboanalyst,mzmine,stats,sirius,tmp}}\n\nmkdir -p results/{cytoscape,met_annot_enhancer,metaboanalyst,mzmine,stats,sirius,tmp} && touch results/{cytoscape/.gitignore,met_annot_enhancer/.gitignore,metaboanalyst/.gitignore,mzmine/.gitignore,stats/.gitignore,sirius/.gitignore,tmp/.gitignore}\n\nmkdir -p {metadata,results/{cytoscape,met_annot_enhancer,metaboanalyst,mzmine,stats,sirius,tmp}} && touch {metadata/.gitignore,results/{cytoscape/.gitignore,met_annot_enhancer/.gitignore,metaboanalyst/{.gitignore,placeholder.out},mzmine/{.gitignore,placeholder.out},stats/.gitignore,sirius/{.gitignore,placeholder.out},tmp/.gitignore}}","n":0.104}}},{"i":369,"$":{"0":{"v":"CLI","n":1}}},{"i":370,"$":{"0":{"v":"Vscode","n":1},"1":{"v":"\n# Multicursor editing in vscode\n\nhttps://tahoeninjas.blog/2019/03/30/multi-cursor-editing-in-visual-studio-code/\n\n\nCTRL+ALT+ ↑ / ↓: Select next/previous line\nALT-CLICK: Create cursors\nCTRL-U: Undo last cursor operation\nCTRL-SHIFT-L: Select current match\n\n# Fold markdown \n\nVisual Studio Code now supports code folding for Markdown documents by heading. Folding a header collapses all content and subheadings under that header. \nCMD + K + CMD + 0/1/2/3 — to fold\nCMD + K + CMD + J — to unfold\n\n\n# Define the stoppers for a word selection\n\nhttps://stackoverflow.com/a/46417503\n\n\n# Replcae text at several places\n\n\nCmd + D in Vscode can replace the current text at several places \n\n\nseveral.gsgsg\n\n\n\n","n":0.106}}},{"i":371,"$":{"0":{"v":"Vim","n":1},"1":{"v":"\n# delete a line \n\ndd\n\n# undo\n\nu\n\n# exit\n\nesc :q\n\n# save and exit\n\nesc :wq\n\n\n\n","n":0.289}}},{"i":372,"$":{"0":{"v":"Tmux","n":1},"1":{"v":"\nhttps://tmuxcheatsheet.com/\n\n\nTmux Cheat Sheet\nFinally, we want to share a cheat sheet to use as a reference:\n\nSessions\n\nStart a new Session:\n\n`tmux`\n\nStart a new session with a name:\n\n`tmux new -s [name]`\n\nStart an attached session:\n\n```tmux a #```\n\nIf the Tmux session has a name:\n\n`tmux attach -t [name]`\n %>% \nList all Tmux sessions:\n\n`tmux ls`\n\nExit the utility:\n\n`exit`\n\nKill session:\n\n`tmux kill-session -t [name]`\n\n## Window Handling\n\nNote the Prefix is **Ctrl + B**\n\n* New window\t<prefix>+c\n* Next window\t<prefix>+n\n* List all windows\t<prefix>+w\n* Rename a window\t<prefix>+,\n* Previous window\t<prefix>+p\n* Find a window\t<prefix>+f\n* Kill a window\t<prefix>+&\n\n## Pane Handling\n\n* Split panes vertically\t<prefix>+%\n* Split panes horizontally\t<prefix>+“\n* Toggle last active plane\t<prefix>+;\n* Swap panes\t<prefix>+o\n* Kill pane\t<prefix>+x\n* Show pane numbers\t<prefix>+q\n* Move plan left\t<prefix>+{\n* Move plan right\t<prefix>+}\n* Switching between panes\t<prefix>+arrow key\n\n\n\n\nSessions\ntmux\ntmux new\ntmux new-session\nnew\nStart a new session\n\ntmux new -s mysession\nnew -s mysession\nStart a new session with the name mysession\n\ntmux kill-ses -t mysession\ntmux kill-session -t mysession\nkill/delete session mysession\n\ntmux kill-session -a\nkill/delete all sessions but the current\n\ntmux kill-session -a -t mysession\nkill/delete all sessions but mysession\n\nCtrl + b $\nRename session\n\nCtrl + b d\nDetach from session\n\nattach -d\nDetach others on the session (Maximize window by detach other clients)\n\ntmux ls\ntmux list-sessions\nCtrl + b s\nShow all sessions\n\ntmux a\ntmux at\ntmux attach\ntmux attach-session\nAttach to last session\n\ntmux a -t mysession\ntmux at -t mysession\ntmux attach -t mysession\ntmux attach-session -t mysession\nAttach to a session with the name mysession\n\nCtrl + b w\nSession and Window Preview\n\nCtrl + b (\nMove to previous session\n\nCtrl + b )\nMove to next session\n\nWindows\ntmux new -s mysession -n mywindow\nstart a new session with the name mysession and window mywindow\n\nCtrl + b c\nCreate window\n\nCtrl + b ,\nRename current window\n\nCtrl + b &\nClose current window\n\nCtrl + b w\nList windows\n\nCtrl + b p\nPrevious window\n\nCtrl + b n\nNext window\n\nCtrl + b 0 ... 9\nSwitch/select window by number\n\nCtrl + b l\nToggle last active window\n\nswap-window -s 2 -t 1\nReorder window, swap window number 2(src) and 1(dst)\n\nswap-window -t -1\nMove current window to the left by one position\n\nPanes\nCtrl + b ;\nToggle last active pane\n\nCtrl + b %\nSplit pane with horizontal layout\n\nCtrl + b \"\nSplit pane with vertical layout\n\nCtrl + b {\nMove the current pane left\n\nCtrl + b }\nMove the current pane right\n\nCtrl + b \nCtrl + b \nCtrl + b \nCtrl + b \nSwitch to pane to the direction\n\nsetw synchronize-panes\nToggle synchronize-panes(send command to all panes)\n\nCtrl + b Spacebar\nToggle between pane layouts\n\nCtrl + b o\nSwitch to next pane\n\nCtrl + b q\nShow pane numbers\n\nCtrl + b q 0 ... 9\nSwitch/select pane by number\n\nCtrl + b z\nToggle pane zoom\n\nCtrl + b !\nConvert pane into a window\n\nCtrl + b + \nCtrl + b Ctrl + \nCtrl + b + \nCtrl + b Ctrl + \nResize current pane height(holding second key is optional)\n\nCtrl + b + \nCtrl + b Ctrl + \nCtrl + b + \nCtrl + b Ctrl + \nResize current pane width(holding second key is optional)\n\nCtrl + b x\nClose current pane\n\nCopy Mode\nsetw -g mode-keys vi\nuse vi keys in buffer\n\nCtrl + b [\nEnter copy mode\n\nCtrl + b PgUp\nEnter copy mode and scroll one page up\n\nq\nQuit mode\n\ng\nGo to top line\n\nG\nGo to bottom line\n\nScroll up\n\nScroll down\n\nh\nMove cursor left\n\nj\nMove cursor down\n\nk\nMove cursor up\n\nl\nMove cursor right\n\nw\nMove cursor forward one word at a time\n\nb\nMove cursor backward one word at a time\n\n/\nSearch forward\n\n?\nSearch backward\n\nn\nNext keyword occurance\n\nN\nPrevious keyword occurance\n\nSpacebar\nStart selection\n\nEsc\nClear selection\n\nEnter\nCopy selection\n\nCtrl + b ]\nPaste contents of buffer_0\n\nshow-buffer\ndisplay buffer_0 contents\n\ncapture-pane\ncopy entire visible contents of pane to a buffer\n\nlist-buffers\nShow all buffers\n\nchoose-buffer\nShow all buffers and paste selected\n\nsave-buffer buf.txt\nSave buffer contents to buf.txt\n\ndelete-buffer -b 1\ndelete buffer_1\n\nMisc\nCtrl + b :\nEnter command mode\n\nset -g OPTION\nSet OPTION for all sessions\n\nsetw -g OPTION\nSet OPTION for all windows\n\nset mouse on\nEnable mouse mode\n\nHelp\ntmux list-keys\nlist-keys\nCtrl + b ?\nList key bindings(shortcuts)\n\ntmux info\nShow every session, window, pane, etc...\n\n\n### Scrolling\n\nCtrl-b then [ then you can use your normal navigation keys to scroll around (eg. Up Arrow or PgDn). Press q to quit scroll mode.","n":0.041}}},{"i":373,"$":{"0":{"v":"Tar","n":1},"1":{"v":"\n\n## tar command lines \n\nTo create a tar.gz archive from a given folder you can use the following command. This will compress the contents of source-folder-name to a tar.gz \narchive named tar-archive-name.tar.gz\n\n```bash\ntar -zcvf tar-archive-name.tar.gz source-folder-name\n```\n\nTo extract a tar.gz compressed archive you can use the following command\n\ntar -zxvf tar-archive-name.tar.gz\n```\n\nIf its a gzipped file\n\n```bash\ngzip -d tar-archive-name.tar.gz\n```\n\nThis will extract the archive to the folder tar-archive-name.\n\nTo Preserve permissions\n\n```bash\ntar -pcvzf tar-archive-name.tar.gz source-folder-name\n```\n\nSwitch the ‘c’ flag to an ‘x’ to extract (uncompress).\n\n```bash\ntar -pxvzf tar-archive-name.tar.gz\n```\n\n\nsudo certbot --authenticator standalone --installer nginx   -d directus.dbgi.org --pre-hook \"service nginx stop\" --post-hook \"service nginx start\"","n":0.104}}},{"i":374,"$":{"0":{"v":"Sed_bash","n":1},"1":{"v":"\n[[#oneday|tag.oneday]]\nautomate with a sed script ? the bib cleaning \n\nSome sed black magic \n\n```bash\necho \"\\{\" | sed \"s|\\\\\\{|\\\\\\'{|\"\n````\nDouble \\\\ to escape the \\\\\n\nAnd repeat \n\n```bash\necho \"\\{jhdgjshgjhfsjdhgf\\}\" | sed \"s|\\\\\\{|\\\\\\'{|g; s|\\\\\\}|\\\\\\'}|g;\"\n````\nNow add input and outputs \n\n```bash\nsed \"s|\\\\\\{|\\\\\\'{|g; s|\\\\\\}|\\\\\\'}|g\" library.bib > library_formatted.bib\n```\n\nWe'll try to automatize the process using https://stackoverflow.com/a/13807906 fswatch and alternative to inotifywatch on linux https://linux.die.net/man/1/inotifywatch\n\nSo here is the small bash script. It will take the command line arg 1 and add the _formatted prefix to it. Could be cleaner and directly extract the filename to accomodate for various type of extension. Not the point here. If any body has an idea, please contribute ! :point_down: \n\n\n```bash\n#!/bin/bash\nsed \"s|\\\\\\{|\\\\\\'{|g; s|\\\\\\}|\\\\\\'}|g\" \"$1\" > \"${1%.bib}_formatted.bib\"\n```\n\n```bash\n#!/bin/bash\n\n# fullfilename=\"$(basename $1)\"\n# extension=\"${fullfilename##*.}\"\n# filename=\"${fullfilename%.*}\"\n\n# echo $fullfilename\n# echo $extension\n# echo $filename\n\n#echo \"File added: \" \"$(basename $1)\" \"$(basename $1)\"\nsed \"s|\\\\\\{|\\\\\\'{|g; s|\\\\\\}|\\\\\\'}|g\" \"$1\" > \"./formatted_bib/${filename}_formatted.bib\"\n\n````\n\n\n\n\nfswatch has been somehow a nightmare to understand ...\n\nto trouble shoot use the follwoing line to be sure of what exactly you take as input \n\n```bash\nfswatch -0 ./mendeley_output/ | xargs -0 -n1 -I{} echo \"{}\"\n```\n\n## quick replace in text file\n\n`sed -i 's/original/new/g' file.txt`\n\nsed -i'' 's/CHARGE=1-/CHARGE=-1/g' /Users/pma/01_large_files/mgf/isdb_neg.mgf","n":0.075}}},{"i":375,"$":{"0":{"v":"Lowercase","n":1},"1":{"v":"\nhttps://stackoverflow.com/a/7787159/4908629\n\n\n❗ Mind were you are doing this ! It's not possible to go back :P \n\n\nfor f in *; do mv \"$f\" \"$f.tmp\"; mv \"$f.tmp\" \"`echo $f | tr \"[:upper:]\" \"[:lower:]\"`\"; done\n\n\n\n","n":0.177}}},{"i":376,"$":{"0":{"v":"Find","n":1},"1":{"v":"\n### Count number of directories in current directory\n\n```bash\nfind . -maxdepth 1 -type d | wc -l\n```\n\nDetails at https://stackoverflow.com/a/17648137\n\n","n":0.236}}},{"i":377,"$":{"0":{"v":"Cut","n":1},"1":{"v":"\n## Check for duplicate according to a column\n\n```bash\ncut -f1 '/home/allardpm/git_repos/COMMONS/dataset-extractor-lotus/data/230106_frozen_metadata_for_mines.csv' | sort | uniq -d\n```\nThis will return the duplicates in the first column of the file.\n\n","n":0.196}}},{"i":378,"$":{"0":{"v":"Csv","n":1},"1":{"v":"https://www.stefaanlippens.net/pretty-csv.html\n\n\nplaceholder (testing submodule)\n","n":0.577}}},{"i":379,"$":{"0":{"v":"Chemoinformatics","n":1}}},{"i":380,"$":{"0":{"v":"Qiime","n":1},"1":{"v":"\n## Core concepts \n\nhttps://docs.qiime2.org/2020.8/concepts\n\n\n## Semantic types\n\nhttps://docs.qiime2.org/2020.8/semantic-types/\n\n\n## Glossary\n\nhttps://docs.qiime2.org/2020.8/glossary/\n\n\n## Running Qiime\n\n`conda activate qiime2-2020.8`\n\n`qiime`\n\n\n## lets try to make a heatmap\n\nqiime feature-table heatmap \\\n--i-table table-with-phyla.qza \\\n--o-visualization heatmap.qzv\n\n## importing and exporting tables\n\nThis passes by the BIOM format https://forum.qiime2.org/t/exporting-and-modifying-biom-tables-e-g-adding-taxonomy-annotations/3630\n\n\n  \n","n":0.171}}},{"i":381,"$":{"0":{"v":"Isfrag","n":1},"1":{"v":"\nPasting an old recipee from ZettelKasten\n\n\n\nLinked to [[202002251433]] in silico fragmentation worflow.\n\nChildren workflow on the beast MAPP \n\n\nSide notes : try to write everything as scripts so that they can be launched without a GUI (ex on X2Go or directly Boabab).\n\n\n# Tutorial for NPatlas in silico fragmentation data treatment\n\n\n## Prior to fragmentation \n\n### Prepare space delimited input file\n\nComplete metadate file is converted to list of Unique ID and smiles space separated (for cfm id input)\n\npython frag_list_preparator.py ../npatlas_data/np_atlas_2019_12.tsv ../npatlas_data/np_atlas_2019_12_for_frag.tsv NPAID SMILES\n\npython frag_list_preparator.py ../open_np_db_data/open_NP_db.tsv ../open_np_db_data/open_NP_db_tofrag.txt shortinchikey shortinchikey smiles\n\n### Split the file\n\n(Works on Linux based shells)\n\nsplit -a 5 -l 500 -d ../open_np_db_data/open_NP_db_tofrag.txt ../open_np_db_data/opennpdb_tofrag/opennpdb_\nsplit -a 5 -l 500 -d ./lotus_data/lotus_data_for_frag.txt ./lotus_data/lotus_data_for_frag/lotus_data_\n\nsplit -a 5 -l 500 -d ./ ./lotus_data/lotus_data_for_frag/lotus_data_\nsplit -a 5 -l 500 -d cfm/cfm_input/platinum_tofrag.tsv cfm/cfm_input/splitted/lotus_to_frag_\n\nThis one allows to preserve extensions and is build on number of desired chunks without splitting lines\nsplit -a 5 -n l/199 -d --additional-suffix=.txt  cfm_input/sub_platinum_tofrag.tsv cfm_input/splitted/lotus_to_frag_\n\n### When using the docker cli files need to have an extension (or taken as folder ?)\n\nfor f in *; do mv \"$f\" \"$f.txt\"; done\n\nif you made a mistacke \n\nfind / -type f -name '*.txt' -exec sh -c 'mv -- \"$0\" \"${0%.txt}\"' {} \\;\n\n### Prepare mutilple bash file to launch on baobab\n\n(strangely enough the .sh incrementer script return an error on Linux, runned OK on MacOS command line )\n\nNote: apparently sbatch as been replaced by srun on the boabab server side. Be sure to update the scripts accordingly\n\n\n\n## Fetching cfm-predict results\n\nDownload cfm-predict fragmentation results from the baob server using rsync command\n\nrsync -rvz -e 'ssh' --progress allardp@baobab2.unige.ch:/home/allardp/CFM_results/npatlas ./results\nrsync -rvz -e 'ssh' --progress allardp@baobab2.unige.ch:/home/allardp/CFM_results/coconut/ .\n\nfind ./ -type f -name '*.mgf' | wc  \n\n\nallows to count all file in a folder \nHere 25090 files for NPatalas\n\nCoconut 384222 .log files\n\n\n 384150 mgf files\n\n\n## We might eventually need to move all files from subfolders recursively to a superior folder\n\nfind ./bacasable -type f -print0 | xargs -0 mv -t ./bacasable\n\n\n\nfind ./results_coconut -type f -print0 | xargs -0 mv -t ./results_coconut\n\n\n## Pruning the raw log files\n\nThe output of cfm-predict consist of .log file containing mass spectra, where each fragments are individually labelled and eventually linked to a substrcture. Such information might be usefull later but for now we only want to keep the raw ms data\n\n(need to define a help function here)\n\npython raw_log_treater_npatlas.py ../npatlas_data/results_npatlas/npatlas/ .log\npython raw_log_treater.py ../coconut_data/results_coconut/ .log\n\n\n\nAt this step .log file should be pruned and contains only digits (m/z and intensities)\n\n\nfor coconut Parsing directory../coconut_data/results_coconut/ with file extension :.log\n\n'mass' ../coconut_data/results_coconut/CNP0402147.log\n'mass' ../coconut_data/results_coconut/CNP0153817.log\n'mass' ../coconut_data/results_coconut/CNP0155980.log\n'mass' ../coconut_data/results_coconut/CNP0086807.log\n'mass' ../coconut_data/results_coconut/CNP0199206.log\n'mass' ../coconut_data/results_coconut/CNP0334817.log\n'mass' ../coconut_data/results_coconut/CNP0366374.log\n'mass' ../coconut_data/results_coconut/CNP0232712.log\n'mass' ../coconut_data/results_coconut/CNP0370068.log\n'mass' ../coconut_data/results_coconut/CNP0055178.log\n'mass' ../coconut_data/results_coconut/CNP0228597.log\n'mass' ../coconut_data/results_coconut/CNP0119974.log\n'mass' ../coconut_data/results_coconut/CNP0132139.log\n'mass' ../coconut_data/results_coconut/CNP0145457.log\n'mass' ../coconut_data/results_coconut/CNP0230801.log\n'mass' ../coconut_data/results_coconut/CNP0310370.log\n'mass' ../coconut_data/results_coconut/CNP0149436.log\n'mass' ../coconut_data/results_coconut/CNP0396848.log\n'mass' ../coconut_data/results_coconut/CNP0401434.log\n'mass' ../coconut_data/results_coconut/CNP0101561.log\n'mass' ../coconut_data/results_coconut/CNP0390928.log\n'mass' ../coconut_data/results_coconut/CNP0405256.log\n'mass' ../coconut_data/results_coconut/CNP0395006.log\n'mass' ../coconut_data/results_coconut/CNP0159145.log\n'mass' ../coconut_data/results_coconut/CNP0131085.log\n'mass' ../coconut_data/results_coconut/CNP0230696.log\n'mass' ../coconut_data/results_coconut/CNP0014450.log\n'mass' ../coconut_data/results_coconut/CNP0214739.log\n'mass' ../coconut_data/results_coconut/CNP0302005.log\n'mass' ../coconut_data/results_coconut/CNP0279314.log\n'mass' ../coconut_data/results_coconut/CNP0177036.log\n'mass' ../coconut_data/results_coconut/CNP0274256.log\n'mass' ../coconut_data/results_coconut/CNP0403745.log\n'mass' ../coconut_data/results_coconut/CNP0039287.log\n'mass' ../coconut_data/results_coconut/CNP0238803.log\n'mass' ../coconut_data/results_coconut/CNP0014261.log\n'mass' ../coconut_data/results_coconut/CNP0077076.log\n'mass' ../coconut_data/results_coconut/CNP0125300.log\n'mass' ../coconut_data/results_coconut/CNP0228582.log\n'mass' ../coconut_data/results_coconut/CNP0393136.log\n'mass' ../coconut_data/results_coconut/CNP0338003.log\n'mass' ../coconut_data/results_coconut/CNP0070182.log\n'mass' ../coconut_data/results_coconut/CNP0230961.log\n'mass' ../coconut_data/results_coconut/CNP0001326.log\n'mass' ../coconut_data/results_coconut/CNP0088652.log\n'mass' ../coconut_data/results_coconut/CNP0045797.log\n'mass' ../coconut_data/results_coconut/CNP0175458.log\n'mass' ../coconut_data/results_coconut/CNP0300969.log\n'mass' ../coconut_data/results_coconut/CNP0030335.log\n'mass' ../coconut_data/results_coconut/CNP0126194.log\n'mass' ../coconut_data/results_coconut/CNP0334816.log\n'mass' ../coconut_data/results_coconut/CNP0290616.log\n'mass' ../coconut_data/results_coconut/CNP0386127.log\n'mass' ../coconut_data/results_coconut/CNP0406328.log\n'mass' ../coconut_data/results_coconut/CNP0127289.log\n'mass' ../coconut_data/results_coconut/CNP0032755.log\n'mass' ../coconut_data/results_coconut/CNP0258640.log\n'mass' ../coconut_data/results_coconut/CNP0199475.log\n'mass' ../coconut_data/results_coconut/CNP0350989.log\n'mass' ../coconut_data/results_coconut/CNP0333350.log\n'mass' ../coconut_data/results_coconut/CNP0213544.log\n'mass' ../coconut_data/results_coconut/CNP0204567.log\n'mass' ../coconut_data/results_coconut/CNP0148525.log\n'mass' ../coconut_data/results_coconut/CNP0053639.log\n'mass' ../coconut_data/results_coconut/CNP0118368.log\n'mass' ../coconut_data/results_coconut/CNP0226584.log\n'mass' ../coconut_data/results_coconut/CNP0254221.log\n'mass' ../coconut_data/results_coconut/CNP0241364.log\n'mass' ../coconut_data/results_coconut/CNP0348684.log\n'mass' ../coconut_data/results_coconut/CNP0053255.log\n'mass' ../coconut_data/results_coconut/CNP0167909.log\n'mass' ../coconut_data/results_coconut/CNP0142603.log\nTreated 384150 files, skipped 72\n\n\n\n\n\n\n## Populating the mgf headers\n\n### Preparation of the adducted metadata table\n\nWe need to prepare and adducted dataframe containing the protonated and deprotonated masses\n\nThis script recquire rdkit so we build a environment.yml file from a dedicated conda env\n\nconda env export -n conda-env -f /path/to/environment.yml\n\nEventually you need to fetch the file from the internet (use wget )\n\nwget https://zenodo.org/record/3547718/files/COCONUT4MetFrag.csv?download=1\n\nSometimes since SMILES or INchi can yield error and since there is a MF field, the emass can be calculated directly form the MF as described here \n<https://bioinformatics.stackexchange.com/a/9273>. Noooop actually not working since the GetMass() function yield a molecular weight and not and exact mass ....\n\n\nScript table_adducter_script.py is adapted to cope with different delimiters ... beware and note that $ is mandatory to input the tab delim\n\npython table_adducter_npatlas_script.py ../npatlas_data/np_atlas_2019_12.tsv ../npatlas_data/np_atlas_2019_12_adducted.tsv\n\npython table_adducter_script.py ../coconut_data/COCONUT4MetFrag.csv ',' ../coconut_data/COCONUT4MetFrag_adducted.csv $'\\t'\n\n\n### Addition of the metadata to the individual mgf headers\n\nWe can now populate each raw mgf with its corresponding metadata. For this we use the treat_npatlas.py script\n\npython treat_npatlas.py ../npatlas_data/np_atlas_2019_12_adducted.tsv ../npatlas_data/results_npatlas/npatlas/\n\npython mgf_header_populater.py ../coconut_data/COCONUT4MetFrag_adducted.csv ../coconut_data/results_coconut/ Identifier\n\n\n\non coconut \n\nTreated 384150 files, skipped 28161.\n\n\n\n\n## Generating the final spectral file\n\nWe concatenate each documented mgf files to a single spectral mgf file.\n\nfind ./ -type f -name '*.mgf' | while read F; do cat ${F} >> ../../npatlas_ISDB_pos.mgf; done\nfind ./ -type f -name '*.mgf' | while read F; do cat ${F} >> ../../coconut_ISDB_pos.mgf; done\n\n\n## Outputting non-fragmented entries\n\nFor several reasons (charged compounds, some tautomers, structures too heavy to be fragmented in a reasonable amount of time) some entries might not have been fragmented. \n\nTo find them we will first list all correctly converted mgf\n\nfind ./ -type f -name '*.mgf' | sed 's!.*/!!' | sed 's!^!!' >  list_mgf.txt\n\n%%here eventually without the extension\n\nfind ./ -type f -name '*.mgf' | sed 's!.*/!!' | sed 's!.mgf!!' >  ../../list_mgf.txt\n\nAnd then the list is compared to the initial input using the table_comparator.py \n\npython table_comparator.py ../npatlas_data/npatlas_for_frag.txt ../npatlas_data/list_mgf.txt ../npatlas_data/unfragged_list.txt\n\n\n### check molVS for structure standardization\n\nhttps://molvs.readthedocs.io/en/latest/index.html\n","n":0.036}}},{"i":382,"$":{"0":{"v":"Bibliography","n":1}}},{"i":383,"$":{"0":{"v":"Inciteful","n":1},"1":{"v":"\n\n\nInciteful.xyz\n","n":1}}},{"i":384,"$":{"0":{"v":"Datawarrior","n":1},"1":{"v":"\n(sublime ZK imported)\n\n# idea_datawarrior\ntags = #database #datawarrior #bibliography o\n\nAdd bibliographic reference to each compounds using the google scholar patents links functionality of DataWarrior.\n\nIt looks like an automatic query of the SMILES string can be done.\nExample \n\nhttps://patents.google.com/?q=SMILES%3dO%3dC1(OC2(C(C4(CCCCN3(C4(C(C2(C1C))CC3))))CC))&patents=false&scholar&oq=SMILES%3dO%3dC1(OC2(C(C4(CCCCN3(C4(C(C2(C1C))CC3))))CC))\n\n# directly fetches results and download them as csv file\nhttps://patents.google.com/xhr/query?url=q%3DSMILES%253dO%253dC1(OC2(C(C4(CCCCN3(C4(C(C2(C1C))CC3))))CC))%26patents%3Dfalse%26scholar%26oq%3DSMILES%253dO%253dC1(OC2(C(C4(CCCCN3(C4(C(C2(C1C))CC3))))CC))&exp=&download=concepts\n\n\n# actually it goes even further as on can add terms to filter the query.\nHere for example terms form the European Patent Office corresponding to Medicinal preparations of undetermined constitution containing material from algae, lichens, fungi or plants, or derivatives thereof, e.g. traditional herbal medicines (A61K36/00) https://worldwide.espacenet.com/classification#!/CPC=A61K36/00\n\nhttps://patents.google.com/xhr/query?url=q%3DSMILES%253dO(C3(%253dC1(C(NC2(%253dC1C%253dCC%253dC2O))%253dC(C%253dC)N%253dC3)))C%26q%3DA61K%26patents%3Dfalse%26scholar%26sort%3Dold&exp=&download=concepts\n\nNote that the %3D character can pe passed to = for more readibility\n\n<https://patents.google.com/xhr/query?url=q=SMILES%253dO(C3(%253dC1(C(NC2(%253dC1C%253dCC%253dC2O))%253dC(C%253dC)N%253dC3)))C%26q=A61K36/00%26patents=false%26scholar%26sort=old&exp=&download=concepts>\n\n\nNote that a scrapper as been written to download all associated pdfs\n\nhttps://github.com/wenyalintw/Google-Patents-Scraper\n\nhttps://patents.google.com/xhr/query?url=q=SMILES%253dO(C3(%253dC1(C(NC2(%253dC1C%253dCC%253dC2O))%253dC(C%253dC)N%253dC3)))C%26q=A61K36/00%26patents=false%26scholar%26sort=old\n","n":0.094}}},{"i":385,"$":{"0":{"v":"Web","n":1},"1":{"v":"\n[TOC]\n\n\n# Web hosting of a single page \n2021-01-28 10:29\n## Context\nI need to share html rendered md notes coming from dendrons private daily journal notes. I use these as an electronic lab notebook and sometime want to share them to collaborators instead of preparing a ppt or keynote slide presentation.\n## Need\nWhat I currently have is the daily journal notes as .md files. I can render them as .html using MPE. Make a TOC as a sidebar (just add [TOC] at the head of the file), display images, mermaid diagrams etc. They can be automatically published in the github pages. This is OK for dendron notes that I want to publish. However I need to find a solution to efficiently share private notes as html files.\n\nThe remote notes :\n\n- [ ] should be accessible by a simple link, no download required\n- [ ] should rendered the exact same way as the dendrons published notes\n- [ ] should be versionable by git or similar\n- [ ] should be automatically updated upon local changes\n- [ ] should be self encapsulated (if i have them hosted on a git the user whith the link to note C should not be able to jump to upper levels or see note A)\n\n\n## Task (of the note/paragraph/text/paper/project)\n\nThis is what I did up to now and what I plan to do to tackle this\n\n- [x] ~~recreated this ctno snippet~~\n\n- [x] ~~created this note~~\n\n- [ ] check for hosting solutions\n\n    - [x] ~~dropbox~~\n\n    Not good anymore as the discontinued the direct disply of html files. Would have been a perfect solution.\n    https://superuser.com/questions/764641/how-to-serve-html-off-my-dropbox\n\n    - [x] ~~https://www.fast.io/~~ (appears to be discontinued as of 2021-01-16)\n    - [ ] http://pomf.se/\n    - [ ] https://www.netlify.com/\n    - [ ] https://wowchemy.com/\n        - [ ] https://www.jameswright.xyz/post/deploy-hugo-academic-using-githubio/\n\n## Object (of the note/paragraph/text/paper/project)\nThis is a self contained ctno snippet. It does not aim to introduce anything other than itself.\nThat was the object. //TODO Snippets. Work on different and more adapted snippets (self sufficient, introductory etc ...)\n\n\n## Hugo\n\n\nhttps://www.ctomlinson.net/post/building-a-website-with-hugo-academic/\n\n","n":0.055}}},{"i":386,"$":{"0":{"v":"Visualization","n":1},"1":{"v":"\n# Links\n\nA set of links and ressources on data viz found when researching Vega engines\n\nhttps://observablehq.com/\n\nhttps://vega.github.io/voyager/\n\nhttps://octo.github.com/projects/flat-data\n\n\nhttps://streamlit.io/\n\n\n# Data Visualization\nA practical introduction\n\nhttps://socviz.co/","n":0.229}}},{"i":387,"$":{"0":{"v":"Plotly","n":1},"1":{"v":"\n# plotly html integration\n\nhttps://ig248.gitlab.io/post/2018-11-05-plotly-sample/  (merci Jo)\n\nafter a bunch of slightly outdate tutorial I found this one wich worked in my case\n\nhttps://medium.com/analytics-vidhya/how-to-export-a-plotly-chart-as-html-3b5df568df4a\n\n \n just embbed like this\n\n```html\n<div class=\"container-fluid\" style=\"margin-top:40px\">\n  <iframe src=\"sariette_pos_pos_organisms_sunburst.html\" width=\"100%\" height=\"600\" style=\"border:none;\"></iframe>\n</div>\n```\n\n\n\n# customization of fig (margin/titles and other nasty stuff)\n\n\n\n```python\n# %%\n# using px express to plot some quick and dirty sunbursts (https://plotly.com/python/sunburst-charts/)\n# customize fonts in titles following https://stackoverflow.com/a/57926862\n# customize margins following https://stackoverflow.com/a/63162535\n\nimport plotly.express as px\n\n\nfig = px.sunburst(df4cyto_flat, path=['Superclass_cf_DNP_consensus', 'Class_cf_DNP_consensus', 'Subclass_cf_DNP_consensus', 'Parent_Level_1_cf_DNP_consensus'],\n                  )\nfig.update_layout(\n    #font_family=\"Courier New\",\n    title_font_family=\"Courier New\",\n    title_font_color=\"black\",\n    title_font_size=14,\n    legend_title_font_color=\"black\",\n    title_text=\"<b> Overview of the consensus chemical annotions <br> as the superclass, class, subclass and parent_1 level for <br>\" + project_name + \"</b>\",\n    title_x=0.5\n)\n\nfig.update_layout(\n    title={\n        'text': \"<b> Overview of the consensus chemical annotions <br> as the superclass, class, subclass and parent_1 level for <br>\" + '<span style=\"font-size: 20px;\">' + project_name + '</span>' + \"</b>\",\n        'y':0.96,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\n\nfig.update_layout(margin=dict(l=50, r=50, t=100, b=50)\n#,paper_bgcolor=\"Black\"\n)\n\nfig.show()\nfig.write_html(sunburst_chem_results_path)\n```\n\n## On the display via github\n\nhttps://community.plotly.com/t/how-to-display-plotly-graph-on-github-pages/44398/2\n\n\nhttps://automating-gis-processes.github.io/2016/Lesson5-share-on-github.html\n\nhttps://mertbakir.gitlab.io/hugo/plotly-with-hugo/\n\nWhen displaying iframe in hugo pages be sure to have \n\nhttps://stackoverflow.com/a/66741389\n\n\n\n\n# Monday 06 December 2021\n\nGetting plotly to work within a jupoyter nb file on github https://binnisb.github.io/blog/datascience/2020/04/02/Plotly-in-lab.html\n\n\n\n# Phylogeny vis\n\n\nhttps://dash.gallery/dash-phylogeny/\n\n\nhttp://etetoolkit.org/","n":0.076}}},{"i":388,"$":{"0":{"v":"Onlin","n":1},"1":{"v":"\nhttps://www.csvplot.com/\n\n\n","n":1}}},{"i":389,"$":{"0":{"v":"Geodata","n":1},"1":{"v":"\n# Geo Data visu\n\nLooking to display and share .gpx data \n\nhttps://marketplace.visualstudio.com/items?itemName=RandomFractalsInc.geo-data-viewer\n\nIt is apparently possible to add .csv data to an existing .gpx map\nhttps://docs.kepler.gl/docs/user-guides/b-kepler-gl-workflow/a-add-data-to-the-map#csv\n\nI used https://geogeek.xyz/wp-content/uploads/2017/08/coordinate_converter.xlsx to convert UTM coord to decimal lon lat. Not ideal but did the job.\n\nYou can then add and combine .gpx or csv of lat long in the geo-data-viewer and export the .html.\nWhen you open this one it will be opened in the kepler website. There you can export as shareable html (dont forget to add your personal token)\nHere is an example [finca](../../../../../Users/pma/Dropbox/dendron/vault/assets/private.assets/terreno_pma_kepler.gl.html)\n\n\nAu cours des siècles précédents, les scientifiques occidentaux ont exploré le monde à la recherche de nouvelles espèces végétales et animales, qu'ils ont répertoriées et dont ils ont caractérisé le contenu chimique. Certaines de ces découvertes ont conduit à l'exploitation des ressources naturelles au profit de divers secteurs industriels, notamment l'industrie pharmaceutique, parfois au détriment des communautés locales qui détenaient des connaissances traditionnelles sur les vertus médicinales des plantes concernées. La mise en œuvre du protocole de Nagoya en 2014 a établi un cadre juridique protecteur pour favoriser des échanges plus équitables de ressources naturelles et de connaissances associées entre les pays. Aujourd'hui, la bioprospection est encadrée par ce protocole et toute recherche de nouvelles molécules passe par un accord avec les pays d'origine des plantes concernées.\n\n\nLooking to pass these coordinates to Restor plot\n\n{\"name\":\"coordTimes\",\"type\":\"geojson\",\"format\":\"\",\"analyzerType\":\"ARRAY\"}]}},{\"version\":\"v1\",\"data\":{\"id\":\"3hssoo2mf\",\"label\":\"terreno_1_decimal.csv\",\"color\":[0,92,255],\"allData\":[[-1.30233732,-78.02393279],[-1.30101016,-78.03649421],[-1.30267186,-78.03776368],[-1.30406734,-78.02385553],[-1.30331076,-78.02325757],[-1.30324003,-78.02395417]],\"fields\":[{\"name\":\"lat\",\"type\":\"real\",\"format\":\"\",\"analyzerType\":\"FLOAT\"},{\"name\":\"lon\",\"type\":\"real\",\"format\":\"\",\"analyzerType\":\"FLOAT\"}]}},{\"version\":\"v1\",\"data\":{\"id\":\"h5zw1xlsa\",\"label\":\"terreno_2_decimal.csv\",\"color\":[192,108,132],\"allData\":[[-1.30571595,-78.02514168],[-1.30406734,-78.02385553],[-1.30267186,-78.03776368],[-1.30433356,-78.03903305]],\"fields\":[{\"name\":\"lat\",\"type\":\"real\",\"format\":\"\",\"analyzerType\":\"FLOAT\"},{\"name\":\"lon\",\"type\":\"real\",\"format\":\"\",\"analyzerType\":\"FLOAT\"}]}}];\n\nI generate it using https://geojson.io/#map=14.18/-1.30079/-78.03852\nTerreno1 \n\n{\n  \"type\": \"FeatureCollection\",\n  \"features\": [\n    {\n      \"type\": \"Feature\",\n      \"properties\": {},\n      \"geometry\": {\n        \"coordinates\": [\n          [\n            [\n              -78.02393279,\n                -1.30233732\n            ],\n            [\n              -78.03649421,\n                -1.30101016\n            ],\n            [\n              -78.03776368,\n                -1.30267186\n            ],\n            [\n              -78.02385553,\n                -1.30406734\n            ],\n            [\n              -78.02325757,\n                -1.30331076\n            ],\n            [\n              -78.02395417,\n                -1.30324003\n            ],\n            [\n              -78.02514168,\n                -1.30571595\n          ],\n          [\n            -78.02385553,\n              -1.30406734\n          ],\n          [\n            -78.03776368,\n              -1.30267186\n          ],\n          [\n            -78.03903305,\n              -1.30433356\n          ]\n        ],\n        \"type\": \"Polygon\"\n      }\n    }\n  ]\n}\n\nCorrected format\n\n```json\n{\n  \"type\": \"FeatureCollection\",\n  \"features\": [\n    {\n      \"type\": \"Feature\",\n      \"properties\": {},\n      \"geometry\": {\n        \"coordinates\": [\n          [\n            [-78.02393279, -1.30233732],\n            [-78.03649421, -1.30101016],\n            [-78.03776368, -1.30267186],\n            [-78.02385553, -1.30406734],\n            [-78.02325757, -1.30331076],\n            [-78.02395417, -1.30324003],\n            [-78.02514168, -1.30571595],\n            [-78.02385553, -1.30406734],\n            [-78.03776368, -1.30267186],\n            [-78.03903305, -1.30433356],\n            [-78.02393279, -1.30233732]  // Repeated to close the ring\n          ]\n        ],\n        \"type\": \"Polygon\"\n      }\n    }\n  ]\n}\n```\n\n\n-1.30233732,-78.02393279\n-1.30101016,-78.03649421\n-1.30267186,-78.03776368\n-1.30406734,-78.02385553\n-1.30331076,-78.02325757\n-1.30324003,-78.02395417\n-1.30571595,-78.02514168\n-1.30406734,-78.02385553\n-1.30267186,-78.03776368\n-1.30433356,-78.03903305\n\n\nWe write  .shp file using the previosu coordinates\n\n\n\n\n{\n  \"type\": \"FeatureCollection\",\n  \"features\": [\n    {\n      \"type\": \"Feature\",\n      \"properties\": {},\n      \"geometry\": {\n        \"coordinates\": [\n          [\n            [-1.30233732,-78.02393279],\n            [-1.30101016,-78.03649421],\n            [-1.30267186,-78.03776368],\n            [-1.30406734,-78.02385553],\n            [-1.30331076,-78.02325757],\n            [-1.30324003,-78.02395417],\n            [-1.30571595,-78.02514168],\n            [-1.30406734,-78.02385553],\n            [-1.30267186,-78.03776368],\n            [-1.30433356,-78.03903305]  // Repeated to close the ring\n          ]\n        ],\n        \"type\": \"Polygon\"\n      }\n    }\n  ]\n}\n\n\nTerreno pix \nhttps://photos.app.goo.gl/D7R9LkTbJo9CwNf22\n\n\nRestor plot created at https://restor.eco/sites/2a4c1765-f607-46b6-9bce-373f67ef8fc8/?lat=-1.3033646961059957&lng=-78.03114165500001&zoom=16\n\n","n":0.051}}},{"i":390,"$":{"0":{"v":"Sql","n":1},"1":{"v":"\n# MySQL\n\ncreating a mysql instance for MyLabBook test\n\nhttps://medium.com/macoclock/mysql-on-mac-getting-started-cecb65b78e\n\nfrom cli\n\nhttps://www.a2hosting.com/kb/developer-corner/mysql/managing-mysql-databases-and-users-from-the-command-line\n\nif you have issue to log https://stackoverflow.com/questions/4359131/brew-install-mysql-on-macos\n\n\nGRANT ALL PRIVILEGES ON *.* TO 'pma'@'localhost' IDENTIFIED BY 'password';\n","n":0.204}}},{"i":391,"$":{"0":{"v":"Snakemake","n":1},"1":{"v":"\n\n#snakemake is something I should definitively look into https://snakemake.github.io/\n\nhttps://slides.com/johanneskoester/snakemake-tutorial\n\nHere is another one https://carpentries-incubator.github.io/snakemake-novice-bioinformatics/\n\nhttps://github.com/leipzig/SandwichesWithSnakemake\n\nI am having an issue to deal with a singlae archive beeing expanded to multipl folder\n\nhere is maybe a way\nhttps://taylorreiter.github.io/2020-02-03-How-to-use-snakemake-checkpoints-to-extract-files-from-an-archive/\n\nSo apparently two mechanisms can be used \n\ncheckpoints and dynamics \n\nhttp://ivory.idyll.org/blog/2021-snakemake-checkpoints.html\n\nhttps://evodify.com/snakemake-checkpoint-tutorial/\n\n","n":0.154}}},{"i":392,"$":{"0":{"v":"Pg","n":1},"1":{"v":"# Installing PG on Ubuntu \n\n\nFollowing https://computingforgeeks.com/install-postgresql-12-on-ubuntu/\n\n","n":0.378}}},{"i":393,"$":{"0":{"v":"Mongo","n":1},"1":{"v":"\n# Mongo DB related infos\n\nA pres by Matt Swain\nhttps://speakerdeck.com/mcs07/chemical-structure-handling-in-mongodb\n\nhttps://matt-swain.com/blog/2014-06-03-chemical-similarity-search-in-mongodb\n\nAssociated repo https://github.com/mcs07/mongodb-chemistry\nAnd a derived notebook https://mnowotka.github.io/notebooks/mongo.html\n\nhttps://mnowotka.github.io/notebooks/\n\nBunch of chembl related info here also\nhttp://chembl.blogspot.com/ n\n","n":0.213}}},{"i":394,"$":{"0":{"v":"Mnemonics","n":1},"1":{"v":"\n\nA list of Mnemonics related tools \n\nhttps://numinous.productions/ttft/#top\n\n[[mnemonics related side note | scratch.2020-09-24-000451]] \n\n\nA new mnemonic medium \nhttps://quantum.country/qcvc\n\n\n\n## Prompts \n\nHow to write good prompts: using spaced repetition to create understanding\n\nhttps://andymatuschak.org/prompts/ \nLinked to ![[tools.mnemonics.anki]]\n\nOrbit's inspirational description \n\n> _When you read a text that’s written with Orbit, you don’t just read it once and then set it aside, perhaps forever. The review sessions keep you in contact with the ideas, returning you to the material again and again over weeks and months. The ongoing practice changes your relationship to what you read. It gives you a way to bring ideas into your orbit. … When something seems interesting, you can tie a string to it and throw it up in a lazy arc. It’ll swing back around at some point, but you’re not terribly concerned with when. You’ll give its string more or less slack over time. Floating above your head, then, is an ever-shifting constellation of inklings, facts, questions, prompts, obsessions. Every day you stare up at the slice of sky above you and respond to what’s there.\n> _\n\nAn app to create prompted and enhanced text, also by Matuschak https://withorbit.com/\n~~I have read about similar plugin in vscode. Dig this. ~~\nCould be useful mostly for class material. \n\n* https://github.com/frenya/vscode-recall\n* https://github.com/jasonwilliams/anki Directly send test from markdown to Anki !\n\n\n## Wednesday 08 September 2021\n\nYay have a look at this one for spaced repetitions\nhttps://recall.frenya.net/\n\n","n":0.066}}},{"i":395,"$":{"0":{"v":"Anki","n":1},"1":{"v":"\n## Anki\n\nThere is a guy in the dendron community using Anki (https://apps.ankiweb.net/)\n\nhttps://texdeck.net/\n\n//TODO Investigate this \n\n\n## Anki plants\n\nHere is an Anki deck if you are interested in learning more about plants taxonomy.\n\nhttps://ankiweb.net/shared/info/594735105\n\nYou have more than 4800 genus of chemically studied plants to learn !\n\nUse the desktop app with a browser side by side in order to easily fetch info (general aspects, medicinal uses, facts, geography) which will help you memorize the plants.\n\nYou can the get a bunch of stats telling you how bad you are ... Repetition is key. (I have not been looking at these in the last 2 months)\nBut I think that a small period of learning each 2/3 days is great. What I did not cath is a way to get reminder from Anki, since it's objective is to schedule the relearning this could be a useful option. Have to check this.\n\nStats that you can get from the Anki deck soft \n[stats](assets/anki-stats-2021-01-12@21-47-51.pdf)\n","n":0.081}}},{"i":396,"$":{"0":{"v":"Metabolomics","n":1}}},{"i":397,"$":{"0":{"v":"Feature Detection","n":0.707},"1":{"v":"\nnf-core/metaboigniter is a bioinformatics pipeline that ...\n\nThis pipeline ingests raw mass spectrometry data in mzML format, typically in the form of peak lists and MS2 spectral data, for comprehensive metabolomics analysis. The key stages involve centroiding, feature detection, adduct detection, alignment, and linking, which progressively refine and align the data. The pipeline can also perform requantification to compensate for missing values and leverages MS2Query for compound identification based on MS2 data, outputting a comprehensive list of detected and potentially identified metabolites.\n\nhttps://github.com/nf-core/metaboigniter/tree/2.0.0\n\n","n":0.111}}},{"i":398,"$":{"0":{"v":"Annotation","n":1},"1":{"v":"\n\nhttps://jorainer.github.io/MetaboAnnotationTutorials/index.html\n\nhttps://www.mdpi.com/2218-1989/12/2/173\n\n\n\n","n":1}}},{"i":399,"$":{"0":{"v":"Lims","n":1},"1":{"v":"\n\n# LIMS wiki\n\nhttps://www.limswiki.org/index.php/Main_Page\n\n\n[[#lab|tag.lab]]\n[[#organization|tag.organization]]\n","n":0.577}}},{"i":400,"$":{"0":{"v":"Km","n":1},"1":{"v":"\n# DBpedia\n\ncheck in https://fr.wikipedia.org/wiki/DBpedia\n\n\n# Tarql\n\nhttp://tarql.github.io/\n\nSPARQL for Tables: Turn CSV into RDF using SPARQL syntax\n\n\n\n\n\nhttps://knotation.org/\n\nhttp://robot.obolibrary.org/\n\n\n# RDF \n\n## convert csv to RDF \n\nhttps://stackoverflow.com/questions/43524943/creating-rdf-file-using-csv-file-as-input\n\ncheck in RDFlib\n\nhttps://rdflib.readthedocs.io/en/stable/index.html\n\n\n## GraphDB ressources\n\nhttps://graphdb.ontotext.com/free/devhub/ontologies.html?utm_campaign=GraphDB&utm_medium=email&_hsmi=101117907&_hsenc=p2ANqtz-_P3Mf-7bSerJeAWtWCXHAZCx1giPfGzHa47wQ142kn_amyTL8j2BVL7Od06EHFGR9oDXhIsdHaUL4Ln1hALrq7yMChlQ&utm_content=101117907&utm_source=hs_automation\n\n# Semantic markdown\n\nhttp://blog.sparna.fr/2020/02/20/semantic-markdown/\n\n\n# INDRA labs\n\nhttps://indralab.github.io/\n\n\n# Tiago Lubiana\n\nhttps://pointstodots.wordpress.com/2021/05/15/intro/\n\n# Linking different knowledge graphs together\n\nhttp://www.bobdc.com/blog/linkingkgs/\n\n\n# Bob DuCharme\n\nhttp://www.bobdc.com/blog/\n\n","n":0.162}}},{"i":401,"$":{"0":{"v":"Git","n":1},"1":{"v":"## Github Discussions template for questions\n\nhttps://github.blog/news-insights/product-news/github-discussions-just-got-better-with-category-forms/\n\n\n\n# Nice intro\n\nLooks good for tuto and convince of git adoption Version Control with Git\n\nhttps://carpentries-incubator.github.io/git-novice-branch-pr/\n# Get info of the git remote\n\n`git config --get remote.origin.url`\n\n# Get history as a graph\n\n```\ngit fetch\ngit log --all --decorate --oneline --graph\n```\n\n\n# Pull\n\nhttps://stackoverflow.com/a/4924044\n\nSo I imagine you want to do something like:\n\n`git pull origin dev`\n\nTo set it up so that it does this by default while you're on the dev branch:\n\n`git branch --set-upstream-to dev origin/dev`\n\n\n# Reset to specific commit and push to master \n\n git reset --hard <commit-hash>\n git push -f origin main\n \n\n# What should you do when you get the infamous \"You have divergent branches and need to specify how to reconcile them.\"\n\n```\nhint: You have divergent branches and need to specify how to reconcile them.\nhint: You can do so by running one of the following commands sometime before\nhint: your next pull:\nhint: \nhint:   git config pull.rebase true   # rebase\nhint:   git config pull.ff only       # fast-forward only\nhint: \nhint: You can replace \"git config\" with \"git config --global\" to set a default\nhint: preference for all repositories. You can also pass --rebase, --no-rebase,\nhint: or --ff-only on the command line to override the configured default per\nhint: invocation.\n```\n\nhttps://stackoverflow.com/a/62653400/4908629\n\n\n## What is the git fast-forward option ?\nhttps://blog.mergify.com/what-is-a-git-merge-fast-forward/\n\n> When Git detects that your commit is about to be merged into your project's main branch without the main branch having been modified since your feature branch was first made, it chooses to use a fast-forward merge instead of a three-way merge. Fast-forward merges literally move your main branch's tip forward to the end of your feature branch. This keeps all commits created in your feature branch sequential while integrating it neatly back into your main branch.\n> \n> \n\n## For git sensitive information removal\n\nhttps://rtyley.github.io/bfg-repo-cleaner/\n\n\n# Undo a git commit & redo  \n\n$ git commit -m \"Something terribly misguided\" # (0: Your Accident)\n$ git reset HEAD~                              # (1)\n[ edit files as necessary ]                    # (2)\n$ git add .                                    # (3)\n$ git commit -c ORIG_HEAD                      # (4)\n\nhttps://stackoverflow.com/a/927386\n\n\n\n\n\n/Users/pma/02_tmp/","n":0.056}}},{"i":402,"$":{"0":{"v":"Merge","n":1},"1":{"v":"\nWhen you need to accept a lot of external files generating conflicts\n\nhttps://linuxpip.org/git-accept-all-incoming-changes/\n\ngit checkout --theirs .\n","n":0.258}}},{"i":403,"$":{"0":{"v":"Mainmaster","n":1},"1":{"v":"\nTo address the REALLY annoying master/main issue \n\n\nhttps://www.r-bloggers.com/2020/07/5-steps-to-change-github-default-branch-from-master-to-main/\n\nand eventually you need to \n\ngit pull origin master --allow-unrelated-histories\n\n(https://www.educative.io/edpresso/the-fatal-refusing-to-merge-unrelated-histories-git-error)\n\n\n","n":0.243}}},{"i":404,"$":{"0":{"v":"Gitignore","n":1},"1":{"v":"\ndesc: ''\nhttps://stackoverflow.com/questions/25436312/gitignore-not-working\n\ngit rm -rf --cached .\ngit add .\n➜  vault git:(main) git status --ignored  \n","n":0.267}}},{"i":405,"$":{"0":{"v":"Emojis","n":1},"1":{"v":"https://gist.github.com/rxaviers/7360908\n\n","n":1}}},{"i":406,"$":{"0":{"v":"Argumentation","n":1},"1":{"v":"\nCheck an investigate about Argdown\nhttps://github.com/christianvoigt/argdown, a VSCode plugin to create md formated [argument maps](https://en.wikipedia.org/wiki/Argument_map)\n\nCheck also the associated research of the group http://debatelab.philosophie.kit.edu/\n\n\nNote : observed conflicts with dendron plgions\n","n":0.189}}},{"i":407,"$":{"0":{"v":"Test","n":1}}},{"i":408,"$":{"0":{"v":"Vincenzo","n":1},"1":{"v":"hello vincenzo","n":0.707}}},{"i":409,"$":{"0":{"v":"Simon","n":1},"1":{"v":"test","n":1}}},{"i":410,"$":{"0":{"v":"Projects","n":1}}},{"i":411,"$":{"0":{"v":"Commons Public","n":0.707}}},{"i":412,"$":{"0":{"v":"Wikipathways","n":1},"1":{"v":"\nMost likely THE place to start learning about Wikipathways https://wikipathways.org/academy/\n\nRan into the following issues\n\n➜  pathvisio-3.3.0 sh pathvisio.sh\nProblem creating boot delegation class loader: java.lang.reflect.InaccessibleObjectException: Unable to make protected java.security.SecureClassLoader(java.lang.ClassLoader) accessible: module java.base does not \"opens java.security\" to unnamed module @49b70bc7\nInstalling bundles that are embedded in the jar.\nDetected embedded bundle: org.apache.batik.svggen_1.7.0.v201011041433.jar\nLoading jar:file:/Applications/pathvisio-3.3.0/pathvisio.jar!/org.apache.batik.svggen_1.7.0.v201011041433.jar\n^C^C%\n➜  pathvisio-3.3.0 java --version\nopenjdk 17.0.1 2021-10-19\nOpenJDK Runtime Environment (build 17.0.1+12-39)\nOpenJDK 64-Bit Server VM (build 17.0.1+12-39, mixed mode, sharing)\n\n\nPathvisio aparently only supports java 8 https://github.com/PathVisio/pathvisio/issues/155\n\n\nhttps://medium.com/@brunofrascino/working-with-multiple-java-versions-in-macos-9a9c4f15615a\n\nAdapted line for java8 to\n\nhttps://stackoverflow.com/a/28635465\n\n\nNeeded to echo eval \"$(jenv init -)\" >> /Users/pma/.zshrc\n\nDocumented here https://github.com/PathVisio/pathvisio/issues/155#issuecomment-1059946761\n\nStopped here https://wikipathways.org/academy/stages/wp-publish/index.html\nNow waiting for an auth from Wikipathways to upload\n\nhttps://wikipathways.org/academy/path.html\n\nThe last part (QA protocol) could give some inspiration regarding a curation interface for lotus data\n\n\n\nWas having a look at BioCyc when ... oh surprise \n![](/assets/images/2022-03-06-15-10-52.png)\n\n\n(#amoeba) <<< will use this tag when I know amoeba splitting will be required later on\n\n\nhttp://ambit.sourceforge.net/\nhttps://apps.ideaconsult.net/data/demo/reaction?search=C%5BS%2B%5D%28C%5BC%40%40H%5D3%28%5BC%40%40H%5D%28O%29%5BC%40%40H%5D%28O%29%5BC%40H%5D%28N1%28C2%28%5CN%3DC%2FN%3DC%28C%28%5CN%3DC%2F1%29%3D2%29%2FN%29%29%29O3%29%29CC%5BC%40%40H%5D%28C%28%5BO-%5D%29%3DO%29%5BNH3%2B%5D&smirks=%5BC%3A1%5D%28%5BH%5D%29%5BO%3A2%5D%5BH%5D%3E%3E%5BC%3A1%5D%3D%5BO%3A2%5D\n\n\nhttp://ideaconsult.github.io/Toxtree.js/\n\n\nhttps://github.com/ideaconsult/notebooks-ambit\n\nLooks like arabit hole afternoon to me ... https://github.com/twosigma/beakerx\nNow installing java kernel for jupyter nb\n\nSince \nhttps://github.com/twosigma/beakerx/issues/8317\n\nI\n\n\nconda create --name ambit -c beakerx -c conda-forge python=3.7 beakerx_kernel_java\n\nCould not run the notebooks.\nFiled an issue at https://github.com/ideaconsult/notebooks-ambit/issues/2\n\nhttps://onlinelibrary.wiley.com/doi/abs/10.1002/minf.202100027\n","n":0.077}}},{"i":413,"$":{"0":{"v":"Wikidata","n":1}}},{"i":414,"$":{"0":{"v":"Scholia","n":1},"1":{"v":"\nContribute this query to Scholia https://w.wiki/42KM\n\n\nIn order to have metabolites for a genus and below\n\n","n":0.258}}},{"i":415,"$":{"0":{"v":"Mismall","n":1},"1":{"v":"This is a placeholder to test xvaults\n","n":0.378}}},{"i":416,"$":{"0":{"v":"Mibig","n":1},"1":{"v":"# Context\n\nRecently Marnix Medema twitted about their necessity to furnish MIBIG with further BGC <-> metabolites pairs.\nhttps://twitter.com/marnixmedema/status/1431190836289617923\n\nThis is an \"annotathon\"\n\nMaybe LOTUS could help here.\nhttps://mibig.secondarymetabolites.org/\n\n\n§# Log book \n\n2021-08-28 17:00\n\nLet's see is Thiago's app can help here [[wikidata.apps]]\nThe idea would be to find a list of paper having described both a metabolites and it's associated BGC\n\n\nLet's try a SPARQL Query as following :\n\nhttps://w.wiki/3yN7\ndetailed https://w.wiki/3yNw \nwith single ref https://w.wiki/3yNL\nlimited to specific strains https://w.wiki/3yPf\n\n\n\nPosted https://twitter.com/allard_pm/status/1431640111440138245\n\nAnd updated at 2021-09-07 18:10\n\n","n":0.115}}},{"i":417,"$":{"0":{"v":"Assane","n":1},"1":{"v":"Batch creation of short url for WD SPARQL queries.\n\nThanks to Jo I can  start with this curl command \n\n```bash\ncurl 'https://meta.wikimedia.org/w/api.php' -X POST -H 'User-Agent: PMAs Query shortener' -H 'Accept: application/json, text/javascript, /; q=0.01' -H 'Accept-Language: en-US,en;q=0.5' --compressed -H 'Referer: https://meta.wikimedia.org/wiki/Special:UrlShortener' -H 'Content-Type: application/x-www-form-urlencoded; charset=UTF-8' -H 'X-Requested-With: XMLHttpRequest' -H 'Origin: https://meta.wikimedia.org' -H 'DNT: 1' -H 'Connection: keep-alive' -H 'Sec-Fetch-Dest: empty' -H 'Sec-Fetch-Mode: cors' -H 'Sec-Fetch-Site: same-origin' -H 'TE: trailers' --data-raw 'action=shortenurl&format=json&url=https%3A%2F%2Fquery.wikidata.org%2F%23FOU%250A'\n```\n\n\nI now need to automatise the creation of the commands starting from a list of plants\nAs a supplemental option add a qr code for this\n\nLe's try an example with the query for Abrus precatorius\n\nhttps://w.wiki/45ZX\n\nhttps://query.wikidata.org/#SELECT%20%3Fchemical_compound%20%3Fchemical_compoundLabel%20%3Fqueried_taxa%20%3Fqueried_taxaLabel%20%3Freference%20%3FreferenceLabel%20WHERE%20%7B%0A%20%20VALUES%20%3Fchemical_classes%20%7B%0A%20%20%20%20wd%3AQ11173%20%23%20chemical%20compound%0A%20%20%20%20wd%3AQ59199015%20%23%20group%20of%20stereoisomers%0A%20%20%7D%0A%20%20%3Fchemical_compound%20wdt%3AP31%20%3Fchemical_classes.%20%23%20We%20select%20instance%20of%20the%20chemical%20classes%20%28chemical%20compound%20or%20group%20of%20stereoisomers%29%0A%20%20VALUES%20%3Fqueried_taxa%20%7B%0A%20%20%20%20wd%3AQ190887%20%23Enter%20the%20Wikidata%20identifier%20of%20your%20taxa%20of%20interest%0A%20%20%20%20%23%20You%20can%20remove%20the%20Qxxxxxxx%20id%20and%20hit%20Ctrl%2Bspace%2C%20thype%20in%20the%20first%20letters%20and%20it%20should%20autocomplete%0A%20%20%7D%0A%20%20%7B%0A%20%20%20%20%3Fchemical_compound%20p%3AP703%20%3Fstmt.%20%23%20We%20select%20chemical%20classes%20having%20the%20found%20in%20taxon%20statement%0A%20%20%20%20%3Fstmt%20ps%3AP703%20%3Fqueried_taxa.%20%23%20and%20the%20restrict%20the%20found%20in%20taxon%20statement%20to%20match%20our%20queried%20taxa%0A%20%20%20%20OPTIONAL%20%7B%0A%20%20%20%20%20%20%3Fstmt%20prov%3AwasDerivedFrom%20%3Fref.%0A%20%20%20%20%20%20%3Fref%20pr%3AP248%20%3Freference.%20%23%20We%20optionally%20return%20the%20reference%20if%20present%20stated%20in%0A%20%20%20%20%7D%0A%20%20%7D%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22%5BAUTO_LANGUAGE%5D%2Cen%22.%20%7D%0A%7D\n\n\ncurl 'https://meta.wikimedia.org/w/api.php' -X POST -H 'User-Agent: PMAs Query shortener' -H 'Accept: application/json, text/javascript, /; q=0.01' -H 'Accept-Language: en-US,en;q=0.5' --compressed -H 'Referer: https://meta.wikimedia.org/wiki/Special:UrlShortener' -H 'Content-Type: application/x-www-form-urlencoded; charset=UTF-8' -H 'X-Requested-With: XMLHttpRequest' -H 'Origin: https://meta.wikimedia.org' -H 'DNT: 1' -H 'Connection: keep-alive' -H 'Sec-Fetch-Dest: empty' -H 'Sec-Fetch-Mode: cors' -H 'Sec-Fetch-Site: same-origin' -H 'TE: trailers' --data-raw 'action=shortenurl&format=json&url=https://query.wikidata.org/#SELECT%20%3Fchemical_compound%20%3Fchemical_compoundLabel%20%3Fqueried_taxa%20%3Fqueried_taxaLabel%20%3Freference%20%3FreferenceLabel%20WHERE%20%7B%0A%20%20VALUES%20%3Fchemical_classes%20%7B%0A%20%20%20%20wd%3AQ11173%20%23%20chemical%20compound%0A%20%20%20%20wd%3AQ59199015%20%23%20group%20of%20stereoisomers%0A%20%20%7D%0A%20%20%3Fchemical_compound%20wdt%3AP31%20%3Fchemical_classes.%20%23%20We%20select%20instance%20of%20the%20chemical%20classes%20%28chemical%20compound%20or%20group%20of%20stereoisomers%29%0A%20%20VALUES%20%3Fqueried_taxa%20%7B%0A%20%20%20%20wd%3AQ190887%20%23Enter%20the%20Wikidata%20identifier%20of%20your%20taxa%20of%20interest%0A%20%20%20%20%23%20You%20can%20remove%20the%20Qxxxxxxx%20id%20and%20hit%20Ctrl%2Bspace%2C%20thype%20in%20the%20first%20letters%20and%20it%20should%20autocomplete%0A%20%20%7D%0A%20%20%7B%0A%20%20%20%20%3Fchemical_compound%20p%3AP703%20%3Fstmt.%20%23%20We%20select%20chemical%20classes%20having%20the%20found%20in%20taxon%20statement%0A%20%20%20%20%3Fstmt%20ps%3AP703%20%3Fqueried_taxa.%20%23%20and%20the%20restrict%20the%20found%20in%20taxon%20statement%20to%20match%20our%20queried%20taxa%0A%20%20%20%20OPTIONAL%20%7B%0A%20%20%20%20%20%20%3Fstmt%20prov%3AwasDerivedFrom%20%3Fref.%0A%20%20%20%20%20%20%3Fref%20pr%3AP248%20%3Freference.%20%23%20We%20optionally%20return%20the%20reference%20if%20present%20stated%20in%0A%20%20%20%20%7D%0A%20%20%7D%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22%5BAUTO_LANGUAGE%5D%2Cen%22.%20%7D%0A%7D'\n\nThis doesnt work.\n\nAs Jo said\n\n\nBjonnh: ça marche ça\n\nBjonnh: faut juste urlencoder l'url de ta query (donc double encodage!)\n\nBjonnh: python fait ça facile\n\nBjonnh: et tu mets ça dans le paramètre url\n\nBjonnh: tout ça tu peux le faire en python avec requests et urlencode. Left as an exercise for you ;)\n\n","n":0.07}}},{"i":418,"$":{"0":{"v":"Microcosmics","n":1}}},{"i":419,"$":{"0":{"v":"Metabolomics","n":1}}},{"i":420,"$":{"0":{"v":"Soil","n":1},"1":{"v":"\n\n### Extraction \n\nhttps://sci-hub.se/10.1007/978-1-4939-8757-3_4\n\n\n","n":0.577}}},{"i":421,"$":{"0":{"v":"Strain","n":1},"1":{"v":"\n\nThe followoing strains have been identified through their 16RNA sequencing data.\n\n## Streptomyces lusitanus\n\nWD query for compounds https://w.wiki/BfHS\n\n30 compound isolated https://w.wiki/BfHK\n\n\n#wd \n\nMore info in the related note [[projects.commons-public.microcosmics.strains.Streptomyces lusitanus]]\n\n## Streptomyces xanthophaeus\n\n\n\nWD query for compounds https://w.wiki/BfHN\nhttps://scholia.toolforge.org/taxon/Q26293525#metabolome\n\n## Paecilomyces lilacinus\n\nWD query for compounds https://w.wiki/BfHT\nNot to be worked on.\nHuman pathogen.\n\n## 16S DNA sequences \n>S3\nAAGTCGAACGATGAACCACTTCGGTGGGGATTAGTGGCGAACGGGTGAGTAACACGTGGGCAATCTGCCCTGCACTCTGGGACAAGCCCTGGAAACGGGGTCTAATACCGGATACTGATCGCCTTGGGCATCCTTGGTGATCGAAAGCTCCGGCGGTGCAGGATGAGCCCGCGGCCTATCAGCTTGTTGGTGAGGTAATGGCTCACCAAGGCGACGACGGGTAGCCGGCCTGAGAGGGCGACCGGCCACACTGGGACTGAGACACGGCCCAGACTCCTACGGGAGGCAGCAGTGGGGAATATTGCACAATGGGCGAAAGCCTGATGCAGCGACGCCGCGTGAGGGATGACGGCCTTCGGGTTGTAAACCTCTTTCAGCAGGGAAGAAGCGAAAGTGACGGTACCTGCAGAAGAAGCGCCGGCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGGCGCGAGCGTTGTCCGGAATTATTGGGCGTAAAGAGCTCGTAGGCGGCTTGTCGCGTCGGTTGTGAAAGCCCGGGGCTTAACCCCGGGTCTGCAGTCGATACGGGCAGGCTAGAGTTCGGTAGGGGAGATCGGAATTCCTGGTGTAGCGGTGAAATGCGCAGATATCAGGAGGAACACCGGTGGCGAAGGCGGATCTCTGGGCCGATACTGACGCTGAGGAGCGAAAGCGTGGGGAGCGAACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACGGTGGGCACTAGGTGTGGGCGACATTCCACGTCGTCCGTGCCGCAGCTAACGCATTAAGTGCCCCGCCTGGGGAGTACGGCCGCAAGGCTAAAACTCAAAGGAATTGACGGGGGCCCGCACAAGCGGCGGAGCATGTGGCTTAATTCGACGCAACGCGAAGAACCTTACCAAGGCTTGACATACACCGGAAACGCCCGGAGATGGGCGCCCCTTGTGGTCGGAGTACAGGTGGTGCATGGCTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCGCAACGAGCGCACCCTTGTCCCGTGTTGCCAGCAGGCCCTTGGGGTGCTGGGAATCACGGGAGACCGCCGGGGTCAATCGGAGGAAGGGGGG\n>S6\nATGCAGTCGAACGATGAAGCCCTTCGGGGTGGATTAGTGGCGAACGGGTGAGTAACACGTGGGCAATCTGCCCTTCACTCTGGGACAAGCCCTGGAAACGGGGTCTAATACCGGATACCACTCCTGCCTGCATGGGCGGGGGTTGAAAGCTCCGGCGGTGAAGGATGAGCCCGCGGCCTATCAGCTTGTTGGTGGGGTAATGGCCCACCAAGGCGACGACGGGTAGCCGGCCTGAGAGGGCGACCGGCCACACTGGGACTGAGACACGGCCCAGACTCCTACGGGAGGCAGCAGTGGGGAATATTGCACAATGGGCGAAAGCCTGATGCAGCGACGCCGCGTGAGGGATGACGGCCTTCGGGTTGTAAACCTCTTTCAGCAGGGAAGAAGCGAAAGTGACGGTACCTGCAGAAGAAGCGCCGGCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGGCGCAAGCGTTGTCCGGAATTATTGGGCGTAAAGAGCTCGTAGGCGGCTTGTCACGTCGGATGTGAAAGCCCGAGGCTTAACCTCGGGTCTGCATTCGATACGGGCTAGCTAGAGTGTGGTAGGGGAGATCGGAATTCCTGGTGTAGCGGTGAAATGCGCAGATATCAGGAGGAACACCGGTGGCGAAGGCGGATCTCTGGGCCATTACTGACGCTGAGGAGCGAAAGCGTGGGGAGCGAACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACGTTGGGAACTAGGTGTTGGCGACATTCCACGTCGTCGGTGCCGCAGCTAACGCATTAAGTTCCCCGCCTGGGGAGTACGGCCGCAAGGCTAAAACTCAAAGGAATTGACGGGGGCCCGCACAAGCGGCGGAGCATGTGGCTTAATTCGACGCAACGCGAAGAACCTTACCAAGGCTTGACATATACCGGAAAGCATTAGAGATAGTGCCCCCCTTGTGGTCGGTATACAGGTGGTGCATGGCTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCGCAACGAGCGCAACCCTTGTCCTGTGTTGCCAGCATGCCCTTCGGGGTGATGGGGACTCACAGGAGACCGCCGGGGTCAACTCGGAGGAGGTGGGGACGACGTCAGTCATCATGCCCCTTAG\n## ITS Fungi sequences \n>CH6\nAGCGGAGGGATCATTACCGAGTTATACAACTCCCAAACCCACTGTGAACCTTACCTCAGTTGCCTCGGCGGGAACGCCCCGGCCGCCTGCCCCCGCGCCGGCGCCGGACCCAGGCGCCCGCCGCAGGGACCCCAAACTCTCTTGCATTACGCCCAGCGGGCGGAATTTCTTCTCTGAGTTGCACAAGCAAAAACAAATGAATCAAAACTTTCAACAACGGATCTCTTGGTTCTGGCATCGATGAAGAACGCAGCGAAATGCGATAAGTAATGTGAATTGCAGAATTCAGTGAATCATCGAATCTTTGAACGCACATTGCGCCCGCCAGCATTCTGGCGGGCATGCCTGTTCGAGCGTCATTTCAACCCTCGAGCCCCCCCCGGGGGCCTCGGTGTTGGGGGACGGCACACCAGCCGCCCCCGAAATGCAGTGGCGACCCCGCCGCAGCCTCCCCTGCGTAGTAGCACACACCTCGCACCGGAGCGCGGAGGCGGTCACGCCGTAAAACGCCCAACTTTCTTAGAGTTGACCTCGGATCAGGTAGGAATACCCGCTGAACTTAAGCATATCAATAAGCGGAGGAA\n\n\n##  DNA Protocol extraction \nPCR PROTOCOL FOR Actinomycetes\nDNA extraction (heat shock method):\n1.\tTake bacterial mycelium in a clean 1.5 mL Eppendorf tube.\n2.\tGrind the cells using a clean tip and suspend them thoroughly in 1 mL of distilled water. \n3.\tHeat the samples at 95°C in the heating block for 20 min.\n4.\tTransfer the tube (suddenly) to ice for 10 min. \n5.\tRe-heat the sample in the heating block at 95°C for 10 min.\n6.\tStore DNA at -20°C.\n\n16S rDNA Primers:\n•\t27F and 1492R\n27F: 5’-AGAGTTTGATCCTGGCTCAG-3’\n1492R: 5’-CGGTTACCTTGTTACGACTT-3’\n(A)\t PCR amplification in 25 μl of reaction (Accustart II):\n•\t5 μL of genomic DNA \n•\t0.5 μL of primer F (25 μM)\n•\t0.5 μL of primer R (25 μM)\n•\t12.5 μL of Accustart II PCR toughmix (2x)\n•\t0.5 μL of gel track loading Dye (50X)\n•\t6 μL of water\n\n(B)\tPCR amplification in 25 μl of reaction (Solifast):\n•\t5 μL of genomic DNA\n•\t0.5 μL of primer F (25 μM)\n•\t0.5 μL of primer R (25 μM)\n•\t5 μL of Solifast (5x)\n•\t14 μL of water\n\nAmplification conditions: \n•\tInitial denaturation at 94°C for 3 min\n•\tFollowed by 35 cycles of\n1.\ta denaturation step at 94°C for 30 s,\n2.\tan annealing step at 56°C for 30 s, and\n3.\tan extension step at 72°C for 1 min 40 s,\n•\tFollowed by a final extension step at 72°C for 10 min.\n\nGel electrophoresis:\n1.\tPrepare 1% agarose: 1g agarose in 100 mL of 1X TAE buffer (40 mol/L Tris-acetate, and 1 mM EDTA, pH 8.0). (0.6 g in 60 mL for small trays)\n2.\tStain the gel with 6 μl of GreenSafe solution (3 for 60 mL).\n3.\tImmerse the gel in 1X TAE (pH 8.0) buffer.\n4.\tLoad the prepared PCR products into the wells. \n5.\t Use a 1 Kbp-DNA ladder as a molecular weight marker. \n6.\tPass 100 volts of electric current through the gel for 30 min.\n7.\tRemove and visualize the gel, in a Trans illumination cabinet.\n8.\tCapture the image using a gel documentation system. \n\n•\tAppearance of the target band specified for the primer set on the agarose gel is considered as a positive amplification product.\n\n\n\n## Strains picture \nCH6\n![alt text](photo_57@22-10-2024_09-06-59_thumb.jpg)\n![alt text](photo_92@22-10-2024_09-13-16_thumb.jpg)\n![alt text](photo_71@22-10-2024_09-07-00_thumb.jpg)\n\nS3\n\n![alt text](photo_97@22-10-2024_09-13-17_thumb.jpg)\n\nS6\n![alt text](photo_53@22-10-2024_09-06-59.jpg)\n\nCH4\n![alt text](photo_86@22-10-2024_09-13-09_thumb.jpg)\n![alt text](photo_63@22-10-2024_09-07-00_thumb.jpg)\n![alt text](photo_108@22-10-2024_09-13-17.jpg)\nV1\n![alt text](photo_59@22-10-2024_09-06-59_thumb.jpg)\n\n\n## To do next week\n1- Saturday culture bacteria \n1- run LC-MS for vials soil \n2- ITS extraction of CH4, CH2, V1\n## Saturday \nCulture CH2 and CH4 \n## Fungal DNA extraction protocol without kit \n* Protocol 1\nAll fungal isolates were treated with 70% ethanol and heat inactivated (100°C for 30 min). A bead beating step was added to assist with mechanical lysis of the fungal cell wall. A viability study showed that these steps resulted in no growth of a variety of diverse clinically relevant fungi, including both yeasts and molds (Supplemental Table S2). For all samples, the Qiagen (Valencia, CA, USA) EZ1 Blood and Tissue Kit as well as the EZ1 Advanced XL instrument were used (following manufacturer’s instructions) to extract genomic DNA from fungal isolates. Post extraction, DNA was quantified using Qubit 1× double-stranded DNA HS assay with the Qubit 3.0 Fluorometer (Thermo Fisher Scientific, Waltham, MA, USA). DNA quantities greater than 0.04 ng/µL were considered acceptable. PCR grade water was used as a negative extraction and sequencing control. A reference strain of Candida tropicalis (CDC AR Bank 3045) was used as a sequencing positive control for each run [ doi: 10.3390/jof9020183]. \nJe résume:\n1. Inactivation des isolats : Tous les isolats fongiques ont été traités avec de l'éthanol à 70 % et chauffés à 100°C pendant 30 minutes pour être inactivés. Ce traitement par la chaleur et l'alcool élimine la viabilité des champignons, empêchant leur croissance, ce qui est confirmé par une étude montrant l'absence de croissance après ces étapes, même pour des champignons cliniquement importants (levures et moisissures).\n\n2. Lyse mécanique : Une étape de broyage avec des billes (\"bead beating\") est ajoutée pour aider à briser la paroi cellulaire des champignons, qui est très résistante. Cette étape facilite la libération de l'ADN contenu à l'intérieur des cellules fongiques.\n\n3. Extraction de l'ADN : Le kit Qiagen EZ1 Blood and Tissue et l’instrument EZ1 Advanced XL ont été utilisés pour extraire l'ADN génomique des isolats, en suivant les instructions du fabricant.\n\n4. Quantification de l'ADN : Après l'extraction, la quantité d'ADN est mesurée avec le test Qubit 1× double-brin d’ADN HS et le fluoromètre Qubit 3.0. Seules les quantités supérieures à 0,04 ng/µL sont considérées comme acceptables pour les analyses suivantes.\n\n5.Contrôles de qualité : De l'eau de qualité PCR est utilisée comme contrôle négatif pour s'assurer qu'aucune contamination n'est introduite pendant l'extraction et le séquençage. Une souche de référence de Candida tropicalis (CDC AR Bank 3045) sert de contrôle positif pour vérifier la qualité et la précision de chaque séquençage.\n\n\n## Culture V1 in TSB for tomorrow \n\n## Sequencing platforme \nLes plateformes de séquençage Illumina HiSeq, PacBio Sequel II, et Nanopore PromethION sont des technologies avancées utilisées pour le séquençage de l'ADN, mais elles se différencient en termes de méthode de séquençage, de précision, de longueur de lecture, et de coût. Voici un aperçu de chaque plateforme :\n1. Illumina HiSeq Platform\nTechnologie de Séquençage : Illumina utilise une méthode de \"séquençage par synthèse\". Les brins d'ADN sont fragmentés et chaque fragment est amplifié pour former des clusters. Lors du séquençage, des bases fluorescentes sont ajoutées une à une, et chaque fluorescence est capturée par une caméra.\nLongueur de Lecture : Cette plateforme produit généralement des lectures de courte longueur (entre 50 et 300 paires de bases par lecture).\nAvantages : Haute précision et faible taux d'erreur, adaptée aux projets nécessitant une couverture profonde, comme l'exome ou le génome complet.\nInconvénients : Longueur de lecture limitée, donc moins adaptée à l'assemblage de génomes complexes et à la détection de certaines variations structurelles.\n2. PacBio Sequel II Platform\nTechnologie de Séquençage : Utilise la technologie de séquençage par observation directe d'une enzyme polymérase, appelée SMRT (Single Molecule, Real-Time sequencing). L'ADN n'est pas amplifié ; la plateforme lit directement les longues molécules d'ADN.\nLongueur de Lecture : Produits de très longues lectures (jusqu'à 100 000 bases), avec une longueur moyenne d’environ 10 000-30 000 bases.\nAvantages : Adaptée aux séquences complexes et aux longues répétitions, idéale pour l’assemblage de novo de génomes et pour détecter des variations structurelles.\nInconvénients : Coût élevé par rapport aux plateformes Illumina, avec un taux d’erreur plus élevé, même s'il est réduit avec les lectures corrigées par consensus.\n3. Nanopore PromethION Platform\nTechnologie de Séquençage : La technologie de Nanopore permet de séquencer en temps réel en faisant passer une molécule d'ADN à travers un nanopore et en mesurant les changements de courant électrique pour identifier les bases.\nLongueur de Lecture : Elle peut produire des lectures extrêmement longues, dépassant plusieurs centaines de milliers de bases.\nAvantages : Longueur de lecture quasiment illimitée et rapidité de séquençage en temps réel. Elle est portable et peut être utilisée pour des séquençages directement sur le terrain.\nInconvénients : Taux d'erreur plus élevé que les autres plateformes, bien que les taux d’erreur aient diminué avec les améliorations technologiques.\nEn résumé, le choix de la plateforme dépendra du type de projet de séquençage : Illumina pour les projets nécessitant une haute précision et une profondeur de couverture, PacBio pour des lectures longues et une bonne résolution des régions répétées, et Nanopore pour les lectures ultra-longues et les séquençages rapides en temps réel.\n## \n\n## Lab work today \nDNA extraction of CH2 and CH6, both liquid and solide culture \nculture V1 from the stock to avoid contamination \n## To do this week \nStorage all active strains in glycerol 70% at -80°C.\n## claen your samples \n## Today 30-11-2024\nDNA extraction and purification of CH2, CH4 and V1 \nResults\nPCR Does'n work for CH4 and V1 i have to redo extraction!\n## Tomorrow 31-10-24\nstorage of all strains \nredo DNA isolation of CH4 solide and liquid media \n### Summary of the Week (10-26-2024)\n\nI cultivated the remaining strains CH2, CH4, and V1, and performed a DNA extraction. \nI successfully obtained the sequence for CH2 only. V1's DNA appeared fragmented on the agarose gel. \nCH4 showed no detectable DNA, likely due to its very rigid cell wall, which may have hindered the extraction process.\nNext week i will try other protocol for DNA extraction according to Floriane sugestions \n\n## CH2 seq \nthe seq was very clean means my culture is pure \nCH2\n>TCATTACAGAGTTGCAAAACTCCCCAAACCATCGTGAACGCTACCTAAACCGTTGCTTCGGCGGGCGGCGCCCTCGCGCGCCCCCCTGGGCCCGCACCGCGGGCGCCCGCCGGAGGTACACCAAACTCTTGATATGTCATGGCCACTCTGAGTCTTCTATACTGAATAAGTCAAAACTTTCAACAACGGATCTCTTGGTTCTGGCATCGATGAAGAACGCAGCGAAATGCGATAAGTAATGTGAATTGCAGAATTCAGTGAATCATCGAATCTTTGAACGCACATTGCGCCCGCCAGGATAGTATCCTGGCGGGCATGCCTGTTCGAGCGTCATTTCAACCCATCAAGCCCACGGCTTGTGTTGGGGACCTGCGGCTGCCCGCAGGCCCTGAAAACCAGTGGCGGGCTCGCTAGTCACACCGAGCGTAGTAGCATACGACCTCGCTCAGGGCGTGCTGCGGGTTCCAGCCGTAAAACGACCTTCGCGACCCCAAGGTTGACCTCGGATCAGGTAGGAGGACCCGCTGAACTTAAGCATATCAATAAGCGGAGGAA\n#NCBI BLAST\n![alt text](image-1.png)\n\nThermothelomyces guttulatus \n\nWD query for compounds https://w.wiki/Bnes\n\n## Monday \nDNA extraction of CH4 and V1 \n## active strains storage \nI stored all the active strains in 70% glycerol, each strain has 4 copies, and the tudes are at -80°C.\n![alt text](<conserved strains.jpg>)\n\n## today's review (04-11-2024)\nFinaly i get bands for V1 and CH4 isolates \nsend for sequencing \nall strains stored at -80°C.\n## Tommorow 02-11-2024\nwrite on my lab note book\nwait for results sequences.\nclean cutures wastes\nanalyses ITS seq of CH4 and 16S for V1. \n\n## We have sent the sequences of V1 and CH4 to sequencing, the results are not reliable, to be reextract. \nresults recieved 05-11-2024\nCH4\nCATTACCGAKTGCGGGCTGCCTCCGGGCGCCCAACCTCCCWCCCGTGACTACCTAACACTGTTGCTTCRGCGGGGAGCCCCCCAGGGGGCGAGCCGCCGGGGACCACTGAACTTCATGCCTGASAGKGATGCAGWCTGASCCTGAATACAAATCAGTCAAAACTTTCAACAATGGATCTCTTGGTTCCGGCATCRATGAAGAACGCAGCGAACTGC\n\nL'intensité du signal de votre réaction de séquençage est très faible. Par conséquent, le résultat de votre séquençage doit être soigneusement évalué.\nRésultat de séquençage modéré ou ambigu. Veuillez vérifier l'état de votre réaction, qui sera mise à jour dans la zone de téléchargement dans le courant de la matinée (jours ouvrables uniquement).\nEconomy Run (Tube)\n13787654 94799985\nV1\nNNNNN\n\n##  Today 06-11-2024\n-DNA extraction of CH4 AND V1\n## Tomorrow 07-11-2024\nPCR, agarose gel and purification.\n## Reviev's 07-11-2024\n\n\n\n\n\n\n\n","n":0.025}}},{"i":422,"$":{"0":{"v":"Streptomyces lusitanus","n":0.707},"1":{"v":"WD query for compounds https://w.wiki/BfHS\n\n\n","n":0.447}}},{"i":423,"$":{"0":{"v":"Rima","n":1}}},{"i":424,"$":{"0":{"v":"Test","n":1},"1":{"v":"\n\ntest rima \n\n# titre\n\n## sous titre \nfdjhfdjhfhd\n\n\n\n- shgdhgs\n- dshgdsgd\n- dshdshd\n\n*dddhsgd*\n**ddsd**\n## resume","n":0.302}}},{"i":425,"$":{"0":{"v":"Ressources","n":1},"1":{"v":"\nRima proposed some ideas to think about https://docs.google.com/document/d/1Sub8ccgML1JCPGMOg2srQmUXQMBdrnj5/edit\n\n\nTuesday 19 September 2023\n\nBriefly discussed the topic with Laure Weisskopf.\nShe recommended that we look for Biolog plates https://www.biolog.com/\n\nWe should get in touch with the persons having worked on soils in the botaniucal gardem\n\n\nhttps://www.unifr.ch/jardin-botanique/fr/assets/public/files/publications/BotaBota_brochure_Sols_WEB.pdf\n\n\n\nMicrocosm facility\n\nhttps://www.thuenen.de/en/institutes/climate-smart-agriculture/laboratory-department/microcosm-facility\n\n\n\n","n":0.156}}},{"i":426,"$":{"0":{"v":"Meetings","n":1},"1":{"v":"\n\n# Tuesday 26 September 2023\n\n\n### Thursday 19 September 2024\n\n#### Assembled and annotated genomes\n\n- Avec qui peut on faire du génome complet de 2 champi, 3 actinos 1 bacterie.\nLaurent Falquet.\n\nhttps://www.ngs.unibe.ch/about_us/contact/\n\nPamel Nicolson\n\n\n#### Metabolomics\n\n\n\n#### Paired omics platform \n\nhttps://pairedomicsdata.bioinformatics.nl/\n\n\n20231131_PMA_RO_01_15_01_HM.mzML\n20231131_PMA_RO_01_15_02_HM.mzML\n20231131_PMA_RO_01_15_03_HM.mzML\n20231131_PMA_RO_01_15_04_HM.mzML\n20231131_PMA_RO_01_15_05_HM.mzML\n20231131_PMA_RO_01_15_06_HM.mzML\n20231131_PMA_RO_01_15_07_HM.mzML\n20231131_PMA_RO_01_15_08_HM.mzML\n20231131_PMA_RO_01_15_09_HM.mzML\n20231131_PMA_RO_01_15_10_HM.mzML\n20231131_PMA_RO_01_15_11_HM.mzML\n20231131_PMA_RO_01_15_12_HM.mzML\n20231131_PMA_RO_01_15_13_HM.mzML\n20231131_PMA_RO_01_15_14_HM.mzML\n20231131_PMA_RO_01_15_15_HM.mzML\n20231131_PMA_RO_01_15_16_HM.mzML\n20231131_PMA_RO_01_15_17_HM.mzML\n20231131_PMA_RO_01_15_18_HM.mzML\n20231131_PMA_RO_01_15_19_HM.mzML\n20231131_PMA_RO_01_15_20_HM.mzML\n20231131_PMA_RO_01_15_21_HM.mzML\n20231131_PMA_RO_01_15_22_HM.mzML\n20231131_PMA_RO_01_15_23_HM.mzML\n20231131_PMA_RO_01_15_24_HM.mzML\n20231131_PMA_RO_01_15_25_HM.mzML\n20231131_PMA_RO_01_15_26_HM.mzML\n20231131_PMA_RO_01_15_27_HM.mzML\n20231131_PMA_mapp_post_00_HM.mzML\n20231131_PMA_mapp_pre_00_HM.mzML\n20231131_PMA_mapp_pre_01_HM.mzML","n":0.169}}},{"i":427,"$":{"0":{"v":"Historic","n":1},"1":{"v":"\nThis project was submitted two times (unsucessfully to the Gebert Ruft Stiftuing Microbiall Calls for project). In 2016 and 2017.\nHere is the submitted proposal https://drive.google.com/file/d/1XTwGtdrprWFst1pUwxTs6pu6zXEjhDNP/view?usp=drive_link\n\n","n":0.2}}},{"i":428,"$":{"0":{"v":"Experimental Design","n":0.707},"1":{"v":"\n\n# Litterature\n\n","n":0.707}}},{"i":429,"$":{"0":{"v":"Hplc Matrix Tubes Transition","n":0.5}}},{"i":430,"$":{"0":{"v":"Anticipated Lotus","n":0.707}}},{"i":431,"$":{"0":{"v":"Model","n":1},"1":{"v":"\n# ATTENTION\nPlease look at the [following link](https://commons-research.github.io/common_dws_public_storage/anticipated_lotus/thesis/main.pdf) for the full models. \n\nSeveral models have been tested. ","n":0.25}}},{"i":432,"$":{"0":{"v":"Explore","n":1},"1":{"v":"\n\nDiscussed in group meeting today.\n\nMaybe explore MCS (Maximum Common Substructure) to establish a tress of the LOTUS structural set.\n\nSome refs\n\nhttps://www.mdpi.com/2079-3197/8/2/48\n\nhttps://pubs.acs.org/doi/full/10.1021/acs.jcim.0c00741\n\nhttps://chemistry-europe.onlinelibrary.wiley.com/doi/full/10.1002/cmdc.201700482\n\nVery likely Luca should have some ideas on this and this is a subgraph search problemeatic. \n\nWould offer the advantage over and complement classical chemical classifiers as we would have a chemical structures associated with higher taxonomomical levels.\n\n\nrBAN: retro-biosynthetic analysis of nonribosomal peptides\nhttps://jcheminf.biomedcentral.com/articles/10.1186/s13321-019-0335-XXXX\n\nIn silico methods for linking genes and secondary metabolites: The way forward\nhttps://www.sciencedirect.com/science/article/pii/S2405805X1530020X\n\n\nDeep learning driven biosynthetic pathways navigation for natural products with BioNavi-NP\nhttps://www.nature.com/articles/s41467-022-30970-9\n\nhttp://biopathnavi.qmclab.com/\nhttps://github.com/prokia/BioNavi-NP\n\n\nhttps://retrorules.org/\nhttps://retrorules.org/diy\n\nEnumerating all possible biosynthetic pathways in metabolic networks\nhttps://www.nature.com/articles/s41598-018-28007-7\n\n\nhttps://edepot.wur.nl/469860\n\nA computational workflow for the expansion of heterologous biosynthetic pathways to natural product derivatives\nhttps://www.nature.com/articles/s41467-021-22022-5\n\nExpanding biochemical knowledge and illuminating metabolic dark matter with ATLASx\nhttps://www.nature.com/articles/s41467-022-29238-z#MOESM1\n\nExploring Chemical Biosynthetic Design Space with Transform-MinER\nhttps://doi.org/10.1021/acssynbio.9b00105\n\nA pathway for every product? Tools to discover and design plant metabolism\nhttps://doi.org/10.1016/j.plantsci.2018.03.025\n\n\nEfficient Enumeration of Branched Novel Biochemical Pathways Using a Probabilistic Technique\nhttps://doi.org/10.1021/acs.iecr.1c02211\n\n\nhttps://github.com/SeulLee05/READRetro?tab=readme-ov-file","n":0.085}}},{"i":433,"$":{"0":{"v":"Help","n":1},"1":{"v":"\nhttps://himalayanhelp.com/\n\nhttps://en.wikipedia.org/wiki/Manaslu_Conservation_Area\n\nhttps://ca.tealeaves.com/\n\n\nJardin Botanique de Katmandou\n\nMCAP\nManaslu Conservation Area Project\n\nNTNC \nNational Trust for Nature Conservation","n":0.289}}},{"i":434,"$":{"0":{"v":"People","n":1}}},{"i":435,"$":{"0":{"v":"Ted Nelson","n":0.707},"1":{"v":"\nhttp://www.thetednelson.com/index.php\n\n# Ted Nelson\n\nTed Nelson is a pioneer in the field of computer science and information technology, best known for coining the terms \"hypertext\" and \"hypermedia.\" He envisioned a global information system that would allow users to easily navigate and link documents in a non-linear fashion, which laid the groundwork for the development of the World Wide Web.","n":0.132}}},{"i":436,"$":{"0":{"v":"Meetings","n":1}}},{"i":437,"$":{"0":{"v":"Group Meetings","n":0.707}}},{"i":438,"$":{"0":{"v":"2024","n":1}}},{"i":439,"$":{"0":{"v":"03","n":1}}},{"i":440,"$":{"0":{"v":"28","n":1},"1":{"v":"\n\n# Present\n\n\n- Edouard\n- Heloise\n- Marco\n- Colin\n- Pascal\n\n\n# Colin\n\n\n- established a list of standards for the MAPP platform\n\n- How do we store sample ?\n- Moved to 9x9 boxes\n\nCoordinate with Edouard on the best way to \n- Noni sample for analysis to be treated \n\n- Legal disclaimer is done \n\n# Edouard\n\nLast week. \nDirectus update, running on a docker.\n\nLast directus version. \n/docker \n\nDocker is automatically restarted\n\nhttp://directus.dbgi.org\n\nNocodb is also running on the same server docker \nFor MAPP \n\nPG is version each 2 hours (for 48h) + weekly backup.\n\n- Mass Spectrometry manager \n- iNat-fetcher (takes info from iNat to Directus)\ndidnt link it back to the lab part of the\n\nNocoDB.\n\nhttps://www.inaturalist.org/observations/153546334\n\nExample of a wrongly tagged observation\nThe user is no longer part opf the lab ...\n\n\n\n\n\n# Heloise\n\n- Collected entire Greenhouse\n- Doing extraction (half done)\n- Personal project, checked with FIBL for the long term experiment\n\nCall Hans. When ? \n\nProblem with iNat.\n\nNext week absent. \n\n# Marco\n\nTwo week \nFinding a chemical classifier \nNPClassifier and Classyfire.\n\nQuite bad.\nMCCS\n\n\n\n- Irreproducibility of the results\n\npythonChebiAI\n\nLinking molecule through chemical similarity \n\nMonorepo\n\n# Pascal\n\n4 week ago with the dataset extractor\n\n- MINE dataset extractor\n\nReading about MongoDB \nNoSQL database using JSON string \n\n\nDoctring\nMKDocs build from the readme\n\n\n\n\n\n\n\n","n":0.073}}},{"i":441,"$":{"0":{"v":"2023","n":1}}},{"i":442,"$":{"0":{"v":"03","n":1}}},{"i":443,"$":{"0":{"v":"09","n":1},"1":{"v":"\n\n# Group meeting 2023.03.09\n\nPresent : \n\n- Lëndita\n- Maëlle \n- Marco\n- PM\n- Stéphanie\n\n# Program\n\nShort (from 10 - 20 min) presentation of everybody's project with some background\n\n- Maëlle \n- Marco\n- Lëndita\n- Stéphanie\n\n# Notes \n\n## Marco\nTold us :\n> never say that the probability is one !\n\n## Lëndita\n\n- Switch from the \"cutting\" pilot to testing the effects of repeated freeze-drying cycle.\n- Take Datawarrior to explore the https://github.com/digital-botanical-gardens-initiative/taxonomical-preparator/blob/main/data/out/species_list_croisee_final.csv \nThis can be used for preparing plots (e.g. what is the taxonomical composition of the Serre 1 ?)\n\n## PM\n\nChecked with everybody and Wednesday mornings should be OK.\n\n\n\nCheck prices of : \n\n- lyophilisator\n- 1mg precision scale\n\n\n","n":0.101}}},{"i":444,"$":{"0":{"v":"Research Seminars","n":0.707},"1":{"v":"\n\n# Tuesday 29 April 2025\n\nhttps://mbu.cas.cz/employee/zdenek-kamenik\n\nhttps://mbu.cas.cz/en/research/laboratory-of-antibiotic-resistance-and-microbial-metabolomics/research/cluseek\n\n\nLucentamycin A https://www.wikidata.org/wiki/Q104937391\n\n\n\nLucentamycin\n\n#  Thursday 07 March 2024\n\n\nNatacha Bodenhausen (https://scholia.toolforge.org/author/Q81408765)\n\nImprooving arbuscular mycorrhizal fungi inoculation success with microbiomes diagnostics\n\nFIBL is the Swiss Research Institute of Organic Agriculture\n\nForshungsinstitut für biologischen Landbau\n\nhttps://www.fibl.org/en\n\n\nInoculation with AMF (arbuscular mycorrhizal fungi).\n\nPhylum [Glomeromycota](https://en.wikipedia.org/wiki/Glomeromycota \"Glomeromycota \\(often referred to as glomeromycetes, as they include only one class, Glomeromycetes\\) are one of eight currently recognized divisions within the kingdom Fungi, with approximately 230 described species. Members of the Glomeromycota form arbuscular mycorrhizas \\(AMs\\) with the thalli of bryophytes and the roots of vascular land plants. Not all species have been shown to form AMs, and one, Geosiphon pyriformis, is known not to do so. Instead, it forms an endocytobiotic association with Nostoc cyanobacteria. The majority of evidence shows that the Glomeromycota are dependent on land plants \\(Nostoc in the case of Geosiphon\\) for carbon and energy, but there is recent circumstantial evidence that some species may be able to lead an independent existence. The arbuscular mycorrhizal species are terrestrial and widely distributed in soils worldwide where they form symbioses with the roots of the majority of plant species \\(&gt;80%\\). They can also be found in wetlands, including salt-marshes, and associated with epiphytic plants.\nAccording to multigene phylogenetic analyses, this taxon is located as a member of the phylum Mucoromycota. Currently, the phylum name Glomeromycota is invalid, and the subphylum Glomeromycotina should be used to describe this taxon.\")\n\nhttps://scholia.toolforge.org/taxon/Q753723\n\nhttps://scholia.toolforge.org/taxon/Q753723#metabolome\n\n\nNatacha's idea is to devlopp an app able to anticipate the success of the inoculation of AMF in the soil based on soil analysis reports (mandatory each 10 years in Switzerland).\n\n\"Forward biogeography\". \n\nSoil microbiome indicators can predict crop growth response to large-scale inoculation with arbuscular mycorrhizal fungi\nhttps://doi.org/10.1038/s41564-023-01520-w\n\n\n\n\n\n\n#  Thursday 29 February 2024\n\nKohpeno\n\n[Strigolactone](https://en.wikipedia.org/wiki/Strigolactone \"Strigolactones are a group of chemical compounds produced by roots of plants. Due to their mechanism of action, these molecules have been classified as plant hormones or phytohormones. So far, strigolactones have been identified to be responsible for three different physiological processes: First, they promote the germination of parasitic organisms that grow in the host plant's roots, such as Striga lutea and other plants of the genus Striga. Second, strigolactones are fundamental for the recognition of the plant by symbiotic fungi, especially arbuscular mycorrhizal fungi, because they establish a mutualistic association with these plants, and provide phosphate and other soil nutrients. Third, strigolactones have been identified as branching inhibition hormones in plants; when present, these compounds prevent excess bud growing in stem terminals, stopping the branching mechanism in plants.\nStrigolactones comprise a diverse group, but they all have core common chemical structure, as shown in the image to the right. The structure is based on a tricyclic lactone linked to a hydroxymethyl butenolide; the former is represented in the figure as the A-B-C part, while the latter is the D part of the molecule. It is important to note that most strigolactones present variations in the ABC part, but the D ring is quite constant across the different species, which led researchers to suspect that the biological activity relies on this part of the molecule. Different studies have demonstrated that the activity of the molecules is lost when the C-D section of the molecules is modified.Since strigolactones are involved in the signaling pathway required for germination of parasitic species \\(such as Striga sp.\\), they have been a proposed target to control pests and overgrowth of these parasitic organism. Using a molecule similar to strigolactones could be the key to designing a chemical and biological mechanism to stop the colonization of a plant's root by parasitic plants.\")\n\nInduce hyphal branching in AM fungi.\n\nNepoli experiment :\n\n- graft of WT and dad1 mutant plants. Shows the direction of strigolactone transport (from root to shoot).\n\nXylem has some living tissues called xylem parenchyma. They are involved in the transport of water and nutrients.\n\n[Karrikin](https://en.wikipedia.org/wiki/Karrikin \"Karrikins are a group of plant growth regulators found in the smoke of burning plant material. Karrikins help stimulate seed germination and plant development because they mimic a signaling hormone known as strigolactone. Strigolactones are hormones that help increase growth of symbiotic arbuscular mycorrhizal fungi in the soil, which enhances plant growth and leads to an increase in plant branching.Smoke from wildfires or bushfires has been known for a long time to stimulate the germination of seeds. In 2004, the butenolide karrikinolide \\(KAR1\\) was shown to be responsible for this effect. Later, several closely related compounds were discovered in smoke, and are collectively known as karrikins.\") \n\n\n\n\n# Thursday 02 November 2023\n\n\nthan Nguyen\n\nTrait evolution\n\nnode support value\n\n\nWhite noise model https://timeseriesreasoning.com/contents/white-noise-model/#:~:text=White%20noise%20are%20variations%20in,explained%20by%20any%20regression%20model.&text=The%20observed%20value%20Y_i%20at,N_i%20around%20the%20current%20level.\n\n\nAlison Bender\n\nHoneypots ants\n\n[Myrmecocystus mexicanus](https://en.wikipedia.org/wiki/Myrmecocystus_mexicanus \"Myrmecocystus mexicanus is a species of ant in the genus Myrmecocystus, which is one of the six genera that bear the common name \"honey ant\" or \"honeypot ant\", due to curious behavior where some of the workers will swell with liquid food until they become immobile and hang from the ceilings of nest chambers, acting as living food storage for the colony.   Honey ants are found in North America, Australia, and Africa. Ant species belonging to the genus Myrmecocystus reside in North America.  M. mexicanus in particular is found in the southwestern United States and parts of Mexico.\")\n\n\n[Myrmecocystus](https://en.wikipedia.org/wiki/Myrmecocystus \"Myrmecocystus is a North American genus of ants in the subfamily Formicinae. It is one of five genera that includes honeypot ants. Worker ants keep and tend plerergates, which are other ants that store large quantities of nutritious fluid in their abdomens to feed the colony during famine times. Some species engage in highly territorial tournaments, which can result in intraspecific slavery. During the raids, they carry off larvae, workers, and plerergates.\")\n\nLily Khadempour\n\nHoneypot Ant Consortium\n\n\nhttps://www.mdpi.com/1420-3049/27/7/2154\n\nhttps://ielc.libguides.com/sdzg/factsheets/honeypot-ant\n\n\n","n":0.033}}},{"i":445,"$":{"0":{"v":"Matchms","n":1}}},{"i":446,"$":{"0":{"v":"Workshop","n":1},"1":{"v":"\n\nMatchMS workshop.\n\n## Approximate neirest neighbours\n\nRoman Bushuiev \nhttps://www.uochb.cz/en/directory/1019/roman-bushuiev\n\nhttps://florian-huber.github.io/python-introduction-eng/lesson_material_english/cover.html\n\n### Filtering\n\nMetadata filters\n\nEach filter clone the spectra.\n\n\nhttps://usegalaxy.eu/\n\nTheir is a way to fetch GBIF species occurences there !\n\nHere are the recipees for matchms proposed by Helge\n\nhttps://github.com/RECETOX/galaxytools\n\nhttps://bio.tools/\n\nhttps://edamontology.org/page","n":0.18}}},{"i":447,"$":{"0":{"v":"Fundings","n":1}}},{"i":448,"$":{"0":{"v":"Wemakeit","n":1},"1":{"v":"\n\nWe have been very deceived wioth MArco to findo out at the end of the submission of our proposal on experimenet.com that they only funded US/UK based project\n\n![](/assets/images/2024-03-26-11-52-16.png)\n\n\nCan I launch a project outside of the United States?\nWe currently support projects that wish to receive their funds to a bank account in the United States, Canada, United Kingdom, and Australia. If you are conducting your research in another country, but have a bank account in one of our supported countries, you are eligible.\n\nWe intend to support researchers regardless of their bank account currency, but we are not there yet.\n\n\n\n\n\n\nWe transition to https://wemakeit.com/channels/science\n\n\n","n":0.1}}},{"i":449,"$":{"0":{"v":"Experiment","n":1}}},{"i":450,"$":{"0":{"v":"Mvisani","n":1},"1":{"v":"\n# Google doc link\nhttps://docs.google.com/document/d/1M2tU1GmtFWkD05RSsxgKfchrQRhUnmf_q77IV8wyBMk/edit\n\n# experiment.com\nExperiment is a platform for funding scientific discoveries.\n\nIt is an all-or-nothing funding platform. This means the project must reach the funding target, or no one's pledges are charged.\n\n# Title\nHere are some ideas for the title of the project:\n- Predicting the molecules of life with AI\n- Predicting the molecules of Earth\n- Where are our best medicines ? \n- Predicting the chemistry of life\n- Can AI help us predict the chemistry of life ? \n- Predicting the molecules of life\n\n# Ressources\nhttps://www.earthspecies.org/\nhttps://experiment.com/projects/jvqjplzolhyncosrbpob?s=discover\n\n\n# Draft \n\n## About This Project\n\nThe Earth Metabolome Initiative aims to identify and protect the chemistry of Life. The largely unexplored metabolic diversity, which is rapidly disappearing due to species extinction, is vital for human health and nutrition. In order to uncover and protect this essential natural resource, this initiative has launched a worldwide sampling and digitization project that will encourage cooperation. Our goals include protecting biodiversity, advancing life sciences, and assisting human society by developing sustainable solutions through the creation of an open, accessible, and interoperable Earth Metabolome Knowledge Base and faster global metabolome discovery.\n\n\n## What is the context of this research?\nThe Earth's metabolic diversity, fundamental to biosphere processes, faces an alarming decline as species disappear. The Earth Metabolome Initiative responds to this crisis with a collaborative, global effort to sample and digitize this diversity, creating resources and technologies for accelerated metabolome discovery.\n\n## What is the significance of this project?\n1. Advance Life Sciences: Systematically expand knowledge on global chemodiversity, placing it in the context of biosphere processes and functions. This contributes to the advancement of life sciences and a deeper understanding of the intricate relationships within ecosystems.\n\n2. Benefit Human Society: Develop novel, sustainable solutions in agriculture, medicine, and other fields by connecting metabolites with their roles in living systems. This effort aims to improve human well-being and address societal challenges through the application of metabolome knowledge.\n\n3. Protect Biodiversity: Provide critical information for monitoring, develop novel metrics, and inform predictive tools to prioritize protection and incentivize conservation. The Earth Metabolome Knowledge Base becomes a valuable resource for safeguarding biodiversity and guiding conservation efforts.\n\n## What are the goals of the project?\nIn an effort to accelerate the discovery of metabolites, we are actively working on the development of a machine learning model capable of anticipating metabolite occurrences across various species. Our objective is to use the data that the LOTUS database offers, to forecast metabolite occurrences in species that have not yet undergone detailed examination. This approach would enable us to strategically prioritize species for sampling and digitization, ultimately pinpointing the most promising candidates for uncovering novel metabolites.\n\nTo bring this vision to fruition, we have hired Marco Visani as a Junior Bioinformatician. Marco's role involves crafting an algorithm that integrates historical data from LOTUS and untargeted metabolomics analyses to perform sensitive predictions of the occurences of metabolites in species. Should the project be fully funded, we plan to extend Marco's contract by an additional six months, ensuring the thorough development and refinement of the predictive model.\n\nBy successfully implementing this model, we aim to revolutionize the metabolite discovery process, providing a valuable tool for researchers in various scientific domains. The ability to predict metabolite occurrences not only accelerates the pace of scientific discovery but also optimizes resource allocation for targeted sampling efforts. This initiative aligns with our commitment to advancing open science, and upon completion, the model and its findings will be made available to the scientific community, fostering collaboration and furthering our understanding of the chemistry of life.\n\n\n","n":0.042}}},{"i":451,"$":{"0":{"v":"Expanded_np_chemspace","n":1}}},{"i":452,"$":{"0":{"v":"Abbreviations","n":1},"1":{"v":"\n\n## Keywords\nNP - Natural Products  \nDNP - Dictionary of Natural Products (commercially available effors for comiling NP data - https://dnp.chemnetbase.com/)  \nLNPN - [LOTUS database](https://lotus.naturalproducts.net)  \nSSOT - Single Source of Truth  \nOTL - Open Tree of life  \nIDSM - Integrated Database of Small Molecules  \nSMILES - Simplified Molecular Input Line Entry System (represents chemical structures in a linear string)\nBNICE - Biochemical Network Integated Computational Explorer (enzymatic algorythms)  \nKEGG - Kyoto Encyclopedia of Genes and Genomes (database)  \nSMARTS - \"SMiles ARbitrary Target Specification\" \nSMIRKS - \"Simplified Molecular Input Line Entry System\" is a hybrid of SMILES and SMARTS. It represent reactions in a string. \nFP2 - Fingerprints  \nFP4 - Fingerprints  \n[MINEs](https://minedatabase.mcs.anl.gov/#/home) - Metabolic In silico Network Expansions (predicted enzyme promiscuity products - database)\nBAM - Biotransformation-based Annotation Method  \nCOMMONS Lab - COMputational Metabolomics & Open science for Natural products reSearch  \n[SMART](http://smart.embl-heidelberg.de/) - (Simple Modular Architecture Research Tool) is a used for the identification and annotation of protein domains within protein sequences.  \n*.sdf - text-based file for storing chemical information (structure, ...).","n":0.077}}},{"i":453,"$":{"0":{"v":"CLI","n":1}}},{"i":454,"$":{"0":{"v":"Yazi","n":1},"1":{"v":"\n## yazi cheatsheet\n\n\nhttps://kb.adamsdesk.com/application/yazi-keyboard-shortcuts/","n":0.577}}},{"i":455,"$":{"0":{"v":"Xpra","n":1},"1":{"v":"\nhttps://bytexd.com/xpra/\n\n\nxpra attach ssh:xxxx@xxxxx:100 should restore the session.\n\n\nWorking smoothly :)\n\n\n## Starting (on the server)\n\nxpra start :100 --start=chromium\nxpra start :200 --start=xterm\nxpra start :300 --start=xterm\n\nTo view running session\n\nxpra sessions \n\nTo rename a session\nxpra control :10 name WHATEVER\n\nEx:\nxpra start :200 --start=xterm\nxpra control :200 name MZMINE\n\n\nxpra start :100 --start=chromium\nxpra control :100 name CHROMIUM\n\n\n\n## List of xpra servers\nCommand to attach from the client\n\n### Chromium\nxpra attach ssh:allardpm@biolpc045600:100\n\n### Xterm\nxpra attach ssh:allardpm@biolpc045600:200\n\n\n### Xterm2\nxpra attach ssh:allardpm@biolpc045600:300\n\n\n","n":0.123}}},{"i":456,"$":{"0":{"v":"Wikidata","n":1}}},{"i":457,"$":{"0":{"v":"Sparql","n":1},"1":{"v":"\n# SPARQL queries\n\n\n\n# all compounds produced by a given taxon or group of taxa (including children taxa) : \n\nhttps://w.wiki/4CMd\n\nwith ref\n\nhttps://w.wiki/4CMg\n\n\n\n# all compounds produced by a given taxon or group of taxa (including children taxa) which have a described bioactivity : \n\nhttps://w.wiki/3YMo\n\nresumed as treemap https://w.wiki/3YMt\n\nfor archive on zenodo https://w.wiki/4N8G\nresults https://w.wiki/4N8J\n\n\n\n## All organisms containing compound for which a given MeSh id has been reported.\n\nChange MeSH Id according to https://meshb.nlm.nih.gov/search\n\nhttps://w.wiki/vo9\n\n### displayed as a treemap\n\nhttps://w.wiki/zkK\n\n\n## compounds in organisms who have a parent taxon with a given taxon name\n\nhttps://w.wiki/vo$\n\n## compounds in organisms who have a parent taxon with a given taxon name - grouped and counted \n\nhttps://w.wiki/368M\n\n## compounds in organisms who have a parent taxon with a given taxon name - with mf and accurate mass\n\n\nhttps://w.wiki/36Ki\n\n\n\n## compounds displaying a found in a taxon property\n\nhttps://w.wiki/q$H\n\n## idsm powered !!!\n\n\nhttps://w.wiki/xMJ\n\n[[mail_jakub|scratch.2021.02.02.150258.mail_jakub]] \n\n## genus counting indole substrutcures\n\nThis SPAQRL query is based on a proposition of Jakub Galgonek <jakub.galgonek@uochb.cas.cz> (https://idsm.elixir-czech.cz/) and adapted by Pierre-Marie Allard (pierre-marie.allard@unige.ch)\nIt returns an order list of organisms known to produce chemical compounds having an indolic moiety.\nThe organisms are aggregated at the parent taxon level\nand the list is ordered by number of compound occurence in the parent t\n\nhttps://w.wiki/xMN\n\n\n## all molecules isolated by author X\n\nhttps://w.wiki/32D6\nhttps://w.wiki/32$m\n\n\n## count of the authors having isolated a given scaffold\n\nhttps://w.wiki/32DF\n\n## compare authors by count of compound\n\nhttps://w.wiki/32Vb\nhttps://w.wiki/32Vk (bar-chart)\n\n\n## compare authors by count of compound (substructure-refinable)\n\nhttps://w.wiki/32Vd\n\n## compare authors by count of compound (structuresimilarity-refinable)\n\nhttps://w.wiki/32Vg (indolic)\nhttps://w.wiki/32Vj (bubblechart - indolic)\nhttps://w.wiki/32Vi (bubblechart - tropanic)\n\n## count of authors isolating substances with a given role\n\nhttps://w.wiki/32Vr\n\n## all distinct article/substances/org for a given biological role\n\nhttps://w.wiki/32Vu\n\n## all disticnt antibiotics\n\nhttps://w.wiki/32Vv\n\n\n## drug-prot interaction \n\n```SPARQL\nSELECT DISTINCT ?parent_taxon ?parent_taxon_name ?compound ?interaction ?compoundLabel ?geneLabel ?biological_processLabel ?diseaseLabel WHERE {\n  #?compound wdt:P2868 ?mesh.\n  #?mesh wdt:P486 \"D000962\".\n  ?compound wdt:P235 ?inchikey.\n  {\n    ?compound p:P703 ?statement.\n    ?statement ps:P703 ?taxon.\n    ?taxon wdt:P171 ?parent_taxon.\n    OPTIONAL { ?taxon wdt:P171 ?parent_taxon. }\n    OPTIONAL { ?parent_taxon wdt:P225 ?parent_taxon_name. }\n    {\n      ?statement prov:wasDerivedFrom ?ref.\n      ?ref pr:P248 ?reference.\n      ?reference wdt:P356 ?reference_doi;\n        wdt:P1476 ?reference_title.\n    }\n   #?compound p:P129 ?interaction.\n   #?interaction wdt: wd:Q21119831.\n    \n    ?compound wdt:P129 ?gene_product .   # drug interacts with a gene_product\n    ?gene wdt:P688 ?gene_product .  # gene_product (usually a protein) is a product of a gene (a region of DNA)\n    ?disease  wdt:P2293 ?gene .    # genetic association between disease and gene\n    ?disease wdt:P279*  wd:Q12078 .  # limit to cancers wd:Q12078 (the * operator runs up a transitive relation..)\n    ?gene_product wdt:P682 ?biological_process . #add information about the GO biological processes that the gene is related to \n\n    ?biological_process (wdt:P361|wdt:P279)* wd:Q14599311.\n  }\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n}\n  \nGROUP BY ?parent_taxon ?parent_taxon_name ?compound ?interaction ?compoundLabel ?geneLabel ?biological_processLabel ?diseaseLabel\n#ORDER BY DESC (?count)\n```\n\n\n## Generic LOTUS queries\n\nhttps://w.wiki/$Q$\nhttps://w.wiki/$R3\nhttps://w.wiki/$RD apparently working !\nhttps://w.wiki/$RR with wd: for structure and org\nhttps://w.wiki/$RU wd: for everyone ...still ok\nhttps://w.wiki/$SF full monty\n\n## Sachem non-permanent endpoint\n\nhttps://idsm.elixir-czech.cz:2443/sachem/#/search\n\n\n## Sachem grand parents\nhttps://w.wiki/32Wz\n\n## Retrun compound present in invasive species\n\nhttps://w.wiki/32fa\nhttps://w.wiki/32fc\n\n## check taxon for a givin INChikey (regex)\n\nhttps://w.wiki/32j3\n\n## chemotax graph queries\n\nhttps://w.wiki/32q9\nhttps://w.wiki/32qC\n\n\nhttps://w.wiki/32qN\n\n\n# to tweet \n\nAll the compounds found in the Streptomyces avermitilis taxon and the references documenting this link. \nhttps://w.wiki/33V$\n\nWe can remove the references to get all unique compounds found in the Streptomyces coelicolor\n\nhttps://w.wiki/33WG\n\n\n\nAll the biological taxa where the chemical compound erysodine is found in.\nhttps://w.wiki/33WA\n\n\n\n# molecules found within vegetables\n\nhttps://w.wiki/4EAh\n\n# molecules found within toxic plants\n\n\nhttps://w.wiki/4EAw\n\n#  mlecules in IUCN threatned species\n\nhttps://w.wiki/4EGg\n\nhttps://w.wiki/4EHQ\n\n\n\n# looking for molecules present in old species according to life span\n\nhttps://w.wiki/4EH8\nhttps://w.wiki/4EHB\n\nwith preclass\n\nhttps://w.wiki/4EHD\n\nand prepreclass \n\nat all levels\nhttps://w.wiki/4EHH\n\nat a single level\n\nhttps://w.wiki/4EHJ\n\n\nclassed by chem classes\nhttps://w.wiki/4EHP\n\n\n\n\n# Messing around with pathways\n\nhttps://w.wiki/4EK7\n\noriginal query \n\nhttps://w.wiki/4EK9\n\n\n# highest mountains in Switzerland \n\nhttps://w.wiki/4EKE\n\n\n# all biologist with a twitter account\n\n\nhttps://w.wiki/4EKW\n\nstrictly biologists\nhttps://w.wiki/4EKM\n\neducated in Switzerland \n\nhttps://w.wiki/4EKk\n\n# example for prsenattion UniFr\n\nhttps://w.wiki/4EMf \nAll compounds + ref for S. coelicolor\n\nhttps://w.wiki/4EMo (bioact listed)\n\n#  Compounds from species wuth given IUCN status and lifespan\nhttps://w.wiki/4EMw\n\n# compounds in taxa and children filtered by SMILES pattern regex\n\nhttps://w.wiki/4JWv\n\n# Melochia genus query\n\nhttps://w.wiki/4VYy\n\n\n# IDSM queries \n\nPREFIX sachem: <http://bioinfo.uochb.cas.cz/rdf/v1.0/sachem#>\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\nPREFIX bd: <http://www.bigdata.com/rdf#>\nPREFIX wd: <http://www.wikidata.org/entity/>\nPREFIX wdt: <http://www.wikidata.org/prop/direct/>\nPREFIX wdtn: <http://www.wikidata.org/prop/direct-normalized/>\nPREFIX p: <http://www.wikidata.org/prop/>\nPREFIX prov: <http://www.w3.org/ns/prov#>\nPREFIX ps: <http://www.wikidata.org/prop/statement/>\nPREFIX pr: <http://www.wikidata.org/prop/reference/>\nPREFIX endpoint: <https://idsm.elixir-czech.cz/sparql/endpoint/>\n\n\n\n#title: Which are the available referenced structure-organism pairs on Wikidata? (example limited to 1000 results)\nSELECT DISTINCT ?structure ?structure_inchikey ?taxon ?taxon_name ?reference ?reference_doi WHERE {\n  ?structure wdt:P235 ?structure_inchikey;       # get the inchikey\n    p:P703[                                      # statement found in taxon\n     ps:P703 ?taxon;                             # get the taxon\n     (prov:wasDerivedFrom/pr:P248) ?reference ]. # get the reference\n  ?taxon wdt:P225 ?taxon_name.                   # get the taxon scientific name\n  ?reference wdt:P356 ?reference_doi.            # get the reference DOI\n}\nLIMIT 10\n\n\n\n\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\nPREFIX sachem: <http://bioinfo.uochb.cas.cz/rdf/v1.0/sachem#>\nPREFIX endpoint: <https://idsm.elixir-czech.cz/sparql/endpoint/>\n\nSELECT * WHERE {\n  SERVICE endpoint:chebi {\n    ?COMPOUND sachem:substructureSearch\n        [ sachem:query \"CC(=O)Oc1ccccc1C(O)=O\" ]\n  }\n  ?COMPOUND rdfs:label ?o\n}\n\n\n\n\n# title: Compounds of the Melochia genus bearing the quinoline substructure\n\nhttps://w.wiki/4wbY\n\n\n# all articles documenting found in taxonn Prop by authors of a given country \n\nhttps://w.wiki/4z7M\n\n\n\n-----\n\n\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\nPREFIX jlw: <https://www.sinergiawolfender.org/jlw/>\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\nPREFIX wd: <http://www.wikidata.org/entity/>\nPREFIX wdt: <http://www.wikidata.org/prop/direct/>\nPREFIX p: <http://www.wikidata.org/prop/>\nPREFIX ps: <http://www.wikidata.org/prop/statement/>\nPREFIX prov: <http://www.w3.org/ns/prov#>\nPREFIX pr: <http://www.wikidata.org/prop/reference/>\nPREFIX wikibase: <http://wikiba.se/ontology#>\nPREFIX bd: <http://www.bigdata.com/rdf#>\nPREFIX wdraw: <http://www.wikidata.org/>\nPREFIX vit: <https://www.sinergiawolfender.org/vit/>\n\nSELECT ?chemical_compound ?compoundLabel ?queried_taxa  ?queried_taxaLabel ?queried_taxall ?queried_taxallLabel ?pfcode WHERE {\n       \nSERVICE <https://query.wikidata.org/sparql> {\n  VALUES ?queried_taxa {\n    wd:Q310915\n  }\n  {\n    ?chemical_compound p:P703 ?stmt.# We selecte chemical classes having the found in taxon statement\n    ?queried_taxall wdt:P171* ?queried_taxa.\n    ?stmt ps:P703 ?queried_taxall. # and the restrict the found in taxon statement to match our queried taxa\n  }\n ?chemical_compound rdfs:label ?compoundLabel.\n ?queried_taxa rdfs:label ?queried_taxaLabel.\n ?queried_taxall rdfs:label ?queried_taxallLabel.\n        \n FILTER (LANG(?compoundLabel) = \"en\") . # filter for English\n FILTER (LANG(?queried_taxaLabel) = \"en\") .\n FILTER (LANG(?queried_taxallLabel) = \"en\") .\n}\n    \n?pfcode       jlw:is_from_plant_part               ?plant_part;\n              vit:has_taxon ?taxon.\n    \n?taxon jlw:has_wd_QID ?queried_taxall. \n    \n}\n\n\n\n\n\n\n\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\nPREFIX jlw: <https://www.sinergiawolfender.org/jlw/>\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\nPREFIX wd: <http://www.wikidata.org/entity/>\nPREFIX wdt: <http://www.wikidata.org/prop/direct/>\nPREFIX p: <http://www.wikidata.org/prop/>\nPREFIX ps: <http://www.wikidata.org/prop/statement/>\nPREFIX prov: <http://www.w3.org/ns/prov#>\nPREFIX pr: <http://www.wikidata.org/prop/reference/>\nPREFIX wikibase: <http://wikiba.se/ontology#>\nPREFIX bd: <http://www.bigdata.com/rdf#>\nPREFIX wdraw: <http://www.wikidata.org/>\nPREFIX vit: <https://www.sinergiawolfender.org/vit/>\n\nSELECT ?chemical_compound ?mf ?mf_formatted ?compoundLabel ?queried_taxa  ?queried_taxaLabel ?queried_taxall ?queried_taxallLabel ?pfcode ?labprocess ?feature ?sirius_formula ?sirius_formula_string WHERE {\n       \nSERVICE <https://query.wikidata.org/sparql> {\n  VALUES ?queried_taxa {\n    wd:Q310915\n  }\n  {\n    ?chemical_compound p:P703 ?stmt.# We selecte chemical classes having the found in taxon statement\n  OPTIONAL { ?chemical_compound wdt:P231 ?cas. }\n  OPTIONAL { ?chemical_compound wdt:P233 ?smiles_canonical. }\n  OPTIONAL { ?chemical_compound wdt:P234 ?inchi. }\n  OPTIONAL { ?chemical_compound wdt:P592 ?chembl. }\n  OPTIONAL { ?chemical_compound wdt:P662 ?pubchem. }\n  OPTIONAL { ?chemical_compound wdt:P683 ?chebi. }\n  OPTIONAL { ?chemical_compound wdt:P2017 ?smiles_isomeric. }\n  OPTIONAL { ?chemical_compound wdt:P274 ?mf. }\n  OPTIONAL { ?chemical_compound wdt:P2067 ?mass. }\n            #BIND(LCASE(STR(?mf)) as ?lowmf)\n            #BIND(REPLACE(STR(?mf),\"₀₁₂₃₄₅₆₇₈₉\",\"B\") AS ?mf_b) .\n            BIND(REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(STR(?mf),\"₀\",\"0\"),\"₁\",\"1\"),\"₂\",\"2\"),\"₃\",\"3\"),\"₄\",\"4\"),\"₅\",\"5\"),\"₆\",\"6\"),\"₇\",\"7\"),\"₈\",\"8\"),\"₉\",\"9\") AS ?mf_formatted) .\n\n\n            \n    ?queried_taxall wdt:P171* ?queried_taxa.\n    ?stmt ps:P703 ?queried_taxall. # and the restrict the found in taxon statement to match our queried taxa\n  }\n ?chemical_compound rdfs:label ?compoundLabel.\n ?queried_taxa rdfs:label ?queried_taxaLabel.\n ?queried_taxall rdfs:label ?queried_taxallLabel.\n        \n FILTER (LANG(?compoundLabel) = \"en\") . # filter for English\n FILTER (LANG(?queried_taxaLabel) = \"en\") .\n FILTER (LANG(?queried_taxallLabel) = \"en\") .\n}\n    \n?pfcode       jlw:is_from_plant_part               ?plant_part;\n              jlw:has_lab_process ?labprocess;\n              vit:has_taxon ?taxon.\n?labprocess jlw:has_MZmine_chromatogram ?mzmine_chromatogram .\n    \n?mzmine_chromatogram jlw:has_MZmine_feature ?feature .\n\n?feature jlw:has_SIRIUS_formula ?sirius_formula.\n    \n?sirius_formula jlw:has_SIRIUS_formula_string ?sirius_formula_string.\n    \n?taxon jlw:has_wd_QID ?queried_taxall. \n    \nFILTER(?mf_formatted = ?sirius_formula_string)\n}\n\n# Compounds produced by plants endemic to New caledonia\n\nhttps://w.wiki/57ap\n\ncleaner with mass and mf\n\nhttps://w.wiki/57hN\n\n\n# listing compounds in meals\n\nhttps://w.wiki/5Bs7\n\n\nhttps://w.wiki/5Bs9\n\n# Compounds of the Arachnida class\n\nhttps://w.wiki/5Doy\n\n\n# Compounds from taxa and children clean\n\nhttps://w.wiki/5LJf\n\n\n# References and occurences of Alstonine \n\nhttps://w.wiki/5WXP\n\n# compare occurences in WD of entries with a given taxon id  (OTL versus WFO)\n\nhttps://w.wiki/5WYx\n\n\n\n## endpoints\n\nhttps://www.wikidata.org/wiki/Wikidata:Lists/SPARQL_endpoints\n\n\n\n#### quest query mod from Mietchen to compounds (not working)\n\n# Pay attention to edge cases\nSELECT DISTINCT ?n_formatted\n(CONCAT(\nREPLACE(STR(?i)\n\".*Q\"\n\"Q\")\n\"|P921|\"\nREPLACE(STR(?ta)\n\".*Q\"\n\"Q\")\n\"|P1932|\"\n(CONCAT(\"\\\"\"\n?a\n\"\\\"\"))\n\"|S887|Q69652283\") AS ?QuickStatements)\nWITH {\nSELECT DISTINCT ?ta WHERE {\nSERVICE bd:sample { ?ta wdt:P31 wd:Q11173 . bd:serviceParam bd:sample.limit 5 }\n}\nLIMIT 2\n}\nAS %t\nWITH\n{ SELECT ?i ?n ?ta ?ti WHERE {\nINCLUDE %t\n        \n?ta rdfs:label ?n.\nFILTER (LANG(?n) = \"en\") .\nBIND(REPLACE(STR(?n),\"@en\",\"\") AS ?n_formatted) .\n                                         \n\nSERVICE wikibase:mwapi\n{\nbd:serviceParam wikibase:endpoint \"www.wikidata.org\";\nwikibase:api \"Generator\";\nmwapi:generator \"search\";\nmwapi:gsrsearch ?n_formatted ;\nmwapi:gsrlimit \"max\".\n?i wikibase:apiOutputItem mwapi:title.\n}\n?i wdt:P1476 ?ti .\n#MINUS {?i wdt:P921 ?ta }\n#MINUS {?i wdt:P921 [wdt:P171* ?ta ] } \nFILTER (REGEX(LCASE(?ti)\nLCASE(CONCAT( \"\\\\\"\n\"b\"\n?n_formatted ,\"\\\\\"\n\"b\"))))\nFILTER (!REGEX(LCASE(?ti)\nLCASE(CONCAT( ?n_formatted ,\"-\"))))\nFILTER (!REGEX(LCASE(?ti)\nLCASE(CONCAT( ?n_formatted ,\"(.)virus\"))))\nFILTER (!REGEX(LCASE(?ti)\nLCASE(CONCAT( \"pseudo(.?)\"\n?n_formatted))))\n}\n}\nAS %i\nWHERE {\nINCLUDE %i\nINCLUDE %t\nBIND (SUBSTR(?ti\nSTRLEN(STRBEFORE(REPLACE(?ti\n?n\n\"=HELP=\"\n\"i\")\n\"=HELP=\")) +1\nSTRLEN(?n_formatted)) AS ?a)\n}       \n\n\n-----\nNo error but no results neither \n\nSELECT DISTINCT ?n_formatted\n(CONCAT(\nREPLACE(STR(?i)\n\".*Q\"\n\"Q\")\n\"|P921|\"\nREPLACE(STR(?ta)\n\".*Q\"\n\"Q\")\n\"|P1932|\"\n(CONCAT(\"\\\"\"\n?a\n\"\\\"\"))\n\"|S887|Q69652283\") AS ?QuickStatements)\nWITH {\nSELECT DISTINCT ?ta ?n_formatted WHERE {\nSERVICE bd:sample { ?ta wdt:P31 wd:Q11173 . bd:serviceParam bd:sample.limit 5000 }\n\n?ta rdfs:label ?n.\nFILTER (LANG(?n) = \"en\") .\nBIND(REPLACE(STR(?n),\"@en\",\"\") AS ?n_formatted) .\n     \n\n}\nLIMIT 100\n}\nAS %t\nWITH\n{ SELECT ?i ?n_formatted ?ta ?ti WHERE {\nINCLUDE %t\n        \n                                    \n\nSERVICE wikibase:mwapi\n{\nbd:serviceParam wikibase:endpoint \"www.wikidata.org\";\nwikibase:api \"Generator\";\nmwapi:generator \"search\";\nmwapi:gsrsearch ?n_formatted ;\nmwapi:gsrlimit \"max\".\n?i wikibase:apiOutputItem mwapi:title.\n}\n?i wdt:P1476 ?ti .\n#MINUS {?i wdt:P921 ?ta }\n#MINUS {?i wdt:P921 [wdt:P171* ?ta ] } \nFILTER (REGEX(LCASE(?ti)\nLCASE(CONCAT( \"\\\\\"\n\"b\"\n?n_formatted ,\"\\\\\"\n\"b\"))))\nFILTER (!REGEX(LCASE(?ti)\nLCASE(CONCAT( ?n_formatted ,\"-\"))))\nFILTER (!REGEX(LCASE(?ti)\nLCASE(CONCAT( ?n_formatted ,\"(.)virus\"))))\nFILTER (!REGEX(LCASE(?ti)\nLCASE(CONCAT( \"pseudo(.?)\"\n?n))))\n}\n}\nAS %i\nWHERE {\nINCLUDE %i\nINCLUDE %t\nBIND (SUBSTR(?ti\nSTRLEN(STRBEFORE(REPLACE(?ti\n?n_formatted\n\"=HELP=\"\n\"i\")\n\"=HELP=\")) +1\nSTRLEN(?n_formatted)) AS ?a)\n}\n\n\n\n-----\n\nWorks !!!\n\n# adapted from Daniel Mietchen https://w.wiki/5a7K\nSELECT DISTINCT ?n_formatted\n(CONCAT(\nREPLACE(STR(?i)\n\".*Q\"\n\"Q\")\n\"|P921|\"\nREPLACE(STR(?ta)\n\".*Q\"\n\"Q\")\n\"|P1932|\"\n(CONCAT(\"\\\"\"\n?a\n\"\\\"\"))\n\"|S887|Q69652283\") AS ?QuickStatements)\nWITH {\nSELECT DISTINCT ?ta ?n_formatted WHERE {\nSERVICE bd:sample { ?ta wdt:P31 wd:Q11173 . bd:serviceParam bd:sample.limit 5000 }\n?ta p:P703 ?stmt.\n?stmt ps:P703 ?taxa.\n?ta rdfs:label ?n.\nFILTER (LANG(?n) = \"en\") .\nBIND(REPLACE(STR(?n),\"@en\",\"\") AS ?n_formatted) .\n}\nLIMIT 25\n}\nAS %t\nWITH\n{ SELECT ?i ?n_formatted ?ta ?ti WHERE {\nINCLUDE %t\nSERVICE wikibase:mwapi\n{\nbd:serviceParam wikibase:endpoint \"www.wikidata.org\";\nwikibase:api \"Generator\";\nmwapi:generator \"search\";\nmwapi:gsrsearch ?n_formatted ;\nmwapi:gsrlimit \"max\".\n?i wikibase:apiOutputItem mwapi:title.\n}\n?i wdt:P1476 ?ti .\nMINUS {?i wdt:P921 ?ta }\n#MINUS {?i wdt:P921 [wdt:P171* ?ta ] } \n#FILTER (REGEX(LCASE(?ti)\nLCASE(CONCAT( \"\\\\\"\n\"b\"\n?n_formatted ,\"\\\\\"\n\"b\"))))\n#FILTER (!REGEX(LCASE(?ti)\nLCASE(CONCAT( ?n_formatted ,\"-\"))))\n#FILTER (!REGEX(LCASE(?ti)\nLCASE(CONCAT( ?n_formatted ,\"(.)virus\"))))\n#FILTER (!REGEX(LCASE(?ti)\nLCASE(CONCAT( \"pseudo(.?)\"\n?n))))\n}\n}\nAS %i\nWHERE {\nINCLUDE %i\nINCLUDE %t\nBIND (SUBSTR(?ti\nSTRLEN(STRBEFORE(REPLACE(?ti\n?n_formatted\n\"=HELP=\"\n\"i\")\n\"=HELP=\")) +1\nSTRLEN(?n_formatted)) AS ?a)\n}\n\n\nhttps://w.wiki/5a8b\n\nescaping dangling meta chracters https://w.wiki/5a8g\n\n----- \n\nwith taxa and compound\n\n# Adapted from Daniel Mietchen https://w.wiki/5a7K\nSELECT DISTINCT\n(CONCAT(\nREPLACE(STR(?i)\n\".*Q\"\n\"Q\")\n\"|P921|\"\nREPLACE(STR(?ta)\n\".*Q\"\n\"Q\")\n\"|P1932|\"\n(CONCAT(\"\\\"\"\n?a\n\"\\\"\"))\n\"|S887|Q69652283\") AS ?QuickStatements)\nWITH {\nSELECT DISTINCT ?ta ?n_formatted WHERE {\nSERVICE bd:sample { ?ta wdt:P31 wd:Q11173 . bd:serviceParam bd:sample.limit 5000 }\n?ta p:P703 ?stmt.\n?stmt ps:P703 ?taxa.\n?ta rdfs:label ?n.\nFILTER (LANG(?n) = \"en\") .\nBIND(REPLACE(REPLACE(REPLACE(STR(?n),\"@en\",\"\"),\"\\\\+\",\"\"),\"\\\\-\",\"\") AS ?n_formatted) .\n}\nLIMIT 25\n}\nAS %t\nWITH\n{ SELECT ?i ?n_formatted ?ta ?ti WHERE {\nINCLUDE %t\nSERVICE wikibase:mwapi\n{\nbd:serviceParam wikibase:endpoint \"www.wikidata.org\";\nwikibase:api \"Generator\";\nmwapi:generator \"search\";\nmwapi:gsrsearch ?n_formatted;\nmwapi:gsrlimit \"max\".\n?i wikibase:apiOutputItem mwapi:title.\n}\n?i wdt:P1476 ?ti .\nMINUS {?i wdt:P921 ?ta }\n}\n}\nAS %i\nWITH\n{ SELECT ?j ?taxa ?ta ?ti WHERE {\nINCLUDE %t\nSERVICE wikibase:mwapi\n{\nbd:serviceParam wikibase:endpoint \"www.wikidata.org\";\nwikibase:api \"Generator\";\nmwapi:generator \"search\";\nmwapi:gsrsearch ?taxa;\nmwapi:gsrlimit \"max\".\n?j wikibase:apiOutputItem mwapi:title.\n}\n?j wdt:P1476 ?ti .\nMINUS {?j wdt:P921 ?taxa }\n}\n}\nAS %j\nWHERE {\nINCLUDE %i\nINCLUDE %j\nINCLUDE %t\nBIND (SUBSTR(?ti\nSTRLEN(STRBEFORE(REPLACE(?ti\n?n_formatted\n\"=HELP=\"\n\"i\")\n\"=HELP=\")) +1\nSTRLEN(?n_formatted)) AS ?a)\n}\n\n\nUsing filter EXISTS \n\nhttps://w.wiki/5a8t\n\nhttps://w.wiki/5a9B\n\n\n------\nCurating query \n\n# Adapted from Daniel Mietchen https://w.wiki/5a7K\nSELECT DISTINCT ?taxa ?taxaLabel ?taxa_chem ?taxa_chemLabel ?ta ?taLabel ?ti \n(CONCAT(\nREPLACE(STR(?ta)\n\".*Q\"\n\"Q\")\n\"|P703|\"\nREPLACE(STR(?taxa)\n\".*Q\"\n\"Q\")\n\"|S248|\"\nREPLACE(STR(?i)\n\".*Q\"\n\"Q\")) AS ?QuickStatements)\nWITH {\nSELECT DISTINCT ?ta ?n_formatted ?taxa_chem WHERE {\nSERVICE bd:sample { ?ta wdt:P31 wd:Q11173 . bd:serviceParam bd:sample.limit 25000 }\nOPTIONAL { ?ta p:P703 ?stmt. }\nOPTIONAL { ?stmt ps:P703 ?taxa_chem. }\n?ta rdfs:label ?n.\nFILTER (LANG(?n) = \"en\") .\nBIND(REPLACE(REPLACE(REPLACE(STR(?n),\"@en\",\"\"),\"\\\\+\",\"\"),\"\\\\-\",\"\") AS ?n_formatted) .\n}\nLIMIT 30\n}\nAS %t\nWITH\n{ SELECT ?i ?n_formatted ?ta ?ti ?taxa WHERE {\nINCLUDE %t\nSERVICE wikibase:mwapi\n{\nbd:serviceParam wikibase:endpoint \"www.wikidata.org\";\nwikibase:api \"Generator\";\nmwapi:generator \"search\";\nmwapi:gsrsearch ?n_formatted ;\nmwapi:gsrlimit \"max\".\n?i wikibase:apiOutputItem mwapi:title.\n}\n?i wdt:P1476 ?ti .\n?i wdt:P921 ?taxa.\n?taxa wdt:P105 wd:Q7432.\nFILTER (?taxa != ?taxa_chem)\n}\n}\nAS %i\nWHERE {\nINCLUDE %i\nINCLUDE %t\nBIND (SUBSTR(?ti\nSTRLEN(STRBEFORE(REPLACE(?ti\n?n_formatted\n\"=HELP=\"\n\"i\")\n\"=HELP=\")) +1\nSTRLEN(?n_formatted)) AS ?a)\nSERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n}\n\n\nhttps://w.wiki/5a9T\n\nhttps://w.wiki/5a9g\n\n\n# Solanum genus compounds\n\nhttps://w.wiki/5h8g\n\n# Solanum and erythroxylum genus compounds\n\nhttps://w.wiki/5h9f\n\n# Solanum and erythroxylum and Apocynaceae genus compounds\n\nhttps://w.wiki/5h9p\n\nManager\n\n\n# Limit by journal \n\nhttps://w.wiki/5imt\nScorfi shiny version https://w.wiki/5imj\n\n\n# filter papers which do not have found in taxon\n\nhttps://w.wiki/5ipT\n\n\n\n\n\n# 10 papers (random) from journal of natural products\n\nhttps://w.wiki/5ity\n\n\n# 10 papers (random) from phytochemistry\n\nhttps://w.wiki/5it$\n\n\n### Restricting quest queries to journals and taxa\n\n# Adapted from Daniel Mietchen https://w.wiki/5a7K\nSELECT DISTINCT *\n#(CONCAT(\n#REPLACE(STR(?ta)\n\".*Q\"\n\"Q\")\n\"|P703|\"\nREPLACE(STR(?taxa)\n\".*Q\"\n\"Q\")\n\"|S248|\"\nREPLACE(STR(?i)\n\".*Q\"\n\"Q\")) AS ?QuickStatements)\nWITH {\nSELECT DISTINCT ?ta ?n_formatted ?taxa_chem WHERE {\n#SERVICE bd:sample { ?ta wdt:P31 wd:Q11173 . bd:serviceParam bd:sample.limit 1000 }\n?ta wdt:P31 wd:Q11173 .\nSERVICE bd:sample { ?taxa_int wdt:P171 wd:Q173756 . bd:serviceParam bd:sample.limit 2000 }\n?taxa_chem wdt:P171 ?taxa_int .\n#?taxa_chem (wdt:P171*) wd:Q173756 .\n?ta p:P703 ?stmt.\n?stmt ps:P703 ?taxa_chem.\n?ta rdfs:label ?n.\nFILTER (LANG(?n) = \"en\") .\nBIND(REPLACE(REPLACE(REPLACE(STR(?n),\"@en\",\"\"),\"\\\\+\",\"\"),\"\\\\-\",\"\") AS ?n_formatted) .\n}\nLIMIT 40\n}\nAS %t\nWITH\n{ SELECT ?i ?n_formatted ?ta ?ti ?taxa ?taxa_chem  WHERE {\nINCLUDE %t\nSERVICE wikibase:mwapi\n{\nbd:serviceParam wikibase:endpoint \"www.wikidata.org\";\nwikibase:api \"Generator\";\nmwapi:generator \"search\";\nmwapi:gsrsearch ?n_formatted ;\nmwapi:gsrlimit \"max\".\n?i wikibase:apiOutputItem mwapi:title.\n}\nVALUES ?ref_journal {\n    wd:Q1884753\n    wd:Q165584\n}\n?i wdt:P1433 ?ref_journal.\n?i wdt:P1476 ?ti .\n?i wdt:P921 ?taxa.\n?taxa wdt:P105 wd:Q7432.\n#?taxa (wdt:P171*) wd:Q173756 .\nFILTER (?taxa != ?taxa_chem) .\n}\n}\nAS %i\nWHERE {\nINCLUDE %i\nINCLUDE %t\nBIND (SUBSTR(?ti\nSTRLEN(STRBEFORE(REPLACE(?ti\n?n_formatted\n\"=HELP=\"\n\"i\")\n\"=HELP=\")) +1\nSTRLEN(?n_formatted)) AS ?a)\nSERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n}\n\n# Compounds and ref from the Actinobacteria phylum \nhttps://w.wiki/5kCC\nwith Chembl ids\n\nhttps://w.wiki/5kDz\n\n# NP with drug interactions  \nhttps://w.wiki/5o9R\n\n\n\n# Query for simon \nhttps://w.wiki/5rxD\n\n\n# Researcher in the field of X working in an organisation located in country Z filter by sex Y\n\nhttps://w.wiki/65F4\n\n\n\n# Organisms containing 7-methyl-2,3,5,7a-tetrahydro-1H-pyrrolizin-1-ol\n\nSMILES CC1=CCN2CCC(O)C12\n\n## Aggregate producing organisms at the superior taxa level\ncount and order descending\nhttps://w.wiki/6w6J\n## Return all referenced pairs metadata\nhttps://w.wiki/6w7R\n## Count individual compounds\nhttps://w.wiki/6w7S = 369\n\n# Organisms containing 7-methyl-2,3,5,7a-tetrahydro-1H-pyrrolizine-1,1-diol\n\nSMILES CC1=CCN2CCC(O)(O)C12\n\n## Aggregate producing organisms at the superior taxa level\ncount and order descending\nhttps://w.wiki/6w6R\n## Return all referenced pairs metadata\nhttps://w.wiki/6w7L\n## Count individual compounds\nhttps://w.wiki/6w7N = 0\n\n# Organisms containing 7-methyl-2,3,5,7a-tetrahydro-1H-pyrrolizine-1,3-diol\n\nSMILES CC1=CCN2C(O)CC(O)C12\n\n## Aggregate producing organisms at the superior taxa level\ncount and order descending\nhttps://w.wiki/6w6T\n## Return all referenced pairs metadata\nhttps://w.wiki/6w7G\n## Count individual compounds\nhttps://w.wiki/6w7H = 0\n\n# Organisms containing 1-hydroxy-7-methyl-1,2,3,4,5,7a-hexahydropyrrolizin-4-ium-4-olate\n\nSMILES CC1=CC[N+]2([O-])CCC(O)C12\n\n## Aggregate producing organisms at the superior taxa level\ncount and order descending\nhttps://w.wiki/6w6a\n## Return all referenced pairs metadata\nhttps://w.wiki/6w73\n## Count individual compounds\nhttps://w.wiki/6w77 = 45\n\n\n\n\n### containing taxa + ref for a given IK\n\nSELECT  ?compound ?InChIKey ?taxon ?taxonLabel ?reference ?referenceLabel WITH {\n  SELECT ?queryKey ?srsearch ?filter WHERE {\n    VALUES ?queryKey {\n      \"KWIUHFFTVRNATP\"\n    }\n    BIND (CONCAT(substr($queryKey,1,14)\n\" haswbstatement:P235\") AS ?srsearch)\n    BIND (CONCAT(\"^\"\nsubstr($queryKey,1,14)) AS ?filter)\n  }\n} AS %comps WITH {\n  SELECT ?compound ?InChIKey WHERE {\n    INCLUDE %comps\n            SERVICE wikibase:mwapi {\n              bd:serviceParam wikibase:endpoint \"www.wikidata.org\";\n                              wikibase:api \"Search\";\n                              mwapi:srsearch ?srsearch;\n                              mwapi:srlimit \"max\".\n              ?compound wikibase:apiOutputItem mwapi:title.\n            }\n    ?compound wdt:P235 ?InChIKey .\n    FILTER (REGEX(STR(?InChIKey)\n?filter))\n  }\n} AS %compounds\nWHERE {\n  INCLUDE %compounds\n            {\n    ?compound p:P703 ?stmt.\n    ?stmt ps:P703 ?taxon.\n  }\n  OPTIONAL {\n    ?stmt prov:wasDerivedFrom ?ref.\n    ?ref pr:P248 ?reference.\n  }         \n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n}\nLIMIT 10000\n\n\n\nSELECT  ?compound ?InChIKey ?taxon ?taxonLabel ?reference ?referenceLabel WITH {\n  SELECT ?queryKey ?srsearch ?filter WHERE {\n    VALUES ?queryKey {\n      \"KWIUHFFTVRNATP\"\n    }\n    BIND (CONCAT(substr($queryKey,1,14)\n\" haswbstatement:P235\") AS ?srsearch)\n    BIND (CONCAT(\"^\"\nsubstr($queryKey,1,14)) AS ?filter)\n  }\n} AS %comps WITH {\n  SELECT ?compound ?InChIKey WHERE {\n    INCLUDE %comps\n            SERVICE wikibase:mwapi {\n              bd:serviceParam wikibase:endpoint \"www.wikidata.org\";\n                              wikibase:api \"Search\";\n                              mwapi:srsearch ?srsearch;\n                              mwapi:srlimit \"max\".\n              ?compound wikibase:apiOutputItem mwapi:title.\n            }\n    ?compound wdt:P235 ?InChIKey .\n    FILTER (REGEX(STR(?InChIKey)\n?filter))\n  }\n} AS %compounds\nWHERE {\n  INCLUDE %compounds\n   VALUES ?taxon {\n      wd:Q1303946\n    }\n  {\n    ?compound p:P703 ?stmt.\n    ?stmt ps:P703 ?taxon.\n  }\n  OPTIONAL {\n    ?stmt prov:wasDerivedFrom ?ref.\n    ?ref pr:P248 ?reference.\n    #?reference wdt:P921 ?main_subject.\n    #?main_subject ps:P921 ?taxon_ref.\n  } \n  #FILTER ( ?taxon = ?match)\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n}\nLIMIT 10000\n\nhttps://query.wikidata.org/#SELECT%20%3Ftaxon_name%20%3Fcompound%20%3FInChIKey%20WITH%20%7B%0A%20%20SELECT%20%3FqueryKey%20%3Fsrsearch%20%3Ffilter%20WHERE%20%7B%0A%20%20%20%20VALUES%20%3FqueryKey%20%7B%0A%20%20%20%20%20%20%22KZJWDPNRJALLNS-VJSFXXLFSA-N%22%20%23%20beta-sitosterol%0A%20%20%20%20%7D%0A%20%20%20%20BIND%20%28CONCAT%28substr%28%24queryKey%2C1%2C14%29%2C%20%22%20haswbstatement%3AP235%22%29%20AS%20%3Fsrsearch%29%0A%20%20%20%20BIND%20%28CONCAT%28%22%5E%22%2C%20substr%28%24queryKey%2C1%2C14%29%29%20AS%20%3Ffilter%29%0A%20%20%7D%0A%7D%20AS%20%25comps%20WITH%20%7B%0A%20%20SELECT%20%3Fcompound%20%3FInChIKey%20WHERE%20%7B%0A%20%20%20%20INCLUDE%20%25comps%0A%20%20%20%20%20%20%20%20%20%20%20%20SERVICE%20wikibase%3Amwapi%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20bd%3AserviceParam%20wikibase%3Aendpoint%20%22www.wikidata.org%22%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3Aapi%20%22Search%22%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mwapi%3Asrsearch%20%3Fsrsearch%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mwapi%3Asrlimit%20%22max%22.%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3Fcompound%20wikibase%3AapiOutputItem%20mwapi%3Atitle.%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%3Fcompound%20wdt%3AP235%20%3FInChIKey%20.%0A%20%20%20%20FILTER%20%28REGEX%28STR%28%3FInChIKey%29%2C%20%3Ffilter%29%29%0A%20%20%20%20FILTER%20%28%3FInChIKey%20%21%3D%20%3FqueryKey%29%0A%20%20%7D%0A%7D%20AS%20%25compounds%0AWHERE%20%7B%0A%20%20INCLUDE%20%25compounds%0A%20%20%20%20%20%20%20%20%20%20%3Fcompound%20%28wdt%3AP703%2Fwdt%3AP225%29%20%3Ftaxon_name.%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22en%22.%20%7D%0A%7D%0ALIMIT%2010000\n\n\n\nhttps://query.wikidata.org/index.html#%23Goats%0ASELECT%20%3Fitem%20%3FitemLabel%20%0AWHERE%20%0A%7B%0A%20%20%3Fitem%20wdt%3AP31%20wd%3AQ2934.%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22%5BAUTO_LANGUAGE%5D%2Cen%22.%20%7D%0A%7D\n\nhttps://query.wikidata.org/embed.html#%23Goats%0ASELECT%20%3Fitem%20%3FitemLabel%20%0AWHERE%20%0A%7B%0A%20%20%3Fitem%20wdt%3AP31%20wd%3AQ2934.%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22%5BAUTO_LANGUAGE%5D%2Cen%22.%20%7D%0A%7D\n\n\n\nhttps://query.wikidata.org/embed.html#SELECT%20%20%3Fcompound%20%3FInChIKey%20%3Ftaxon%20%3FtaxonLabel%20%3Freference%20%3FreferenceLabel%20WITH%20%7B%0A%20%20SELECT%20%3FqueryKey%20%3Fsrsearch%20%3Ffilter%20WHERE%20%7B%0A%20%20%20%20VALUES%20%3FqueryKey%20%7B%0A%20%20%20%20%20%20%22SVFKZPQPMMZHLZ%22%0A%20%20%20%20%7D%0A%20%20%20%20BIND%20%28CONCAT%28substr%28%24queryKey%2C1%2C14%29%2C%20%22%20haswbstatement%3AP235%22%29%20AS%20%3Fsrsearch%29%0A%20%20%20%20BIND%20%28CONCAT%28%22%5E%22%2C%20substr%28%24queryKey%2C1%2C14%29%29%20AS%20%3Ffilter%29%0A%20%20%7D%0A%7D%20AS%20%25comps%20WITH%20%7B%0A%20%20SELECT%20%3Fcompound%20%3FInChIKey%20WHERE%20%7B%0A%20%20%20%20INCLUDE%20%25comps%0A%20%20%20%20%20%20%20%20%20%20%20%20SERVICE%20wikibase%3Amwapi%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20bd%3AserviceParam%20wikibase%3Aendpoint%20%22www.wikidata.org%22%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20wikibase%3Aapi%20%22Search%22%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mwapi%3Asrsearch%20%3Fsrsearch%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mwapi%3Asrlimit%20%22max%22.%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3Fcompound%20wikibase%3AapiOutputItem%20mwapi%3Atitle.%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%3Fcompound%20wdt%3AP235%20%3FInChIKey%20.%0A%20%20%20%20FILTER%20%28REGEX%28STR%28%3FInChIKey%29%2C%20%3Ffilter%29%29%0A%20%20%7D%0A%7D%20AS%20%25compounds%0AWHERE%20%7B%0A%20%20INCLUDE%20%25compounds%0A%20%20%20VALUES%20%3Ftaxon%20%7B%0A%20%20%20%20%20%20wd%3AQ136894%0A%20%20%20%20%7D%0A%20%20%7B%0A%20%20%20%20%3Fcompound%20p%3AP703%20%3Fstmt.%0A%20%20%20%20%3Fstmt%20ps%3AP703%20%3Ftaxon.%0A%20%20%7D%0A%20%20OPTIONAL%20%7B%0A%20%20%20%20%3Fstmt%20prov%3AwasDerivedFrom%20%3Fref.%0A%20%20%20%20%3Fref%20pr%3AP248%20%3Freference.%0A%20%20%20%20%23%3Freference%20wdt%3AP921%20%3Fmain_subject.%0A%20%20%20%20%23%3Fmain_subject%20ps%3AP921%20%3Ftaxon_ref.%0A%20%20%7D%20%0A%20%20%23FILTER%20%28%20%3Ftaxon%20%3D%20%3Fmatch%29%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22en%22.%20%7D%0A%7D%0ALIMIT%2010000\n\n\n### Cleaned queryies cpds per taxa\n\nhttps://w.wiki/7WL3\n\n\n## Filter by atoms in MF\n\nhttps://w.wiki/7WL9\n\nWith a regex substring in the mf \n\nhttps://w.wiki/7WLb\n\n## Wd all\n\nhttps://w.wiki/7Woz\n\n## Most described taxon\nExcluding humans + only at the species level\n\nhttps://w.wiki/7YDr\n\n\n## sr WD by MF\n\nhttps://w.wiki/9AAN\n\nsame with refs\n\nhttps://w.wiki/9AAe\n\n\n## Genome\nproteome\nmetabolome\n\nhttps://w.wiki/9qZT\n\n\n### CRetrieve list of OTT id from inat taxon id,\n\nhttps://w.wiki/rL\n\nhttps://w.wiki/9tCe\n\n### Qlever WD OTT id for LOTUS taxa\n\nhttps://qlever.cs.uni-freiburg.de/wikidata/TqdMNf\n\n###  WD taxa lacking OTT ids\n\nhttps://qlever.cs.uni-freiburg.de/wikidata/ThyZSf\n\n2024.07.12 2024-07-12 09:47 > 1'755'037\n\n### Qlever LOTUS chemical count\n\nhttps://qlever.cs.uni-freiburg.de/wikidata/0Slm8l\n\n227,090\n\"227090\"^^<http://www.w3.org/2001/XMLSchema#int>\n\n### Qlever LOTUS chemical count with Isomeric SMILES\n\nhttps://qlever.cs.uni-freiburg.de/wikidata/wnFz75\n\n172,598\n\"172598\"^^<http://www.w3.org/2001/XMLSchema#int>\n\n### Qlever LOTUS organisms count \n\nhttps://qlever.cs.uni-freiburg.de/wikidata/1e5Rdg\n\n37,471\n\n### Qlever LOTUS organisms count with taxon name\n\nhttps://qlever.cs.uni-freiburg.de/wikidata/f0F9Y4\n\n37,461\n\"37461\"^^<http://www.w3.org/2001/XMLSchema#int>\n\n\n\n\n\n```rust\n#[cfg(feature = \"64-column-tables\")]\ndiesel::table! {\n    #[sql_name = \"Field_Data\"] public.field_data(id) { id -> diesel::sql_types::Integer,\n    status -> diesel::sql_types::Text\nuser_created -> diesel::sql_types::Nullable <\n    diesel::sql_types::Uuid >\ndate_created -> diesel::sql_types::Nullable <\n    diesel::sql_types::Timestamptz >\nuser_updated -> diesel::sql_types::Nullable <\n    diesel::sql_types::Uuid >\ndate_updated -> diesel::sql_types::Nullable <\n    diesel::sql_types::Timestamptz >\nsample_name -> diesel::sql_types::Nullable <\n    diesel::sql_types::Text >\nsample_id -> diesel::sql_types::Text\npicture_panel ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\npicture_general ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\npicture_detail ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\npicture_cut ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\npicture_panel_label ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\nx_coord ->\n    diesel::sql_types::Nullable < diesel::sql_types::Float >\ny_coord ->\n    diesel::sql_types::Nullable < diesel::sql_types::Float >\n#[sql_name =\n    \"herbivory_(percent)\"] herbivory_percent -> diesel::sql_types::Nullable <\n    diesel::sql_types::Float >\n#[sql_name = \"temperature_(°C)\"] temperature_celsius ->\n    diesel::sql_types::Nullable < diesel::sql_types::Float >\ngeometry ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\nlatitude ->\n    diesel::sql_types::Nullable < diesel::sql_types::Float >\nlongitude ->\n    diesel::sql_types::Nullable < diesel::sql_types::Float >\nmatch_name ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\nott_id ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\nrank ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\n#[sql_name = \"wikidataID\"]\n    wikidata_id -> diesel::sql_types::Nullable < diesel::sql_types::Text >\nunknown ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\nqfield_project ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\ncollector_fullname ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\npicture_free ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\nno_name_on_list ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\nname_proposition ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\ncomment_eco ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\nsoil_type ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\nweather ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\ncomment_env ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\nobservation_subject ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\ncollector_inat ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\ncollector_orcid ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\ndate ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\ntaxon_name ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text >\nis_wild ->\n    diesel::sql_types::Nullable < diesel::sql_types::Integer >\ninat_upload ->\n    diesel::sql_types::Nullable < diesel::sql_types::Integer >\nipen ->\n    diesel::sql_types::Nullable < diesel::sql_types::Text > }\n}\n```\n\n## Mind the famous WD graph split regarding scholarly articles  \n\nWhy is that not working https://w.wiki/Eexo\n5 min\n\neyes\n\nAntiviral chlorinated daphnane diterpenoid orthoesters from the bark and wood of Trigonostemon cherrieri\nscientific article published on 29 August 2012\nwww.wikidata.org\n\nFor https://www.wikidata.org/wiki/Q40275796\n5 min\n\nE\n\nEgon\nbecause all the scholarly articles moved to a different SPARQL endpoint #wikidataSplit\n4 min\n\nWhile that https://w.wiki/Eexs works\n4 min\n\nfor https://www.wikidata.org/wiki/Q103883147\n4 min\n\nE\n\nEgon\ne.g. use https://w.wiki/Eext\n4 min\n\nheart\n\nahhh the famous Split\n4 min\n\nEgon\nor...\n\nE\n\nhttps://w.wiki/Eexz\n2 min\n\n+1\n\nThanks, i'll  note these down once for all. Not the first time that I forget this split\n\n\n","n":0.02}}},{"i":458,"$":{"0":{"v":"Scripts","n":1},"1":{"v":"\nHow cool would this be to have a script allowing to automatically fetch the wikidata link and id of any selected word.\nThis would clearly facilitate the addition of  wd links in manuscripts and documents. Such script could facilitate the use of wd while exploring a given topic. Ideally a small snapshot of the wd article could be displayed.\nI have no idea of how doable this is.\nApperas cool to me at the moment (2021-03-13 00:17) might be full BS.\n\n- [ ] check for similar plugins using google or wikipedia \nMake a small project out of this ? \nTo discuss with Daniel.\n\n\n----------\nSome related stuff\n\nhttps://chrome.google.com/webstore/detail/right-click-search-wikipe/eikmpmafdimllogceehaijmnlndineje\n\nhttps://chrome.google.com/webstore/detail/wikidata-search/ingjkjibhnkhomomlmlabndfmiaejkpn\n\nhttps://chrome.google.com/webstore/detail/entity-explosion/bbcffeclligkmfiocanodamdjclgejcn\n\n(the two previous ones are not functional on chromium ...)\n\n\nwikidata\nhttp://hints.macworld.com/article.php?story=20070528090709539\n\n\nNot exactly what we want here but could worth looking at it in more details\n(VScode plugin)https://github.com/blokhinnv/wikidataqidlabels\n\nQ1 (https://www.wikidata.org/wiki/Q1) Amazing stuff !\n\nHave a look into this API https://www.wikidata.org/w/api.php?action=help&modules=wbsearchentities\n\n\nhttps://www.digitalocean.com/community/tutorials/how-to-create-your-first-visual-studio-code-extension\nhttps://medium.com/@sanik.bajracharya/vscode-how-to-create-your-own-extension-pack-483385644c29\n","n":0.086}}},{"i":459,"$":{"0":{"v":"Scholia","n":1},"1":{"v":"\n\n\n# Scholia\n\nhttps://github.com/fnielsen/scholia\n\nScholia is a python package and webapp for interaction with scholarly information in Wikidata.\n\nhttps://scholia.toolforge.org/\n\n## Interest of Scholia as a curation page for LOTUS data\n\nCan deal with chemical object \n\nhttps://scholia.toolforge.org/inchikey/QOVGHDRCAGYGEB-FFZYJECLSA-N\n\n\n## Contribution \n\nhttps://github.com/fnielsen/scholia/blob/master/CONTRIBUTING.rst\n\n\n\n## Egon's footnote \n\nHave you heard about Wikidata already? \"Use Scholia and Wikidata to find scientific literature\" is a new tutorial from my colleague Lauren Dupuis. https://laurendupuis.github.io/Scholia_tutorial/\n\n## Daniels mail\n\nRegarding the use of Scholia for visualizing structure-taxon relationships, I think this is very possible - we already have aspects for chemicals and for taxa, e.g. as per\nhttps://scholia.toolforge.org/taxon/Q157892\nor\nhttps://scholia.toolforge.org/chemical/Q121802 .\n\nWith regards to forks, the most prominent example is probably\nhttps://ordia.toolforge.org/ ,\nwhich visualizes linguistic information based on the lexeme namespace in Wikidata.\n\nAnother thing to think about would be genome browsers like\nhttp://wikigenomes.org/\nor\nhttps://chlambase.org/ .\n\n\nadding additional SPARQL queries to existing Scholia pages is relatively straightforward (the main issue here is performance), so things like adding \"found in taxon\"-based queries to Scholia pages about compounds or taxa and perhaps also pathways could be solved quickly.\n\nWhat might be even more interesting - but would require a bit more work - would be what we call subaspects, i.e. pages that combine two main classes, like https://scholia.toolforge.org/location/Q1748/topic/Q2539 .\n\nWith that in mind, we could think of things like\nhttps://scholia.toolforge.org/compound/QID1/taxon/QID2\nor\nhttps://scholia.toolforge.org/taxon/QID3/compound/QID4 .\n\nThe work on such subaspects has been described in\nhttps://www.wikidata.org/wiki/Q50813856 for the example of geodata,\nwhich would probably be a good starting point when considering the effort involved.\n\n\n\n## Other links\n\nhttps://cthoyt.com/2021/01/23/updating-the-wikidata-integrator.html\n\nA protocol for adding knowledge to Wikidata, a case report.\nhttps://www.biorxiv.org/content/10.1101/2020.04.05.026336v2.full.pdf\n\n\n## Scholia search examples \n### Combined topics\n\nhttps://scholia.toolforge.org/topics/Q30046,Q1172284\n\nhttps://scholia.toolforge.org/topics/Q33002955,Q1418791\n\nhttps://scholia.toolforge.org/topics/Q33002955,Q420\n\n\n\n\n\n","n":0.065}}},{"i":460,"$":{"0":{"v":"Prefixes","n":1},"1":{"v":"# Wikidata prefixes\n\nhttps://www.wikidata.org/wiki/EntitySchema:E49\n\n\n# list of prefixes for import\nPREFIX bd: <http://www.bigdata.com/rdf#>\nPREFIX cc: <http://creativecommons.org/ns#>\nPREFIX dct: <http://purl.org/dc/terms/>\nPREFIX geo: <http://www.opengis.net/ont/geosparql#>\nPREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\nPREFIX owl: <http://www.w3.org/2002/07/owl#>\nPREFIX p: <http://www.wikidata.org/prop/>\nPREFIX pq: <http://www.wikidata.org/prop/qualifier/>\nPREFIX pqn: <http://www.wikidata.org/prop/qualifier/value-normalized/>\nPREFIX pqv: <http://www.wikidata.org/prop/qualifier/value/>\nPREFIX pr: <http://www.wikidata.org/prop/reference/>\nPREFIX prn: <http://www.wikidata.org/prop/reference/value-normalized/>\nPREFIX prov: <http://www.w3.org/ns/prov#>\nPREFIX prv: <http://www.wikidata.org/prop/reference/value/>\nPREFIX ps: <http://www.wikidata.org/prop/statement/>\nPREFIX psn: <http://www.wikidata.org/prop/statement/value-normalized/>\nPREFIX psv: <http://www.wikidata.org/prop/statement/value/>\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\nPREFIX schema: <http://schema.org/>\nPREFIX skos: <http://www.w3.org/2004/02/skos/core#>\nPREFIX wd: <http://www.wikidata.org/entity/>\nPREFIX wdata: <http://www.wikidata.org/wiki/Special:EntityData/>\nPREFIX wdno: <http://www.wikidata.org/prop/novalue/>\nPREFIX wdref: <http://www.wikidata.org/reference/>\nPREFIX wds: <http://www.wikidata.org/entity/statement/>\nPREFIX wdt: <http://www.wikidata.org/prop/direct/>\nPREFIX wdtn: <http://www.wikidata.org/prop/direct-normalized/>\nPREFIX wdv: <http://www.wikidata.org/value/>\nPREFIX wikibase: <http://wikiba.se/ontology#>\nPREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n","n":0.12}}},{"i":461,"$":{"0":{"v":"Gadget","n":1},"1":{"v":"\n\nThe Gadgets are setup on the commons.js page of a WD user\n\nsee for ex for Adriano https://www.wikidata.org/wiki/User:AdrianoRutz/common.js\n\n\n\n<!DOCTYPE html>\n<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n<head>\n<meta charset=\"UTF-8\"/>\n<title>trigocherrin A - Wikidata</title>\n<script>document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"c53e26a3-3183-4dcc-aa1b-2c192ac390dc\",\"wgCSPNonce\":false,\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Q105674316\",\"wgTitle\":\"Q105674316\",\"wgCurRevisionId\":1730455050,\"wgRevisionId\":1730455050,\"wgArticleId\":101037319,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":\"GrndStt\",\"wgUserGroups\":[\"*\",\"user\",\"autoconfirmed\"],\"wgCategories\":[],\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikibase-item\",\"wgRelevantPageName\":\"Q105674316\",\"wgRelevantArticleId\":101037319,\"wgUserId\":4432768,\"wgUserEditCount\":11553,\"wgUserRegistration\":1594036183000,\"wgIsProbablyEditable\":true,\n\"wgRelevantPageIsProbablyEditable\":true,\"wgRestrictionEdit\":[],\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\"},\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"nearby\":true,\"watchlist\":true,\"tagline\":false},\"wgWMESchemaEditAttemptStepOversample\":false,\"wgWMEPageLength\":8000,\"wgNoticeProject\":\"wikidata\",\"wgNoticeUserData\":{\"registration\":\"20200706114943\"},\"wgVectorDisableSidebarPersistence\":false,\"wgVector2022PreviewPages\":[],\"wgGlobalGroups\":[],\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgULSAcceptLanguageList\":[\"fr-fr\",\"fr\",\"en-us\",\"en\",\"ja\"],\"wgULSBabelLanguages\":[\"fr\",\"es\",\"en\",\"de\"],\"wgULSCurrentAutonym\":\"English\",\"wbIsEditView\":true,\"wbEntityId\":\"Q105674316\",\"wgEditSubmitButtonLabelPublish\":true,\"wbUserSpecifiedLanguages\":[\"de\",\"en\",\"es\",\"fr\"],\"wbCopyright\":{\"version\":\"wikibase-1\",\"messageHtml\":\n\"By clicking \\\"publish\\\", you agree to the \\u003Ca href=\\\"https://foundation.wikimedia.org/wiki/Terms_of_Use\\\" class=\\\"extiw\\\" title=\\\"wikimedia:Terms of Use\\\"\\u003Eterms of use\\u003C/a\\u003E, and you irrevocably agree to release your contribution under the \\u003Ca rel=\\\"nofollow\\\" class=\\\"external text\\\" href=\\\"https://creativecommons.org/publicdomain/zero/1.0/\\\"\\u003ECreative Commons CC0 License\\u003C/a\\u003E.\"},\"wbBadgeItems\":{\"Q17437798\":\"wb-badge-goodarticle\",\"Q17437796\":\"wb-badge-featuredarticle\",\"Q17559452\":\"wb-badge-recommendedarticle\",\"Q17506997\":\"wb-badge-featuredlist\",\"Q17580674\":\"wb-badge-featuredportal\",\"Q20748091\":\"wb-badge-notproofread\",\"Q20748094\":\"wb-badge-problematic\",\"Q20748092\":\"wb-badge-proofread\",\"Q20748093\":\"wb-badge-validated\",\"Q28064618\":\"wb-badge-digitaldocument\",\"Q51759403\":\"wb-badge-goodlist\",\"Q70893996\":\"wb-badge-redirect-sitelink\",\"Q70894304\":\"wb-badge-redirect-intentional-sitelink\"},\"wbMultiLingualStringLimit\":250,\"wbTaintedReferencesEnabled\":true,\n\"wgULSPosition\":\"personal\",\"wgULSisCompactLinksEnabled\":true,\"wgEchoSeenTime\":{\"alert\":\"2022-09-01T06:01:18Z\",\"notice\":\"2022-08-30T10:41:02Z\"}};RLSTATE={\"ext.globalCssJs.user.styles\":\"ready\",\"site.styles\":\"ready\",\"user.styles\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"user\":\"loading\",\"user.options\":\"loading\",\"wikibase.common\":\"ready\",\"jquery.wikibase.toolbar.styles\":\"ready\",\"skins.vector.styles.legacy\":\"ready\",\"jquery.makeCollapsible.styles\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"ext.echo.styles.badge\":\"ready\",\"oojs-ui.styles.icons-alerts\":\"ready\",\"ext.wikidata-org.badges\":\"ready\",\"ext.wikimediaBadges\":\"ready\",\"ext.uls.pt\":\"ready\"};RLPAGEMODULES=[\"wikibase.entityPage.entityLoaded\",\"wikibase.ui.entityViewInit\",\"site\",\"mediawiki.page.ready\",\"jquery.makeCollapsible\",\"skins.vector.legacy.js\",\"mediawiki.page.watch.ajax\",\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visualEditor.targetLoader\",\"ext.citoid.wikibase.init\",\"ext.echo.init\",\"ext.eventLogging\",\n\"ext.wikimediaEvents\",\"ext.wikimediaEvents.wikibase\",\"ext.navigationTiming\",\"wikibase.ui.entitysearch\",\"propertySuggester.suggestions\",\"wikibase.quality.constraints.suggestions\",\"wikibase.quality.constraints.gadget\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\"ext.gadget.Merge\",\"ext.gadget.Search\",\"ext.gadget.AuthorityControl\",\"ext.gadget.SiteIdToInterwiki\",\"ext.gadget.ProtectionIndicators\",\"ext.gadget.relateditems\",\"ext.gadget.imagelinks\",\"ext.gadget.NewSection\",\"ext.gadget.formWizard\",\"ext.centralauth.centralautologin.clearcookie\",\"ext.uls.compactlinks\",\"ext.uls.interface\"];</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.load(\"/w/load.php?lang=en\\u0026modules=user\\u0026skin=vector\\u0026user=GrndStt\\u0026version=15r5a\");mw.loader.implement(\"user.options@12s5i\",function($,jQuery,require,module){mw.user.tokens.set({\"patrolToken\":\"6dbbb97b9f650071e1ce1164f8d2e91e6325c550+\\\\\",\"watchToken\":\"c1f229a7477c4390e535298da3c598f66325c550+\\\\\",\"csrfToken\":\"9a793a68fa6497381639659a4e28772b6325c550+\\\\\"});mw.user.options.set({\"VectorSkinVersion\":\"1\",\"beta-feature-flow-user-talk-page\":0,\"discussiontools-betaenable\":\"1\",\"discussiontools-editmode\":\"source\",\"discussiontools-newtopictool-hint-shown\":\"1\",\"discussiontools-newtopictool-opened\":\"1\",\"discussiontools-showadvanced\":\"1\",\"echo-subscriptions-email-edit-thank\":\"1\",\"echo-subscriptions-email-edit-user-talk\":1,\"echo-subscriptions-email-mention\":\"1\",\"echo-subscriptions-web-article-linked\":\"1\",\"echo-subscriptions-web-reverted\":0,\"gadget-Merge\":\"1\",\"gadget-relateditems\":\"1\",\"ipinfo-beta-feature-enable\":0,\"rcenhancedfilters-seen-highlight-button-counter\":\"6\",\"rcenhancedfilters-seen-tour\":\"1\",\"rcenhancedfilters-tried-highlight\":\"1\",\"rcfilters-limit\":\"500\",\n\"rcfilters-rc-collapsed\":0,\"rcfilters-saved-queries\":\"{\\\"queries\\\":{},\\\"version\\\":\\\"2\\\"}\",\"rcfilters-wl-collapsed\":0,\"rcfilters-wl-saved-queries\":\"{\\\"queries\\\":{},\\\"version\\\":\\\"2\\\"}\",\"twl-notified\":\"yes\",\"twocolconflict\":0,\"uls-preferences\":\"{\\\"ime\\\":{\\\"language\\\":\\\"en\\\",\\\"previousLanguages\\\":[\\\"en\\\"],\\\"previousInputMethods\\\":[],\\\"imes\\\":{\\\"en\\\":\\\"system\\\"}}}\",\"usecodemirror-colorblind\":0,\"usenewrc\":\"1\",\"visualeditor-hidebetawelcome\":\"1\",\"wb-acknowledgedcopyrightversion\":\"wikibase-1\",\"wikibase-entitytermsview-showEntitytermslistview\":\"1\",\"wikieditor-realtime-preview\":0,\"wlenhancedfilters-seen-tour\":\"1\"});});});</script>\n<link rel=\"stylesheet\" href=\"/w/load.php?lang=en&amp;modules=ext.echo.styles.badge%7Cext.uls.pt%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikidata-org.badges%7Cext.wikimediaBadges%7Cjquery.makeCollapsible.styles%7Cjquery.wikibase.toolbar.styles%7Coojs-ui.styles.icons-alerts%7Cskins.vector.styles.legacy%7Cwikibase.common&amp;only=styles&amp;skin=vector\"/>\n<script async=\"\" src=\"/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector\"></script>\n<meta name=\"ResourceLoaderDynamicStyles\" content=\"\"/>\n<link rel=\"stylesheet\" href=\"/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector\"/>\n<meta name=\"generator\" content=\"MediaWiki 1.40.0-wmf.1\"/>\n<meta name=\"referrer\" content=\"origin\"/>\n<meta name=\"referrer\" content=\"origin-when-crossorigin\"/>\n<meta name=\"referrer\" content=\"origin-when-cross-origin\"/>\n<meta name=\"format-detection\" content=\"telephone=no\"/>\n<meta property=\"og:title\" content=\"trigocherrin A\"/>\n<meta name=\"description\" content=\"chemical compound\"/>\n<meta property=\"og:description\" content=\"chemical compound\"/>\n<meta property=\"og:type\" content=\"summary\"/>\n<meta name=\"viewport\" content=\"width=1000\"/>\n<link rel=\"alternate\" href=\"https://www.wikidata.org/wiki/Special:EntityData/Q105674316.json\" type=\"application/json\"/>\n<link rel=\"alternate\" href=\"https://www.wikidata.org/wiki/Special:EntityData/Q105674316.php\" type=\"application/vnd.php.serialized\"/>\n<link rel=\"alternate\" href=\"https://www.wikidata.org/wiki/Special:EntityData/Q105674316.n3\" type=\"text/n3\"/>\n<link rel=\"alternate\" href=\"https://www.wikidata.org/wiki/Special:EntityData/Q105674316.ttl\" type=\"text/turtle\"/>\n<link rel=\"alternate\" href=\"https://www.wikidata.org/wiki/Special:EntityData/Q105674316.nt\" type=\"application/n-triples\"/>\n<link rel=\"alternate\" href=\"https://www.wikidata.org/wiki/Special:EntityData/Q105674316.rdf\" type=\"application/rdf+xml\"/>\n<link rel=\"alternate\" href=\"https://www.wikidata.org/wiki/Special:EntityData/Q105674316.jsonld\" type=\"application/ld+json\"/>\n<link rel=\"alternate\" media=\"only screen and (max-width: 720px)\" href=\"//m.wikidata.org/wiki/Q105674316\"/>\n<link rel=\"alternate\" type=\"application/x-wiki\" title=\"Edit\" href=\"/w/index.php?title=Q105674316&amp;action=edit\"/>\n<link rel=\"apple-touch-icon\" href=\"/static/apple-touch/wikidata.png\"/>\n<link rel=\"icon\" href=\"/static/favicon/wikidata.ico\"/>\n<link rel=\"search\" type=\"application/opensearchdescription+xml\" href=\"/w/opensearch_desc.php\" title=\"Wikidata (en)\"/>\n<link rel=\"EditURI\" type=\"application/rsd+xml\" href=\"//www.wikidata.org/w/api.php?action=rsd\"/>\n<link rel=\"license\" href=\"/wiki/Wikidata:Copyright\"/>\n<link rel=\"canonical\" href=\"https://www.wikidata.org/wiki/Q105674316\"/>\n<link rel=\"dns-prefetch\" href=\"//meta.wikimedia.org\" />\n</head>\n<body class=\"mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Q105674316 rootpage-Q105674316 skin-vector action-view wb-entitypage wb-itempage wb-itempage-Q105674316 skin-vector-legacy vector-toc-not-collapsed vector-feature-language-in-header-disabled vector-feature-language-in-main-page-header-disabled vector-feature-language-alert-in-sidebar-disabled vector-feature-sticky-header-disabled vector-feature-sticky-header-edit-disabled vector-feature-table-of-contents-disabled vector-feature-visual-enhancement-next-disabled\"><div id=\"mw-page-base\" class=\"noprint\"></div>\n<div id=\"mw-head-base\" class=\"noprint\"></div>\n<div id=\"content\" class=\"mw-body\" role=\"main\">\n\t<a id=\"top\"></a>\n\t<div id=\"siteNotice\"><!-- CentralNotice --></div>\n\t<div class=\"mw-indicators\">\n\t</div>\n\t<h1 id=\"firstHeading\" class=\"firstHeading mw-first-heading\"><span class=\"wikibase-title \">\n<span class=\"wikibase-title-label\">trigocherrin A</span>\n<span class=\"wikibase-title-id\">(Q105674316)</span>\n</span></h1>\n\t<div id=\"bodyContent\" class=\"vector-body\">\n\t\t<div id=\"siteSub\" class=\"noprint\">From Wikidata</div>\n\t\t<div id=\"contentSub\"></div>\n\t\t<div id=\"contentSub2\"></div>\n\t\t\n\t\t<div id=\"jump-to-nav\"></div>\n\t\t<a class=\"mw-jump-link\" href=\"#mw-head\">Jump to navigation</a>\n\t\t<a class=\"mw-jump-link\" href=\"#searchInput\">Jump to search</a>\n\t\t<div id=\"mw-content-text\" class=\"mw-body-content mw-content-ltr\" lang=\"en\" dir=\"ltr\"><div id=\"wb-item-Q105674316\" class=\"wikibase-entityview wb-item\" lang=\"en\" dir=\"ltr\">\n<div class=\"wikibase-entityview-main\"><div class=\"wikibase-entitytermsview\">\n<div class=\"wikibase-entitytermsview-heading\">\n<div class=\"wikibase-entitytermsview-heading-description \">chemical compound</div><div class=\"wikibase-entitytermsview-heading-aliases wb-empty\"></div>\n</div>\n<span class=\"wikibase-toolbar-container\"><span class=\"wikibase-toolbar-item wikibase-toolbar \"><span class=\"wikibase-toolbar-item wikibase-toolbar-button wikibase-toolbar-button-edit\"><a href=\"/wiki/Special:SetLabelDescriptionAliases/Q105674316/en\" title=\"\"><span class=\"wb-icon\"></span>edit</a></span></span></span>\n<div class=\"wikibase-entitytermsview-entitytermsforlanguagelistview \"><table class=\"wikibase-entitytermsforlanguagelistview\">\n<thead class=\"wikibase-entitytermsforlanguagelistview-header\">\n<tr class=\"wikibase-entitytermsforlanguagelistview-header-row\">\n<th scope=\"col\" class=\"wikibase-entitytermsforlanguagelistview-cell wikibase-entitytermsforlanguagelistview-language\">Language</th>\n<th scope=\"col\" class=\"wikibase-entitytermsforlanguagelistview-cell wikibase-entitytermsforlanguagelistview-label\">Label</th>\n<th scope=\"col\" class=\"wikibase-entitytermsforlanguagelistview-cell wikibase-entitytermsforlanguagelistview-description\">Description</th>\n<th scope=\"col\" class=\"wikibase-entitytermsforlanguagelistview-cell wikibase-entitytermsforlanguagelistview-aliases\">Also known as</th>\n</tr>\n</thead>\n<tbody class=\"wikibase-entitytermsforlanguagelistview-listview\"><tr class=\"wikibase-entitytermsforlanguageview wikibase-entitytermsforlanguageview-en\" >\n<th class=\"wikibase-entitytermsforlanguageview-language\">English</th>\n<td class=\"wikibase-entitytermsforlanguageview-label\"><div class=\"wikibase-labelview \" dir=\"ltr\" lang=\"en\"><div class=\"wikibase-labelview-container\"><span class=\"wikibase-labelview-text\">trigocherrin A</span></div></div></td>\n<td class=\"wikibase-entitytermsforlanguageview-description\"><div class=\"wikibase-descriptionview \" dir=\"ltr\" lang=\"en\"><div class=\"wikibase-descriptionview-container\"><span class=\"wikibase-descriptionview-text\">chemical compound</span></div></div></td>\n<td class=\"wikibase-entitytermsforlanguageview-aliases\"><div class=\"wikibase-aliasesview wb-empty\">\n<ul class=\"wikibase-aliasesview-list\" dir=\"\" lang=\"en\"></ul>\n\n</div></td>\n\n</tr><tr class=\"wikibase-entitytermsforlanguageview wikibase-entitytermsforlanguageview-de\" >\n<th class=\"wikibase-entitytermsforlanguageview-language\">German</th>\n<td class=\"wikibase-entitytermsforlanguageview-label\"><div class=\"wikibase-labelview wb-empty\" dir=\"ltr\" lang=\"en\"><div class=\"wikibase-labelview-container\"><span class=\"wikibase-labelview-text\">No label defined</span></div></div></td>\n<td class=\"wikibase-entitytermsforlanguageview-description\"><div class=\"wikibase-descriptionview \" dir=\"ltr\" lang=\"de\"><div class=\"wikibase-descriptionview-container\"><span class=\"wikibase-descriptionview-text\">chemische Verbindung</span></div></div></td>\n<td class=\"wikibase-entitytermsforlanguageview-aliases\"><div class=\"wikibase-aliasesview wb-empty\">\n<ul class=\"wikibase-aliasesview-list\" dir=\"\" lang=\"de\"></ul>\n\n</div></td>\n\n</tr><tr class=\"wikibase-entitytermsforlanguageview wikibase-entitytermsforlanguageview-es\" >\n<th class=\"wikibase-entitytermsforlanguageview-language\">Spanish</th>\n<td class=\"wikibase-entitytermsforlanguageview-label\"><div class=\"wikibase-labelview wb-empty\" dir=\"ltr\" lang=\"en\"><div class=\"wikibase-labelview-container\"><span class=\"wikibase-labelview-text\">No label defined</span></div></div></td>\n<td class=\"wikibase-entitytermsforlanguageview-description\"><div class=\"wikibase-descriptionview \" dir=\"ltr\" lang=\"es\"><div class=\"wikibase-descriptionview-container\"><span class=\"wikibase-descriptionview-text\">compuesto químico</span></div></div></td>\n<td class=\"wikibase-entitytermsforlanguageview-aliases\"><div class=\"wikibase-aliasesview wb-empty\">\n<ul class=\"wikibase-aliasesview-list\" dir=\"\" lang=\"es\"></ul>\n\n</div></td>\n\n</tr><tr class=\"wikibase-entitytermsforlanguageview wikibase-entitytermsforlanguageview-fr\" >\n<th class=\"wikibase-entitytermsforlanguageview-language\">French</th>\n<td class=\"wikibase-entitytermsforlanguageview-label\"><div class=\"wikibase-labelview wb-empty\" dir=\"ltr\" lang=\"en\"><div class=\"wikibase-labelview-container\"><span class=\"wikibase-labelview-text\">No label defined</span></div></div></td>\n<td class=\"wikibase-entitytermsforlanguageview-description\"><div class=\"wikibase-descriptionview \" dir=\"ltr\" lang=\"fr\"><div class=\"wikibase-descriptionview-container\"><span class=\"wikibase-descriptionview-text\">composé chimique</span></div></div></td>\n<td class=\"wikibase-entitytermsforlanguageview-aliases\"><div class=\"wikibase-aliasesview wb-empty\">\n<ul class=\"wikibase-aliasesview-list\" dir=\"\" lang=\"fr\"></ul>\n\n</div></td>\n\n</tr></tbody>\n</table></div>\n</div><div id=\"toc\"></div><h2 class=\"wb-section-heading section-heading wikibase-statements\" dir=\"auto\"><span class=\"mw-headline\" id=\"claims\">Statements</span></h2><div class=\"wikibase-statementgrouplistview\"><div class=\"wikibase-listview\"><div class=\"wikibase-statementgroupview\" id=\"P31\" data-property-id=\"P31\">\n<div class=\"wikibase-statementgroupview-property\">\n<div class=\"wikibase-statementgroupview-property-label\" dir=\"auto\"><a title=\"Property:P31\" href=\"/wiki/Property:P31\">instance of</a></div>\n</div>\n<div class=\"wikibase-statementlistview\">\n<div class=\"wikibase-statementlistview-listview\">\n<div id=\"Q105674316$5fde4bc0-4aa3-43ad-f981-5154f0a8c8d8\" class=\"wikibase-statementview wikibase-statement-Q105674316$5fde4bc0-4aa3-43ad-f981-5154f0a8c8d8 wb-normal\">\n<div class=\"wikibase-statementview-rankselector\"><div class=\"wikibase-rankselector ui-state-disabled\">\n<span class=\"ui-icon ui-icon-rankselector wikibase-rankselector-normal\" title=\"Normal rank\"></span>\n</div></div>\n<div class=\"wikibase-statementview-mainsnak-container\">\n<div class=\"wikibase-statementview-mainsnak\" dir=\"auto\"><div class=\"wikibase-snakview wikibase-snakview-e823b98d1498aa78e139709b1b02f5decd75c887\">\n<div class=\"wikibase-snakview-property-container\">\n<div class=\"wikibase-snakview-property\" dir=\"auto\"></div>\n</div>\n<div class=\"wikibase-snakview-value-container\" dir=\"auto\">\n<div class=\"wikibase-snakview-typeselector\"></div>\n<div class=\"wikibase-snakview-body\">\n<div class=\"wikibase-snakview-value wikibase-snakview-variation-valuesnak\"><a title=\"Q11173\" href=\"/wiki/Q11173\">chemical compound</a></div>\n<div class=\"wikibase-snakview-indicators\"></div>\n</div>\n</div>\n</div></div>\n<div class=\"wikibase-statementview-qualifiers\"></div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n<div class=\"wikibase-statementview-references-container\">\n<div class=\"wikibase-statementview-references-heading\">0 references</div>\n<div class=\"wikibase-statementview-references \"></div>\n</div>\n</div><div id=\"Q105674316$030F9BFE-CF4C-4264-8E31-17F138E2F4A0\" class=\"wikibase-statementview wikibase-statement-Q105674316$030F9BFE-CF4C-4264-8E31-17F138E2F4A0 wb-normal\">\n<div class=\"wikibase-statementview-rankselector\"><div class=\"wikibase-rankselector ui-state-disabled\">\n<span class=\"ui-icon ui-icon-rankselector wikibase-rankselector-normal\" title=\"Normal rank\"></span>\n</div></div>\n<div class=\"wikibase-statementview-mainsnak-container\">\n<div class=\"wikibase-statementview-mainsnak\" dir=\"auto\"><div class=\"wikibase-snakview wikibase-snakview-fc359dbdb02acd1ad3a81f1a71bfb70f620c6bd2\">\n<div class=\"wikibase-snakview-property-container\">\n<div class=\"wikibase-snakview-property\" dir=\"auto\"></div>\n</div>\n<div class=\"wikibase-snakview-value-container\" dir=\"auto\">\n<div class=\"wikibase-snakview-typeselector\"></div>\n<div class=\"wikibase-snakview-body\">\n<div class=\"wikibase-snakview-value wikibase-snakview-variation-valuesnak\"><a title=\"Q108430166\" href=\"/wiki/Q108430166\">daphnane diterpenoid</a></div>\n<div class=\"wikibase-snakview-indicators\"></div>\n</div>\n</div>\n</div></div>\n<div class=\"wikibase-statementview-qualifiers\"></div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n<div class=\"wikibase-statementview-references-container\">\n<div class=\"wikibase-statementview-references-heading\">1 reference</div>\n<div class=\"wikibase-statementview-references wikibase-initially-collapsed\"><div class=\"wikibase-listview\"><div class=\"wikibase-referenceview wikibase-referenceview-2bc481ce9b67ca7898070f92cdae9d7b3b0f65be\">\n<div class=\"wikibase-referenceview-heading\"></div>\n<div class=\"wikibase-referenceview-listview\"><div class=\"wikibase-snaklistview\">\n<div class=\"wikibase-snaklistview-listview\"><div class=\"wikibase-snakview wikibase-snakview-bb30e9659b9a588b20f91c8a9efa935b002982db\">\n<div class=\"wikibase-snakview-property-container\">\n<div class=\"wikibase-snakview-property\" dir=\"auto\"><a title=\"Property:P3452\" href=\"/wiki/Property:P3452\">inferred from</a></div>\n</div>\n<div class=\"wikibase-snakview-value-container\" dir=\"auto\">\n<div class=\"wikibase-snakview-typeselector\"></div>\n<div class=\"wikibase-snakview-body\">\n<div class=\"wikibase-snakview-value wikibase-snakview-variation-valuesnak\"><a title=\"Q108430166\" href=\"/wiki/Q108430166\">daphnane diterpenoid</a></div>\n<div class=\"wikibase-snakview-indicators\"></div>\n</div>\n</div>\n</div></div>\n</div></div>\n</div></div></div>\n</div>\n</div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n</div>\n</div><div class=\"wikibase-statementgroupview\" id=\"P274\" data-property-id=\"P274\">\n<div class=\"wikibase-statementgroupview-property\">\n<div class=\"wikibase-statementgroupview-property-label\" dir=\"auto\"><a title=\"Property:P274\" href=\"/wiki/Property:P274\">chemical formula</a></div>\n</div>\n<div class=\"wikibase-statementlistview\">\n<div class=\"wikibase-statementlistview-listview\">\n<div id=\"Q105674316$B1A2E5D4-C200-43B4-BFD4-4DA77E13092D\" class=\"wikibase-statementview wikibase-statement-Q105674316$B1A2E5D4-C200-43B4-BFD4-4DA77E13092D wb-normal\">\n<div class=\"wikibase-statementview-rankselector\"><div class=\"wikibase-rankselector ui-state-disabled\">\n<span class=\"ui-icon ui-icon-rankselector wikibase-rankselector-normal\" title=\"Normal rank\"></span>\n</div></div>\n<div class=\"wikibase-statementview-mainsnak-container\">\n<div class=\"wikibase-statementview-mainsnak\" dir=\"auto\"><div class=\"wikibase-snakview wikibase-snakview-1d19ead669b8887be50cfd48886093d5e2f1558f\">\n<div class=\"wikibase-snakview-property-container\">\n<div class=\"wikibase-snakview-property\" dir=\"auto\"></div>\n</div>\n<div class=\"wikibase-snakview-value-container\" dir=\"auto\">\n<div class=\"wikibase-snakview-typeselector\"></div>\n<div class=\"wikibase-snakview-body\">\n<div class=\"wikibase-snakview-value wikibase-snakview-variation-valuesnak\">C₃₈H₃₆Cl₂O₁₂</div>\n<div class=\"wikibase-snakview-indicators\"></div>\n</div>\n</div>\n</div></div>\n<div class=\"wikibase-statementview-qualifiers\"></div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n<div class=\"wikibase-statementview-references-container\">\n<div class=\"wikibase-statementview-references-heading\">0 references</div>\n<div class=\"wikibase-statementview-references \"></div>\n</div>\n</div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n</div>\n</div><div class=\"wikibase-statementgroupview\" id=\"P233\" data-property-id=\"P233\">\n<div class=\"wikibase-statementgroupview-property\">\n<div class=\"wikibase-statementgroupview-property-label\" dir=\"auto\"><a title=\"Property:P233\" href=\"/wiki/Property:P233\">canonical SMILES</a></div>\n</div>\n<div class=\"wikibase-statementlistview\">\n<div class=\"wikibase-statementlistview-listview\">\n<div id=\"Q105674316$f36f0b65-4371-5a66-f3a8-851bdb81af9f\" class=\"wikibase-statementview wikibase-statement-Q105674316$f36f0b65-4371-5a66-f3a8-851bdb81af9f wb-normal\">\n<div class=\"wikibase-statementview-rankselector\"><div class=\"wikibase-rankselector ui-state-disabled\">\n<span class=\"ui-icon ui-icon-rankselector wikibase-rankselector-normal\" title=\"Normal rank\"></span>\n</div></div>\n<div class=\"wikibase-statementview-mainsnak-container\">\n<div class=\"wikibase-statementview-mainsnak\" dir=\"auto\"><div class=\"wikibase-snakview wikibase-snakview-0c1351041af25f73eb28630c40051737f72bff01\">\n<div class=\"wikibase-snakview-property-container\">\n<div class=\"wikibase-snakview-property\" dir=\"auto\"></div>\n</div>\n<div class=\"wikibase-snakview-value-container\" dir=\"auto\">\n<div class=\"wikibase-snakview-typeselector\"></div>\n<div class=\"wikibase-snakview-body\">\n<div class=\"wikibase-snakview-value wikibase-snakview-variation-valuesnak\">CC1C2C(C3C4C1(C5=CC(=C(Cl)Cl)C(C5(C(C6(C4O6)COC(=O)C)OC(=O)C)O)OC(=O)C7=CC=CC=C7)OC(O2)(O3)C8=CC=CC=C8)(C(=C)C)O</div>\n<div class=\"wikibase-snakview-indicators\"></div>\n</div>\n</div>\n</div></div>\n<div class=\"wikibase-statementview-qualifiers\"></div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n<div class=\"wikibase-statementview-references-container\">\n<div class=\"wikibase-statementview-references-heading\">0 references</div>\n<div class=\"wikibase-statementview-references \"></div>\n</div>\n</div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n</div>\n</div><div class=\"wikibase-statementgroupview\" id=\"P2017\" data-property-id=\"P2017\">\n<div class=\"wikibase-statementgroupview-property\">\n<div class=\"wikibase-statementgroupview-property-label\" dir=\"auto\"><a title=\"Property:P2017\" href=\"/wiki/Property:P2017\">isomeric SMILES</a></div>\n</div>\n<div class=\"wikibase-statementlistview\">\n<div class=\"wikibase-statementlistview-listview\">\n<div id=\"Q105674316$70096e67-40d0-5db2-f349-e8dc98c77567\" class=\"wikibase-statementview wikibase-statement-Q105674316$70096e67-40d0-5db2-f349-e8dc98c77567 wb-normal\">\n<div class=\"wikibase-statementview-rankselector\"><div class=\"wikibase-rankselector ui-state-disabled\">\n<span class=\"ui-icon ui-icon-rankselector wikibase-rankselector-normal\" title=\"Normal rank\"></span>\n</div></div>\n<div class=\"wikibase-statementview-mainsnak-container\">\n<div class=\"wikibase-statementview-mainsnak\" dir=\"auto\"><div class=\"wikibase-snakview wikibase-snakview-3a345b032144c63c3de8fac1403b6ef83a5aa06c\">\n<div class=\"wikibase-snakview-property-container\">\n<div class=\"wikibase-snakview-property\" dir=\"auto\"></div>\n</div>\n<div class=\"wikibase-snakview-value-container\" dir=\"auto\">\n<div class=\"wikibase-snakview-typeselector\"></div>\n<div class=\"wikibase-snakview-body\">\n<div class=\"wikibase-snakview-value wikibase-snakview-variation-valuesnak\">C[C@@H]1C2[C@]([C@H]3[C@H]4[C@]1(C5=CC(=C(Cl)Cl)[C@@H]([C@]5([C@@H]([C@@]6([C@H]4O6)COC(=O)C)OC(=O)C)O)OC(=O)C7=CC=CC=C7)OC(O3)(O2)C8=CC=CC=C8)(C(=C)C)O</div>\n<div class=\"wikibase-snakview-indicators\"></div>\n</div>\n</div>\n</div></div>\n<div class=\"wikibase-statementview-qualifiers\"></div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n<div class=\"wikibase-statementview-references-container\">\n<div class=\"wikibase-statementview-references-heading\">0 references</div>\n<div class=\"wikibase-statementview-references \"></div>\n</div>\n</div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n</div>\n</div><div class=\"wikibase-statementgroupview\" id=\"P703\" data-property-id=\"P703\">\n<div class=\"wikibase-statementgroupview-property\">\n<div class=\"wikibase-statementgroupview-property-label\" dir=\"auto\"><a title=\"Property:P703\" href=\"/wiki/Property:P703\">found in taxon</a></div>\n</div>\n<div class=\"wikibase-statementlistview\">\n<div class=\"wikibase-statementlistview-listview\">\n<div id=\"Q105674316$e336d4d2-4282-ecc2-85a2-b25411d8a95c\" class=\"wikibase-statementview wikibase-statement-Q105674316$e336d4d2-4282-ecc2-85a2-b25411d8a95c wb-normal\">\n<div class=\"wikibase-statementview-rankselector\"><div class=\"wikibase-rankselector ui-state-disabled\">\n<span class=\"ui-icon ui-icon-rankselector wikibase-rankselector-normal\" title=\"Normal rank\"></span>\n</div></div>\n<div class=\"wikibase-statementview-mainsnak-container\">\n<div class=\"wikibase-statementview-mainsnak\" dir=\"auto\"><div class=\"wikibase-snakview wikibase-snakview-38a3933c80a9eee9e203bb4d62ede5271b665c96\">\n<div class=\"wikibase-snakview-property-container\">\n<div class=\"wikibase-snakview-property\" dir=\"auto\"></div>\n</div>\n<div class=\"wikibase-snakview-value-container\" dir=\"auto\">\n<div class=\"wikibase-snakview-typeselector\"></div>\n<div class=\"wikibase-snakview-body\">\n<div class=\"wikibase-snakview-value wikibase-snakview-variation-valuesnak\"><a title=\"Q3006048\" href=\"/wiki/Q3006048\">Trigonostemon cherrieri</a></div>\n<div class=\"wikibase-snakview-indicators\"></div>\n</div>\n</div>\n</div></div>\n<div class=\"wikibase-statementview-qualifiers\"></div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n<div class=\"wikibase-statementview-references-container\">\n<div class=\"wikibase-statementview-references-heading\">1 reference</div>\n<div class=\"wikibase-statementview-references wikibase-initially-collapsed\"><div class=\"wikibase-listview\"><div class=\"wikibase-referenceview wikibase-referenceview-07f736c8060f7800732830a4b671900b0aa37bd3\">\n<div class=\"wikibase-referenceview-heading\"></div>\n<div class=\"wikibase-referenceview-listview\"><div class=\"wikibase-snaklistview\">\n<div class=\"wikibase-snaklistview-listview\"><div class=\"wikibase-snakview wikibase-snakview-041fad37d58be4cbaba0ec0b86bcbf3bb0a0808f\">\n<div class=\"wikibase-snakview-property-container\">\n<div class=\"wikibase-snakview-property\" dir=\"auto\"><a title=\"Property:P248\" href=\"/wiki/Property:P248\">stated in</a></div>\n</div>\n<div class=\"wikibase-snakview-value-container\" dir=\"auto\">\n<div class=\"wikibase-snakview-typeselector\"></div>\n<div class=\"wikibase-snakview-body\">\n<div class=\"wikibase-snakview-value wikibase-snakview-variation-valuesnak\"><a title=\"Q83059010\" href=\"/wiki/Q83059010\">Trigocherrin A, the first natural chlorinated daphnane diterpene orthoester from Trigonostemon cherrieri</a></div>\n<div class=\"wikibase-snakview-indicators\"></div>\n</div>\n</div>\n</div></div>\n</div></div>\n</div></div></div>\n</div>\n</div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n</div>\n</div></div></div><h2 class=\"wb-section-heading section-heading wikibase-statements wikibase-statements-identifiers\" dir=\"auto\"><span class=\"mw-headline\" id=\"identifiers\">Identifiers</span></h2><div class=\"wikibase-statementgrouplistview\"><div class=\"wikibase-listview\"><div class=\"wikibase-statementgroupview\" id=\"P234\" data-property-id=\"P234\">\n<div class=\"wikibase-statementgroupview-property\">\n<div class=\"wikibase-statementgroupview-property-label\" dir=\"auto\"><a title=\"Property:P234\" href=\"/wiki/Property:P234\">InChI</a></div>\n</div>\n<div class=\"wikibase-statementlistview\">\n<div class=\"wikibase-statementlistview-listview\">\n<div id=\"Q105674316$76d9125d-42fb-0fab-a3f9-3d06c71d9df7\" class=\"wikibase-statementview wikibase-statement-Q105674316$76d9125d-42fb-0fab-a3f9-3d06c71d9df7 wb-normal\">\n<div class=\"wikibase-statementview-rankselector\"><div class=\"wikibase-rankselector ui-state-disabled\">\n<span class=\"ui-icon ui-icon-rankselector wikibase-rankselector-normal\" title=\"Normal rank\"></span>\n</div></div>\n<div class=\"wikibase-statementview-mainsnak-container\">\n<div class=\"wikibase-statementview-mainsnak\" dir=\"auto\"><div class=\"wikibase-snakview wikibase-snakview-b0b4dcfbbb2c0028b10b31a7476eb5b86df3ec93\">\n<div class=\"wikibase-snakview-property-container\">\n<div class=\"wikibase-snakview-property\" dir=\"auto\"></div>\n</div>\n<div class=\"wikibase-snakview-value-container\" dir=\"auto\">\n<div class=\"wikibase-snakview-typeselector\"></div>\n<div class=\"wikibase-snakview-body\">\n<div class=\"wikibase-snakview-value wikibase-snakview-variation-valuesnak\"><a class=\"wb-external-id external\" href=\"https://chemapps.stolaf.edu/jmol/jmol.php?&amp;model=InChI%3D1S/C38H36Cl2O12/c1-18%282%2935%2844%2927-19%283%2937-25-16-24%2831%2839%2940%2928%2848-32%2843%2922-12-8-6-9-13-22%2936%2825%2C45%2933%2847-21%285%2942%2934%2817-46-20%284%2941%2929%2849-34%2926%2837%2930%2835%2951-38%2850-27%2C52-37%2923-14-10-7-11-15-23/h6-16%2C19%2C26-30%2C33%2C44-45H%2C1%2C17H2%2C2-5H3/t19-%2C26%2B%2C27%3F%2C28%2B%2C29%2B%2C30-%2C33-%2C34%2B%2C35%2B%2C36-%2C37%2B%2C38%3F/m1/s1\" rel=\"nofollow\">InChI=1S/C38H36Cl2O12/c1-18(2)35(44)27-19(3)37-25-16-24(31(39)40)28(48-32(43)22-12-8-6-9-13-22)36(25,45)33(47-21(5)42)34(17-46-20(4)41)29(49-34)26(37)30(35)51-38(50-27,52-37)23-14-10-7-11-15-23/h6-16,19,26-30,33,44-45H,1,17H2,2-5H3/t19-,26+,27?,28+,29+,30-,33-,34+,35+,36-,37+,38?/m1/s1</a></div>\n<div class=\"wikibase-snakview-indicators\"></div>\n</div>\n</div>\n</div></div>\n<div class=\"wikibase-statementview-qualifiers\"></div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n<div class=\"wikibase-statementview-references-container\">\n<div class=\"wikibase-statementview-references-heading\">0 references</div>\n<div class=\"wikibase-statementview-references \"></div>\n</div>\n</div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n</div>\n</div><div class=\"wikibase-statementgroupview\" id=\"P235\" data-property-id=\"P235\">\n<div class=\"wikibase-statementgroupview-property\">\n<div class=\"wikibase-statementgroupview-property-label\" dir=\"auto\"><a title=\"Property:P235\" href=\"/wiki/Property:P235\">InChIKey</a></div>\n</div>\n<div class=\"wikibase-statementlistview\">\n<div class=\"wikibase-statementlistview-listview\">\n<div id=\"Q105674316$970f629e-4c0f-0f2c-dbda-a1367eae1000\" class=\"wikibase-statementview wikibase-statement-Q105674316$970f629e-4c0f-0f2c-dbda-a1367eae1000 wb-normal\">\n<div class=\"wikibase-statementview-rankselector\"><div class=\"wikibase-rankselector ui-state-disabled\">\n<span class=\"ui-icon ui-icon-rankselector wikibase-rankselector-normal\" title=\"Normal rank\"></span>\n</div></div>\n<div class=\"wikibase-statementview-mainsnak-container\">\n<div class=\"wikibase-statementview-mainsnak\" dir=\"auto\"><div class=\"wikibase-snakview wikibase-snakview-71c6ecf9f874bc5646a9b37c7d7bc3a9c86ffb37\">\n<div class=\"wikibase-snakview-property-container\">\n<div class=\"wikibase-snakview-property\" dir=\"auto\"></div>\n</div>\n<div class=\"wikibase-snakview-value-container\" dir=\"auto\">\n<div class=\"wikibase-snakview-typeselector\"></div>\n<div class=\"wikibase-snakview-body\">\n<div class=\"wikibase-snakview-value wikibase-snakview-variation-valuesnak\"><a class=\"wb-external-id external\" href=\"https://www.ncbi.nlm.nih.gov/sites/entrez?cmd=search&amp;db=pccompound&amp;term=%22QOVGHDRCAGYGEB-FFZYJECLSA-N%22%5BInChIKey%5D\" rel=\"nofollow\">QOVGHDRCAGYGEB-FFZYJECLSA-N</a></div>\n<div class=\"wikibase-snakview-indicators\"></div>\n</div>\n</div>\n</div></div>\n<div class=\"wikibase-statementview-qualifiers\"></div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n<div class=\"wikibase-statementview-references-container\">\n<div class=\"wikibase-statementview-references-heading\">0 references</div>\n<div class=\"wikibase-statementview-references \"></div>\n</div>\n</div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n</div>\n</div><div class=\"wikibase-statementgroupview\" id=\"P662\" data-property-id=\"P662\">\n<div class=\"wikibase-statementgroupview-property\">\n<div class=\"wikibase-statementgroupview-property-label\" dir=\"auto\"><a title=\"Property:P662\" href=\"/wiki/Property:P662\">PubChem CID</a></div>\n</div>\n<div class=\"wikibase-statementlistview\">\n<div class=\"wikibase-statementlistview-listview\">\n<div id=\"Q105674316$fee6fe60-49fa-4f75-5124-5683768eed76\" class=\"wikibase-statementview wikibase-statement-Q105674316$fee6fe60-49fa-4f75-5124-5683768eed76 wb-normal\">\n<div class=\"wikibase-statementview-rankselector\"><div class=\"wikibase-rankselector ui-state-disabled\">\n<span class=\"ui-icon ui-icon-rankselector wikibase-rankselector-normal\" title=\"Normal rank\"></span>\n</div></div>\n<div class=\"wikibase-statementview-mainsnak-container\">\n<div class=\"wikibase-statementview-mainsnak\" dir=\"auto\"><div class=\"wikibase-snakview wikibase-snakview-5ee1169092db5e4fed4a5757c4ed83c2d206adff\">\n<div class=\"wikibase-snakview-property-container\">\n<div class=\"wikibase-snakview-property\" dir=\"auto\"></div>\n</div>\n<div class=\"wikibase-snakview-value-container\" dir=\"auto\">\n<div class=\"wikibase-snakview-typeselector\"></div>\n<div class=\"wikibase-snakview-body\">\n<div class=\"wikibase-snakview-value wikibase-snakview-variation-valuesnak\"><a class=\"wb-external-id external\" href=\"https://pubchem.ncbi.nlm.nih.gov/compound/101556657\" rel=\"nofollow\">101556657</a></div>\n<div class=\"wikibase-snakview-indicators\"></div>\n</div>\n</div>\n</div></div>\n<div class=\"wikibase-statementview-qualifiers\"></div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n<div class=\"wikibase-statementview-references-container\">\n<div class=\"wikibase-statementview-references-heading\">0 references</div>\n<div class=\"wikibase-statementview-references \"></div>\n</div>\n</div>\n</div>\n<span class=\"wikibase-toolbar-container\"></span>\n</div>\n</div></div></div></div>\n<div class=\"wikibase-entityview-side\"><div class=\"wikibase-pageImage\">\n<div class=\"help\">\n<span class=\"wb-help-field-hint wikibase-toolbar-item wikibase-wbtooltip\" title=\"This image is taken from the statements of this Item. You can adjust the image by changing the statement.\">&nbsp;</span>\n</div>\n</div><h2 class=\"wb-section-heading section-heading wikibase-sitelinks\" dir=\"auto\"><span class=\"mw-headline\" id=\"sitelinks\">Sitelinks</span></h2><div class=\"wikibase-sitelinkgrouplistview\"><div class=\"wikibase-listview\"><div class=\"wikibase-sitelinkgroupview\" data-wb-sitelinks-group=\"wikipedia\">\n<div class=\"wikibase-sitelinkgroupview-heading-section\">\n<div class=\"wikibase-sitelinkgroupview-heading-container\">\n<h3 class=\"wb-sitelinks-heading\" dir=\"auto\" id=\"sitelinks-wikipedia\">Wikipedia<span class=\"wikibase-sitelinkgroupview-counter\">(0 entries)</span></h3>\n<span class=\"wikibase-toolbar-container\"><span class=\"wikibase-toolbar-item wikibase-toolbar \"><span class=\"wikibase-toolbar-item wikibase-toolbar-button wikibase-toolbar-button-edit\"><a href=\"/wiki/Special:SetSiteLink/Q105674316\" title=\"\"><span class=\"wb-icon\"></span>edit</a></span></span></span>\n</div>\n</div>\n<div class=\"mw-collapsible-content\">\n<div class=\"wikibase-sitelinklistview\">\n<ul class=\"wikibase-sitelinklistview-listview\"></ul>\n</div>\n</div>\n</div><div class=\"wikibase-sitelinkgroupview\" data-wb-sitelinks-group=\"wikibooks\">\n<div class=\"wikibase-sitelinkgroupview-heading-section\">\n<div class=\"wikibase-sitelinkgroupview-heading-container\">\n<h3 class=\"wb-sitelinks-heading\" dir=\"auto\" id=\"sitelinks-wikibooks\">Wikibooks<span class=\"wikibase-sitelinkgroupview-counter\">(0 entries)</span></h3>\n<span class=\"wikibase-toolbar-container\"><span class=\"wikibase-toolbar-item wikibase-toolbar \"><span class=\"wikibase-toolbar-item wikibase-toolbar-button wikibase-toolbar-button-edit\"><a href=\"/wiki/Special:SetSiteLink/Q105674316\" title=\"\"><span class=\"wb-icon\"></span>edit</a></span></span></span>\n</div>\n</div>\n<div class=\"mw-collapsible-content\">\n<div class=\"wikibase-sitelinklistview\">\n<ul class=\"wikibase-sitelinklistview-listview\"></ul>\n</div>\n</div>\n</div><div class=\"wikibase-sitelinkgroupview\" data-wb-sitelinks-group=\"wikinews\">\n<div class=\"wikibase-sitelinkgroupview-heading-section\">\n<div class=\"wikibase-sitelinkgroupview-heading-container\">\n<h3 class=\"wb-sitelinks-heading\" dir=\"auto\" id=\"sitelinks-wikinews\">Wikinews<span class=\"wikibase-sitelinkgroupview-counter\">(0 entries)</span></h3>\n<span class=\"wikibase-toolbar-container\"><span class=\"wikibase-toolbar-item wikibase-toolbar \"><span class=\"wikibase-toolbar-item wikibase-toolbar-button wikibase-toolbar-button-edit\"><a href=\"/wiki/Special:SetSiteLink/Q105674316\" title=\"\"><span class=\"wb-icon\"></span>edit</a></span></span></span>\n</div>\n</div>\n<div class=\"mw-collapsible-content\">\n<div class=\"wikibase-sitelinklistview\">\n<ul class=\"wikibase-sitelinklistview-listview\"></ul>\n</div>\n</div>\n</div><div class=\"wikibase-sitelinkgroupview\" data-wb-sitelinks-group=\"wikiquote\">\n<div class=\"wikibase-sitelinkgroupview-heading-section\">\n<div class=\"wikibase-sitelinkgroupview-heading-container\">\n<h3 class=\"wb-sitelinks-heading\" dir=\"auto\" id=\"sitelinks-wikiquote\">Wikiquote<span class=\"wikibase-sitelinkgroupview-counter\">(0 entries)</span></h3>\n<span class=\"wikibase-toolbar-container\"><span class=\"wikibase-toolbar-item wikibase-toolbar \"><span class=\"wikibase-toolbar-item wikibase-toolbar-button wikibase-toolbar-button-edit\"><a href=\"/wiki/Special:SetSiteLink/Q105674316\" title=\"\"><span class=\"wb-icon\"></span>edit</a></span></span></span>\n</div>\n</div>\n<div class=\"mw-collapsible-content\">\n<div class=\"wikibase-sitelinklistview\">\n<ul class=\"wikibase-sitelinklistview-listview\"></ul>\n</div>\n</div>\n</div><div class=\"wikibase-sitelinkgroupview\" data-wb-sitelinks-group=\"wikisource\">\n<div class=\"wikibase-sitelinkgroupview-heading-section\">\n<div class=\"wikibase-sitelinkgroupview-heading-container\">\n<h3 class=\"wb-sitelinks-heading\" dir=\"auto\" id=\"sitelinks-wikisource\">Wikisource<span class=\"wikibase-sitelinkgroupview-counter\">(0 entries)</span></h3>\n<span class=\"wikibase-toolbar-container\"><span class=\"wikibase-toolbar-item wikibase-toolbar \"><span class=\"wikibase-toolbar-item wikibase-toolbar-button wikibase-toolbar-button-edit\"><a href=\"/wiki/Special:SetSiteLink/Q105674316\" title=\"\"><span class=\"wb-icon\"></span>edit</a></span></span></span>\n</div>\n</div>\n<div class=\"mw-collapsible-content\">\n<div class=\"wikibase-sitelinklistview\">\n<ul class=\"wikibase-sitelinklistview-listview\"></ul>\n</div>\n</div>\n</div><div class=\"wikibase-sitelinkgroupview\" data-wb-sitelinks-group=\"wikiversity\">\n<div class=\"wikibase-sitelinkgroupview-heading-section\">\n<div class=\"wikibase-sitelinkgroupview-heading-container\">\n<h3 class=\"wb-sitelinks-heading\" dir=\"auto\" id=\"sitelinks-wikiversity\">Wikiversity<span class=\"wikibase-sitelinkgroupview-counter\">(0 entries)</span></h3>\n<span class=\"wikibase-toolbar-container\"><span class=\"wikibase-toolbar-item wikibase-toolbar \"><span class=\"wikibase-toolbar-item wikibase-toolbar-button wikibase-toolbar-button-edit\"><a href=\"/wiki/Special:SetSiteLink/Q105674316\" title=\"\"><span class=\"wb-icon\"></span>edit</a></span></span></span>\n</div>\n</div>\n<div class=\"mw-collapsible-content\">\n<div class=\"wikibase-sitelinklistview\">\n<ul class=\"wikibase-sitelinklistview-listview\"></ul>\n</div>\n</div>\n</div><div class=\"wikibase-sitelinkgroupview\" data-wb-sitelinks-group=\"wikivoyage\">\n<div class=\"wikibase-sitelinkgroupview-heading-section\">\n<div class=\"wikibase-sitelinkgroupview-heading-container\">\n<h3 class=\"wb-sitelinks-heading\" dir=\"auto\" id=\"sitelinks-wikivoyage\">Wikivoyage<span class=\"wikibase-sitelinkgroupview-counter\">(0 entries)</span></h3>\n<span class=\"wikibase-toolbar-container\"><span class=\"wikibase-toolbar-item wikibase-toolbar \"><span class=\"wikibase-toolbar-item wikibase-toolbar-button wikibase-toolbar-button-edit\"><a href=\"/wiki/Special:SetSiteLink/Q105674316\" title=\"\"><span class=\"wb-icon\"></span>edit</a></span></span></span>\n</div>\n</div>\n<div class=\"mw-collapsible-content\">\n<div class=\"wikibase-sitelinklistview\">\n<ul class=\"wikibase-sitelinklistview-listview\"></ul>\n</div>\n</div>\n</div><div class=\"wikibase-sitelinkgroupview\" data-wb-sitelinks-group=\"wiktionary\">\n<div class=\"wikibase-sitelinkgroupview-heading-section\">\n<div class=\"wikibase-sitelinkgroupview-heading-container\">\n<h3 class=\"wb-sitelinks-heading\" dir=\"auto\" id=\"sitelinks-wiktionary\">Wiktionary<span class=\"wikibase-sitelinkgroupview-counter\">(0 entries)</span></h3>\n<span class=\"wikibase-toolbar-container\"><span class=\"wikibase-toolbar-item wikibase-toolbar \"><span class=\"wikibase-toolbar-item wikibase-toolbar-button wikibase-toolbar-button-edit\"><a href=\"/wiki/Special:SetSiteLink/Q105674316\" title=\"\"><span class=\"wb-icon\"></span>edit</a></span></span></span>\n</div>\n</div>\n<div class=\"mw-collapsible-content\">\n<div class=\"wikibase-sitelinklistview\">\n<ul class=\"wikibase-sitelinklistview-listview\"></ul>\n</div>\n</div>\n</div><div class=\"wikibase-sitelinkgroupview\" data-wb-sitelinks-group=\"special\">\n<div class=\"wikibase-sitelinkgroupview-heading-section\">\n<div class=\"wikibase-sitelinkgroupview-heading-container\">\n<h3 class=\"wb-sitelinks-heading\" dir=\"auto\" id=\"sitelinks-special\">Multilingual sites<span class=\"wikibase-sitelinkgroupview-counter\">(0 entries)</span></h3>\n<span class=\"wikibase-toolbar-container\"><span class=\"wikibase-toolbar-item wikibase-toolbar \"><span class=\"wikibase-toolbar-item wikibase-toolbar-button wikibase-toolbar-button-edit\"><a href=\"/wiki/Special:SetSiteLink/Q105674316\" title=\"\"><span class=\"wb-icon\"></span>edit</a></span></span></span>\n</div>\n</div>\n<div class=\"mw-collapsible-content\">\n<div class=\"wikibase-sitelinklistview\">\n<ul class=\"wikibase-sitelinklistview-listview\"></ul>\n</div>\n</div>\n</div></div></div></div>\n</div>\n<!-- Saved in parser cache with key wikidatawiki:pcache:idhash:101037319-0!termboxVersion=1!wb=3 and timestamp 20220917123407 and revision id 1730455050.\n -->\n\n<div class=\"printfooter\" data-nosnippet=\"\">Retrieved from \"<a dir=\"ltr\" href=\"https://www.wikidata.org/w/index.php?title=Q105674316&amp;oldid=1730455050\">https://www.wikidata.org/w/index.php?title=Q105674316&amp;oldid=1730455050</a>\"</div></div>\n\t\t<div id=\"catlinks\" class=\"catlinks catlinks-allhidden\" data-mw=\"interface\"></div>\n\t</div>\n</div>\n\n<div id=\"mw-navigation\">\n\t<h2>Navigation menu</h2>\n\t<div id=\"mw-head\">\n\t\t\n\n<nav id=\"p-personal\" class=\"vector-menu mw-portlet mw-portlet-personal vector-user-menu-legacy\" aria-labelledby=\"p-personal-label\" role=\"navigation\"  >\n\t<h3\n\t\tid=\"p-personal-label\"\n\t\t\n\t\tclass=\"vector-menu-heading \"\n\t>\n\t\t<span class=\"vector-menu-heading-label\">Personal tools</span>\n\t</h3>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\"><li id=\"pt-uls\" class=\"mw-list-item active\"><a class=\"uls-trigger\" href=\"#\"><span>English</span></a></li><li id=\"pt-userpage\" class=\"mw-list-item\"><a href=\"/wiki/User:GrndStt\" title=\"Your user page [.]\" accesskey=\".\"><span>GrndStt</span></a></li><li id=\"pt-notifications-alert\" class=\"mw-list-item\"><a class=\"mw-echo-notifications-badge mw-echo-notification-badge-nojs oo-ui-icon-bell mw-echo-unseen-notifications\" href=\"/wiki/Special:Notifications\" data-event-name=\"ui.notifications\" data-counter-num=\"4\" data-counter-text=\"4\" title=\"Your alerts\"><span>Alerts (4)</span></a></li><li id=\"pt-notifications-notice\" class=\"mw-list-item\"><a class=\"mw-echo-notifications-badge mw-echo-notification-badge-nojs oo-ui-icon-tray mw-echo-unseen-notifications\" href=\"/wiki/Special:Notifications\" data-counter-num=\"5\" data-counter-text=\"5\" title=\"Your notices\"><span>Notices (5)</span></a></li><li id=\"pt-mytalk\" class=\"mw-list-item\"><a href=\"/wiki/User_talk:GrndStt\" title=\"Your talk page [n]\" accesskey=\"n\"><span>Talk</span></a></li><li id=\"pt-preferences\" class=\"mw-list-item\"><a href=\"/wiki/Special:Preferences\" title=\"Your preferences\"><span>Preferences</span></a></li><li id=\"pt-betafeatures\" class=\"mw-list-item\"><a href=\"/wiki/Special:Preferences#mw-prefsection-betafeatures\" title=\"Beta features\"><span>Beta</span></a></li><li id=\"pt-watchlist\" class=\"mw-list-item\"><a href=\"/wiki/Special:Watchlist\" title=\"A list of pages you are monitoring for changes [l]\" accesskey=\"l\"><span>Watchlist</span></a></li><li id=\"pt-mycontris\" class=\"mw-list-item\"><a href=\"/wiki/Special:Contributions/GrndStt\" title=\"A list of your contributions [y]\" accesskey=\"y\"><span>Contributions</span></a></li><li id=\"pt-logout\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Special:UserLogout&amp;returnto=Q105674316\" data-mw=\"interface\" title=\"Log out\"><span>Log out</span></a></li></ul>\n\t\t\n\t</div>\n</nav>\n\n\t\t<div id=\"left-navigation\">\n\t\t\t\n\n<nav id=\"p-namespaces\" class=\"vector-menu mw-portlet mw-portlet-namespaces vector-menu-tabs vector-menu-tabs-legacy\" aria-labelledby=\"p-namespaces-label\" role=\"navigation\"  >\n\t<h3\n\t\tid=\"p-namespaces-label\"\n\t\t\n\t\tclass=\"vector-menu-heading \"\n\t>\n\t\t<span class=\"vector-menu-heading-label\">Namespaces</span>\n\t</h3>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\"><li id=\"ca-nstab-main\" class=\"selected mw-list-item\"><a href=\"/wiki/Q105674316\" title=\"View the item [c]\" accesskey=\"c\"><span>Item</span></a></li><li id=\"ca-talk\" class=\"new mw-list-item\"><a href=\"/w/index.php?title=Talk:Q105674316&amp;action=edit&amp;redlink=1\" rel=\"discussion\" title=\"Discussion about the content page (page does not exist) [t]\" accesskey=\"t\"><span>Discussion</span></a></li></ul>\n\t\t\n\t</div>\n</nav>\n\n\t\t\t\n\n<nav id=\"p-variants\" class=\"vector-menu mw-portlet mw-portlet-variants emptyPortlet vector-menu-dropdown\" aria-labelledby=\"p-variants-label\" role=\"navigation\"  >\n\t<input type=\"checkbox\"\n\t\tid=\"p-variants-checkbox\"\n\t\trole=\"button\"\n\t\taria-haspopup=\"true\"\n\t\tdata-event-name=\"ui.dropdown-p-variants\"\n\t\tclass=\"vector-menu-checkbox\"\n\t\taria-labelledby=\"p-variants-label\"\n\t/>\n\t<label\n\t\tid=\"p-variants-label\"\n\t\t aria-label=\"Change language variant\"\n\t\tclass=\"vector-menu-heading \"\n\t>\n\t\t<span class=\"vector-menu-heading-label\">English</span>\n\t</label>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\"></ul>\n\t\t\n\t</div>\n</nav>\n\n\t\t</div>\n\t\t<div id=\"right-navigation\">\n\t\t\t\n\n<nav id=\"p-views\" class=\"vector-menu mw-portlet mw-portlet-views vector-menu-tabs vector-menu-tabs-legacy\" aria-labelledby=\"p-views-label\" role=\"navigation\"  >\n\t<h3\n\t\tid=\"p-views-label\"\n\t\t\n\t\tclass=\"vector-menu-heading \"\n\t>\n\t\t<span class=\"vector-menu-heading-label\">Views</span>\n\t</h3>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\"><li id=\"ca-view\" class=\"selected vector-tab-noicon mw-list-item\"><a href=\"/wiki/Q105674316\"><span>Read</span></a></li><li id=\"ca-history\" class=\"vector-tab-noicon mw-list-item\"><a href=\"/w/index.php?title=Q105674316&amp;action=history\" title=\"Past revisions of this page [h]\" accesskey=\"h\"><span>View history</span></a></li><li id=\"ca-unwatch\" class=\"mw-watchlink icon mw-list-item\"><a href=\"/w/index.php?title=Q105674316&amp;action=unwatch\" data-mw=\"interface\" title=\"Remove this page from your watchlist [w]\" accesskey=\"w\"><span>Unwatch</span></a></li></ul>\n\t\t\n\t</div>\n</nav>\n\n\t\t\t\n\n<nav id=\"p-cactions\" class=\"vector-menu mw-portlet mw-portlet-cactions emptyPortlet vector-menu-dropdown\" aria-labelledby=\"p-cactions-label\" role=\"navigation\"  title=\"More options\" >\n\t<input type=\"checkbox\"\n\t\tid=\"p-cactions-checkbox\"\n\t\trole=\"button\"\n\t\taria-haspopup=\"true\"\n\t\tdata-event-name=\"ui.dropdown-p-cactions\"\n\t\tclass=\"vector-menu-checkbox\"\n\t\taria-labelledby=\"p-cactions-label\"\n\t/>\n\t<label\n\t\tid=\"p-cactions-label\"\n\t\t\n\t\tclass=\"vector-menu-heading \"\n\t>\n\t\t<span class=\"vector-menu-heading-label\">More</span>\n\t</label>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\"></ul>\n\t\t\n\t</div>\n</nav>\n\n\t\t\t\n<div id=\"p-search\" role=\"search\" class=\"vector-search-box-vue  vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box\">\n\t<div>\n\t\t\t<h3 >\n\t\t\t\t<label for=\"searchInput\">Search</label>\n\t\t\t</h3>\n\t\t<form action=\"/w/index.php\" id=\"searchform\"\n\t\t\tclass=\"vector-search-box-form\">\n\t\t\t<div id=\"simpleSearch\"\n\t\t\t\tclass=\"vector-search-box-inner\"\n\t\t\t\t data-search-loc=\"header-navigation\">\n\t\t\t\t<input class=\"vector-search-box-input\"\n\t\t\t\t\t type=\"search\" name=\"search\" placeholder=\"Search Wikidata\" aria-label=\"Search Wikidata\" autocapitalize=\"sentences\" title=\"Search Wikidata [f]\" accesskey=\"f\" id=\"searchInput\"\n\t\t\t\t>\n\t\t\t\t<input type=\"hidden\" name=\"title\" value=\"Special:Search\">\n\t\t\t\t<input id=\"mw-searchButton\"\n\t\t\t\t\t class=\"searchButton mw-fallbackSearchButton\" type=\"submit\" name=\"fulltext\" title=\"Search the pages for this text\" value=\"Search\">\n\t\t\t\t<input id=\"searchButton\"\n\t\t\t\t\t class=\"searchButton\" type=\"submit\" name=\"go\" title=\"Go to a page with this exact name if it exists\" value=\"Go\">\n\t\t\t</div>\n\t\t</form>\n\t</div>\n</div>\n\n\t\t</div>\n\t</div>\n\t\n\n<div id=\"mw-panel\">\n\t<div id=\"p-logo\" role=\"banner\">\n\t\t<a class=\"mw-wiki-logo\" href=\"/wiki/Wikidata:Main_Page\"\n\t\t\ttitle=\"Visit the main page\"></a>\n\t</div>\n\t\n\n<nav id=\"p-navigation\" class=\"vector-menu mw-portlet mw-portlet-navigation vector-menu-portal portal\" aria-labelledby=\"p-navigation-label\" role=\"navigation\"  >\n\t<h3\n\t\tid=\"p-navigation-label\"\n\t\t\n\t\tclass=\"vector-menu-heading \"\n\t>\n\t\t<span class=\"vector-menu-heading-label\">Navigation</span>\n\t</h3>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\"><li id=\"n-mainpage-description\" class=\"mw-list-item\"><a href=\"/wiki/Wikidata:Main_Page\" title=\"Visit the main page [z]\" accesskey=\"z\"><span>Main page</span></a></li><li id=\"n-portal\" class=\"mw-list-item\"><a href=\"/wiki/Special:MyLanguage/Project:Community_portal\" title=\"About the project, what you can do, where to find things\"><span>Community portal</span></a></li><li id=\"n-villagepump\" class=\"mw-list-item\"><a href=\"/wiki/Wikidata:Project_chat\"><span>Project chat</span></a></li><li id=\"n-special-newitem\" class=\"mw-list-item\"><a href=\"/wiki/Special:NewItem\"><span>Create a new Item</span></a></li><li id=\"n-recentchanges\" class=\"mw-list-item\"><a href=\"/wiki/Special:RecentChanges\" title=\"A list of recent changes in the wiki [r]\" accesskey=\"r\"><span>Recent changes</span></a></li><li id=\"n-randompage\" class=\"mw-list-item\"><a href=\"/wiki/Special:Random\" title=\"Load a random item [x]\" accesskey=\"x\"><span>Random Item</span></a></li><li id=\"n-wikibase-queryservice\" class=\"mw-list-item\"><a href=\"//query.wikidata.org/\"><span>Query Service</span></a></li><li id=\"n-mobile-frontend-nearby-title\" class=\"mw-list-item\"><a href=\"/wiki/Special:Nearby\"><span>Nearby</span></a></li><li id=\"n-help\" class=\"mw-list-item\"><a href=\"/wiki/Special:MyLanguage/Help:Contents\" title=\"The place to find out\"><span>Help</span></a></li><li id=\"n-sitesupport\" class=\"mw-list-item\"><a href=\"//donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_wikidata.org&amp;uselang=en\" title=\"Support us\"><span>Donate</span></a></li></ul>\n\t\t\n\t</div>\n</nav>\n\n\t\n\n<nav id=\"p-wikibase-lexeme-lexicographical-data\" class=\"vector-menu mw-portlet mw-portlet-wikibase-lexeme-lexicographical-data vector-menu-portal portal\" aria-labelledby=\"p-wikibase-lexeme-lexicographical-data-label\" role=\"navigation\"  >\n\t<h3\n\t\tid=\"p-wikibase-lexeme-lexicographical-data-label\"\n\t\t\n\t\tclass=\"vector-menu-heading \"\n\t>\n\t\t<span class=\"vector-menu-heading-label\">Lexicographical data</span>\n\t</h3>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\"><li id=\"n-special-newlexeme\" class=\"mw-list-item\"><a href=\"/wiki/Special:NewLexeme\"><span>Create a new Lexeme</span></a></li><li id=\"n-recentchanges-lexemes\" class=\"mw-list-item\"><a href=\"https://www.wikidata.org/wiki/Special:RecentChanges?namespace=146%3B147\"><span>Recent changes</span></a></li><li id=\"n-wikibase-lexeme-randomlexeme\" class=\"mw-list-item\"><a href=\"/wiki/Special:Random/Lexeme\"><span>Random Lexeme</span></a></li></ul>\n\t\t\n\t</div>\n</nav>\n\n\n<nav id=\"p-tb\" class=\"vector-menu mw-portlet mw-portlet-tb vector-menu-portal portal\" aria-labelledby=\"p-tb-label\" role=\"navigation\"  >\n\t<h3\n\t\tid=\"p-tb-label\"\n\t\t\n\t\tclass=\"vector-menu-heading \"\n\t>\n\t\t<span class=\"vector-menu-heading-label\">Tools</span>\n\t</h3>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\"><li id=\"t-whatlinkshere\" class=\"mw-list-item\"><a href=\"/wiki/Special:WhatLinksHere/Q105674316\" title=\"A list of all wiki pages that link here [j]\" accesskey=\"j\"><span>What links here</span></a></li><li id=\"t-recentchangeslinked\" class=\"mw-list-item\"><a href=\"/wiki/Special:RecentChangesLinked/Q105674316\" rel=\"nofollow\" title=\"Recent changes in pages linked from this page [k]\" accesskey=\"k\"><span>Related changes</span></a></li><li id=\"t-specialpages\" class=\"mw-list-item\"><a href=\"/wiki/Special:SpecialPages\" title=\"A list of all special pages [q]\" accesskey=\"q\"><span>Special pages</span></a></li><li id=\"t-permalink\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Q105674316&amp;oldid=1730455050\" title=\"Permanent link to this revision of this page\"><span>Permanent link</span></a></li><li id=\"t-info\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Q105674316&amp;action=info\" title=\"More information about this page\"><span>Page information</span></a></li><li id=\"t-wb-concept-uri\" class=\"mw-list-item\"><a href=\"http://www.wikidata.org/entity/Q105674316\" title=\"URI that identifies the concept described by this Item\"><span>Concept URI</span></a></li><li id=\"t-cite\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Special:CiteThisPage&amp;page=Q105674316&amp;id=1730455050&amp;wpFormIdentifier=titleform\" title=\"Information on how to cite this page\"><span>Cite this page</span></a></li></ul>\n\t\t\n\t</div>\n</nav>\n\n\n<nav id=\"p-coll-print_export\" class=\"vector-menu mw-portlet mw-portlet-coll-print_export vector-menu-portal portal\" aria-labelledby=\"p-coll-print_export-label\" role=\"navigation\"  >\n\t<h3\n\t\tid=\"p-coll-print_export-label\"\n\t\t\n\t\tclass=\"vector-menu-heading \"\n\t>\n\t\t<span class=\"vector-menu-heading-label\">Print/export</span>\n\t</h3>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\"><li id=\"coll-create_a_book\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Q105674316\"><span>Create a book</span></a></li><li id=\"coll-download-as-rl\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Special:DownloadAsPdf&amp;page=Q105674316&amp;action=show-download-screen\"><span>Download as PDF</span></a></li><li id=\"t-print\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Q105674316&amp;printable=yes\" title=\"Printable version of this page [p]\" accesskey=\"p\"><span>Printable version</span></a></li></ul>\n\t\t\n\t</div>\n</nav>\n\n\t\n</div>\n\n</div>\n\n<footer id=\"footer\" class=\"mw-footer\" role=\"contentinfo\" >\n\t<ul id=\"footer-info\">\n\t<li id=\"footer-info-lastmod\"> This page was last edited on 17 September 2022, at 12:34.</li>\n\t<li id=\"footer-info-copyright\">All structured data from the main, Property, Lexeme, and EntitySchema namespaces is available under the <a href=\"//creativecommons.org/publicdomain/zero/1.0/\" title=\"Definition of the Creative Commons CC0 License\">Creative Commons CC0 License</a>; text in the other namespaces is available under the <a href=\"//creativecommons.org/licenses/by-sa/3.0/\" title=\"Definition of the Creative Commons Attribution/Share-Alike License\">Creative Commons Attribution-ShareAlike License</a>; additional terms may apply. By using this site, you agree to the <a href=\"//foundation.wikimedia.org/wiki/Terms_of_Use\">Terms of Use</a> and <a href=\"//foundation.wikimedia.org/wiki/Privacy_policy\">Privacy Policy.</a></li>\n</ul>\n\n\t<ul id=\"footer-places\">\n\t<li id=\"footer-places-privacy\"><a href=\"https://foundation.wikimedia.org/wiki/Privacy_policy\">Privacy policy</a></li>\n\t<li id=\"footer-places-about\"><a href=\"/wiki/Special:MyLanguage/Project:Introduction\">About Wikidata</a></li>\n\t<li id=\"footer-places-disclaimer\"><a href=\"/wiki/Special:MyLanguage/Project:General_disclaimer\">Disclaimers</a></li>\n\t<li id=\"footer-places-mobileview\"><a href=\"//m.wikidata.org/w/index.php?title=Q105674316&amp;mobileaction=toggle_view_mobile\" class=\"noprint stopMobileRedirectToggle\">Mobile view</a></li>\n\t<li id=\"footer-places-data-access\"><a href=\"/wiki/Special:MyLanguage/Wikidata:Data_access\">Data access</a></li>\n\t<li id=\"footer-places-developers\"><a href=\"https://developer.wikimedia.org\">Developers</a></li>\n\t<li id=\"footer-places-statslink\"><a href=\"https://stats.wikimedia.org/#/www.wikidata.org\">Statistics</a></li>\n\t<li id=\"footer-places-cookiestatement\"><a href=\"https://foundation.wikimedia.org/wiki/Cookie_statement\">Cookie statement</a></li>\n</ul>\n\n\t<ul id=\"footer-icons\" class=\"noprint\">\n\t<li id=\"footer-copyrightico\"><a href=\"https://wikimediafoundation.org/\"><img src=\"/static/images/footer/wikimedia-button.png\" srcset=\"/static/images/footer/wikimedia-button-1.5x.png 1.5x, /static/images/footer/wikimedia-button-2x.png 2x\" width=\"88\" height=\"31\" alt=\"Wikimedia Foundation\" loading=\"lazy\" /></a></li>\n\t<li id=\"footer-poweredbyico\"><a href=\"https://www.mediawiki.org/\"><img src=\"/static/images/footer/poweredby_mediawiki_88x31.png\" alt=\"Powered by MediaWiki\" srcset=\"/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x\" width=\"88\" height=\"31\" loading=\"lazy\"/></a></li>\n</ul>\n\n</footer>\n\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgBackendResponseTime\":108,\"wgHostname\":\"mw1414\"});});</script>\n</body>\n</html>\n\n\n\n\n\n\n","n":0.024}}},{"i":462,"$":{"0":{"v":"Create_item","n":1},"1":{"v":"\n\n[TOC]\n# Manual addition of a documented structure-organism pair to Wikidata\n\n## Select a documented structure-organism pair\n\nThroughout this demonstration, we are going to use the following example:\n> [trigocherrin A](https://pubchem.ncbi.nlm.nih.gov/compound/101556657) is found in [_Trigonostemon cherrieri_](http://gni.globalnames.org/name_strings?search_term=trigonostemon+cherrieri&commit=Search), as stated in [Trigocherrin A, the first natural chlorinated daphnane diterpene orthoester from Trigonostemon cherrieri](https://doi.org/10.1021/OL2030907).\n\n## Fetch the information for the documented structure-organism pair\n\n### Structure\n\nSearch PubChem for your compound, here [trigocherrin A](https://pubchem.ncbi.nlm.nih.gov/#query=%22trigocherrin%20A%22). This leads to [https://pubchem.ncbi.nlm.nih.gov/compound/101556657](https://pubchem.ncbi.nlm.nih.gov/compound/101556657).\n\n![](/assets/images/2021-02-25-14-15-54.png)\n\nFrom there, you can fetch the compound's name, InChIKey and InChI as well as its Canonical and Isomeric SMILES.\nHere we keep, respectively:\n\n```\n* trigocherrin A\n* QOVGHDRCAGYGEB-FFZYJECLSA-N\n* InChI=1S/C38H36Cl2O12/c1-18(2)35(44)27-19(3)37-25-16-24(31(39)40)28(48-32(43)22-12-8-6-9-13-22)36(25,45)33(47-21(5)42)34(17-46-20(4)41)29(49-34)26(37)30(35)51-38(50-27,52-37)23-14-10-7-11-15-23/h6-16,19,26-30,33,44-45H,1,17H2,2-5H3/t19-,26+,27?,28+,29+,30-,33-,34+,35+,36-,37+,38?/m1/s1\n* CC1C2C(C3C4C1(C5=CC(=C(Cl)Cl)C(C5(C(C6(C4O6)COC(=O)C)OC(=O)C)O)OC(=O)C7=CC=CC=C7)OC(O2)(O3)C8=CC=CC=C8)(C(=C)C)O\n* C[C@@H]1C2[C@]([C@H]3[C@H]4[C@]1(C5=CC(=C(Cl)Cl)[C@@H]([C@]5([C@@H]([C@@]6([C@H]4O6)COC(=O)C)OC(=O)C)O)OC(=O)C7=CC=CC=C7)OC(O3)(O2)C8=CC=CC=C8)(C(=C)C)O\n```\n\n### Organism\n\nYou can check if your organism name is correctly spelled using the Global Names resolver service: [http://gni.globalnames.org/name_strings?search_term=trigonostemon+cherrieri&commit=Search](http://gni.globalnames.org/name_strings?search_term=trigonostemon+cherrieri&commit=Search).\n\n![](/assets/images/2021-02-27-18-40-20.png)\n\nAlternatively, you can use [gnfinder](https://github.com/gnames/gnfinder) in your command line interface to check for the spelling of your organism string.\n \n```\necho \"Trigonostemion cherrieri\" | gnfinder find -c -l eng\n\n{\n  \"metadata\": {\n    \"date\": \"2021-02-27T18:44:41.640982+01:00\",\n    \"gnfinderVersion\": \"v0.11.1\",\n    \"withBayes\": true,\n    \"tokensAround\": 0,\n    \"language\": \"eng\",\n    \"detectLanguage\": false,\n    \"totalWords\": 2,\n    \"totalCandidates\": 1,\n    \"totalNames\": 1\n  },\n  \"names\": [\n    {\n      \"cardinality\": 2,\n      \"verbatim\": \"Trigonostemion cherrieri\",\n      \"name\": \"Trigonostemion cherrieri\",\n      \"odds\": 77581.46698350731,\n      \"start\": 0,\n      \"end\": 24,\n      \"annotationNomenType\": \"NO_ANNOT\",\n      \"annotation\": \"\",\n      \"verification\": {\n        \"bestResult\": {\n          \"dataSourceId\": 1,\n          \"dataSourceTitle\": \"Catalogue of Life\",\n          \"taxonId\": \"1575885\",\n          \"matchedName\": \"Trigonostemon cherrieri Veillon\",\n          \"matchedCardinality\": 2,\n          \"matchedCanonicalSimple\": \"Trigonostemon cherrieri\",\n          \"matchedCanonicalFull\": \"Trigonostemon cherrieri\",\n          \"classificationPath\": \"Plantae|Tracheophyta|Magnoliopsida|Malpighiales|Euphorbiaceae|Trigonostemon|Trigonostemon cherrieri\",\n          \"classificationRank\": \"kingdom|phylum|class|order|family|genus|species\",\n          \"classificationIds\": \"3939764|3942634|3942724|3942777|3942795|4210752|1575885\",\n          \"editDistance\": 1,\n          \"stemEditDistance\": 1,\n          \"matchType\": \"FuzzyCanonicalMatch\"\n        },\n        \"dataSourcesNum\": 13,\n        \"dataSourceQuality\": \"HasCuratedSources\",\n        \"retries\": 1\n      }\n    }\n  ]\n}\n```\n\nFor misspellings like _Trigonstemion cherrieri_, gnfinder can help resolve them, in this case to _Trigonostemon cherrieri_.\n\n\n### Reference\n\nMake sure that you have the correct [Digital Object Identifier (DOI)](https://www.doi.org/doi_handbook/Glossary.html#doi) for it.\nFor \"[Trigocherrin A, the first natural chlorinated daphnane diterpene orthoester from Trigonostemon cherrieri](https://doi.org/10.1021/OL2030907)\", this is  **10.1021/ol2030907**. Note that DOIs are uppercase-normalized in Wikidata.\n\n## Check for the presence of your compound in Wikidata <a name=\"check_compound\"></a>\n\nUsing the compound's InChIKey (i.e. ```QOVGHDRCAGYGEB-FFZYJECLSA-N``` for trigocherrin A), run a SPARQL query to check if your compound is present in Wikidata or not:\n\n\n```SPARQL\nSELECT ?item ?itemLabel WHERE {\n  VALUES ?classes {\n    wd:Q11173 # chemical compound\n    wd:Q59199015 # group of stereoisomers\n    wd:Q79529 # chemical substance\n    wd:Q17339814 # group of chemical substances\n    wd:Q47154513 # structural class of chemical compounds\n  }\n  ?item wdt:P31 ?classes. # instance of\n  ?item wdt:P235 'QOVGHDRCAGYGEB-FFZYJECLSA-N'\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n}\n```\n[Try this query](https://w.wiki/32zU). You can adapt it by replacing the InChIKey with the one for your compound.\n\nAlternatively you can use the following Scholia link (replace by your compounds InChIKey) [https://scholia.toolforge.org/inchikey/QOVGHDRCAGYGEB-FFZYJECLSA-N](https://scholia.toolforge.org/inchikey/QOVGHDRCAGYGEB-FFZYJECLSA-N) \n\nIf your compound is already present on Wikidata, you can directly skip to the [Add the biological source information](#add_bio) section below.\n\n## Add your data manually to Wikidata <a name=\"add_your_data_manually\"></a>\n\nFirst, if you do not have a Wikidata account already, it is advisable that you create one via [https://www.wikidata.org/wiki/Special:CreateAccount](https://www.wikidata.org/wiki/Special:CreateAccount). While an account is not strictly required for manual edits, having one will be useful if you want to contribute more than once, and it helps in getting your contributions recognized. Note that Wikidata accounts are integrated with accounts across the Wikimedia ecosystem, so if you already have an account on, say, any Wikipedia or on Wikispecies, then you can use the same credentials on Wikidata.\n\nIf you are unfamiliar with how Wikidata works, you can start by reading the Wikidata introduction page [https://www.wikidata.org/wiki/Wikidata:Introduction](https://www.wikidata.org/wiki/Wikidata:Introduction) and have a look at the Wikidata Tours page [https://www.wikidata.org/wiki/Wikidata:Tours](https://www.wikidata.org/wiki/Wikidata:Tours).\n\nNow that you are all set up, you can go to Wikidata's page for creating new items, [https://www.wikidata.org/wiki/Special:NewItem](https://www.wikidata.org/wiki/Special:NewItem):\n\n\n![](/assets/images/2021-02-25-14-18-03.png)\n\nAn empty page with a new Wikidata identifier is created \n\n![](/assets/images/2021-02-25-14-18-50.png)\n\n### Add the chemical compound information <a name=\"add_chemical\"></a>\n\nCreate a new statement for ```is an instance of```\n\n![](/assets/images/2021-02-25-14-20-08.png)\n\nand select chemical compound (i.e. [Q11173](https://www.wikidata.org/wiki/Q11173)):\n\n![](/assets/images/2021-02-25-14-20-58.png)\n\nClick ```publish``` to save your changes and make them public.\n\nSince you created a new item about an instance of a chemical compound, the user interface will automatically propose to you a set of additional statements commonly found on items about chemical compounds.\n\n![](/assets/images/2021-02-25-14-22-44.png)\n\nYou can then go on and fill these in.\n\nHere, we start with the InChIKey. \nNote the little flag which will automatically tell you if you have some problems with the recently created statements.\n\n![](/assets/images/2021-02-25-14-24-34.png)\n\nHere, Wikidata tells us that if we add an InChiKey, we will need to also add an InChI. Logical, but good to have a reminder !\n\nLet's go ahead and add the InChI string.\n\nLikewise, the addition of an isomeric SMILES string will require us to add a Canonical SMILES.\n\nNote that you might have to copy and paste the SMILES string from PubChem to a plain text editor and then back to Wikidata because of some formatting issues when copy pasting directly from PubChem.\n\n```\nC[C@@H]1C2[C@]([C@H]3[C@H]4[C@]1(C5=CC(=C(Cl)Cl)[C@@H]([C@]5([C@@H]([C@@]6([C@H]4O6)COC(=O)C)OC(=O)C)O)OC(=O)C7=CC=CC=C7)OC(O3)(O2)C8=CC=CC=C8)(C(=C)C)O\n\nCC1C2C(C3C4C1(C5=CC(=C(Cl)Cl)C(C5(C(C6(C4O6)COC(=O)C)OC(=O)C)O)OC(=O)C7=CC=CC=C7)OC(O2)(O3)C8=CC=CC=C8)(C(=C)C)O\n```\n\n### Add the biological source information <a name=\"add_bio\"></a>\n\nNow let's add the ```found in taxon``` property ([P703](https://www.wikidata.org/wiki/Property:P703)).\n\nJust click on ```Add a new statement``` and type in the first letters of the property you want to add:\n\n![](/assets/images/2021-02-25-14-31-56.png)\n\nAgain, type in the first letters of the taxon, and if the organism is present, it will autocomplete. Here is how this looks like for _Trigonostemon cherrieri_:\n\n![](/assets/images/2021-02-25-14-33-14.png)\n\nClick ```publish``` to save your changes and make them public.\n\n\nIf your target taxon is not yet present on Wikidata and you are sure you have a valid taxon name that is spelled correctly, then you can go to [https://www.wikidata.org/wiki/Special:NewItem](https://www.wikidata.org/wiki/Special:NewItem), as described in the [Add your data manually to Wikidata](#add_your_data_manually) section. For items about taxa, the ```instance of``` statement should have a value ```taxon``` (i.e. [Q16521](https://www.wikidata.org/wiki/Q16521)). As for chemical compounds, the user interface will then suggest to you further statements to add. For taxa, these include taxon name, parent taxon and taxon rank.\n\n\n### Add the reference documenting the structure-organism pair <a name=\"add_ref\"></a>\n\nFinally, since we report documented structure-organisms pairs, we need to add the reference for this newly created ```compound found in taxon``` relationship.\nThis happens on the item about the compound, just below the ```found in taxon``` statement. Click on the ```0 references``` link and then on ```add reference```:\n\n![](/assets/images/2021-02-25-14-35-33.png)\n\nHere, we use the ```stated in``` property ([P248](https://www.wikidata.org/wiki/Property:P248)):\n\n![](/assets/images/2021-02-25-14-36-33.png)\n\nNow, type in the first letters or word of the scientific publication documenting the natural product occurence, autocompletion happens again. Note that multiple publications might have the same title, and that there could be minor differences in punctuation or special characters between the information you and Wikidata have about the same reference. If you are not sure whether your target reference is already in Wikidata, you can use its DOI to check, as outlined in the [Check whether your target reference is already on Wikidata](#check_ref) section.\n\n![](/assets/images/2021-02-25-14-38-54.png)\n\nClick ```publish``` to save your changes and make them public.\n\n![](/assets/images/2021-02-25-14-39-48.png)\n\n### Check whether your target reference is already on Wikidata <a name=\"check_ref\"></a>\n\nIf you are not sure whether your target reference is already in Wikidata, you can use its DOI to check. For our DOI ```10.1021/ol2030907```, the URL [https://scholia.toolforge.org/doi/___10.1021/ol2030907___](https://scholia.toolforge.org/doi/10.1021/ol2030907) will lead you to a [Scholia](https://www.wikidata.org/wiki/Wikidata:Scholia) page about this publication: [https://scholia.toolforge.org/work/Q83059010](https://scholia.toolforge.org/work/Q83059010). Scholia visualizes information from Wikidata, so if it has an entry for your target reference, then so does Wikidata, and both of them will use the same identifier (in this case [Q83059010](https://www.wikidata.org/wiki/Q83059010)). If you prefer to resolve your DOI to Wikidata directly, you can do so by using the uppercase-normalized DOI in the following URL pattern: [https://hub.toolforge.org/P356:**10.1021/OL2030907**](https://hub.toolforge.org/P356:10.1021/OL2030907), which will lead you to the respective Wikidata page, in this case [Q83059010](https://www.wikidata.org/wiki/Q83059010).\n\nIf you think that no Wikidata entry exists for your target reference, you can use the DOI in the URL pattern [https://sourcemd.toolforge.org/index_old.php?id=**10.1021/ol2030907**&doit=Check+source](https://sourcemd.toolforge.org/index_old.php?id=10.1021/ol2030907&doit=Check+source), which will trigger a check with both Crossref and Wikidata, and if no Wikidata entry can be found, the metadata from Crossref will be fetched and presented to you for creating the respective Wikidata item semi-automatically. Using such semi-automated workflows does require and account that is a minimum number of days old and has made a minimum number of edits on Wikidata.\n\nIf you are interested the annotation of article with topics in Scholia here is a tutorial [https://laurendupuis.github.io/Scholia_tutorial/](https://laurendupuis.github.io/Scholia_tutorial/)\n\n\n## Voila !\n\nYou have added your first documented structure-organism relationship to Wikidata and made a valuable contribution to the community.\nYou can add further statements, e.g. ```molecular formula```, or ```SPLASH code``` for linking to spectral data.\n\nThe Wikidata entry [https://www.wikidata.org/wiki/Q105674316](https://www.wikidata.org/wiki/Q105674316) has been started using these instructions.\n\nYou can run a SPARQL query and check that everything went smoothly by modifying the InChiKey line in the following [SPARQL query](https://w.wiki/32zb):\n\n```SPARQL\nSELECT ?item ?itemLabel ?taxonLabel ?artLabel WHERE {\n  VALUES ?classes {\n    wd:Q11173 # chemical compound\n    wd:Q59199015 # group of stereoisomers\n    wd:Q79529 # chemical substance\n    wd:Q17339814 # group of chemical substances\n    wd:Q47154513 # structural class of chemical compounds\n  }\n  ?item wdt:P31 ?classes. # instance of\n  ?item wdt:P235 'QOVGHDRCAGYGEB-FFZYJECLSA-N' # InChiKey\n  {\n    ?item p:P1582 ?stmt. # natural product of taxon\n    ?stmt ps:P1582 ?taxon. # natural product of taxon\n    OPTIONAL {\n      ?stmt prov:wasDerivedFrom ?ref. \n      ?ref pr:P248 ?art. # stated in\n    }\n  }\n  UNION\n  {\n    ?item p:P703 ?stmt. # found in taxon\n    ?stmt ps:P703 ?taxon. # found in taxon\n    OPTIONAL {\n      ?stmt prov:wasDerivedFrom ?ref.\n      ?ref pr:P248 ?art. # stated in\n    }\n  }\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n}\n```\n","n":0.026}}},{"i":463,"$":{"0":{"v":"Apps","n":1},"1":{"v":"# Topic tagger\n\nhttps://lubianat.shinyapps.io/topictagger/\n\n# bot tutorial\n\nhttps://heardlibrary.github.io/digital-scholarship/host/wikidata/bot/\n\n","n":0.447}}},{"i":464,"$":{"0":{"v":"Wget","n":1},"1":{"v":"\n\n`wget --cookies=on --header=\"Cookie: your_session_cookie\" \"https://filesender.switch.ch/filesender2/download.php?token=2b1ff8d0-80e7-49ac-ac76-8145dacb41f7&files_ids=XXXXXXX\"`\n\nwhile \n\n`wget https://filesender.switch.ch/filesender2/download.php?token=2b1ff8d0-80e7-49ac-ac76-8145dacb41f7&files_ids=XXXXXXX`\n\nwont.\n\nTo be noted if trouble when wgetting a file on the server.","n":0.236}}},{"i":465,"$":{"0":{"v":"Welcome","n":1},"1":{"v":"\n\nWelcome the the COMMONS Lab Open Dendron.\n\nIn the COMMONS Lab we intent to follow the Open Notebook Science approach to document our research.\n\nFor this we use the Dendron system as a mean to efficiently capture notes and publish them.\n\n## What is this note\n\nThis note is a succinct tutorial note aiming to get you started in the use of the DBGI Dendron.\n\n## Tutorial\n\n### Dendron. \n\n#### What is Dendron ?\n\n> Dendron is an open-source, local-first, markdown-based, note-taking tool. Think of it as a cache for everything that you care about - if you've spent more then five minutes solving a problem, you should never spent any more time solving the same exact problem.\n> \n> Dendron is a knowledge base built by and for developers and integrates natively with IDEs like VS Code and VSCodium.\n\n#### Where to get more info on Dendron ?\n\n- You can get more information in the Dendron system at the official website www.dendron.so\n- All the Dendron documentation is hosted here https://wiki.dendron.so/ . It is, obviously, a Dendron itself.\n\n#### Concrete steps to access and contribute to the DBGI Dendron\n\n1. Install [VSCode](https://code.visualstudio.com/download)\n2. Install [Dendron](https://marketplace.visualstudio.com/items?itemName=dendron.dendron) from the VSCode marketplace \n3. Clone the COMMONS Dendron repo\n\n    In your terminal\n    ```\n    git clone https://github.com/commons-research/commons-dws-public.git\n    ```\n4. In VSCode open (File/Open) the cloned repository.\n5. Voila ! You should now be in the COMMONS Lab Open Dendron.\n\nFeel free to explore and contribute.\nA first, important step could be to configure VSCode so that you can easily add a daily note. See steps described at [[open-notebook.commons.setup]]\n\n\n## Questions, comments, suggestions ?\n\nFeel free to contribute here https://github.com/orgs/commons-research/discussions\n\n","n":0.063}}},{"i":466,"$":{"0":{"v":"Website","n":1}}},{"i":467,"$":{"0":{"v":"DNS","n":1},"1":{"v":"\nhttps://www.cameronmacleod.com/blog/github-pages-dns\n\n\n","n":1}}},{"i":468,"$":{"0":{"v":"W0","n":1},"1":{"v":"\n\nhttps://small-tech.org/\n\n\nDamn it !!!\n\n![](/assets/images/2025-05-09-22-18-28.png)\n\nWas not expecting this","n":0.408}}},{"i":469,"$":{"0":{"v":"Virtuoso","n":1},"1":{"v":"\nhttps://hub.docker.com/r/openlink/virtuoso-opensource-7/","n":1}}},{"i":470,"$":{"0":{"v":"Viewpoint","n":1},"1":{"v":"\n# Log\n\n## 2023.06.26\n2023-06-26 22:00\n2023-06-26 22:18\n\n# 2023.06.27\n2023-06-27 18:17\n2023-06-27 18:34\n\n\n# Wednesday 28 June 2023\n2023-06-28 15:20\n2023-06-28 15:35\n\n# Saturday 01 July 2023\n2023-07-01 17:51\n2023-07-01 18:08\n\n# Tuesday 04 July 2023\n2023-07-04 08:11\n\n\n# Wednesday 05 July 2023\n2023-07-05 09:23\n2023-07-05 09:42\n\n# Saturday 08 July 2023\n2023-07-08 08:16\n\n# Tuesday 25 July 2023\n2023-07-25 09:07\n\n# Friday 28 July 2023\n2023-07-28 07:54\n\n# Saturday 29 July 2023\n2023-07-29 11:29\n2023-07-29 12:17\n\n# Saturday 02 September 2023\n2023-09-02 07:28\n2023-09-02 08:30\n\n\n\n# Monday 27 November 2023\n\n\n# Thursday 11 January 2024\n\n2024-01-11 18:48\n\n\n\n\n# Todo\n\n# Doing \n\n- [ ] Messing around with ChatGPT for the Extraction of chemical and bio info from \nWorking here \n\n\n\n\n# Done\n\n\n\n- [x] Proposing doodle 2024 for the Open Science for Natural Products Research Viewpoint\n- [x] Information email to the coauthors regarding the delayed deadline for the Viewpoint [[viewpoint.communication.emails]]\nMeeting for the \"Open Science for Natural Products Research\" Viewpoint - 2024\nhttps://framadate.org/VdniELdaR1c9a3gm\n\n- [x] Answering NPR people, advising for 6 month delay min\n- [x] Setting up google docs for the Viewpoint\nhttps://docs.google.com/document/d/1quzvx2BbMlbUTwiqp9ksJinFR7-PQ9yKDj_9edaoguQ/edit?usp=sharing\n- [x] Share with viewpoint.communication.emails.coauthors\n\n- [x] Invite Donat \n- [x] Send synopsis final version to NPR\n\n- [x] Meeting pre-Synopsis\n\nWorking at [[viewpoint.synopsis]]\nMeeting at https://meet.jit.si/OSNPR_viewpoint from 8:00 till 10:00 am this Friday 28th.\n\n\n- [x] Mail and meeting pre synopsis sending \n[[dendron://commons-dws-private-22ZymH6cx0ls7Lc71khYE/viewpoint.communication.emails]]\n\n\n- [x] Set a common place for the ressources exchanges in the email conversations sofar\n\n\nEmail conversations archived at https://mypads2.framapad.org/p/email-conversations-n92xnz9pv\nIdeas and ressources at https://mypads2.framapad.org/p/ideas-and-ressources-osnpr-viewpoint-5p30rz9fm\nSynopsis at https://mypads2.framapad.org/mypads/?/mypads/group/osnpr-2739qh9rj/pad/view/synopsis-441tvn9p1\n\n- [x] Draft a Synopsis\n[[viewpoint.synopsis]]\n- [x] Mail for additional \n[[viewpoint.communication.emails.coauthors.md]]\n- [x] Mail to possible coauthors\nDraft at [[viewpoint.communication.emails.coauthors]].  \n~~To discuss with Adriano before sending.~~\n- [x] get in touch with UniFr library regarding possibility to take in charge the Open Access publishing fees\nDraft at [[viewpoint.communication.emails.thomas-henkel]]\nSent 2023-06-24 19:02\n- [x] answer back editor regarding delay for the viewpoint synopsis\nDraft at [[viewpoint.communication.emails.npr-editor]]\nIndicated end of July for the submission of the synopsis\nSent 2023-06-24 19:09\n\n# Friday 23 June 2023\n\nInitial invitation email\n\n> Dear Pierre-Marie,\n> \n> I hope you are doing well,\n> \n> Since a number of years, I have been on the editorial board of Natural Product Reports.\n> I saw the nice website of your group (https://www.unifr.ch/bio/en/groups/allard/), and this made me think: might you be interested in writing a Viewpoint (together with any relevant co-authors) on open science in natural products research?\n> \n> If you are enthusiastic, the next step would be to prepare a synopsis (see attachments for instructions), which I would then circulate among the editorial board for suggestions and approval.\n> \n> I am looking forward to hearing what you think!\n\nAttachements at [](../../../Dropbox/UniFr/COMMONS_Lab/Papers_PMA/2023/Viewpoint_OSNPR/Submitting%20a%20synopsis%20to%20NPR%20-%20Invited%20authors.pdf)\nAttachements at [](../../../Dropbox/UniFr/COMMONS_Lab/Papers_PMA/2023/Viewpoint_OSNPR/Synopsis%20example.pdf)\n\n\nYesterday answered to the NPR editor.\n> \n> Many thanks for your email and invitation.\n> \n> I am pretty much interested in your suggestion as I believe writing and proposing ressources and perspectives on the topic of Open Science is of interest in most disciplines.\n> I would be happy to propose such Viewpoint for the field of NP research.\n> \n> I have already some possible coauthors in mind and have discussed with some.\n> They are willing to participate but everyone is (like always nowadays) somehow underwater.\n> What would be the delays (if any) to hand over this Viewpoint ?\n> \n> Second point would it be possible to have it published in Open Access (it would indeed be ironical to have such article paywalled)\n\n\nHis answer\n\n> Great to hear back from you. And fantastic to hear that you are enthusiastic about contributing something on this topic.\n> \n> Yes, submitting the synopsis somewhat later is no problem. When do you think you can send it in?\n> \n> And sure, NPR has several open access options: https://www.rsc.org/journals-books-databases/about-journals/npr/\n> RSC also made many deals with many universities and countries, through which authors do not have to pay open access fees themselves: https://www.rsc.org/journals-books-databases/open-access-publishing/read-and-publish/deals/\n> It looks like your university is included in such a deal, but best to check with your library to make sure.\n\n\nPossible coauthors\n\n- Adriano Rutz (contacted)\n- Egon Willighagen (contacted)\n- Peter Murray Rust (contacted)\n- Jean-Marc Nuzillard (contacted)\n- Jonathan Bisson (contacted)\n- Emma Schymanski (contacted)\n- Tobias Kühn (contacted)\n- Ana Claudia Sima (contacted)\n\n\n[[viewpoint.authors]]","n":0.04}}},{"i":471,"$":{"0":{"v":"Communication","n":1}}},{"i":472,"$":{"0":{"v":"Emails","n":1}}},{"i":473,"$":{"0":{"v":"Exchanged","n":1},"1":{"v":"\n\n# Recap of exchanged ideas and comments in the emails \n\n- ACS: Ana Claudia Sima\n- AR: Adriano Rutz\n- DM: Daniel Mietchen\n- ES: Emma Schymanski\n- EW: Egon Willighagen\n- JB: Jonathan Bisson\n- JMN: Jean-Marc Nuzillard\n- PMR: Peter Murray Rust\n- TK: Tobias Kühn\n\n\nFinally, not sur anyone is OK to have their email published and gitversionned. Thus pasting the whole stuff on a pad (can be easily unlinked if needed)\nhttps://mypads2.framapad.org/p/r.a5198b81e8c8728cf70c02be6fed4ff8\n","n":0.123}}},{"i":474,"$":{"0":{"v":"Synopsis","n":1},"1":{"v":"\n# Framapad\n\nat https://mypads2.framapad.org/p/synopsis-bo39rh90k\n\n# Guidelines for submitting a synopsis to Natural Product Reports\n\nNPR articles are designed to give an interesting insight into the topic, focussing on the key developments that have shaped a field rather than giving a very comprehensive overview of all results. Authors are encouraged to include their own perspective on developments, trends and future directions.\nBefore commissioning articles for NPR we ask that authors provide a brief synopsis. This is circulated to members of the editorial board for comment.  \n\nPlease include the following information in your synopsis:\n\n1. A proposed title for the work\n\n\n2. Authors and affiliations (including co-authors if known)\n\n[[viewpoint.authors]]\n\n3. A suggested length of the article – this should be the number of printed journal pages\n\n8 pages\n\n4. The time span of the literature you intend to cover\n\nFrom [Ebers papyrus](https://en.wikipedia.org/wiki/Ebers_Papyrus \"The Ebers Papyrus, also known as Papyrus Ebers, is an Egyptian medical papyrus of herbal knowledge dating to c. 1550 BCE \\(the late Second Intermediate Period or early New Kingdom\\). Among the oldest and most important medical papyri of Ancient Egypt, it was purchased at Luxor in the winter of 1873–1874 by the German Egyptologist Georg Ebers. It is currently kept at the Leipzig University Library in Germany.\") to nowadays.\n\n5. A brief description of the review and topic to be covered, including:\n\n    - What the implications are for the wider scientific community\n\n    - Which communities your article will appeal to\n\n6. Suggested section headings\n\n\n\n7. A brief list of key references, noting any other reviews which have been published in the area.\n\n\n- Adriano Rutz, Maria Sorokina, Jakub Galgonek, Daniel Mietchen, Egon Willighagen, Arnaud Gaudry, James G Graham, Ralf Stephan, Roderic Page, Jiří Vondrášek, Christoph Steinbeck, Guido F Pauli, Jean-Luc Wolfender, Jonathan Bisson, Pierre-Marie Allard (2022) The LOTUS initiative for open knowledge management in natural products research eLife 11:e70780 https://doi.org/10.7554/eLife.70780\n\n- Henning Otto Brinkhaus, Kohulan Rajan, Jonas Schaub, Achim Zielesny, Christoph Steinbeck,\nOpen data and algorithms for open science in AI-driven molecular informatics,\nCurrent Opinion in Structural Biology, Volume 79, 2023, 102542, ISSN 0959-440X, https://doi.org/10.1016/j.sbi.2023.102542. (https://www.sciencedirect.com/science/article/pii/S0959440X23000167)\n\n\n\n\n8. An approximate date of article submission","n":0.055}}},{"i":475,"$":{"0":{"v":"Bitsandpieces","n":1}}},{"i":476,"$":{"0":{"v":"History","n":1},"1":{"v":"# History of NP research \ntime\n## Context\nFirst, provide some context to orient you/readers/your grandma who are less familiar with your topic and to establish the importance of this note/paragraph/text/paper/project.\n## Need\nSecond, state the need for your note/paragraph/text/paper/project, as an opposition between what you/others/the scientific community/your grandma currently has and what it wants.\n## Task (of the note/paragraph/text/paper/project)\nThird, indicate what you have done in an effort to address the need (this is the task).\n- [ ] did this\n- [ ] did that\n- [ ] oh and this also\n## Object (of the note/paragraph/text/paper/project)\nFinally, preview the remainder of the paper to mentally prepare you/readers for its structure, in the object of the document.","n":0.096}}},{"i":477,"$":{"0":{"v":"Draft","n":1},"1":{"v":"\n\n*Guidelines for submitting a synopsis to Natural Product Reports\n\nNPR articles are designed to give an interesting insight into the topic, focussing on the key developments that have shaped a field rather than giving a very comprehensive overview of all results. Authors are encouraged to include their own perspective on developments, trends and future directions.\nBefore commissioning articles for NPR we ask that authors provide a brief synopsis. This is circulated to members of the editorial board for comment.  \n\n\nThe OSNPR folder https://mypads2.framapad.org/mypads/?/mypads/group/osnpr-2739qh9rj/view\n\nIdeas and ressources https://mypads2.framapad.org/mypads/?/mypads/group/osnpr-2739qh9rj/pad/view/ideas-and-ressources-osnpr-viewpoint-5p30rz9fm\n\n\n\nGuidelines for a Viewpoint https://www.rsc.org/globalassets/05-journals-books-databases/our-journals/natural-product-reports/npr-viewpoint-submission-guidelines.pdf\nAn example of viewpoint synopsis proposal https://www.dropbox.com/scl/fi/3z18z0qd75ai2eiskbugx/Synopsis-example.pdf?rlkey=ioedl5re63ljujcmnc5jgz0ax&dl=0\n\nExample of published Viewpoint.\n\nFrom plant to cancer drug: lessons learned from the discovery of taxo https://pubs.rsc.org/en/content/articlelanding/2023/np/d3np00017f (18 Ref 5 page)\nRibosome-independent peptide biosynthesis: the challenge of a unifying nomenclature https://pubs.rsc.org/en/content/articlelanding/2022/np/d1np00019e (39 Ref 7 page)\n\n\nPlease include the following information in your synopsis:\n\n*1. A proposed title for the work\n\nOpen Science in Natural Products Research\n\n\n*2. Authors and affiliations (including co-authors if known)\n\n- ACS: Ana Claudia Sima, SIB Swiss Institute of Bioinformatics, Amphipôle, 1015 Lausanne, Switzerland, ORCID: 0000-0003-3213-4495\n- AR: Adriano Rutz: Institute of Molecular Systems Biology, ETH Zürich, Otto-Stern-Weg 3, 8093, Switzerland. ORCID: 0000-0003-0443-9902\n- DM: Daniel Mietchen: Leibniz Institute for Freshwater Ecology and Inland Fisheries, Müggelseedamm 310, \n12587 Berlin. ORCID: 0000-0001-9488-1870\n- ELS: Emma L. Schymanski: Luxembourg Centre for Systems Biomedicine (LCSB), University of Luxembourg, 6 avenue du Swing, L-4367 Belvaux, Luxembourg. ORCID: 0000-0001-6868-8145\n- EW: Egon Willighagen: Department of Bioinformatics - BiGCaT, NUTRIM School of Nutrition and Translational Research in Metabolism, Maastricht University, Maastricht, The Netherlands. ORCID:0000-0001-7542-0286\n- JB: Jonathan Bisson: Collaborative Drug Discovery, Burlingame, CA, USA ORCID: 0000-0003-1640-9989\n- JMN: Jean-Marc Nuzillard: Université de Reims Champagne-Ardenne, CNRS, ICMR, Reims, France. ORCID: 0000-0002-5120-2556\n- PMA: Pierre-Marie Allard: Department of Biology, University of Fribourg, Ch. du Musée 10, 1700 Fribourg, Switzerland. ORCID: 0000-0003-3389-2191\n- PMR: Peter Murray Rust\n- TK: Tobias Kühn\n\nDonat Agosti : to invite. Great experience regarding the advancement of taxon / taxonomic treatments handling.\n\nThis part (current credit attribution and authorship methods could also be discussed and guidelines proposed ? \nI have done some bibliography on this for another project. What looked like the fairest way and simplest is the one proposed by \"The first author takes it all? Solutions for crediting authors more visibly, transparently, and free of bias\" https://bpspsychub.onlinelibrary.wiley.com/doi/10.1111/bjso.12569 and others. Basically alphabetical ordering of the authors + two clear CRediT tables (one by tasks done, one by authors) looks random enough (should be stated explicitely) and explain who has been doing what. The idea is to break the first/last author monopoly which is not the best way to credit authors contrib. A colleague told me that we shouldn't / coulnt do this with PhD, MSc students because they NEED their first author paper. Im happy to hear your thought here. This small app makes it easy to implement such tables. (In a paper like this one it's maybe overkill as their is not much more than writing involved ...) They also suggest everyone should let their email and be corresponding authors.\nYou put me wherever you want, as long as it helps the people in fields where author positions matter. \n\nSee this vbiewpoint as suggestion to ediotrs.\nFor ex. adoption of the CREDIT for authors in NP journals \n\n*3. A suggested length of the article – this should be the number of printed journal pages\n\nMax. 8 printed pages\n\n\n*4. The time span of the literature you intend to cover\n\nFrom antiquity to nowadays.\n\n\n*5. A brief description of the review and topic to be covered, including:\n\n    This synopsis aims to provide an overview of the emerging field of open science in natural products research, highlighting its significance, key principles, and potential impact on the field. Natural products have long been a valuable source of compounds with diverse biological activities, contributing to the development of novel drugs, foods and dyes; and form the basis of the traditional medicine used by the vast majority of the world's population. However, the traditionally closed and proprietary nature of natural products research has limited and still hinders the accessibility, reproducibility, and collaboration within the scientific community. The concept of open science promotes transparency, accessibility, and collaboration through the unrestricted sharing of research outputs, data, and methodologies. In this review, we will explore the various aspects of open science in the context of natural products research, including open access publishing, open data, open source software, citizen science initiatives, and collaborative networks. We will discuss the benefits, challenges, and potential solutions associated with adopting an open approach in natural products chemistry, emphasizing the potential for accelerating scientific discovery, fostering innovation, and promoting global collaboration in this vital field. Additionally, we will present novel guidelines for publishing and documenting natural products occurrences, with the aim of proposing standardized practices that could be readily adopted by researchers and publishers in the field. By establishing clear and comprehensive guidelines, we seek to enhance the FAIRness (Findability, Accessibility, Interoperability and Reusability) of natural products research, ultimately fostering a more open and collaborative scientific ecosystem.\n\nImplications for the wider scientific community:\n\nThe adoption of open science in natural products research promotes transparency, collaboration, and accessibility. It enhances the reproducibility and reliability of research, accelerates knowledge dissemination, and facilitates the development of NP's applications. It also fosters inclusivity and global collaboration within the scientific community, ultimately advancing the field and benefiting society as a whole. However the transition to open research requires sustained efforts and resources, and these are best mobilized when the benefits of open science are clearly identified by the researchers. Currently, funding agencies are progressively enforcing research outputs, processes and methodologies to be open, making such global transition inevitable in the end. In addition, open science helps people from less privileged places to both learn from and join in on advanced research, breaking down the usual barriers. For individuals outside the institutions of science and industry, it makes complex knowledge easier to access, understand and use, leading to better decisions and creative solutions for problems in their own communities and the wider world.\n\nCommunities the article will appeal to:\n\nnatural products chemists, pharmacologists, medicinal chemists, organic chemists, biochemists, ecologists, cheminformaticians and researchers interested in open science and description of the global chemodiversity. \nIt is also relevant to professionals in academia, industry, regulatory agencies, and those involved in the dissemination of knowledge, including librarians, publishers, and policymakers.\n\nWe therefore aim to address an entire ecosystem, from Knowledge Producers to Knowledge Disseminators in Natural Products Research, as we strongly believe that communities need to act together to improve the health of the whole natural products ecosystem, and that Open Science provides the necessary path and opportunity for strengthening this collaboration in going forward.\n\n*6. Suggested section headings\n\n\t1.  Overview of Natural Products Research from antiquity to nowadays\n\t2. Emergence and current landscape of Open Natural Products Research\n\t3. Key Principles of Open Science in the Context of Natural Products Research\n\t4. The Significance of Open Science in Advancing Natural Products Research\n\t5. Proposed solutions for Publishing and Documenting Natural Products\nHere, we will notably propose a semantically-enriched version of the current viewpoint, a semantically-enriched version of a typical NPR hot-off-the-press (e.g. https://pubs.rsc.org/en/content/articlelanding/2023/np/d3np90029k) and propose to editors a simpler and easy to adopt mechanism for the enhancement of Natural Products Research dissemination (a CSV file to be shared in Supplementary Information, or as a Zenodo repository associated to the published paper). \n\n\n\n*7. A brief list of key references, noting any other reviews which have been published in the area.\n\nhttps://www.unesco.org/en/open-science/about\n\nJournal Open Access and Plan S: Solving Problems or Shifting Burdens?\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/dech.12635\n\nOpen Data, Open Source and Open Standards in chemistry: The Blue Obelisk five years on\nhttps://jcheminf.biomedcentral.com/articles/10.1186/1758-2946-3-37\n\nScience Forum: Wikidata as a knowledge graph for the life sciences\nhttps://elifesciences.org/articles/52614\n\nThe LOTUS initiative for open knowledge management in natural products research\nhttps://elifesciences.org/articles/70780\n\nOpen-access metabolomics databases for natural product research: present capabilities and future potential\nhttps://www.frontiersin.org/articles/10.3389/fbioe.2015.00022/full\n\nReview on natural products databases: where to find data in 2020\nhttps://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-00424-9\n\nSharing and community curation of mass spectrometry data with Global Natural Products Social Molecular Networking\nhttps://www.nature.com/articles/nbt.3597\n\nComputational Literature-based Discovery for Natural Products Research: Current State and Future Prospects\nhttps://www.frontiersin.org/articles/10.3389/fbinf.2022.827207/full\n\nPublishing without Publishers: a Decentralized Approach to Dissemination, Retrieval, and Archiving of Data\nhttps://arxiv.org/abs/1411.2749\n\nExpressing High-Level Scientific Claims with Formal Semantics https://arxiv.org/abs/2109.12907\n\n\n*8. An approximate date of article submission\n\nDecember 2023\n","n":0.027}}},{"i":478,"$":{"0":{"v":"Ressources","n":1}}},{"i":479,"$":{"0":{"v":"Bibliography","n":1},"1":{"v":"\n\nhttps://www.unesco.org/en/open-science/about\n\nhttps://en.wikipedia.org/wiki/Blue_Obelisk\n\nThe Blue Obelisk—Interoperability in Chemical Informatics\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC4878861/\n\nOpen Data, Open Source and Open Standards in chemistry: The Blue Obelisk five years on\nhttps://jcheminf.biomedcentral.com/articles/10.1186/1758-2946-3-37\n\n\nOpen-access metabolomics databases for natural product research: present capabilities and future potential\nhttps://www.frontiersin.org/articles/10.3389/fbioe.2015.00022/full\n\nReview on natural products databases: where to find data in 2020\nhttps://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-00424-9\n\n\n67 million natural product-like compound database generated via molecular language processing\nhttps://www.nature.com/articles/s41597-023-02207-x\n\nThe LOTUS initiative for open knowledge management in natural products research\nhttps://elifesciences.org/articles/70780\n\n\nMicrobial natural product databases: moving forward in the multi-omics era\nhttps://pubs.rsc.org/en/content/articlelanding/2021/np/d0np00053a\n\n\nScience Forum: Wikidata as a knowledge graph for the life sciences\nhttps://elifesciences.org/articles/52614\n\nSharing and community curation of mass spectrometry data with Global Natural Products Social Molecular Networking\nhttps://www.nature.com/articles/nbt.3597\n\nManagement Research as a Design Science: Articulating the Research Products of Mode 2 Knowledge Production in Management\nhttps://doi.org/10.1111/j.1467-8551.2005.00437.x\n\nJournal Open Access and Plan S: Solving Problems or Shifting Burdens?\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/dech.12635","n":0.091}}},{"i":480,"$":{"0":{"v":"Extraction","n":1},"1":{"v":"\n\nRoyal Society of Chemistry\nView PDF VersionPrevious ArticleNext Article\nCheck for updates\n\n Open Access Article\n This Open Access Article is licensed under a\nCreative Commons Attribution 3.0 Unported Licence\nDOI: 10.1039/D1NP00018G (Review Article) Nat. Prod. Rep., 2021, 38, 2315-2346\nMulti-colored shades of betalains: recent advances in betacyanin chemistry\nAgnieszka Kumorkiewicz-Jamro ORCID logo*, Tomasz Świergosz ORCID logo, Katarzyna Sutor ORCID logo, Aneta Spórna-Kucab ORCID logo and Sławomir Wybraniec ORCID logo*\nDepartment of Chemical Technology and Environmental Analysis, Faculty of Chemical Engineering and Technology, Cracow University of Technology, Warszawska 24, 31-155 Cracow, Poland. E-mail: agnieszka.kumorkiewicz-jamro@pk.edu.pl; slawomir.wybraniec@pk.edu.pl\n\nReceived 13th March 2021\nFirst published on 13th September 2021\n\nContents\n1 Introduction\n2 Characterization of betacyanins\n2.1 Sources of betacyanin pigments\n2.2 Biological properties of betacyanins\n2.3 Applications of betacyanin pigments\n3 Chemistry of betacyanins and betalamic acid derivatives\n3.1 Overview of betacyanin chemical reactions\n4 Chemistry of betacyanins and their semi-synthetic derivatives based on betanin hydrolysis\n4.1 Hydrolysis of betanin\n4.2 One step semi-synthesis of betalains from betalamic acid-derivatized support\n4.3 Semi-synthetic betalain pigments with extended conjugated systems\n5 Conclusions\n6 Conflicts of interest\nAcknowledgements\nReferences\nAbstract\nCovering: 2001 to 2021\n\nBetacyanins cover a class of remarkable natural red-violet plant pigments with prospective chemical and biological properties for wide-ranging applications in food, pharmaceuticals, and the cosmetic industry. Betacyanins, forming the betalain pigment group together with yellow betaxanthins, have gained much attention due to the increasing social awareness of the positive impact of natural products on human health. Betalains are commercially recognized as natural food colorants with preliminarily ascertained, but to be further investigated, health-promoting properties. In addition, they exhibit a remarkable structural diversity based on glycosylated and acylated varieties. The main research directions for natural plant pigments are focused on their structure elucidation, methods of their separation and analysis, biological activities, bioavailability, factors affecting their stability, industrial applications as a plant-based food, natural colorants, drugs, and cosmetics as well as methods for high-yield production and stabilization. This review covers period of the last two decades of betacyanin research. In the first part of the review, we present an updated classification of all known betacyanins and their derivatives identified by chemical means as well as by mass spectrometric and NMR techniques. In the second part, we review the current research reports focused on the chemical properties of the pigments (decarboxylation, oxidation, conjugation, and chlorination reactions as well as the acyl group migration phenomenon) and describe the semi-synthesis of natural and artificial fluorescent betalamic acid conjugates, showing various prospective research directions.\n\nimage file: d1np00018g-p1.tif\nAgnieszka Kumorkiewicz-Jamro\n\nAgnieszka Kumorkiewicz-Jamro received her PhD in 2021 from AGH University of Science and Technology (Cracow, Poland). She graduated with a BSc in the field of biotechnology and MSc in analytical chemistry. She is a research and teaching assistant at the Cracow University of Technology. Her main research interests are in phytochemical analysis, and chromatographic methods for natural compounds' separation, purification, and identification. Her current work focuses on (bio)chemical research on betalain pigments isolated from versatile plant sources.\n\nimage file: d1np00018g-p2.tif\nTomasz Świergosz\n\nTomasz Świergosz is a researcher at the Department of Chemical Technology and Environmental Analysis, Faculty of Chemical Engineering and Technology (Cracow University of Technology, Poland). His research interests include natural compounds, active organic and macromolecular materials, in particular, supramolecular chemistry of functional dyes and π-conjugated systems, molecular self-assemblies, nanostructures and molecular probes, synthesis and characterization of polymers, photoinitiators for cationic polymerization processes and the investigation of their effectiveness and efficiency in photopolymerization, along with the synthesis of fluorescent compounds as fluorescent probes for special applications.\n\nimage file: d1np00018g-p3.tif\nKatarzyna Sutor\n\nKatarzyna Sutor is a second year PhD student at the Cracow University of Technology (Faculty of Chemical Engineering and Technology). She graduated from MA studies in the field of biotechnology. During her BSc and MSc studies, she focused on the influence of reactive oxygen species on the properties of cancer cells studied by AFM and fluorescence microscopy. This research was carried out in cooperation with the Department of Biophysical Microstructures, H. Niewodniczański Institute of Nuclear Physics of Polish Academy of Sciences (Cracow, Poland), where she was on internship. Currently, she focuses on the chemical and bioactive properties of acylated betacyanins from plant sources.\n\nimage file: d1np00018g-p4.tif\nAneta Spórna-Kucab\n\nAneta Spórna-Kucab studied at the Cracow University of Technology (Faculty of Chemical Engineering and Technology). She received her MSc degree in 2008 and PhD in 2013 under the guidance of assoc. prof. Sławomir Wybraniec, working on the chemistry of betalains. During her PhD, she was a researcher at Technische Universität Braunschweig (Braunschweig, Germany) and Brunel University (London, England) where she received formal training in countercurrent chromatography. She is particularly interested in the analytical chemistry of betalains, saponins, and polyphenols as well as the antimicrobial and antioxidant activities of natural compounds.\n\nimage file: d1np00018g-p5.tif\nSławomir Wybraniec\n\nSławomir Wybraniec is an associate professor at the Faculty of Chemical Engineering and Technology (Cracow University of Technology, Poland), where he formerly received his BSc and MSc degrees and started his work (in 1991) at the position of Assistant at the Department of Analytical Chemistry. He graduated with a PhD degree from Jagiellonian University (Chemistry Department) in 1997 and after his postdoctoral fellowship (1998–2000) at the Institutes for Applied Research-Ben-Gurion University of the Negev (Beer-Sheva, Israel), he started research on betalain pigments, which he has continued at the Cracow University of Technology to date, exploring the chemistry and bioactivity of betalains.\n\n1 Introduction\nBetacyanins are unique, water-soluble, red-violet indoline- and dihydropyridine-derived nitrogen-containing natural plant pigments that occur in most families of the Caryophyllales order. Betacyanins, together with yellow-orange betaxanthins, form a group of betalain pigments.1 Simultaneously with anthocyanins, carotenoids, and chlorophylls, betalains are one of the most common plant pigments found in nature.2,3 These compounds share betalamic acid as the main chromogenic structural unit condensed with cyclo-DOPA, forming betanidin or glycosylated cyclo-DOPA in other betacyanins as well as different amino acids or amines in betaxanthins.4,5\nSo far, betacyanins (Table 1) have been assigned to four structural groups comprising betanin-type, gomphrenin-type, amaranthin-type, and Bougainvillea-r-I-type,6,7 the latter was recently renamed as melocactin-type.8 However, for a convenient view on a wide spectrum of pigments, an expanded division with three additional betacyanin groups is proposed based on the sugar linkage: oleracin-type9 (a very early result, not indepedently confirmed), apiocactin-type,10–12 and Bougainvillea-v-type (here, we propose to name it as glabranin-type). In particular, the latter group of the pigments with the structures based on gomphrenin is important in the division system not only because of its less common 6-O-glycosylation pattern but also because of its unique and extremely complex profile of ca. 146 betacyanins tentatively detected in only one plant species, Bougainvillea glabra Choisy,11 including nine definitively identified betacyanins by LC-ESI-MS and NMR.13\n\nTable 1 List of betacyanins (with proposed new trivial namesa) identified by chemical methods; LC-MS and NMR in different plant sources\nNo.\tName\tTrivial name/proposed new namea\tm/z [M + H]+\tChem.\tLC-MS\tNMR\tPlant sources(Chem.)/(LC-MS)/(NMR)\tRef. (Chem.)/(LC-MS)/(NMR)\n1\tBetanidin 5-O-β-glucoside\tBetanin\t551\t+\t+\t+\tB. vulgaris/G. globosa/B. vulgaris\t47 and 48/24/24\n2\tBetanidin\tBetanidin\t389\t+\t+\t+\tB. vulgaris/B. glabra/B. vulgaris\t49/50/50\n3\t2-Decarboxy-betanin\t\t507\t−\t+\t+\tB. vulgaris\t51\n4\t14,15-Dehydro-betanin\tNeobetanin\t549\t+\t+\t+\tB. vulgaris\t52 and 53\n5\t6′-O-Sulfate-betanin\tPrebetanin\t631\t+\t+\t+\t3x P. americana; B. vulgaris/B. vulgaris/\t54/10/54\n6\t2-Decarboxy-phyllocactin\t\t593\t−\t+\t+\tB. vulgaris\t51\n7\t2-Decarboxy-betanidin\t\t345\t+\t+\t−\tC. acinaciformis\t55/51\n8\t2′-O-β-Apiosyl-betanin\tApiocactina\t683\t−\t+\t+\tH. ocamponis\t11\n9\t5′′-O-E-Sinapoyl-apiocactin\t\t889\t+\t+\t−\t2x H. ocamponis/Melocactus spp.\t11/8, 11\n10\t4′-O-Malonyl-betanin\t\t637\t+\t+\t−\tH. ocamponis\t11\n11\t5′′-O-E-Feruloyl-apiocactin\t\t859\t+\t+\t+\tP. americana\t10\n12\t6′-O-Malonyl-betanin\tPhyllocactin\t637\t−\t+\t+\tS. buckleyi/P. hybridus\t38/48\n13\t2′-O-β-Apiosyl-phyllocactin\t\t683\t−\t+\t+\tS. buckleyi\t38\n14\t2′-O-β-(5′′-O-E-Feruloyl)-apiosyl-phyllocactin\t\t945\t−\t+\t−\tS. buckleyi\t38\n15\t6′-O-(3′′-Hydroxy-3′′-methylglutaryl)-betanin\tHylocerenin\t695\t−\t+\t+\tH. polyrhizus\t56\n16\tBetanidin 5-O-(6′-O-E-4-coumaroyl-β-glucoside)\tLampranthin I\t(697)\t+\t−\t−\tLampranthus sp.\t57\n17\tBetanidin 5-O-β-(6′-O-E-feruloyl)-glucoside\tLampranthin II\t727\t+\t+\t+\tLampranthus sp./G. globosa/L. sociorum\t57/24/58\n18\t3′-O-Sulfate-betanin\tRivinianin\t(631)\t+\t−\t−\tR. humilis\t59\n19\tBetanidin 5-O-β-sophoroside\tBougainvillein-r-I; melocactina\t713\t+\t+\t+\t3x Boug. Mrs. Butt’/Melocactus spp./\t32/8, 11/11\n20\t(Caffeoyl and/or coumaroyl)-bougainvillein-r I\tBougainvillein-r-II, III, IV, V\t−\t+\t−\t−\tBoug. Mrs. Butt\t32\n21\tBetanidin 5-O-(2′-O-β-glucuronosyl)-glucoside\tAmaranthin\t727\t+\t+\t+\tA. tricolor/Amaranthus sp./C. cristata\t60/27/61\n22\t2′′-O-E-4-Coumaroyl-amaranthin\tCelosianin I; argentianina\t873\t−\t+\t−\tC. cristata\t25 and 27\n23\t2′′-O-E-Feruloyl-amaranthin\tCelosianin II; celosianina\t903\t−\t+\t+\tC. cristata\t27 and 58/58\n24\t6′-O-Malonyl-amaranthin\tCeloscristatin\t813\t+\t+\t+\tC. cristata\t29\n25\t4′-O-Malonyl-amaranthin\t\t813\t−\t+\t−\tC. cristata\t29\n26\t6′-O-(3′′-Hydroxy-3′′-methylglutaryl)-amaranthin\tIresinin I\t871\t+\t+\t+\tI. herbstii\t61/27/61\n27\t4′-O-Malonyl-bougainvillein-r I\t\t799\t−\t+\t−\tMammillaria spp.\t36\n28\t6′-O-Malonyl-bougainvillein-r I\tMammillarinin\t799\t−\t+\t+\tMammillaria spp.\t36\n29\t2-Decarboxy-mammillarinin\t\t755\t+\t+\t−\tMammillaria spp.\t36\n30\t17-Decarboxy-mammillarinin\t\t755\t−\t+\t−\tMammillaria spp.\t36\n31\t17-Decarboxy-bougainvillein-r I\t\t669\t−\t+\t−\tMammillaria spp.\t36\n32\tFeruloyl-bougainvillein-r I\t\t889\t−\t+\t−\tM. crystallinum L.; B. vulgaris (Swiss chard)\t62 and 63\n33\t(Dehydrated phyllocactin)\t\t619\t−\t+\t−\tU. tuberosus\t64\n35\tBetanidin 6-O-β-D-sophoroside\tBougainvillein-v; glabranina\t713\t−\t+\t+\tB. glabra v. sander.\t13/33\n36\t6′′-O-Rhamnosyl-glabranin\t\t859\t+\t−\t−\tB. glabra v. sander.\t65\n37\t6′-O-E-Caffeoyl-glabranin\tCafglabranina\t875\t−\t+\t+\tB. glabra\t13\n38\t6′-O-E-4-Coumaroyl-glabranin\tCoumglabranina\t859\t−\t+\t+\tB. glabra\t13\n39\t6′′-O-E-4-Coumaroyl-glabranin\t\t859\t−\t+\t+\tB. glabra\t13\n40\t6′,6′′-Di-O-E-4-coumaroyl-glabranin\tBicoumglabranina\t1005\t−\t+\t+\tB. glabra\t13\n41\t2′′-O-[(6′′-O-E-4-Coumaroyl)]-glucosyl-cafglabranin\t\t1183\t−\t+\t+\tB. glabra\t13\n42\t2′′-O-Glucosyl-bicoumglabranin\t\t1167\t−\t+\t+\tB. glabra\t13\n43\t2′′-O-[(6′′-O-E-4-Coumaroyl)]-sophorosyl-cafglabranin\t\t1345\t−\t+\t+\tB. glabra\t13\n44\tFeruloyl-dihexosyl-betanidin\t\t889\t−\t+\t−\tM. amoenus\t8\n45\tSinapoyl-dihexosyl-betanidin\t\t919\t−\t+\t−\tM. amoenus\t8\n47\tCitryl-(caffeoyl or 4-coumaroyl)-amaranthin\tSuaedin\t−\t+\t−\t−\tS. fruticosa\t66\n48\t2′′-O-E-Sinapoyl-amaranthin\tLindenina\t933\t−\t+\t−\tG. globosa; I. lindenii\t25, 30 and 67\n49\tBetanidin 6-O-β-glucoside\tGomphrenin I; gomphrenina\t551\t+\t+\t+\tG. globosa; B. alba\t68/24/24, 69\n50\t6′-O-E-4-Coumaroyl-gomphrenin I\tGomphrenin II; globosina\t697\t+\t+\t+\tG. globosa\t68/24, 25/24\n51\t6′-O-E-Feruloyl-gomphrenin I\tGomphrenin III; basellina\t727\t+\t+\t+\tG. globosa\t68/24, 25/24\n52\t6′-O-E-Sinapoyl-gomphrenin I\tGomphrenin IV; gandolina\t757\t−\t+\t−\tG. globosa\t25 and 26\n53\tE-Isomer of gomphrenin II\t\t697\t−\t+\t−\tG. globosa\t30\n54\tE-Isomer of gomphrenin III\t\t727\t−\t+\t−\tG. globosa\t30\n55\tBetanidin 5-O-β-(E-feruloyl)-cellobioside\tOleracin I\t(889)\t+\t−\t−\tP. oleracea\t9 and 60\nNumber of betacyanins identified by a given method\t22\t50\t31\t\t\n\nThe schematic division of betacyanins into seven main structural groups based on their chemical structures is shown in Fig. 1. Betacyanins assigned to particular types differ in the attachment of the glucosyl moiety to the oxygen atom in the ortho position of cyclo-DOPA as well as the position of the substitution with additional glycosyl or glucuronosyl moieties.6 The esterification of sugar moieties with organic acids such as ferulic, p-coumaric, caffeic, sinapic, and malonic acids is very common and leads to the formation of various acylated derivatives. The 15R diastereomers (the isoforms, epimers) of betacyanins are found in plants at much lower concentrations than the 15S forms and are regarded rather as artifacts due to epimerization, which takes place during the preparation of extracted plant samples.14 The first studies on isomerization (as well as decarboxylation) mechanism in betacyanins were performed by Dunkelblum et al.15 In more recent reports, the chromatographic differences in the 15S/15R diastereomers of decarboxylated betacyanins16,17 as well as in the acyl migration products18 were investigated.\n\n\nimage file: d1np00018g-f1.tif\nFig. 1 A new comprehensive classification of betacyanin pigments belonging to the betanin-type (A); amaranthin-type (B); melocactin-type (C); oleracin-type (D); apiocactin-type (E); gomphrenin-type (F); and glabranin-type (G). The structures of betacyanins belonging to the (B–E) types are based on betanin (I), while the structures of glabranins are based on the gomphrenin backbone (II).\t\nBetanin (betanidin 5-O-β-D-glucopyranoside) is the main representative and most common betacyanin pigment found in the plant kingdom (Fig. 1 and 2A). In addition, betanin isolated from Beta vulgaris L. (beetroot, red beet) is the most studied pigment in the context of the antioxidant properties of betacyanins. Structurally, betanin and most of its derivatives are composed of aglycone (betanidin) linked by the β-glucosidic bond with the glucose unit at the C-5 carbon atom.19,20 The chemical structures of additional compounds belonging to betanin-type betacyanins are shown in Fig. 2. Such compounds share a common betanidin backbone in their structures with an additional glucose moiety (betanin) along with (3-methyl-3-hydroxy-methyl)glutaryl-, malonyl-, E-4-coumaroyl-, and E-feruloyl-moieties as well as the half sulphate ester in hylocerenin, phyllocactin, lampranthin I, lampranthin II, and prebetanin, respectively, but can be also partially oxidized (neobetanin) (Fig. 2).\n\n\nimage file: d1np00018g-f2.tif\nFig. 2 Chemical structures of betanin-type betacyanins.\t\nGomphrenin (betanidin 6-O-β-D-glucopyranoside), which is the isomeric pigment to betanin, is found at high concentrations in Basella alba L. fruits as well as in the leaves of its variety Basella alba var. ‘Rubra’ L.21,22 According to our recent recommendation, we propose to rename gomphrenin I as “gomphrenin” in order to simplify the naming of its derivatives, especially generated by gomphrenin decarboxylation and oxidation.16 In contrast to betanins, gomphrenins are characterized by the presence of a glucosyl moiety attached at the carbon C-6 (Fig. 1 and 3A).21,22 Furthermore, the acylation of gomphrenin enables the formation of its derivatives such as E-4-coumaroyl-gomphrenin (former gomphrenin II, globosin), E-feruloyl-gomphrenin (former gomphrenin III, basellin), and E-sinapoyl-gomphrenin (gomphrenin IV, gandolin) (Table 1, Fig. 3B–D).12 Gomphrenin pigments are of interest because their glucosylation position at the carbon C-6 should promote an interaction of the acylated residues with the carboxyl groups by increasing the intramolecular stabilization (by intramolecular stacking) of globosin and basellin23 or other types of multiple acylated sophorosyl residues observed in glabranins. Betacyanins were also detected in red and purple Gomphrena globosa L. inflorescences. The most dominant betacyanins present in red G. globosa cultivars are amaranthin and celosianin but in violet species, gomphrenin and especially the acylated derivatives, globosin and basellin, are present.24,25 In addition, other betacyanins were initially identified, namely, Z-4-coumaroyl-gomphrenin and Z-feruloyl-gomphrenin isomers as well as gandolin.25,26\n\n\nimage file: d1np00018g-f3.tif\nFig. 3 Chemical structures of basic betacyanins (A–D) belonging to gomphrenin-type.\t\nPlant pigments belonging to the amaranthin-type group have a characteristic glucuronosylglucosyl moiety attached to the carbon C-5 in their structure. The most common example of these pigments is amaranthin [betanidin 5-O-β-(2′-O-β-glucuronosyl)glucoside] (Fig. 4A) isolated from plants of the Amaranthaceae family.27,28 The other frequently detected pigments in the plants are betanin and 6′-O-malonyl-amaranthin.29 Furthermore, sinapoyl-amaranthin has been tentatively identified in G. globosa petals.30 Iresinin I [6′-O-(3′′-hydroxy-3′′-methyl)glutaryl-2′-O-glucuronosyl-betanin] and amaranthin are the most abundant pigments detected in Iresine herbstii Hook. ex Lindl leaves (Table 1).27 Acylated amaranthin-based pigments, argentianin and celosianin, were also found in Celosia species31 and the purple leaves of I. herbstii (Fig. 4).25\n\n\nimage file: d1np00018g-f4.tif\nFig. 4 Chemical structures of betacyanins (A–E) belonging to amaranthin-type.\t\nMost of the pigments from the two Bougainvillea groups have sophorosyl moieties linked to carbons C-5 or C-6 of the basic skeleton of betanidin, expanded further by glucosyl, rhamnosyl, apiosyl, or xylosyl moieties.13,26,32–35 A complex mixture of betacyanins that differs in acyl-oligoglycoside units and exists mostly in the 6-O-glycosylated forms of betanidin was initially identified in the purple bracts of B. glabra.13 However, due to the complex mixture of a huge number of betacyanins present in B. glabra,34 its profile has not been completely characterized. The examples of bougainvillein-type betacyanins are bougainvillein-r-I (melocactin-type) and bougainvillein-v (glabranin-type) (Table 1, Fig. 5A and B). Similar betacyanins were recently found within Melocactus species.8 The most abundant pigment, melocactin, previously named ‘bougainvillein-r-I’, was identified as betanidin 5-O-β-sophoroside (Fig. 5A). The presence of feruloylated and sinapoylated melocactins as well as melocactin's malonylated derivative, mammillarinin, was also noted (Fig. 5C).8 In some Mammillaria species, mammillarinin [betanidin 5-O-(6′-O-malonyl)-β-sophoroside] was reported as the dominant pigment.36\n\n\nimage file: d1np00018g-f5.tif\nFig. 5 Chemical structures of betacyanins belonging to both the bougainvillein groups: melocactin-type (bougainvillein-r-I (A) and mammillarinin (C)) and glabranin-type (bougainvillein-v) (B).\t\nTwo red-violet acylated betacyanins, oleracins I and II, have been found in Portulaca oleracea L. Upon hydrolysis in alkaline conditions, oleracins gave ferulic acid and two newly detected pigments that were identified as 5-O-β-cellobiosides of betanidin and isobetanidin (Fig. 1E).9 Five other yellow oleracins were also detected in P. oleracea; however, in contrast to oleracins I and II, they did not possess betalamic acid in their structures.37\n\nBetacyanins belonging to the apiocactin-type group contain the rare branched pentose, apiose, bound to the carbon C-2′ of betanin. Pigments such as 2′-O-β-apiosyl-betanin (apiocactin) and/or its acylated derivatives (Table 1, Fig. 6A–C) have been found in fruits of pokeberry and its corresponding suspension and callus cultures (Phytolacca americana L.), Christmas cactus flowers (Schlumbergera x buckleyi), and Hylocereus species.10,11,38 The chemical structure of the basic apiocactin-type betacyanin present in Hylocereus species was confirmed as 2′-O-β-apiosyl-betanin by Wybraniec et al.11 In addition, in the same study, acylated compounds with sinapoyl and feruloyl residues attached to C-5′′ of the apiose moiety were identified as 5′′-O-E-sinapoyl-apiocactin and 5′′-O-E-feruloyl-apiocactin.11 Similarly, 5′′-O-E-feruloyl-apiocactin was identified earlier in P. americana cultures by Schliemann et al.10 Another betacyanin, 2′-O-β-(5′′-O-E-feruloyl)-apiosyl-phyllocactin, which is the first betacyanin example containing both an aliphatic and an aromatic acyl residue, was tentatively detected in Christmas cactus flower extracts together with other apiocactin derivatives38 and later in Hylocereus species.11\n\n\nimage file: d1np00018g-f6.tif\nFig. 6 Chemical structures of betacyanins (A–D) belonging to apiocactin-type.\t\n2 Characterization of betacyanins\n2.1 Sources of betacyanin pigments\nThere are several known edible sources of betacyanins (Table 1). These include red and yellow beetroots (B. vulgaris ssp. vulgaris),1B. alba fruits,39G. globosa flowers,13,30 grainy amaranth (Amaranthus sp.),27 grains of Chenopodium quinoa,40 leaves of A. hortensis var. rubra,41 and fruits/flowers of cacti genera (Opuntia, Hylocereus, Mammillaria, Melocactus, and Myrtillocactus spec.).8,36,42–45 Pokeberry (Phytolacca americana L.) is another source of betacyanins but it has been forbidden as a food colorant due to the presence of toxic saponins and lectins.46\nCompounds tentatively identified as betacyanin-like are also found in some higher fungi such as Amanita muscaria (fly agaric).70,71 The less common edible sources are Ulluco tubers (Ullucus tuberosus)64,72 as well as fruits and berries of pigeonberry (Rivina humilis).73\n\nTable 1 presents a detailed summary of the identified betacyanins in different plant sources along with the methods of their identification. Most of the chemical methods were applied in the early decades of betalain research based on the typical reactions of hydrolysis and derivatization, such as permethylation and partial degradation, resulting in the generation of diagnostic products, which can be identified and can confirm certain parts of the chemical structure of a starting compound. The chemical structures of 31 naturally occurring betacyanins were definitively identified by NMR methods, whereas a huge group of over 187 betacyanins (including pigments from their richest source, B. glabra) were detected by LC-MS techniques and still await the final confirmation. In addition, structures of 18 betacyanin derivatives were also confirmed by NMR and 61 tentatively were identified by LC-MS methods (Fig. 7).\n\n\nimage file: d1np00018g-f7.tif\nFig. 7 The number of naturally-occurring betacyanins and semi-synthesized betacyanins derivatives identified chemically, by NMR techniques and detected by LC-MS methods.\t\n2.2 Biological properties of betacyanins\nNumerous health-promoting activities are attributed to betacyanin pigments, including antioxidative,6,74 chemopreventive,75 and anti-inflammatory76,77 properties. Furthermore, it was noted that betacyanins protect low-density lipoproteins (LDL) against oxidative damage by reacting with the LDL polar groups.78 In addition, betanin present in red beets prevents DNA from damage in lymphocytes and hepatocytes.79 Betanin also shows neuroprotective effects, improves cognitive functions and reduces oxidative stress caused by D-galactose in the brain of mice by increasing the level of antioxidant enzymes and reducing lipid peroxidation.80\nSome betacyanin pigments have been shown to have higher antioxidant activity compared to typical natural antioxidants such as ascorbic acid,81 rutin,82 catechin,83 β-carotene,84 and α-tocopherol.6,85 In a test of the antioxidant activity expressed in TROLOX equivalents, betacyanins extracted from red beet exhibited 1.5–2.0 times higher free radical scavenging activity than some anthocyanins such as cyanidine-3-O-glucoside and cyanidine above pH 4.86,87\n\nThe effect of the hydroxyl group position on the antioxidant activity of the betacyanins bearing the conjugated phenol moiety was studied. Three non-natural regioisomeric phenolic betacyanins (common name: o-, m-, p-OH-pBeets) were semi-synthesized by coupling betalamic acid with appropriate aminophenols in water according to a procedure described by Schliemann and co-authors88 and their antioxidant activity was studied.89,90 The results showed that the meta isomer exhibits greater antiradical activity than most of the betalains, flavonoids, and anthocyanins. This result may be explained by the fact that the phenolic moiety is not conjugated with the diazapolymethine system but both groups are prone to further oxidation and can stabilize the radicals by resonance. In addition, the N–H imine bond present in the meta regioisomeric structure is the preferred site for oxidation, whereas 1e− oxidation of the phenolic groups in p- and o-OH-pBeet results in the formation of semi-quinone and leads to lower values of the potential energy (Ep) compared to m-OH-pBeet.89,90\n\nBetacyanins have been shown to actively participate in free radical scavenging and consequently, their consumption may lead to chemoprevention and delay of the development of cancer tissues.75 Purified betanin shows strong inhibition of melanoma cancer cell proliferation91 and excellent growth inhibition of MCF-7 (breast), HCT-116 (colon), AGS (stomach), SF-268 (CNS), and NCI-H460 (lungs) cancer cell lines with IC50 values of 162, 142, 158, 164, and 147 μg mL−1, respectively.92 It has also been found that betanin induces dose- and time-dependent apoptosis of cells in the human chronic myelogenous leukemia (K562) cell line.93\n\nIn vitro experiments revealed that betalains extracted from B. vulgaris juice show pro-apoptotic effects on activated neutrophils and inhibit the neutrophil oxidative metabolism.94 In addition, pilot clinical trials have shown that short-term treatment with red beet extract improves joint function in people with knee joint discomfort.76,95\n\n2.3 Applications of betacyanin pigments\nIn Fig. 8, betacyanin applications are schematically presented. Natural plant extracts containing betacyanin pigments are increasingly used in food technology as a safe alternative to synthetic food colorants. According to Title 21 of the Code of Federal Regulations part 73.40 of the Food and Drug Administration (FDA), USA, and under the E-162 code in the European Union, beetroot powder rich in betanin is permitted as a natural red food colorant.3 Food preparations obtained in different industrial conditions can significantly vary in their stability and coloration due to the presence and the composition of betacyanin degradation products. Betalains are stable at pH ranging from 3 to 7 and they are suitable for dyeing low acidic and neutral foods. In addition, they may be stabilized by ascorbic acid. In contrast, due to instability at pH over 3, the application of anthocyanins in the coloration of such foods is not possible. Furthermore, the use of ascorbic acid also facilitates the degradation of anthocyanins. For this reason, the utilization of betalain pigments instead of anthocyanins for coloring food with a high amount of vitamin C or vitamin C-supplemented products seems to be more favorable.96,97 Beetroot extracts are utilized to emphasize the redness of dairy products such as tomato soups, sauces, pastes, desserts, jams, sweets, and jelly beans. They are also used to protect meat from discoloration and to extend its shelf-life.98 However, due to the unpleasant flavor of beetroot extracts due to their geosmin and pyrazine derivatives content, a membrane process during juice concentration is needed to be applied for commercial red beet application.14\nimage file: d1np00018g-f8.tif\nFig. 8 Overview of various betacyanin pigment applications.\t\nDue to health-related benefits, betalains are also regarded as natural dietary supplements.99 The effect of food supplements containing betalain-rich extracts (a betalain-rich supplement of red beetroot and a betacyanin-rich supplement of Opuntia stricta) on different atherosclerotic risk factors were tested among coronary artery disease patients. The results showed that the levels of glucose, total cholesterol, homocysteine, triglyceride, and low-density lipoprotein (LDL) of 48 male patients were decreased. Furthermore, betalain-rich supplements taken at a safe dose of 50 mg betalain/betacyanins for 2 week interventions reduced the systolic and diastolic blood pressures.100 In the past 20 years, a number of food and nutraceutical preparations have been developed from quinoa (Chenopodium quinoa Willd.) as well. Several clinical studies have demonstrated that quinoa supplementation exerts prominent effects on the cardiovascular, gastrointestinal, and metabolic health of humans.101\n\nNatural plant pigments were also tested in the context of solar cell applications as a cheaper, faster, low energy, and environment-friendly alternative to dyes based on ruthenium complexes.102,103 Betanin, 2,17-bidecarboxy-betanin, vulgaxanthin I, extracted from red beetroot extract and betanidin-6-O-(6′,6′′-di-O-E-4-coumaroyl)-β-sophoroside from Bougainvillea were also tested toward the application as dye-sensitized solar cells (DSSC). The construction of betalain-based DSSC is possible due to the carboxylic groups in betalains, which serve as anchors after the immersion of TiO2 electrodes in betalain aqueous solutions at pH ≈ 3. The quantum yield of electron injection in betacyanin-based and betaxanthin-based DSSC is about 50% and 70%, respectively. In the case of betaxanthin-based DSSC, the total sunlight conversion efficiency was however smaller because of the blue-shifted absorption band.104 The electron injection from betanin to TiO2 is a two-electron, one-proton process.105,106\n\nEnhanced light-harvesting and the photoconversion efficiency of nanocrystalline TiO2 sensitized with betanin was observed and revealed the self-assembly of betanin on the surface. Due to the fact that an aggregated betanin sensitizer improved the performance in DSSC, the mechanism of improved electron injection and collection in DSSCs with more aggregation as compared to monomeric betanin need to be regarded.107\n\nBetanin is capable of injecting up to two electrons per photon absorbed into the ZnO conduction band in less than 15 ps.108 Betanin was also used for the light-harvesting process in ultra-stable ZnO nanocrystals modified with a carboxylate oligoethylene glycol shell system studied for utilization in H2 production under visible light irradiation.109\n\nThe photophysical properties of betanin in aqueous and alcoholic solutions were determined and formation of betanin electronically excited species was studied. Betanin has a short S1 state lifetime (π, π*) (6.4 ps in water), mainly determined by the efficient S1 → S0 radiationless relaxation, which probably requires a strong geometry change. Other processes, such as photoproduct formation or S1 → T1 intersystem crossing have been reported as virtually absent. In the absence of triplet excited state formation, the fast light-to-heat conversion was observed, supporting the consideration that betanin is a photoprotector in vivo.110,111\n\nDue to the presence of the phenolic moiety within the betanin structure, which may react with 1O2, the colorimetric detection of reactive oxygen species is possible. Efficient singlet oxygen quenching by betanin in deuterated water was reported. The capacity of betanin to quench 1O2 supports the photo-protective role of betanin in vivo.112\n\nIn another study, a red beetroot pigment-based colorimetric sensor for detecting copper ions in drinking water was developed. In addition, an application for quantitative and visual colorimetric analysis was designed for the Android system smartphone. When Cu2+ concentration in drinking water increased, the red beet pigment solution gradually changed from bright purple to orange-red as it formed a complex by chelating Cu2+. The linear range of this detection system ranged from 4 to 20 μM and the limit of detection was 0.84 μM.113\n\nBetanin can also compete with synthetic dyes in terms of the depth and color stability. The possibility of dying of modified acrylic fabrics with betanin was investigated. It was found that the optimal conditions during 45 min dyeing of acrylic fabrics with betanin were 50 °C and pH 5. The modified materials were resistant to color loss under the influence of water and the addition of cobalt(II) sulphate(VI) (CoSO4) ensured light resistance.114\n\nAttempts are being made to develop cheap, green, and easy-to-use betalain-based biosensors. A good example is a need for the early detection of Bacillus species. The highly stable and virulent B. anthracis has been considered as a dangerous bioterrorism agent after the anthrax attack took place in 2001.115 Another threat is pathogenic B. cereus that grows on food.116 In order to detect the Bacillus species early, research on the application of betanin as a ligand in the new europium(III) complex, sensitive to calcium dipicolinate, CaDPA (the major component of the bacterial spore core) was conducted. In the presence of Eu(III) ions, betanin was converted into a water-soluble, non-luminescent orange complex. The addition of CaDPA changes the orange color of the [Eu(betanin)+] aqueous solution to magenta. The limit of detection of CaDPA is about 2.06 × 10−6 mol L−1. In addition, the complex is sensitive to CaDPA but not to other structurally similar aromatic, pyridinic, and acidic ligands.117,118\n\nBeetroot extracts are under consideration as a mild alternative to organometallic reductants, such as NaBH4 and N2H4, and as stabilizing (growth-limiting) agents. Beetroot extract was exploited for the bottom-up synthesis of metal nanoparticles, leading to broad size and shape distributions.119\n\n3 Chemistry of betacyanins and betalamic acid derivatives\n3.1 Overview of betacyanin chemical reactions\nTaking into account the pro-health nature of betacyanin pigments, their diversity, structural characteristics, and light-absorption properties, there is a growing need to supplement and broaden the knowledge on their chemistry. Understanding the reactions that betacyanins undergo may contribute to the determination of their fate and distribution in the human body, increase their stability, the development of betalain-based biosensors, screening assays and tailor-made probes, the preparation of betalain-based potential medicinal substances or cosmetics. In the following part of this contribution, we sum up the current knowledge obtained during the last decade on the chemical properties of betacyanins as well as new perspectives of the semi-synthesis of betalamic acid derivatives with extended chromophoric systems. The list of betacyanin derivatives semi-synthesized from plant sources and betacyanin degradation or chemical conversion products, with their structural identification by LC-MS and NMR methods, is presented in Table 2.\nTable 2 List of betacyanin derivatives semi-synthesized from plant sources and betacyanin degradation or chemical conversion products, with their structural identification by LC-MS and NMR methods\nNo.\tName\tTrivial name or abbreviation\tm/z [M + H]+\tLC-MS\tNMR\tPlant sources (Chem.)/(LC-MS)/(NMR)\tReferences (Chem.)/(LC-MS)/(NMR)\n56\t2-Decarboxy-betanin\t2-dBt\t507\t+\t+\tB. vulgaris/H. polyrhizus\t126/127\n57\t15-Decarboxy-betanin\t15-dBt\t507\t+\t−\tB. vulgaris\t122\n58\t17-Decarboxy-betanin\t17-dBt\t507\t+\t+\tB. vulgaris/H. polyrhizus\t122/127\n59\t2,17-Bidecarboxy-betanin\t2,17-dBt\t463\t+\t+\tB. vulgaris/H. polyrhizus\t126/127\n60\t2,15,17-Tridecarboxy-betanin\t2,15,17-dBt\t419\t+\t−\tB. vulgaris\t126\n61\t2-Decarboxy-neobetanin\t2-dNBt\t505\t+\t−\tB. vulgaris\t126\n62\t2,17-Bidecarboxy-neobetanin\t2,17-dNBt\t461\t+\t−\tB. vulgaris\t126\n63\t2,15,17-Tridecarboxy-neobetanin\t2,15,17-dNBt\t417\t+\t−\tB. vulgaris\t126\n64\t2,17-Bidecarboxy-xanbetanin\t2,17-dXBt\t461\t+\t−\tB. vulgaris\t52\n65\t2-Decarboxy-xanneobetanin\t2-dXNBt\t503\t+\t+\tB. vulgaris\t52\n66\t2,17-Bidecarboxy-xanneobetanin\t2,17-dXNBt\t459\t+\t+\tB. vulgaris\t52\n67\t2,15,17-Tridecarboxy-xanneobetanin\t2,15,17-dXNBt\t415\t+\t+\tB. vulgaris\t52\n68\t18-Chloro-betanin\tBt-Cl\t585\t+\t+\tB. vulgaris\t156\n69\t18-Chloro-17-decarboxy-betanin\t17-dBt-Cl\t541\t+\t+\tB. vulgaris\t156\n70\t18-Chloro-2,17-bidecarboxy-betanin\t2,17-dBt-Cl\t497\t+\t+\tB. vulgaris\t156\n71\t18-Chloro-2-decarboxy-betanin\t2-dBt-Cl\t541\t+\t−\tB. vulgaris\t156\n72\t18-Chloro-15-decarboxy-betanin\t15-dBt-Cl\t541\t+\t−\tB. vulgaris\t156\n73\tCysteinyl-2-decarboxy-xanbetanin\t2-dXBt-Cys\t624\t+\t−\tB. vulgaris\t149\n74\t2-Decarboxy-xanbetanin\t2-dXBt\t505\t+\t−\tB. vulgaris\t149\n75\tN-Methyl-phenyl-betalain\tmepBeet\t301\t+\t+\tB. vulgaris\t165\n76\tN-Aryl-phenyl-betalains\tdipBeet\t363\t+\t+\tB. vulgaris\t165\n77\t2,4-Dimethylpyrrole-betalain\tBeetBlue\t289\t+\t+\tB. vulgaris\t166\n78\t7-Amino-4-methylcoumarin-betalain\tcBeet120\t369\t+\t+\tB. vulgaris\t167\n79\t7-Amino-4-trifluoromethylcoumarin-betalain\tcBeet151\t423\t+\t+\tB. vulgaris\t167\n80\t7-Amino-4-methylcoumarin-betalain\tBtC\t369\t+\t−\tB. vulgaris\t168\n81\t17-Decarboxy-neobetanin\t17-dNBt\t505\t+\t−\tH. polyrhizus\t125\n82\t2-Decarboxy-phyllocactin\t2-dPc\t593\t+\t+\tH. polyrhizus\t125/127\n83\t17-Decarboxy-phyllocactin\t17-dPc\t593\t+\t+\tH. polyrhizus\t125/127\n84\t2,17-Bidecarboxy-phyllocactin\t2,17-dPc\t549\t+\t+\tH. polyrhizus\t125/127\n85\t2,15,17-Tridecarboxy-phyllocactin\t2,15,17-dPc\t505\t+\t−\tH. polyrhizus\t125\n86\t2-Decarboxy-hylocerenin\t2-dHc\t651\t+\t+\tH. polyrhizus\t125/127\n87\t17-Decarboxy-hylocerenin\t17-dHc\t651\t+\t−\tH. polyrhizus\t125\n88\t2,17-Bidecarboxy-hylocerenin\t2,17-dHc\t607\t+\t+\tH. polyrhizus\t125/127\n89\t2,15,17-Tridecarboxy-hylocerenin\t2,15,17-dHc\t563\t+\t−\tH. polyrhizus\t125\n90\t2-Decarboxy-neophyllocactin\t2-dNPc\t591\t+\t−\tH. polyrhizus\t125\n91\t17-Decarboxy-neophyllocactin\t17-dNPc\t591\t+\t−\tH. polyrhizus\t125\n92\t2,17-Bidecarboxy-neophyllocactin\t2,17-dNPc\t547\t+\t−\tH. polyrhizus\t125\n93\t2,15,17-Tridecarboxy-neophyllocactin\t2,15,17-dNPc\t503\t+\t−\tH. polyrhizus\t125\n94\t2-Decarboxy-neohylocerenin\t2-dNHc\t649\t+\t−\tH. polyrhizus\t125\n95\t17-Decarboxy-neohylocerenin\t17-dNHc\t649\t+\t−\tH. polyrhizus\t125\n96\t2,17-Bidecarboxy-neohylocerenin\t2,17-dNHc\t605\t+\t−\tH. polyrhizus\t125\n97\t2,15,17-Tridecarboxy-neohylocerenin\t2,15,17-dNHc\t561\t+\t−\tH. polyrhizus\t125\n98\t2-Decarboxy-xanbetanidin\t2-dXBd\t343\t+\t−\tB. alba\t140\n99\t2,17-Bidecarboxy-xanbetanidin\t2,17-dXBd\t299\t+\t−\tB. alba\t140\n100\t2-Decarboxy-xangomphrenin;\t2-dXGp\t505\t+\t−\tB. alba\t140\n101\t2,17-Bidecarboxy-xangomphrenin\t2,17-dXGp\t461\t+\t−\tB. alba\t140\n102\t2-Decarboxy-xanneobetanidin\t2-dXNBd\t341\t+\t−\tB. alba\t140\n103\t2,17-Bidecarboxy-xanneobetanidin\t2,17-dXNBd\t297\t+\t−\tB. alba\t140\n104\t2-Decarboxy-xanneogomphrenin\t2-dXNGp\t503\t+\t−\tB. alba\t140\n105\t2,17-Bidecarboxy-xanneogomphrenin\t2,17-dXNGp\t459\t+\t−\tB. alba\t140\n106\t2,15,17-Tridecarboxy-xanneogomphrenin\t2,15,17-dXNGp\t415\t+\t−\tB. alba\t140\n107\tCysteinyl-betanidin\tCys-Bd\t508\t+\t−\tB. alba\t149\n108\tCysteaminyl-betanidin\tCSH-Bd\t464\t+\t−\tB. alba\t149\n109\tN-Acetyl-cysteinyl-betanidin\tNAC-Bd\t550\t+\t−\tB. alba\t149\n110\tDithiothreitol-betanidin\tDTT-Bd\t541\t+\t−\tB. alba\t149\n111\tCysteinyl-gomphrenin\tCys-Gp\t670\t+\t−\tB. alba\t149\n112\tCysteaminyl-gomphrenin\tCSH-Gp\t626\t+\t−\tB. alba\t149\n113\tDithiothreitol-gomphrenin\tDTT-Gp\t703\t+\t−\tB. alba\t149\n114\tN-Acetyl-cysteinyl-gomphrenin\tNAC-Gp\t712\t+\t+\tB. alba\t149\n115\tGlutathionyl-betanidin\tGSH-Bd\t694\t+\t+\tB. alba\t140\n116\tGlutathionyl-gomphrenin\tGSH-Gp\t856\t+\t−\tB. alba\t140\nNumber of betacyanin derivatives identified by a given method\t18\t6\t\t\n\n3.1.1 Thermal decarboxylation and dehydrogenation of betacyanins. Considering the significant impact of organoleptic characteristics on food selection and consumer acceptance, color is one of the most important attributes of foods as it is considered as a quality indicator.120,121 Nowadays, the complex processing of most foodstuffs may cause some unwanted changes in their visual appearance, contributing to the fading effect in their coloration. During the degradation of betacyanins, they may undergo deglucosylation, decarboxylation, dehydrogenation, and isomerization processes (Fig. 9).\nimage file: d1np00018g-f9.tif\nFig. 9 Possible pathways of betanin transformation by decarboxylation, dehydrogenation, and deglucosylation.129 The m/z values are from the [M + H]+ ions.\t\nThe first heat-degradation structural studies on betanin from B. vulgaris, as well as betacyanins isolated from H. polyrhizus (betanin, phyllocactin, and hylocerenin), were performed by Herbach et al.122–124 and Wybraniec et al.125–127 Betanin was proven to be the most stable pigment, while the stability of phyllocactin and hylocerenin was seemingly enhanced due to the formation of red degradation products, exhibiting improved color retention in comparison to their precursors. Betanin degradation proceeded through hydrolytic cleavage, while hylocerenin dominated in decarboxylation and dehydrogenation. The degradation of phyllocactin involves the decarboxylation of the malonic acid moiety and the formation of betanin by demalonylation along with subsequent betanin degradation. After prolonged heating, dehydrogenation at C2–C3 carbons was also noticed.123–125,127\n\nDecarboxylated and dehydrogenated betanin derivatives occurring at the highest concentrations in a betacyanin-rich red beetroot extract (RBE) were also characterized (Table 2).128 The main pigments in the RBE are betanin and its isoform with 17-decarboxy-betanin/-isobetanin, 15-decarboxy-betanin, and small quantities of 2-decarboxy-betanin/-isobetanin as well as 2,17-bidecarboxy-betanin/-isobetanin.128 Furthermore, mixtures of mono-, bi-, and tridecarboxylated betanins together with their corresponding neo-derivatives obtained from the RBE were identified as the heating degradation products.129 In addition, new isomeric decarboxylated derivatives, namely, 2,15-bidecarboxy-betanin and 15,17-bidecarboxy-betanin, were detected for the first time. These newly detected derivatives were also formed during heating experiments on red beetroot extract. Furthermore, the presence of 2,15,17-tridecarboxy-betanin was also acknowledged.129 Presumably, the presence of these additional betanin derivatives results from enhanced decarboxylation, which is an integral process during RBE preparation. It was also reported that the higher concentration of acetic acid during the thermal treatment of RBE contributes to a selective formation of 2-decarboxy-betanin/-isobetanin. The latter pigments are present in the RBE at a very low level. However, according to the report, the most decisive factors are the concentrations of the substrate and acetic acid. Higher RBE concentration favors the formation of 2,17-bidecarboxy-betanin/-isobetanin over 2,15-bidecarboxy-betanin.129\n\nAn effective method for the separation of newly formed derivatives was also proposed. A bunch of decarboxylated and dehydrogenated betacyanins obtained during mild thermal treatment of B. vulgaris juice was subjected to high-performance counter-current chromatographic (HPCCC) preparative fractionations.130 The mixtures composed of betacyanins with different polarity and physicochemical properties were separated in highly polar solvent systems containing a high concentration of ammonium sulfate and ion-pairs, aqueous-organic solvent systems including ion-pair reagents (trifluoroacetic acid, heptafluorobutyric acid). The application of both the solvent systems enabled the separation and purification of 2-decarboxy-betanin, 2,17-bidecarboxy-betanin, their corresponding isoforms, and neobetanin from a mixture composed mainly of betacyanins, neobetanin, and their decarboxylated derivatives (Table 2), as well as 17-decarboxy-neobetanin, 2,15,17-tridecarboxy-2,3-dehydro-neobetanin, 2,17-bidecarboxy-2,3-dehydro-neobetanin, 2,15,17-tridecarboxy-neobetanin, and 2-decarboxy-neobetanin from another mixture consisting of decarboxy- and dehydrobetacyanins. The results also show that the utilization of heptafluorobutyric acid as an ion-pair reagent is more suitable than a polar solvent system with trifluoroacetic acid because it contributes to the formation of more hydrophobic betacyanin ion-pairs.130 The separation of betacyanins from a processed B. vulgaris juice (betanin, isobetanin, neobetanin, and decarboxylated betacyanins) was also demonstrated in a food-grade, gradient solvent system consisting of sodium chloride, butanol, water, as well as different volumes of phosphoric acid and/or ethanol. The quality of isolation was dependent on the ethanol and acid concentrations with the lowest volume gradient, providing the best separation conditions. Betacyanins were eluted in the organic, upper mobile phase, which has a low salt content compared to the aqueous lower phase.131\n\nThe first study on the thermal decomposition of gomphrenin pigments present in the fruit juice of B. alba was carried out and the chromatographic profiles, as well as fragmentation pathways of decarboxylation and dehydrogenation products of gomphrenin (Table 2), were determined by LC-DAD-ESI-MS/MS and LC-MS-IT-TOF.16 The short-term treatment of B. alba juice revealed the profiles of mono- and bi-decarboxylated gomphrenins analogous to betacyanins from heated beetroot juice.\n\nProlonged heating of B. alba extract acidified with acetic acid led to the formation of dehydrogenated derivatives as a result of gomphrenin derivative oxidation. The presence of neogomphrenin was detected at a low concentration level in the heated juice, which is opposite to RBE rich in neobetanin. In addition, in contrast to the results of the RBE heating experiments,129 the isomeric 2,15- and 15,17-decarboxylated derivatives were not detected in the heated samples. The above experiments indicated that the chromatographic differences between gomphrenin and betanin derivatives arose from the position of glucosylation in betanidin at carbon atoms C-5 or C-6.16\n\nSawicki and Wiczkowski investigated the impact of boiling and spontaneous fermentation on the betalain profile and content in beetroot. The boiling and fermentation of beetroot decreased the content of the betalains by 51–61% and 61–88%, respectively. Processes occurring during boiling and spontaneous fermentation such as heating, softening, leaching, and acidification together with the matrix effect may be responsible for the changes. In addition, the microbial activity and matrix softening occurring during fermentation caused a release of betalains, which is responsible for the potent antioxidant capacity of the formed beet juice.132\n\nSawicki et al. determined the impact of three technological processes (fermentation, boiling, and microwave-vacuuming treatment) and in vitro digestion on betalain profiles. The content of betalains in the products was reduced by 42–70%. Microwave-vacuuming treatment has contributed to the degradation of betanin at the lowest level and may be regarded as the best treatment method. In addition, the content of betalains released from the beetroot products after in vitro digestion reached the range of 0.001–0.10%, and the number of compounds identified in the digestion phases was decreased.133\n\n3.1.2. Oxidation of betacyanin pigments. Preliminary studies on the enzymatic and non-enzymatic oxidation of betanidin, betanin, neobetanin, as well as decarboxylated betanins along with the research on intermediate and final reaction products, were carried out.134–136\nBetanidin is the basic structure of all the betacyanins and the only one with the catechol moiety (5,6-dihydroxyl moiety). Studies show that during the oxidation of betanidin, the pigment is most likely converted into three tautomeric quinoid derivatives (Fig. 10). Interconvertions, which occur slowly at pH 4–7 and quickly in a more acidic environment, are likely to result in the formation of dehydrogenated and decarboxylated derivatives. Interconversions between the three tautomeric quinoid forms of oxidized betanidin are based on the proven oxidation pathways of DOPA and dopamine.137,138\n\n\nimage file: d1np00018g-f10.tif\nFig. 10 Scheme of the initial transformations of betanidin during its oxidation and with an indication of the intramolecular conversions between three tautomeric forms based on.134\t\nThe initial oxidation of betanidin should generate the transient radical cation, which rapidly loses a proton and forms a neutral phenoxy radical; it is equivalent to the donation of a hydrogen atom by betanidin or to the loss of a proton with further electron transfer. In the next step, the loss of a second proton and electron results in the formation of a two-electron oxidized form, i.e., one of the three quinoid tautomers. Presumably, not only the betanidin o-quinone with its characteristic absorption spectrum (λmax at 550 and 400 nm) is formed on the first oxidation stage but it is assumed that the two other quinoid derivatives are also possible: dopamine derivative and/or quinone methide. The discussion of the balance between the three tautomeric forms of quinoid remains open.135 As a result, 2,17-bidecarboxy-xanbetanidin (synonym of 2,17-bidecarboxy-2,3-dehydro-betanidin) and 2-decarboxy-xanbetanidin (synonym of 2-decarboxy-2,3-dehydro-betanidin) are postulated as the principal oxidation products formed (Table 2). The recently proposed xan is derived from the hypsochromic shift toward the yellow color of the resulting compounds.\n\nThe further oxidation of 2,17-bidecarboxy-xanbetanidin again involves the formation of one of the two possible quinoid forms as the oxidized intermediates, e.g., the dopachromic derivative of the indolic system. Subsequent rearrangement of the conjugated system of the originated structures into the neo-forms (14,15-dehydrogenated derivatives) is possible which finally leads to 2,17-bidecarboxy-xanneobetanidin (2,17-bidecarboxy-2,3-dehydro-neobetanidin), i.e., a compound doubly dehydrogenated at the positions C-2,3 and C-14,15.134–136\n\nIn contrast to betanidin oxidation, no compound that could be regarded as the betanin oxidation intermediate (quinone methide) was detected.139 This could be a consequence of its instability and fast rearrangement combined with decarboxylation. The main compound formed during the first step of betanin oxidation is 2-decarboxy-xanbetanin (Table 2), which exhibits a characteristic protonated molecular ion [M + H]+ at m/z 505 and an absorption maximum at λmax = 446 nm (Fig. 11). It is not excluded, however, that the generated 2-decarboxy-xanbetanin rearranges to a more stable structure of 2-decarboxy-neobetanin (synonym of 2-decarboxy-14,15-dehydro-betanin). According to the alternative pathway proposed by Wybraniec et al.,135 the formation of 2-decarboxy-neobetanin can result from a rearrangement of the quinone methide generated from 2-decarboxy-betanin. This alternate pathway does not include the presumably more stable product, 2-decarboxy-xanbetanin. Further, the decarboxylation of 2-decarboxy-xanbetanin presumably results in the formation of 2,17-bidecarboxy-xanbetanin. The most hydrophobic product of betanin degradation/oxidation is 2-decarboxy-xanneobetanin, characterized by a protonated molecular ion at m/z 503 and maximum absorption at λmax 422 nm, followed by 2,15,17-tridecarboxy-xanneobetanin.\n\n\nimage file: d1np00018g-f11.tif\nFig. 11 Proposed mechanism of betanin oxidation proceeding through the quinone methide intermediate based on.134,136\t\nIn Fig. 12, the schematic formation of dehydrogenated betanin derivatives is presented along with 2,3-dehydro- and 14,15-dehydro-positions marked on particular pigment structures, together with their abbreviations (xan- and neo-, respectively).52\n\n\nimage file: d1np00018g-f12.tif\nFig. 12 Possible pathways of betanin oxidation with dehydrogenation positions marked on dehydrogenated derivative structures.52,136\t\nIn the case of gomphrenin oxidation by the ABTS cation radical, except for its decarboxylated and dehydrogenated derivatives, the formation of betanidin as well as betanidin derivatives was detected. It is assumed that the rearrangement of dopachromic derivative affects the hydrolysis of the glucosidic bond. This is opposite to betanin, which is not deglucosylated during oxidation in the same reaction conditions. Therefore, it is important to notice that the position of betanidin glucosylation at carbon C-5 or C-6 has a significant influence on the differences in the reactivity of both the 5-O- and 6-O-glucosides.140\n\nIt was reported that metal cations, e.g., copper, aluminum, tin, and iron, accelerate the degradation of betanin even at trace amounts. It is worth noting that the release of metals from food packaging materials may also catalyze the unwanted betacyanin degradation.141 The results of high-resolution mass spectrometry experiments (HRMS) and NMR structural studies on key dehydrogenation products generated during the oxidation of betanin, neobetanin, and decarboxylated derivatives by ABTS cation radical as well as by Cu2+ complexation confirmed that Cu2+ catalyzed oxidation of betanin and 2-decarboxy-betanin leads to the formation of neo-derivatives (14,15-dehydrogenated betanins). It has been proven for the first time that betanin oxidation is possible in the dihydropyridine ring and this can be achieved presumably by omitting the stage of quinone methide formation in the dihydroindole system (Fig. 13). The additional results obtained for Cu2+-catalyzed oxidation of 17-decarboxy-betanin and 2,17-bidecarboxy-betanin suggest the possibility of formation of xan-derivatives, similar to the results obtained for oxidation by the ABTS cation radical. In this case, the factor determining the oxidation direction is presumably the absence of the carboxyl moiety at carbon C-17, clearly changing the geometry of the complex formed with Cu2+. In addition, the exclusive effect of 2,3-dehydrogenation in 17-decarboxy-betanin is probably supported by the concurrent occurrence of decarboxylation at carbon C-2.52\n\n\nimage file: d1np00018g-f13.tif\nFig. 13 Proposed general oxidation mechanism for betanin and its derivatives, superimposing the effect of Cu2+-catalyzed oxidation with an indication of marked 2,3- and 14,15-dehydrogenation positions based on.52\t\n3.1.3 Conjugation of oxidized betacyanin pigments with sulfhydryl scavengers. A well-developed approach for the direct detection of reactive, short-lived intermediates generated during the oxidation processes is to utilize trapping agents capable of forming stable adducts with the reactive species. The adducts may be detected and characterized using LC-MS/MS and NMR techniques.142 There are many reports on the formation of adducts between nucleophilic thiols and a variety of compounds.143–148 Research on the conjugation of quinones generated during betacyanin oxidation in the presence of thiols seems essential and may broaden the knowledge on betacyanin functions in biological systems.\nThe first studies on the possibility of conjugation of betacyanin reactive quinoids with sulfhydryl scavengers such as glutathione (GSH), cysteine (Cys), N-acetylcysteine (NAC), cysteamine (CSH), and DL-ditiothreitol (DTT) were performed recently (Table 2, Fig. 14).140,149 The formation of glutathionylated quinoids, following betanidin and gomphrenin oxidation, confirmed the presence of quinoid forms in the products of pigment oxidation. The chemical structure of glutathionylated betanidin was confirmed by NMR studies. It was also reported that glutathione reacts with quinones at the C-4 carbon of the betanidin ring. On the contrary, the conjugation of the betanin quinoid intermediate (quinone methide) with glutathione was not observed, presumably because of a steric hindrance at the C-7 carbon of betanin, which presumably confirms that the quinoid form generated during betanin oxidation is a quinone methide.140\n\n\nimage file: d1np00018g-f14.tif\nFig. 14 Schematic representation of the conjugation mechanism of betanidin and gomphrenin (A) with sulfhydryl radical scavengers as well as the oxidation of betanin to 2-decarboxy-xanbetanin (B) through the quinone methide intermediate with the following conjugation based on.149\t\nIn order to determine the possibility of attaching thiols to the C-7 carbon of the betanin quinoid, additional research was performed using low molecular weight thiols (Cys, CSH, NAC, DTT). Furthermore, since the conjugation of betacyanins with the thiol groups may generate new molecules with the modified chemical and biological properties, the conjugation reactions with quinones derived from betanidin and gomphrenin were also performed (Fig. 14). The chemical structure of N-acetylcysteinyl-gomphrenin, generated with the highest yield, was determined by the NMR method. The dopachrome derivative from gomphrenin oxidation undergoes conjugation at the C-4 carbon atom. In addition, cysteine conjugate with the oxidized betanin derivative was produced for the first time. The results suggest that the formation of quinone methide during the oxidation of betanin and the production of dopachrome derivative during the oxidation of gomphrenin is highly possible.149\n\nThe results confirm so far that gomphrenin is able to form conjugates with a higher yield than betanin but the ability to form stable conjugates with dehydrogenated betanin derivatives produced during the oxidation of betanin or its intermediate conjugates may also favor this pigment as a valuable food protection component.149 From the perspective of the food industry, this aspect appears to be relevant as the biological activity of gomphrenin and betanin in combination with the possibility of adduct formation between the thiols and betacyanin quinoids may contribute to the increased quality and durability of food products such as meat.146 From another perspective, adduct research can significantly contribute to the development of detection methods for betacyanin quinoids formed in the complex food matrices as well as to research the bioavailability and distribution of betacyanins in humans. The sulfhydryl part of the molecules may modulate their ability to penetrate the biological membranes as well as their absorption and metabolism. Many attempts have been made in the food chemistry to inhibit the formation of oxidative cross-linking proteins, affecting the quality, water content, and red color of meat products. In this respect, CS-conjugates of betacyanins may play a significant role in blocking the thiol groups in food proteins, contributing to improving the food quality.150–152\n\nWhether betacyanins act as effective antioxidants without adverse pro-oxidative effects depends on how quickly their oxidized derivatives gradually degrade through decarboxylation and dehydrogenation as well as through other transformations, including hydrolysis and the final polymerization of betalamic acid and cyclo-DOPA to inactive forms.134,136 So far, no research on the toxicity and stability of quinones produced from betacyanins has been conducted. The literature data are lacking on the pro-oxidative properties of betalains. In addition, there are questions whether betalains are susceptible to undesired metabolic activation and if the blocking of the sites prone to the formation of reactive forms in molecules is required for betalain application as potential therapeutic agents.\n\n3.1.4 Chlorination of betacyanins. The literature reports suggest that betacyanins may be regarded as potent scavengers of inflammatory factors such as hypochlorous acid (HOCl). In 2007, Allegra et al. reported that betanin and indicaxanthin are effective in the scavenging of hypochlorous acid.77 In addition, both the betalains reduce the myeloperoxidase activity and oxidation, and are therefore regarded as the two key components of the anti-inflammatory processes, leading to the reduction of hypochlorous acid generation.153 In 2016, Wybraniec et al.154 reported that in the reaction between betanin/betanidin/neobetanin and sodium hypochlorite or myeloperoxidase (MPO)/H2O2/Cl− systems, the chlorination of betanin and betanidin took place within the aglycone unit. In addition, the possible reaction with another potent chlorinating agent, Cl2O, which co-exists with HOCl in equilibrium, especially in acidic conditions, was suggested according to a similar mechanism.\nFor neobetanin, no chlorinated products in the reaction mixtures were detected. The fact that the pyridinic ring within the neobetanin structure cannot be chlorinated to form the detectable pigment products indicates that only the unsaturated bond is attacked, preferably at C-18, due to its partial negative charge.154 Monochloro-betanin and monochloro-betanidin were formed with the highest yield at pH 3–5 while at higher Cl− concentrations, the efficiency was dramatically decreased, suggesting that the generated Cl2 is not the chlorinating agent in the presence of sodium hypochlorite. The low activity of Cl2 during betanin and betanidin chlorination compared to HOCl and/or Cl2O was explained by a special position (C-18) of the attack by HOCl and/or Cl2O. In the case of the MPO/H2O2/Cl− system, the highest efficiency of monochloro-betanin/-betanidin generation was observed at pH 5.\n\nIn another study,155 additional chlorination experiments were extended to decarboxylated betacyanins (Table 2). The comparison of the chromatographic profiles of the chlorinated decarboxylated betanins and betanidins generated under the activity of hypochlorous acid revealed two different directions of retention changes in relation to the corresponding precursors. The chlorination of betacyanins decarboxylated at C-17 (17-, 2,17-bi-, and 2,15,17-tri-decarboxy derivatives) resulted in higher retention times in comparison to the corresponding substrates. In contrast, the non-decarboxylated betacyanins as well as their 2- and 15-decarboxy-derivatives exhibited lower chromatographic retention after chlorination.155\n\nThe identification of the chlorinated betacyanins was completed by a further study on the chlorination mechanism and the position of the electrophilic substitution in betacyanins by high-resolution mass spectrometry and further structural analyses by NMR techniques,156 which confirmed that the chlorination position in betanin and decarboxylated betanins occurs within the dihydropyridinic moiety at the C-18 carbon.156\n\nAccording to an electrophilic mechanism based upon the leaving group ability from Cl+ in HOCl (–OH−) and in Cl2O (–OCl−), the reaction paths between betanin and HOCl/Cl2O were proposed (Fig. 15).157 The mechanism was supported by the NMR elucidation results as well as by the inactivity of neobetanin toward chlorination.154 Chlorination version A shows the position of Cl+ attack on C-18 carbon within the betanin structure. The failure in the chlorination of betanin with Cl2, which is an active oxidizing agent, confirmed that Cl+ leaving from HOCl or Cl2O can be the chlorinating factor. Also, the hypothesis that H2OCl+ may be regarded as a chlorinating factor carrying Cl+ is intriguing but has not been confirmed for decades.158\n\n\nimage file: d1np00018g-f15.tif\nFig. 15 Proposed mechanism of betanin chlorination based on two versions of Cl+ ion attack on C-18 carbon. Chlorination version B presents a cyclic intermediate formed during the electrophilic attack of the whole HOCl or Cl2O with the stabilizing effect of the hydrogen bonding.\t\nIn the chlorination version B, a cyclic intermediate159 is formed during the electrophilic attack of the whole HOCl or Cl2O molecules as a result of the polarization of Cl–O bond along with the stabilizing effect of hydrogen bonding. The oxidation of C-18 carbon in betanin did not take place because of its negative charge, making the nucleophilic attack of oxygen159 impossible.\n\nSince fluorescent probes have been promising analytical tools for the rapid and specific detection of HOCl/OCl−, the HCSe and HCS probes were tested in the determination of the betalains' anti-hypochlorite activity. The comparison of the in vitro anti-hypochlorite activities of a betalain-rich red beetroot extract (RBE) with its pure betalainic pigments revealed that the extract had the highest anti-hypochlorite activity, far exceeding the activity of all of the betalainic derivatives and selected reference antioxidants.160 In addition, the pilot clinical studies showed that the short-term treatment with RBE improved the function and comfort of knee joints in individuals with knee distress resulting from increased hypochlorous acid formation.76\n\n3.1.5 The acyl migration phenomenon. The acyl migration phenomenon in betacyanins isolated from Mammillaria and Hylocereus fruits was discovered by Wybraniec et al.11,18,36,56 The driving force behind the research on the acyl migration effect was the fact that 4′-O-malonyl betanin isolated from the cacti fruits of Hylocereus species isomerized to 6′-O-malonyl betanin (phyllocactin) (Fig. 16). It was proved that acyl migration is intramolecular; hence, hydrolysis and re-esterification mechanisms are not relevant in that process.161 For that reason, free carboxylic groups in the acyl moieties present in hylocerenin, phyllocactin, and their derivatives are not involved in the rearrangement. The acyl migration mechanism is based on the interaction of the adjacent group with an ortho acid ester being an intermediate. In many cases, the distance between the acyl migrating group and the free hydroxyl is appropriate for creating of a cyclic intermediate.161–163 The formation of the six-membered cyclic intermediate between the glucosidic O-6′ and O-4′ hydroxyls may be responsible for the intramolecular rearrangement in phyllocactin. The significant factor that provides this phenomenon is the alkaline reaction environment; however, the effect is also observed in acidic conditions.\nimage file: d1np00018g-f16.tif\nFig. 16 The general chemical structure of 6′-O-acylated betacyanin submitted to acyl migration (A) with an established six-membered cyclic intermediate structure formed during acyl migration between the glucosidic O-6′ and O-4′ oxygens in betacyanins (B); a five-membered cyclic ortho ester formed during the acyl migration between O-4′ and O-3′ (C) as well as the final products of acyl migration (D) and (E) (Bd = the rest of betanidin; R = a fragment of an acyl moiety).\t\nA series of new isomers of various 6′-O-acylated betacyanins as well as decarboxylated betacyanins formed by intramolecular pH-dependent acyl migration between adjacent hydroxy groups on polyhydroxy compounds in aqueous solutions was chromatographically characterized.18 The migration rate was markedly accelerated under alkaline conditions at pH 10.5, however, always favoring the 6′-O-position. The phenomenon of acyl migration was less apparent at pH below 7.0. Partial rearrangement may result in the formation of 3′-O- and 4′-O-acylated compounds. In malonylated betacyanins and 17-decarboxy-betacyanins, the 3′-O-acylated forms were presumably the most polar isomers and were eluted first in RP-HPLC, whereas the 4′-O-forms were characterized by retention higher than the 6′-O forms. In contrast, in 2-decarboxy- and 2,17-bidecarboxy-betacyanins, both 3′-O- and 4′-O-acyl-betacyanins were eluted before the 6′-O-acylated forms. The study on the acyl migration effect in 4′-O-malonyl-betanin revealed a strong tendency to reverse acyl migration (4′ → 6′) and also partial rearrangement (4′ → 3′), leading to the monoester regioisomeric distribution in the proportion 87[thin space (1/6-em)]:[thin space (1/6-em)]7[thin space (1/6-em)]:[thin space (1/6-em)]6 [%] in relation to 6′-O-, 4′-O-, and 3′-O-, respectively.\n\nA new malonyl betacyanin, 6′-O-malonyl-amaranthin (celoscristatin), as well as 4′-O-malonyl-amaranthin, formed as a result of the malonyl group migration in celoscristatin, were also identified in Celosia cristata Linn. callus culture.29\n\n3.1.6 NMR elucidation of betacyanin pigments. First NMR structural investigations on betacyanins performed at low pH resulted in the quick degradation of the substances, preventing longer in-depth structural analysis of the betacyanins.53 Nevertheless, key experiments were performed, e.g., confirming the E/Z-stereoisomerism at one of the partial double bonds (C-11,12) in betanidin/isobetanidin.50 As a consequence, only the 13C NMR spectrum of neobetanin was properly registered due to the stability of this dehydrogenated derivative in a highly acidic environment in contrast to other betacyanins. In Fig. 17, an overview of the solvents used for NMR analysis of particular betacyanin pigments is shown. Data acquisition was improved by changing the solvent system for NMR analysis. D2O was found to be the most suitable solvent, which afforded the best long-term stability required for NOESY, HSQC, and HMQC experiments by preventing betacyanin hydrolysis. 1D (1H, 1D TOCSY) and 2D NMR (COSY, TROESY, HSQC, HMQC) measurements for betanin, isobetanin, phyllocactin, and hylocerenin isolated from red-purple pitaya (H. polyrhizus) were performed in D2O.164 For the confirmation of the presence of malonyl moiety exchangeable protons, additional 1H, HSQC, and HMQC experiments for phyllocactin were carried out in a mixture of H2O and D2O (90/10, v/v), slightly acidified with 20 mL of 0.05% aqueous TFA solution (v/v).164\nimage file: d1np00018g-f17.tif\nFig. 17 The summary of the solvents used for NMR spectra registration of particular betacyanins.\t\nThe key products formed after betanin decomposition were identified and their structures were confirmed by NMR analysis. The structural elucidation of 2-, 17-, and 2,17-decarboxy-betacyanins generated during the decarboxylation of betanin, phyllocactin, and hylocerenin isolated from H. polyrhizus fruits was performed by Wybraniec et al.127 A variety of coupled spin systems of all the analyzed compounds were successfully distinguished and assigned by 1H NMR, 1D TOCSY, gCOSY, and NOESY spectra in D2O. Due to gHSQC correlations, the 13C chemical shifts for all the carbons directly bound to the protons were unambiguously assigned, while the gHMBC (the 1H–13C long-range) correlations enabled the establishment of the chemical shifts of the quaternary carbons. In addition, the first 1H NMR spectra of 2-decarboxy-hylocerenin together with all the studied 17-decarboxy- and 2,17-bidecarboxy-betacyanins were received. Furthermore, the 13C NMR spectra of the decarboxylated betacyanins were obtained for the first time.127\n\nThe NMR spectra of amaranthin and iresinin I were recorded in trifluoroacetic acid.61 The structures of the two other acylated betacyanins and lampranthin II from the petals of Lampranthus peersii and L. sociorum as well as celosianin (previously named as celosianin II) from the cell suspension cultures of Chenopodium rubrum were elucidated as 6′-O-E-feruloyl-betanin and 2′′-O-E-feruloyl-β-(1′′,2′)-glucuronosyl-betanin, respectively, by 1H NMR. All 1D (normal and NOE difference) and 2D spectra (COSY) were registered in acidic DMSO-d6 containing traces of DCl.58 A low field shift of the protons H-6′A and H-6′B of the glucosylic moiety in lampranthin II caused by acylation indicated an attachment of the feruloyl moiety at the C-6′ carbon. For celosianin II, the NOE difference spectra indicated that the β-glucuronosyl moiety was bound to C-2′ of the β-glucosyl moiety. The presence of the feruloyl moiety attached at C-2′′ of β-glucuronosyl was evident from the low field shift of H-2′′.58\n\nIn addition to betanin and phyllocactin in H. polyrhizus fruits, another characteristic pigment, hylocerenin [6′-O-(3′′-hydroxy-3′′-methyl-glutaryl)-betanin], was also characterized by 1D and 2D (COSY) NMR techniques in deuterated methanol (CD3OD) containing traces of deuterium chloride (DCl).56 Other unknown pigments, 2′-O-β-apiofuranosyl-betanin and 2′-O-β-apiofuranosyl-phyllocactin, were also elucidated by 1H and 13C NMR techniques in non-acidified D2O.11 The structure of a new malonyl derivative, celoscristatin (6′-O-malonyl-amaranthin), isolated from C. cristata callus culture was confirmed by NMR analysis in D2O.29\n\nIn order to determine the oxidation mechanism of betanin, structures of tentatively identified key dehydrogenation products of betanin, decarboxylated betanin, and neobetanin oxidation by the ABTS cation radical were elucidated by NMR.52 The 1H and 2D (COSY, TOCSY, HSQC, HMBC, and NOESY) measurements were performed in DMSO-d6 for all the studied compounds except for 2-decarboxy-neobetanin, which was analyzed in CD3OD acidified with 0.01% deuterated TFA. The structures of five neo- and xanneo-derivatives, namely, neobetanin, 2-decarboxy-neobetanin, 2-decarboxy-xanneobetanin, 2,17-bidecarboxy-xanneobetanin, and 2,15,17-tridecarboxy-xanneobetanin, were confirmed.52\n\nThe structures of gomphrenin as well as its acylated derivatives, globosin and basellin, (gomphrenin I, II, and III, respectively) were elucidated by NMR spectroscopy by Heuer et al.24 The 1H and 2D COSY NMR spectra were recorded in CD3OD containing traces of DCl. The presence of acyl (4-coumaroyl- and feruloyl-) moieties at the C-6′ carbon in globosin and basellin, respectively, was indicated by a low field shift of the corresponding protons H-6′A and H-6′B. Non-typical 1H chemical shift differences between gomphrenin I and globosin and basellin suggested intramolecular stacking occurring in the latter two compounds.24 In another attempt, gomphrenin was identified by means of 1H, selective NOESY, and TOCSY as well as 2D NMR (COSY, NOESY, HSQC, and HMBC) techniques in D2O.69 By NOESY-correlation spectral analysis, it was demonstrated that the glucopyranosyl group is linked to the phenolic group at the C-6 carbon of gomphrenin, which differentiated it from betanin.\n\nThe structures of glutathionylated conjugate of betanidin140 and N-acetylcysteinylated gomphrenin149 were established by NMR analysis, confirming the conjugation position at the C-4 carbon, thus indicating the presence of a dopachromic intermediate during gomphrenin oxidation. All 1H and 2D NMR (COSY, HSQC, HMBC, TOCSY, and NOESY) analyses were accomplished in non-acidified D2O. The attachment position of the glutathionyl moiety was primarily indicated by the strong long-range correlation of the H-12a/b′ protons to quaternary C-4 and C-9 carbons as well as a weak correlation to C-8. The lack of the H-4 signal in the 1H spectrum unambiguously confirmed this position.140,149 In the case of N-acetylcysteinylated gomphrenin, the attachment position of the N-acetyl-cysteinyl moiety was initially suggested by a strong, long-range correlation of H-6a/b′′ protons to quaternary carbon C-4. In addition, the lack of the H-4 signal in the 1H spectrum definitely confirmed this position. Furthermore, the CS-conjugation position in gomphrenin was supported by the downfield chemical shift of the H-6a/b′′ proton signal compared to the signal obtained for free N-acetyl-cysteine.149\n\nIn order to prove the position of chlorination in betanin and its decarboxylated derivatives, structural studies were also performed.156 The structure elucidation of 18-chloro-betanin, 18-chloro-17-decarboxy-betanin, and 18-chloro-2,17-bidecarboxy-betanin confirmed that the chlorination position in betanin occurs within the dihydropyridine moiety at carbon C-18. The results of 1H NMR, COSY, and TOCSY analyses obtained for 18-chloro-betanin in non-acidified D2O enabled to distinguish and characterize several diagnostic, conjugated spin systems characteristic for betanin (H-2, H-3ab; H-11, H-12; H-14ab, H-15) in D2O. The dihydroindolic system was indicated by the HSQC correlations of H-2, H-3ab, H-4, and H-7 with their respective carbons. In the dihydropyridine system, the correlations of H-14ab and H-15 with their respective carbons in the HSQC spectra were visible.156\n\nThe structural studies of the newly semi-synthesized pseudo-natural pigments based on betanin hydrolysis were also reported. The structures of various compounds semi-synthesized by coupling betalamic acid with N-methyl anilines, N-aryl anilines, and blue solid named BeetBlue as well as 7-amino-4-methylcoumarin- and 7-amino-4-trifluoromethylcoumarin-betacyanins (cBeet120 and cBeet151) were accomplished by NMR analysis in D2O.165–167\n\n4 Chemistry of betacyanins and their semi-synthetic derivatives based on betanin hydrolysis\n4.1 Hydrolysis of betanin\nBetanin is susceptible to acid- and base-catalyzed hydrolysis, leading to the formation of colorless cyclo-DOPA-5-O-β-D-glucoside and fairly stable bright yellow betalamic acid (Fig. 18). Recently, new light was shed on betanin hydrolysis mechanism.169 The impact of temperature and pH on the rate of betanin hydrolysis was examined. The mechanism of betanin decomposition was studied in the phosphate solution at pH ranging from 2 to 11 and temperature of 60–85 °C. It was postulated that the fully protonated betanin form is reactive toward the nucleophilic attack of water and the intramolecular hydrogen bond between the carboxylic group at C-2 carbon and N-1 nitrogen stabilizes the transition state, leading to the hydrated betanin. The N-1 nitrogen atom was expected to be protonated in the acidic media and to form a leaving group. The protonation of the N-16 nitrogen atom enhances the electrophilicity of C-11, C-13, and C-17 carbons and catalyzes betanin hydrolysis, finally contributing to the opening of the 2,6-dicarboxy-1,2,3,4-tetrahydropyridine ring of betalamic acid. It was indicated that the hydrogen phosphate ion may act as a general base at pH 8.2, even at a low buffer concentration. The formation of cyclo-DOPA and 2,6-dicarboxy-4-methylpyridine as the products of betanin degradation in an alkaline environment at 130 °C identified by IR spectroscopy was reported in the pioneering work of Wyler and Dreiding on betanin purification by crystallization.47,170 In contrast to that study, 2,6-dicarboxy-4-methylpyridine was not detected.169 However, the presence of cyclo-DOPA, betalamic acid, and decarboxylation/oxidation products was observed.\nimage file: d1np00018g-f18.tif\nFig. 18 Hydrolysis of betanin leading to the formation of betalamic acid and cyclo-DOPA-5-O-β-D-glucoside.\t\nBased on theoretical calculations, the double protonation of the nitrogen atom within the tetrahydropyridine ring cannot be excluded from what was observed for the amino dicarboxylic acids of simpler structures.169\n\nNext to hydrolysis, betacyanins are also sensitive to water-catalyzed isomerization. A study on the hydrolytic stability of betanin Bn, indicaxanthin BtP, and an artificial betalainic coumarin BtC soluble hydrogen bond donating 2,2,2-trifluoroethanol (TFE) was conducted.171 The hydrolytic stability in water was as follows: BtP > Bn > BtC. Improved hydrolytic stability of the abovementioned betalains in hydroalcoholic solutions was noticed with an increase in the TFE co-solvent. The hydrolysis rate of betalainic coumarin in water was 700-fold greater than in TFE, whereas the use of TFE as a co-solvent reduced the hydrolysis of betanin and indicaxanthin by 20 and 100-times, respectively. The proportion of water and TFE in the co-solvent mixture determined the hydrogen-bond donating capacity, polarity, and ionization power. However, the most important factor of the enhanced hydrolytic stability of the betacyanins is probably due to the low nucleophilicity of TFE. In addition, the fluorescence quantum yields of betaxanthins were also increased with the presence of TFE.171\n\n4.2 One step semi-synthesis of betalains from betalamic acid-derivatized support\nSo far, all the proposed methods of the de novo synthesis of betalains achieve very low efficiency; therefore, the best way to obtain individual betalain derivatives is to isolate them from the biological material and purify. However, this makes the whole process highly time-consuming due to the plant matrix that is rich in various compounds, especially polysaccharides. The process of betalain formation was simplified using a novel betalamic acid-derivatized support (Fig. 19).172 Betalamic acid was produced during betanin hydrolysis from B. vulgaris extract in the presence of cross-linked polystyrene resin at room temperature and nitrogen atmosphere. After the release of betalamic acid and neutralization with acetic acid, the reaction of imine formation between the aldehyde group of betalamic acid and the free primary amine groups present in the matrix surface was performed, resulting in the immobilization of betalamic acid in the resin. The derivatization of the resin with betalamic acid was indicated by the resin color change from pale to intense yellow. After washing and drying at room temperature, the novel solid support was generated and characterized by SEM. The material exhibited the spectroscopic properties of a pseudobetaxanthin. Then, the resin from the betalamic acid-derivatized support was tested toward the production of betalains. As model amines, individual dopamine, tyramine, indoline, and pyrrolidine were added to the support turning the color of the solutions from colorless into yellow in the case of dopamine, tyramine, and pyrrolidine, as well as into purple in the case of indoline. Then, a Schiff's condensation between the amine and betalamic acid anchored in the support provided the dopamine-, tyramine-, pyrrolidine-, and indoline-betaxanthins.172\nimage file: d1np00018g-f19.tif\nFig. 19 Betalamic acid-derivatized support and the surface reaction leading to pigment isolation, based on dopamine-derived betaxanthin: (A) starting material containing primary amine groups; (B) betalamic acid-derivatized support; (C) amine attack to betalamic acid; (D) synthesis and concomitant release of miraxanthin V.172\t\n4.3 Semi-synthetic betalain pigments with extended conjugated systems\n4.3.1 Semi-synthesis of blue pigments from betanin. Naturally-occurring blue pigments are rare, especially among plants. A metal-free photostable blue pigment was designed by extending the π-system of betalains (Table 2).166 The dye was semi-synthesized from betalamic acid, which may be obtained from the hydrolysis of red beetroot juice or by the enzymatic oxidative cleavage of S-DOPA. The 1,11-diazaundecamethinium chromophore of the dye is formed by the irreversible dehydrative C–C coupling of betalamic acid with the carbon nucleophile 2,4-dimethylpyrrole in acidified ethyl acetate (Fig. 20). The reaction lasted less than 30 min and it was performed at room temperature under air condition. The 1,11-diazaundecamethinium chromophore induces a redshift of the absorption and fluorescence spectra in water in relation to standard betanin and indicaxanthin. The product was purified by flash gel permeation chromatography with water used as eluent. This dye exhibits high solubility in polar solvents, e.g., water, and does not produce singlet oxygen upon photoexcitation.166\nimage file: d1np00018g-f20.tif\nFig. 20 Semi-synthesis of a blue dye from betanin derived from beetroot juice.166\t\n4.3.2 Semi-synthesis of a pseudo-natural betalain-nitrone OxiBeet pigment. A prototypical betalain-nitrone pigment (OxiBeet) based on the N-oxide 1,7-diazaheptamethinium scaffold was semi-synthesized for the first time by Capistrano Pinheiro et al. (Table 2).173 Betalamic acid was produced by the hydrolysis of the betalains present in red beetroot juice and coupled with N-phenylhydroxylamine in acidified water, giving rise to OxiBeet pigment (Fig. 21). The resulting product was purified and isolated with 50% yield, which is twice as high as the values reported for other betalains.\nimage file: d1np00018g-f21.tif\nFig. 21 Semi-synthesis of OxiBeet pigment (3) by the acid-catalyzed coupling of betalamic acid (1) and N-phenylhydroxylamine 2 in water.\t\nThis bio-based molecule exhibits low reduction potential and even higher radical scavenging activity than typical antioxidants such as ascorbic acid and gallic acid. Furthermore, it is non-cytotoxic toward human hepatic cell line HepaRG up to 1 mM concentrations. This pseudo-natural product is resistant to hydrolysis under neutral and slightly alkaline conditions and it may also be converted into a persistent N-oxide 1,7-diazaheptamethinium radical cation in an aqueous solutions via autoxidation. These findings open up new perspectives for utilizing betalain pigments and betalain derivatives as therapeutics against various human diseases.\n\n4.3.3 Semi-synthesis of N-methyl phenyl-betaxanthin and N-aryl phenyl-betaxanthin pigments. The semi-synthesis of N-methyl phenyl-betaxanthin (common name: mepBeets) and N-aryl phenyl-betaxanthin (dipBeets) pigments (Table 2) was described by Pioli et al. and the influence of the structure on the betalain derivatives' hydrolytic stability and electronic properties were compared.165 Eight compounds were formed by the derivatization of betalamic acid and N-methyl-anilines as well as N-aryl-anilines in ethyl acetate in the presence of p-toluenesulfonic acid used as a catalyst (Fig. 22). The stabilization of the positive charge density at the nitrogen atom N-9 by the N-methyl group reduces the rate of hydrolysis by decreasing charge delocalization through the 1,7-diazaheptamethinium system as compared to the non-methylated phenyl-betaxanthin. On the contrary, the N-aryl moiety increases charge delocalization while improving the hydrolytic stability. The electron-withdrawing substituents within the aryl moiety increase the fluorescence quantum yields of semi-synthesized betaxanthins, accelerate hydrolysis, and lower the anodic potential compared to the corresponding unsubstituted betalains. On the other hand, the presence of electron-donating substituents improves their hydrolytic stability. The fluorescence of N-aryl phenyl-betaxanthins is strongly influenced by the polarity and viscosity of the medium which enables the design of the “turn-on” fluorescent (bio)sensors.165\nimage file: d1np00018g-f22.tif\nFig. 22 Semi-synthesis of the mepBeets and the dipBeets via the acid-catalyzed coupling of betalamic acid (1) with N-substituted anilines (2) in ethyl acetate.165\t\n4.3.4 Semi-synthesis of artificial coumarinic betalains. Betalains may be modified to produce water-soluble two-photon fluorophores.167 Coumarinic betalains cBeet120 and cBeet151 (Table 2) were obtained in the reaction between betalamic acid and aminocoumarins in acidified ethyl acetate (Fig. 23). Betalamic acid underwent Schiff condensation (aldimine formation) with 7-amino-4-methylcoumarin c120 and 7-amino-4-trifluoromethylcoumarin c151 in the presence of p-toluenesulfonic acid used as a catalyst. The coupling of the betalamic acid chromophore to the fluorescent hydrophobic chromophore via the 1,7-diazeheptamethine π-bridge results in a D–π–A molecular arrangement. Coumarinic betalain containing a trifluoromethyl electron-withdrawing substituent within the coumarin moiety is more fluorescent than the one with a methyl group but it has a lower two-photon absorption cross-section, which is attributed to the destabilization of the charge transfer character of the excited state affecting the transition dipole moment.167\nimage file: d1np00018g-f23.tif\nFig. 23 Semi-synthesis of artificial coumarinic betalain pigments with an extended conjugated system.167\t\nIn another study, an artificial coumarinic betalain (BtC) semi-synthesized via the aldimine coupling of 7-amino-4-methylcoumarin to betalamic acid was used for the fabrication of the fluorescent probe for the live-cell imaging of erythrocytes infected with Plasmodium falciparum responsible for malaria disease in humans.168 In order to test the capacity of BtC for labeling living Plasmodium-infected red blood cells, erythrocytes with parasites were incubated with BtC and examined by fluorescence microscopy. BtC was accumulated within the infected cells selectively and fluorescence imaging microscopy has shown that only the parasite was stained. On the contrary, no stain was observed in the infected erythrocytes incubated with an indicaxanthin (control probe) and uninfected cells.168\n\n5 Conclusions\nDuring the last two decades, the research on betalains, more specifically on betacyanins, has experienced significant acceleration due to their health-protective properties as well as applications in the food industry. Before 2000, there were no reports on any pro-health activities of betacyanins; from 2020 onwards, this is the main direction of projects and research on betacyanins. Furthermore, studies on the oxidation mechanism of betacyanins are highly relevant because pigments with different chemical structures seem to have different influence on their oxidation pathways. Considering the fairly simple semi-synthetic methods for additional betacyanin derivatives summarized in this review as well as the first promising results of various studies, the perspectives for further investigations on the bioactivity of betacyanins are inexhaustible. For the time being, the main obstacle that limits the research is the lack of highly efficient and inexpensive methods of betacyanin isolation and purification as well as methods of de novo synthesis. The constantly growing number of potential applications of betalains as natural colorants of food, fabrics, and dietary supplements but also their utilization in sensors, photoprotectors, and solar cells set promising directions of the investigations on these still not fully-explored plant pigments in the near future. In spite of the most recognizable betanin-based betacyanins present in a variety of betalainic plant sources, gomphrenin-like pigments also represent a promising group of potentially more stable and more active compounds at once. There are still many unexplored plants with presumably new interesting betacyanin profiles. The chemical structures of only 31 betalain pigments isolated from the plant sources were definitively identified by the NMR method, which is relatively small in comparison to the other groups of plant pigments. Furthermore, a huge group of over 187 betacyanins (including pigments from their richest source, B. glabra) detected by LC-MS techniques still awaits the final confirmation of their structures. Particular attention should also be paid to the chemical modifications of betacyanins that result in the generation of an increasing number of new derivatives with completely unknown bioactivities. The aspects discussed in this review show that the field of betalain chemistry is a goldmine and ideas for further research are still limitless.\n6 Conflicts of interest\nThe authors declare no competing financial interest.\n7 Acknowledgements\nThis research was financed by Polish National Science Centre for the years 2020–2023 (Project No. UMO-2019/33/N/NZ9/01590) as well as for the years 2018–2021 (Project No. UMO-2017/27/B/NZ9/02831). The authors are grateful to Dr Willibald Schliemann for his invaluable suggestions and comments.\n\n\nRaw text of https://pubs.rsc.org/en/content/articlehtml/2021/np/d1np00018g\n\n\n> I am going to paste the plain text of a scientific publication. I would like you to detect all molecules names you can find in this text and report them as a list.\n> \n\n\nBetacyanins\nBetaxanthins\nBetalamic acid\nBetanidin\nCyclo-DOPA\nBetanin\nGomphrenin\nAmaranthin\nBougainvillea-r-I-type (renamed as Melocactin-type)\nOleracin-type\nApiocactin-type\nBougainvillein-v-type (proposed as Glabranin-type)\nHylocerenin\nPhyllocactin\nLampranthin I\nLampranthin II\nRivinianin\nCelosianin I (Argentianina)\nCelosianin II (Celosianina)\nCeloscristatin\nIresinin I\nMammillarinin\nAmaranthin\nIndicaxanthin\n2-Decarboxy-betanin\n14,15-Dehydro-betanin (Neobetanin)\n6′-O-Sulfate-betanin (Prebetanin)\n2-Decarboxy-phyllocactin\n2-Decarboxy-betanidin\n2′-O-β-Apiosyl-betanin (Apiocactin)\n5′′-O-E-Sinapoyl-apiocactin\n4′-O-Malonyl-betanin\n5′′-O-E-Feruloyl-apiocactin\n6′-O-Malonyl-betanin (Phyllocactin)\n2′-O-β-Apiosyl-phyllocactin\n2′-O-β-(5′′-O-E-Feruloyl)-apiosyl-phyllocactin\n6′-O-(3′′-Hydroxy-3′′-methylglutaryl)-betanin (Hylocerenin)\nBetanidin 5-O-(6′-O-E-4-coumaroyl-β-glucoside) (Lampranthin I)\nBetanidin 5-O-β-(6′-O-E-feruloyl)-glucoside (Lampranthin II)\n3′-O-Sulfate-betanin (Rivinianin)\nBetanidin 5-O-β-sophoroside (Bougainvillein-r-I; Melocactin)\n(Caffeoyl and/or coumaroyl)-bougainvillein-r I (Bougainvillein-r-II, III, IV, V)\nBetanidin 5-O-(2′-O-β-glucuronosyl)-glucoside (Amaranthin)\n2′′-O-E-4-Coumaroyl-amaranthin (Celosianin I; Argentianina)\n2′′-O-E-Feruloyl-amaranthin (Celosianin II; Celosianina)\n6′-O-Malonyl-amaranthin (Celoscristatin)\n4′-O-Malonyl-amaranthin\n6′-O-(3′′-Hydroxy-3′′-methylglutaryl)-amaranthin (Iresinin I)\n4′-O-Malonyl-bougainvillein-r I\n6′-O-Malonyl-bougainvillein-r I (Mammillarinin)\n2-Decarboxy-mammillarinin\n17-Decarboxy-mammillarinin\n17-Decarboxy-bougainvillein-r I\nFeruloyl-bougainvillein-r I\n(Dehydrated phyllocactin)\nBetanidin 6-O-β-D-sophoroside (Bougainvillein-v; Glabranina)\n6′′-O-Rhamnosyl-glabranin\n6′-O-E-Caffeoyl-glabranin (Cafglabranina)\n6′-O-E-4-Coumaroyl-glabranin (Coumglabranina)\n6′′-O-E-4-Coumaroyl-glabranin\n6′,6′′-Di-O-E-4-coumaroyl-glabranin (Bicoumglabranina)\n2′′-O-[(6′′-O-E-4-Coumaroyl)]-glucosyl-cafglabranin\n2′′-O-Glucosyl-bicoumglabranin\n2′′-O-[(6′′-O-E-4-Coumaroyl)]-sophorosyl-cafglabranin\nFeruloyl-dihexosyl-betanidin\nSinapoyl-dihexosyl-betanidin\nCitryl-(caffeoyl or 4-coumaroyl)-amaranthin (Suaedin)\n2′′-O-E-Sinapoyl-amaranthin (Lindenina)\nBetanidin 6-O-β-glucoside (Gomphrenin I; Gomphrenina)\n6′-O-E-4-Coumaroyl-gomphrenin I (Gomphrenin II; Globosina)\n6′-O-E-Feruloyl-gomphrenin I (Gomphrenin III; Basellina)\n6′-O-E-Sinapoyl-gomphrenin I (Gomphrenin IV; Gandolina)\nE-Isomer of gomphrenin II\nE-Isomer of gomphrenin III\nBetanidin 5-O-β-(E-feruloyl)-cellobioside (Oleracin I)\n\n\n\nimport pandas as pd\n\n# Creating a DataFrame from the list\ndata = [\n    [\"Betanin\", \"-\", \"Beta vulgaris (beetroot, red beet)\", \"Fruits\"],\n    [\"Betanidin\", \"-\", \"Beta vulgaris\", \"Fruits\"],\n    [\"Gomphrenin\", \"-\", \"Basella alba L.\", \"Fruits\"],\n    [\"Gomphrenin\", \"-\", \"Basella alba var. ‘Rubra’ L.\", \"Leaves\"],\n    [\"Amaranthin\", \"-\", \"Amaranthaceae family plants\", \"-\"],\n    [\"Melocactin\", \"Previously 'Bougainvillein-r-I'\", \"Bougainvillea glabra\", \"Bracts\"],\n    [\"Glabranin\", \"Previously 'Bougainvillein-v'\", \"Bougainvillea glabra\", \"-\"],\n    [\"Hylocerenin\", \"-\", \"Hylocereus polyrhizus\", \"Fruits\"],\n    [\"Phyllocactin\", \"-\", \"Schlumbergera x buckleyi\", \"-\"],\n    [\"Phyllocactin\", \"-\", \"Pereskia hybridus\", \"-\"],\n    [\"Lampranthin I\", \"-\", \"Lampranthus sp.\", \"-\"],\n    [\"Lampranthin II\", \"-\", \"Lampranthus sp.\", \"-\"],\n    [\"Lampranthin II\", \"-\", \"Gomphrena globosa\", \"-\"],\n    [\"Lampranthin II\", \"-\", \"L. sociorum\", \"-\"],\n    [\"Rivinianin\", \"-\", \"Rivina humilis\", \"-\"],\n    [\"Amaranthin\", \"-\", \"Amaranthus tricolor\", \"-\"],\n    [\"Amaranthin\", \"-\", \"Amaranthus sp.\", \"-\"],\n    [\"Amaranthin\", \"-\", \"Celosia cristata\", \"-\"],\n    [\"Celosianin I\", \"Argentianina\", \"Celosia cristata\", \"-\"],\n    [\"Celosianin II\", \"Celosianina\", \"Celosia cristata\", \"-\"],\n    [\"Celoscristatin\", \"-\", \"Celosia cristata\", \"-\"],\n    [\"Iresinin I\", \"-\", \"Iresine herbstii\", \"-\"],\n    [\"Mammillarinin\", \"-\", \"Mammillaria spp.\", \"-\"],\n    [\"Suaedin\", \"-\", \"Suaeda fruticosa\", \"-\"],\n    [\"Lindenina\", \"-\", \"Gomphrena globosa\", \"-\"],\n    [\"Lindenina\", \"-\", \"Iresine lindenii\", \"-\"],\n    [\"Gomphrenin I\", \"Gomphrenina\", \"Gomphrena globosa\", \"-\"],\n    [\"Gomphrenin I\", \"Gomphrenina\", \"Basella alba\", \"-\"],\n    [\"Gomphrenin II\", \"Globosina\", \"Gomphrena globosa\", \"-\"],\n    [\"Gomphrenin III\", \"Basellina\", \"Gomphrena globosa\", \"-\"],\n    [\"Gomphrenin IV\", \"Gandolina\", \"Gomphrena globosa\", \"-\"],\n    [\"Oleracin I\", \"-\", \"Portulaca oleracea\", \"-\"]\n]\n\ndf = pd.DataFrame(data, columns=[\"Molecule Name\", \"Molecule Name Alt\", \"Biological Source\", \"Organ\"])\n\n# Convert DataFrame to CSV\ncsv_file = \"/mnt/data/Betacyanins_Biological_Sources.csv\"\ndf.to_csv(csv_file, index=False)\n\ncsv_file\n\n\n\n\nhttps://chat.openai.com/share/80771cb4-b018-48e4-8573-a9643c0b084d\n\n\n\n\nx","n":0.009}}},{"i":481,"$":{"0":{"v":"Authors","n":1},"1":{"v":"\n\n- Adriano Rutz (contacted)\n- Egon Willighagen\n- Peter Murray Rust\n- Jean-Marc Nuzillard\n- Jonathan Bisson\n\n","n":0.277}}},{"i":482,"$":{"0":{"v":"Utils","n":1}}},{"i":483,"$":{"0":{"v":"Pdf","n":1},"1":{"v":"\n\nWorking from https://superuser.com/a/1217306\nTrying to compress a pdf\n\n\ncompresspdf() {\n    echo 'Usage: compresspdf [input file] [output file] [screen|ebook|printer|prepress]'\n    gs -sDEVICE=pdfwrite -dNOPAUSE -dQUIET -dBATCH -dPDFSETTINGS=/${3:-\"screen\"} -dCompatibilityLevel=1.4 -sOutputFile=\"$2\" \"$1\"\n}\n\ncompresspdf \"Massive.pdf\" \"Small.pdf\" ebook","n":0.189}}},{"i":484,"$":{"0":{"v":"Slow","n":1}}},{"i":485,"$":{"0":{"v":"Productivity","n":1},"1":{"v":"\nSLOW PRODUCTIVITY\n\nA philosophy for organizing knowledge work efforts in a sustainable and meaningful manner, based on the following three principles:\n\t\t\t\t\n1. Do fewer things.\n\n« Strive to reduce your obligations to the point where you can easily imagine accomplishing them with time to spare. Leverage this reduced load to more fully embrace and advance the small number of projects that matter most. »\n\n« Most workers who are fortunate enough to exert some control over their efforts—such as knowledge workers, small-business entrepreneurs, or freelancers—tend to avoid taking on so much work that they crash and burn, but also tend to avoid working a reasonable amount. They exist at that point of maximum sustainable overhead tax that seems to represent the worst of all configurations, as it maintains the pain of having too much to do, but keeps this pain just manageable enough to avoid reform »\n\n\n« We often believe those we work with care only about getting results as fast as possible. But this isn’t true. Often what they really want is the ability to hand something off and not have to worry about whether or not it will be accomplished. If they trust you, they’ll give you latitude to finish things on your own terms. Relief, in other words, trumps expediency. »\n\n\n2. Work at a natural pace.\n« There will always be more work to do. You should give your efforts the breathing room and respect required to make them part of a life well lived, not an obstacle to it. »\n\n\n3. Obsess over quality.\n\n\n### The 70 % rule\n\n\n​\n\nSeventy per cent\nThe 70% rule: If you’re roughly 70% happy with a piece of writing you’ve produced, you should publish it. If you’re 70% satisfied with a product you’ve created, launch it. If you’re 70% sure a decision is the right one, implement it. And if you’re 70% confident you’ve got what it takes to do something that might make a positive difference to the increasingly alarming era we seem to inhabit? Go ahead and do that thing. (Please!)\n\nThere’s more power to this rule than meets the eye. It isn’t solely a way of pushing past perfectionism, though of course that’s valuable in itself. I’m convinced it’s also the way to cultivate a particular kind of sane, action-focused, peaceful-but-energised approach to life that’s becoming more essential by the day. At the risk of offending any sticklers for traditional mathematics, I’m even tempted to argue that 70% is actually better than 100%, at least in this context. Allow me to explain:\n\nIf you’ve any perfectionistic tendencies at all, the 70% rule is unlikely to feel brand new. You’ve probably often been advised to go easy on yourself, to remember that “perfect is the enemy of good”, and so on. Such advice is usually well-meaning, and true so far as it goes: perfectionists should indeed beat themselves up less, and be satisfied with less-than-perfect outcomes. But it still carries the subtle implication that being less than perfect is merely forgivable or excusable – that it would be nice to do better, but since you can’t, there’s no point fretting about it; instead, learn to settle for less. Which makes it tough advice for perfectionists to follow, because it amounts to little more than “don’t be so perfectionistic”. It’s like telling someone who’s a poor swimmer, and wants to become a good swimmer, that what they need to do is to become a better swimmer. I mean, yes. That’s correct! It’s just not especially helpful.\n\nBut the 70% rule – when you begin to grasp it, and to live by it – is something much more potent than that. Following it is a muscular and a muscle-building act. Moving forward at 70% takes more guts, more strength of character, than holding out for 100%, because it entails moving forward amid uncertainty, anxiety, and the disagreeable feeling that comes with putting less-than-perfect work into the world. As so often, a weight-training analogy applies: shooting for 100% is the equivalent of pointlessly straining to lift a dumbbell you can’t possibly lift, then usually giving up, resolving that when you try again tomorrow you’ll magically be strong enough. (But why on earth would you be stronger tomorrow?) Whereas aiming for 70% means lifting the weight you can lift, with a modicum of unpleasant effort. It’s not fun, exactly. But you develop a taste for it. And each time you do it, you’re building the capacity to do more of it in future.\n\nSo every time you release a creative work into the world, or make a commitment, or take an action, despite being no more than 70% satisfied with your output or confident in your abilities, you’re not only bringing something into concrete reality. You’re also expanding your ability to act in the presence of feelings of displeasure, worry and uncertainty, so that you can take more actions, and more ambitious actions, later on.\n\nCrucially, you’ll also be creating a body of evidence to prove to yourself that when you move forward at 70%, the sky stubbornly fails to fall in. People don’t heap scorn on you or punish you. Much of the time, they’re thrilled or grateful you stuck your head above the parapet. The Youtuber Campbell Walker, aka Struthless (one of several people, I learn, who coined the 70% rule before I did) observes that over the long term, this helps you see that your worth isn’t defined by your actions. You don’t need a perfect track record of accomplishments in order to get to count as an adequate human. And this knowledge frees you up to take further, bolder actions, because you’re no longer so fixated on preserving your track record.\n\nThe 70% rule comes with a couple of caveats: You can’t really put a scientific percentage on your feelings, obviously, so perfectionists should beware the risk of obsessing, perfectionistically, over whether they’re at exactly 70% or not. (Note that the rule doesn’t say you should only act when you’re at at least 70% readiness, just that if you’re at 70% readiness, you should act. If you’re happy to act at 60% or 50%, go for it.) And there are big decisions – like, say, whether to get married or divorced, or whether to sign off on the structural safety of the 90-storey skyscraper you’re responsible for building – where a threshold higher than 70% is probably advisable. No need to get perfectionistic about wanting the rule to apply in absolutely every case.\n\nBut such matters aside, I’m willing to bet that making an effort to follow the 70% rule will leave you more productive, more fulfilled, and more able to focus on what matters to you the most. Beyond that, I have a hunch it’ll help you develop precisely the resilience we’re going to need in order to navigate a world that feels ever more beyond our control, and where every day brings destabilising headlines. In this sort of environment, the capacity to act without certainty is essential even just to get through the day, never mind if you’d also like to have an impact on things.\n\nOr to put it in tough-love terms: If you think you might have something to contribute, don’t you have some kind of duty to move forward at 70%, instead of depriving us of your contribution thanks to your finicky and frankly rather self-indulgent insistence on perfection?\n\nThis very newsletter is one small attempt to walk my talk here. I’m still not entirely sure I’ve successfully conveyed why I think the 70% rule is more ambitious than 100%; why it takes guts; why it represents the very opposite of resignation or giving up. But am I about 70% sure I’ve made my point? Yeah, I think so. Time to press send.\n","n":0.028}}},{"i":486,"$":{"0":{"v":"Seminars","n":1},"1":{"v":"\n\nTuesday 26 March 2024\n\n\nConference on https://en.wikipedia.org/wiki/Michael_Polanyi\n\nBruno Lemaitre, Global Health Institute, EPFL, Lausanne, Switzerland\n\nhttps://en.wikipedia.org/wiki/Bruno_Lemaitre\n\nWrote a book on Michael Polanyi\n\nBooks by Polanyi\n\n- Personal Knowledge\n- The Tacit Dimension\n- Science, Faith and Society\n\n\nTacit: unspecifiable and implicit aspects of knowledge, accepted incritically\ne.g. riding a bike, playing the piano, but also reading, writing, speaking a language\n\n- Michael Polanyi, the scientist who wanted to re-enchant the world\n\n\n[Michael Polanyi](https://en.wikipedia.org/wiki/Michael_Polanyi \"Michael Polanyi  \\( poh-LAN-yee; Hungarian: Polányi Mihály; 11 March 1891 – 22 February 1976\\) was a Hungarian-British polymath, who made important theoretical contributions to physical chemistry, economics, and philosophy. He argued that positivism is a false account of knowing.\nHis wide-ranging research in physical science included chemical kinetics, x-ray diffraction, and adsorption of gases. He pioneered the theory of fibre diffraction analysis in 1921, and the dislocation theory of plastic deformation of ductile metals and other materials in 1934. He emigrated to Germany, in 1926 becoming a chemistry professor at the Kaiser Wilhelm Institute in Berlin, and then in 1933 to England, becoming first a chemistry professor, and then a social sciences professor at the University of Manchester. Two of his pupils won the Nobel Prize, as well as one of his children. In 1944 Polanyi was elected to the Royal Society.\nThe contributions which Polanyi made to the social sciences include the concept of a polycentric spontaneous order and his rejection of a value neutral conception of liberty. They were developed in the context of his opposition to central planning.\")\n\n\nTheory of personal knowledge\nPolanyi anti-reductionism\n\n\nStandard model of Science : objectivism\n\nMoral inversion: immoral actions are justified by the moral good they serve (e.g. Nazism, Stalinism)\n\n\n\n\nMaybe to connect with Carlo Rovelli's work on the nature of time and the nature of knowledge\n\nIn 1993, in collaboration with Alain Connes, Rovelli proposed a solution to this problem called the thermal time hypothesis. According to this hypothesis, time emerges only in a thermodynamic or statistical context. If this is correct, the flow of time is not fundamental, deriving from the incompleteness of knowledge.\n\nhttps://en.wikipedia.org/wiki/Carlo_Rovelli\n\n\n\nThomas Kuhn, The Structure of Scientific Revolutions after listening Polanyi's lectures\n\n\n\nPersonal knowledge is NOT subjectivism\n\n- realism: there is an external reality outside of us \n- submission to shared standards (responsability) e.g apply the scientific method\n- intersubjectivity: \n- universal intent: \n\n\nPolanyi's anti-reductionism\n\nNotion of emergence\n\n\n\nConcept of dual control. \n\n\nPolanyi's is post-critical philosophy.\n\n","n":0.052}}},{"i":487,"$":{"0":{"v":"Rust","n":1},"1":{"v":"\n## Functions\n\nRust is an expression based language.\n\n- **Statements** are instructions that perform some action but do not return a value.\n\ne.g. `let x = 6;`\n\n- **Expressions** evaluate to a resulting value.\n\ne.g. `x + 1`\n\n## Crates\n\nThey are collection of rust code files. They are binary crates and library crates. Library crates contains code to be used in other programs an not on its own.\n\n## Doc\n\nIf you don't remeber which traits and functions are available in your codebase you can run \n\n```bash\ncargo doc --open\n```\n\n## Shadowing    \n\nThis is convenient when you want to reuse a variable without having to come up with a new name. \n\n```rust\nlet x = 5;\nlet x = x + 1;\nlet x = x * 2;\n```\n\n\n\n## Questions\n\nWhat exactly is a variant. How is that different from a trait ?\n\nDefine \n\n- type\n- trait\n- struct\n- enum\n- variant\n- module\n- crate\n- arms: an arm consist of a pattern to be matched agaisnt and the code to be run if the pattern is matched.\n\nFor example\n\n```rust\nlet guess: u32 = match guess.trim().parse() {\n    Ok(num) => num,\n    Err(_) => continue,\n};\n```\nThis is also the case in an if statement. Each blocks of code associated to the if and else are called arms.\n\n```rust\nfn main() {\n    let number = 3;\n\n    if number < 5 {\n        println!(\"condition was true\");\n    } else {\n        println!(\"condition was false\");\n    }\n}\n```\n\n## Iif Expressions\n\nIn rust, if should be associated to a boolean. \n\nWhen you have more than one `else if` expression you might want to refactor your code. Rust has a powerful branching construct called `match` for these cases.\n\n## Data types\n\nTwo types of data types in Rust:\n- scalar\n- compound\n\n### Scalar\n\nRepresents a single value. Rust has four primary scalar types: integers, floating-point numbers, Booleans, and characters.\n\n#### integers\n\nSigned or unsigned. Signed can be negative or positive. Unsigned can only be positive.\n\nChar\n\nspecified with single quote \n\ne.g `let c = 'z';`\nunlike strings which are specified with double quotes.\n\n### Compound\n\n- tuples\ncannot grow or shrink. fixed lenght. \ne.g. `let tup: (i32, f64, u8) = (500, 6.4, 1);`\n\n\nTo access values of the tuple we destructure it\n\n```rust\nlet tup = (500, 6.4, 1);\nlet (x, y, z) = tup;\n\nprintln!(\"The value of y is: {}\", y);\n```\n\nAnother way to acess elements of the tupple is by using the index\n\n```rust\nlet x: (i32, f64, u8) = (500, 6.4, 1);\n\nlet five_hundred = x.0;\nlet six_point_four = x.1;\nlet one = x.2;\n```\n\n- arrays\n\nUnlike tupples, every element must be of the same type. They are fixed lenght. \n\n```rust\nlet a = [1, 2, 3, 4, 5];\n```\n\nTo acess elements of an array we use the index\n\n```rust\nlet a = [1, 2, 3, 4, 5];\n\nlet first = a[0];\nlet second = a[1];\n```\n\n## The Slice type\n\n\n\n## Vectors\n\nThese are similar to arrays but can grow or shrink in size. \nThey are stored in the heap rather than the stack which is the case for arrays.\n\nVectors can only store data of the same type.\n\nThe vec! macro is used to create a vector.\n\n```rust\nlet v = vec![1, 2, 3];\n```\n\n## Ownership\n\nOwnership is a set of rule governing how Rust manages memory.\n\nThree possibilities for programming languanges:\n\n- their is garbage collection periodically \n- the programmer must explicitily allocate and free memory\n- memory is managed through a system of **ownership** with a set of rules checked by the compiler (rust)\n\n\n### Stck versus heap\n\nThink of stack as a pile of plates. _last in, first out._ You dont remove stuff from in between.\nYopu _push onto the stack_ or _pop off the stack_. All data on the stack must have known, fixed size.\n\nOn the hep, its different and less organized. The memory allocator check for a big enough spacem marks it as beeing in use and returns a _pointer._ This is called _allocating._ Because the pointer is know, fixed sized, you can in turn store it on the stack. \n\nPushing on the stack is much quicker because you just have to add stuff on top. No time wasted in finding free space.\nSimilarly acccessing data on the stack is quicker.\n\n#### Ownership rules\n\n- each values in Rust as an owner.\n- There can be only one owner at a time.\n- When the owner goes out of scope, the value will be dropped.\n\n#### Variable scope\n\n\nThe scope is the range within the programm for which an item is valid.\n\n```rust\n    {                      // s is not valid here, it’s not yet declared\n        let s = \"hello\";   // s is valid from this point forward\n\n        // do stuff with s\n    }                      // this scope is now over, and s is no longer valid\n```\n\nWhat happens behind the scenes is that rust's `drop` function is automatically runned at the closing opf the curly brackets.\n\n\n## References and borrowing\n\n\nA reference is like a pointer in the sense that it is an adress to be followed to acess the data stored at this adress (data owned by another variable). But unlike a pointer, a reference is guaranteed to point to a valid value of a particular type for the life of that reference.\n\n\nThe ampersands represent a reference e.g `&s1`. Here you refer to some value, without taking ownership.\n\n`*`is the _dereferencing_ operator.\n\nBecause we nevere had ownership when using a reference, we do not need to return the values from a function to give back ownership.\nThe creation of a reference is called _borrowing_.\nLike in real life, if a person owns something, you can, sometimes, borrow it. When you are done you give it back, because you dont own it.\n\n\nYou cannot modify stuff you borrow if it is not mutable. However you can make mutable references.\nOne big restriction: if you have a mutable reference to a value, you cannot meke another reference to that value.\n\n\nThis allows rust to prevent data race condition.\n\nThis happens in the three sceanrii:\n\n- two or more pointers access the same data at the same time.\n- at least one of the pointers is beeing used to write to the data\n- no mechanism used to synchronize acess to the data.\n\nRules of references.\n\n- at any given time you can have either one mutable reference or any number of immutable references.\n- references must always be valid.\n\n## Structs\n\nStructs are similar to Tuples.\nLike tuples pieces of a struct can be different.\nUnlioke tuples, in a Struct youll name each piece of data (these are called fields)\n\nOnce created, structs can be instantiated.\n\n### Tuple structs\n\ne.g. \n```rust \nstruct Color(i32, i32, i32);\n```\n\n### Unit-like structs\n\nEven simpler: they are things such as Unit-like structs.\n\n```rust\nstruct AlwaysEqual;\n\nfn main() {\n    let subject = AlwaysEqual;\n}\n```\n\n## Method syntax\n\nMethods are like functions but unlike functions they are defined within the context of a _struct_ (or an **enum** or a **trait** object). \nThere first parameter is always self, which respresnets the instance of the struct the method is beeing called on.\n\n```rust\nimpl Rectangle {\n    fn area(&self) -> u32 {\n        self.width * self.height\n    }\n    fn width(&self) -> bool {\n        self.width > 0\n    }\n    fn can_hold(&self, other: &Rectangle) -> bool {\n       self.width > other.width && self.height > other.height\n    }\n}\n```\n\nThese methods are called **associated functions**, they are indeed associated to the struct Rectangle. \nWe can define associated function that DO NOT have self as their first parameters (they are thus not methods.9 because they do not need an instance of the type to work with.\n\nThese associated functions which are not methods are often used for constructors that will return a new instance of the structs.\n\n\n\n\n\n\n## Enums\n\n_Enums_ allow to define a type by enumerating its possible _variants._\nOption is a particularly usefull enum. Encodes that a value can be either something or nothing.\nPattern matching using match makes it easy to run different code for different values of an enum.\n\nOne very common enum in rust is Option\n\n```rust\nenum Option<T> {\n    None,\n    Some(T),\n}\n```\n\nYou can even directly \n\n```rust\nlet some_number = Some(5);\nlet absent_number: Option<i32> = None;\n```\n\nOption has a large number of associated methods that can be checked at https://doc.rust-lang.org/std/option/enum.Option.html\n\n### match control flow construct\n\nYou can thing of match as a coin sorting machine. The coins slide down a ramp with holes of incresaing size. The first hole fitting size sorts the condition.\nthink of it as conditional expression with if. But the big difference is that it doesnt need to be a boolean.\n\n\nRemeber that the match arms are made by two parts :\n\n- a pattern \n- some code\n\nsepartaed by => \n\n```rust\nenum Coin {\n    Penny,\n    Nickel,\n    Dime,\n    Quarter,\n}\n\nfn value_in_cents(coin: Coin) -> u8 {\n    match coin {\n        Coin::Penny => 1,\n        Coin::Nickel => 5,\n        Coin::Dime => 10,\n        Coin::Quarter => 25,\n    }\n}\n```\n\nCombining mathc and enums is extremely frequent pattern in rust programming.\n\nfn plus_one(x: Option<i32>) -> Option<i32> {\n    match x {\n        None => None,\n        Some(i) => Some(i + 1),\n    }\n}\n\nfn main() {\n    let five = Some(5);\n    let six = plus_one(five);\n    let none = plus_one(None);\n\n    println!(\"six is {:#?} and none is {:#?}\", six, none);\n}\n\nMatches in Rust are _exhaustive_: all the cases must be covered.\n\n\n### catch all patterns and the _ placeholder\n\n\nThis is usefull when you which to aplly and action to some patterns but then apply the same action for the rest of the cases (i.e. a default action)\n\n```rust\nlet config_max = Some(3u8);\nmatch config_max {\n    Some(max) => println!(\"The maximum is configured to be {max}\"),\n    _ => (),\n}\n```\n\nThe last arms catches all other possible cases. We are exhaustive and covered. The empty tuples means no action is taken.\n\n\n\n### if let (when match get's a bit wordy ...)\n\n```rust\nlet config_max = Some(3u8);\nif let Some(max) = config_max {\n    println!(\"The maximum is configured to be {max}\");\n}\n```\n\n### Pattern syntax\n\nPatterns can be used to destructure struct, enums and tuples and use differents parts of these values.\n\n```rust\nfn main() {\n    let p = Point { x: 0, y: 7 };\n\n    match p {\n        Point { x, y: 0 } => println!(\"On the x axis at {x}\"),\n        Point { x: 0, y } => println!(\"On the y axis at {y}\"),\n        Point { x, y } => {\n            println!(\"On neither axis: ({x}, {y})\");\n        }\n    }\n}\n```\n\n\nDestructuring can work on nested object (here enums)\n\n```rust\nenum Color {\n    Rgb(i32, i32, i32),\n    Hsv(i32, i32, i32),\n}\n\nenum Message {\n    Quit,\n    Move { x: i32, y: i32 },\n    Write(String),\n    ChangeColor(Color),\n}\n\nfn main() {\n    let msg = Message::ChangeColor(Color::Hsv(0, 160, 255));\n\n    match msg {\n        Message::ChangeColor(Color::Rgb(r, g, b)) => {\n            println!(\"Change color to red {r}, green {g}, and blue {b}\");\n        }\n        Message::ChangeColor(Color::Hsv(h, s, v)) => {\n            println!(\"Change color to hue {h}, saturation {s}, value {v}\")\n        }\n        _ => (),\n    }\n}\n```\n\nIf you are not going to use a variable yet but want to ignore it. you prefix by _\n\nfn main() {\n    let _x = 5;\n    let y = 10;\n}\n\n### Extra conditionals with Match guards.\n\nA match guards is and additional if condition specified after the pattern in a match arms.Usefull to express complex logic when patterns are not enough.\n\n## Strings\n\n`String` is actually implemented as a wrapper around a vector of bytes with some extra guarantees, restrictions and capabilities.\n\n\n## Traits\n\n\nShared functionalities across data types.\nSimilar to \"interfaces\" in other languages\n\n### The orphan rule\n\nOther crates that depend on the aggregator crate can also bring the Summary trait into scope to implement Summary on their own types. One restriction to note is that we can implement a trait on a type only if either the trait or the type, or both, are local to our crate. For example, we can implement standard library traits like Display on a custom type like Tweet as part of our aggregator crate functionality because the type Tweet is local to our aggregator crate. We can also implement Summary on Vec<T> in our aggregator crate because the trait Summary is local to our aggregator crate.\n**But we can’t implement external traits on external types**. For example, we can’t implement the Display trait on Vec<T> within our aggregator crate because Display and Vec<T> are both defined in the standard library and aren’t local to our aggregator crate. This restriction is part of a property called coherence, and more specifically the orphan rule, so named because the parent type is not present. This rule ensures that other people’s code can’t break your code and vice versa. Without the rule, two crates could implement the same trait for the same type, and Rust wouldn’t know which implementation to use.\n\n## Modules\n\n## Hash Maps\n\nthese are equivalent to Python's dictionnaries, also called associative arrays in other languages.\n\nHashMap<K, V> \nStored on the heap.\n\nLike Vectors, HashMaps are homegeneous, all of the keys miust have the same \n\nThe HashMaps takes owner ship of the values insert inside.\nYou put them there by hashmap.insert(k, v)\n\n\n#### Overwritting a value\n\nif we \nhashmap.insert(k, v1)\nhashmap.insert(k, v2)\n\nv1 is overwritten\n\n#### Adding value only if absent\n\nhashmap.insert(k, v1)\n\nhashmap.entry(k1).or_insert(v2)\nhashmap.entry(k).or_insert(v2)\n\nv1 is not overwritten because its already present\n\n\n## Iterators\n\nIterators are lazy. They do not do anything until you call a method that consumes the iterator.\nThis is called _consuming an iterator_.\nThe iterator trait is called Iterator. It has a method called next() which returns an Option<T>.\n\n```rust\nlet v = vec![1, 2, 3];\nlet mut iter = v.iter();\nassert_eq!(iter.next(), Some(&1));\nassert_eq!(iter.next(), Some(&2));\nassert_eq!(iter.next(), Some(&3));\nassert_eq!(iter.next(), None);\n```\n\nClosure and map on iterators\n\n```rust\nlet v = vec![1, 2, 3];\nlet mut iter = v.iter();\nlet plus_one = |x| x + 1;\nlet mut iter = iter.map(plus_one);\nassert_eq!(iter.next(), Some(2));\nassert_eq!(iter.next(), Some(3));\nassert_eq!(iter.next(), Some(4));\nassert_eq!(iter.next(), None);\n```\n\ncollect() is a method that consumes the iterator and returns a collection.\n\n```rust\nlet v = vec![1, 2, 3];\nlet mut iter = v.iter();\nlet plus_one = |x| x + 1;\nlet mut iter = iter.map(plus_one);\nlet v: Vec<_> = iter.collect();\nassert_eq!(v, vec![2, 3, 4]);\n```\nThe collect() method is a powerful way to transform an iterator into a collection. It can be used to create a vector, a hash map, or any other collection type that implements the FromIterator trait.\n\n\n\n","n":0.022}}},{"i":488,"$":{"0":{"v":"Ressources","n":1},"1":{"v":"\nIt is possible tun Rust interactively see:\n\nhttps://depth-first.com/articles/2020/09/21/interactive-rust-in-a-repl-and-jupyter-notebook-with-evcxr/\n","n":0.378}}},{"i":489,"$":{"0":{"v":"History","n":1},"1":{"v":"https://huizhou92.com/p/rust-lesson-1-a-gophers-view-on-rust/\n","n":1}}},{"i":490,"$":{"0":{"v":"Ressources","n":1}}},{"i":491,"$":{"0":{"v":"Mass Spectrometry","n":0.707}}},{"i":492,"$":{"0":{"v":"Learning","n":1},"1":{"v":"\n\nSet of papers shared by Adriano regarding ML approaches and MSMS\n\n- https://www.nature.com/articles/s42256-023-00663-z\n- https://doi.org/10.1021/jasms.3c00089\n- https://doi.org/10.1021/jasms.3c00090\n- https://arxiv.org/pdf/2111.04824.pdf\n- https://doi.org/10.1101/2023.06.01.543126\n- https://doi.org/10.1038/s42004-023-00932-3\n- https://doi.org/10.1021/acs.analchem.3c02413\n- https://doi.org/10.26434/chemrxiv-2023-vsmpx-v4\n- https://doi.org/10.1186/s13321-024-00804-5\n- https://arxiv.org/abs/2304.13136\n- https://doi.org/10.26434/chemrxiv-2024-w0wvl\n- https://doi.org/10.26434/chemrxiv-2024-k06gb\n- https://doi.org/10.1038/s42004-024-01112-7\n- https://doi.org/10.26434/chemrxiv-2023-kss3r\n- https://doi.org/10.1038/s42256-024-00816-8\n- https://doi.org/10.48550/arXiv.2404.02360\n- https://doi.org/10.1101/2024.04.22.590551\n- https://doi.org/10.1021/acs.jproteome.3c00857\n- https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/6646443621291e5d1d72fa6b/original/universal-fragmentation-model-for-tandem-mass-spectrometry-based-molecular-structural-elucidation.pdf\n- https://doi.org/10.26434/chemrxiv-2024-k06gb-v3\n- https://chemrxiv.org/engage/chemrxiv/article-details/64f76a0279853bbd7829bf27\n- https://doi.org/10.1186/s13321-024-00905-1\n- https://doi.org/10.1021/acs.analchem.4c02426\n- https://doi.org/10.1021/acs.analchem.4c03724\n\n### Comparison of Cosine, Modified Cosine, and Neutral Loss Based Spectrum Alignment For Discovery of Structurally Related Molecules\n\nhttps://doi.org/10.1021/jasms.2c00153\n\n### Spectral entropy outperforms MS/MS dot product similarity for small-molecule compound identification\n\nhttps://doi.org/10.1038/s41592-021-01331-z\n\n### BLINK enables ultrafast tandem mass spectrometry cosine similarity scoring\n\nhttps://doi.org/10.1038/s41598-023-40496-9\n\n\n","n":0.118}}},{"i":493,"$":{"0":{"v":"Linkerbio","n":1},"1":{"v":"\nUnleashing Digital Knowledge into the Future\nhttps://linker.bio/\n\n\n### Install Preston \n\nhttps://github.com/bio-guoda/preston\n\n### Following recipee @ https://jhpoelen.nl/bees/\n\n\n\n\nhttps://hash-archive.carlboettiger.info/history/https://www.earthmetabolome.org","n":0.277}}},{"i":494,"$":{"0":{"v":"Datasette","n":1},"1":{"v":"\n# Resume\n\nDatasette is a tool for exploring and publishing data. It helps people take data of any shape, analyze and explore it, and publish it as an interactive website and accompanying API.\n\nDatasette is aimed at data journalists, museum curators, archivists, local governments, scientists, researchers and anyone else who has data that they wish to share with the world. It is part of a wider ecosystem of 46 tools and 142 plugins dedicated to making working with structured data as productive as possible.\n\nTry a demo and explore 33,000 power plants around the world, then follow the tutorial or take a look at some other examples of Datasette in action.\n\nThen read how to get started with Datasette, subscribe to the monthly-ish newsletter and consider signing up for office hours for an in-person conversation about the project.\n\nNew: Datasette Desktop - a macOS desktop application for easily running Datasette on your own computer!\n\n# Links\n\nhttps://datasette.io/\n\nhttps://datasette.io/desktop\n\n\n# tutorials\n\nJust followed https://datasette.io/tutorials/clean-data\nThis is stunning !","n":0.08}}},{"i":495,"$":{"0":{"v":"Rcf","n":1},"1":{"v":"\n\nhttps://symposium.enhancer.ch/\n\n\nDate and Venue\n\nEnhanceR Symposium is a full-day event on Sep 4th, 2025. The event will hosted at the HEG-FR in Fribourg.\n\nAddress:\nSchool of Management Fribourg\nChemin du Musée 4\n1700 Fribourg \n\n\nhttps://vib.be/en#/\n\nHow to create a mailing list unifr \n\nhttps://lists.unifr.ch/sympa\n\n\n![](/assets/images/2025-06-24-14-09-53.png)","n":0.167}}},{"i":496,"$":{"0":{"v":"Pubchem","n":1},"1":{"v":"\n\nTo extract data from PubChem starting from the compounds CID\n\nhttps://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/33032,5961,681,439260,5202,119/property/ExactMass,CanonicalSMILES,Title/CSV\n\n\nhttps://pubchem.ncbi.nlm.nih.gov/docs/pug-rest#section=URL-based-API\n\nList of compounds property can be found at https://pubchem.ncbi.nlm.nih.gov/docs/pug-rest#section=Compound-Property-Tables\n\nhttps://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/33032,5961,681,439260,5202,119/property/MolecularFormula,ExactMass,MolecularWeight,CanonicalSMILES,IsomericSMILES,InChI,InChIKey,XLogP,Title/CSV\n\n\n","n":0.236}}},{"i":497,"$":{"0":{"v":"Profiling","n":1},"1":{"v":"\n\nIn order to check which part of your code is more greedy, you can run \n\n```bash\nsudo perf top -p <PID>\n```\n\n","n":0.224}}},{"i":498,"$":{"0":{"v":"Port Forwarding","n":0.707},"1":{"v":"\nLet's say you want to open on your local machine a port that is on a remote machine. You can do this with SSH port forwarding.\n\n```bash\nssh commons-server -L 8888:localhost:8890\n```\n\nThis will cease existing once your bash session is closed. If you want to keep it running, you can use `autossh`.\n\n```bash\nautossh -M 0 -f -N -L 8888:localhost:8890 commons-server\n```\n\nssh metabomaps.nprod.net -L 8888:localhost:80","n":0.13}}},{"i":499,"$":{"0":{"v":"Poetry","n":1},"1":{"v":"\n### In case poetry doesn't detect the active pyenv \n\n`poetry env use $(pyenv which python)`\n\nAs per https://github.com/python-poetry/poetry/issues/651#issuecomment-1073213937\n\n### In case Poetry is not getting the latest pypi package\n\npoetry cache list\n\npoetry cache clear PyPI --all\n\npoetry cache clear _default_cache --all\n\n","n":0.164}}},{"i":500,"$":{"0":{"v":"Pathway Analysis","n":0.707},"1":{"v":"\n\n\nLooking for scripts and approaches to perform pathway analysis on plants/bacterial metabolomics dataset\n\n\n\n# Ressources\n\n- A Systems Biology Workflow to Support the Diagnosis of Pyrimidine and Urea Cycle Disorders\nhttps://github.com/BiGCAT-UM/IMD-PUPY\nhttps://www.medrxiv.org/content/10.1101/2022.01.31.21265847v1\n\n\n- FELLA: an R package to enrich metabolomics data\nhttps://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2487-5\n\n\n- Mummichog\nhttps://shuzhao-li.github.io/mummichog.org/index.html\n\n- Metaboverse\nhttps://metaboverse.readthedocs.io/en/latest/ 😲😲😲😲\n\n\n\n\n\nTODO make a list of metabolomics analysis packages\n\n\n## OMU\nhttps://cran.r-project.org/web/packages/omu/vignettes/Omu_vignette.html\n\n\n## SECIMTools: a suite of metabolomics data analysis tools\nhttps://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2134-1\n\n## A Practical Guide to Metabolomics Software Development\nhttps://pubs.acs.org/doi/10.1021/acs.analchem.0c03581\n\n## iMAP: A Web Server for Metabolomics Data Integrative Analysis\nhttps://www.frontiersin.org/articles/10.3389/fchem.2021.659656/full","n":0.119}}},{"i":501,"$":{"0":{"v":"P2p","n":1},"1":{"v":"\nhttps://forum.safeguar.de/\n\nhttps://forum.safeguar.de/about\n\nhttps://sciop.net/\n\n#p2p\n\n\n\nhttps://ipfs.tech/\n\n\nhttps://www.digipres.org/\n\n\n\nhttps://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=2335&context=etd\n\n\n\nBrigham Young UniversityBrigham Young University\nBYU ScholarsArchiveBYU ScholarsArchive\nTheses and Dissertations\n2008-03-10\nA BitTorrent ProxyA BitTorrent Proxy\nRobert Brent LarsenBrigham Young University - Provo\n\nAdoption of Authenticated Peer-to-Peer Academic\nNetworks – A Case Study of a Failure\n\nhttps://link.springer.com/chapter/10.1007/978-3-642-16419-4_35\n","n":0.183}}},{"i":502,"$":{"0":{"v":"Torrents","n":1},"1":{"v":"\nhttps://antrikshy.com/code/seeding-torrents-using-transmission-cli\n\n/var/lib/transmission-daemon/downloads\n\ntransmission-cli https://academictorrents.com/download/11093a9450b26514f34bc24f1f41c759d2cfac23.torrent -w ~/torrents\n\ntransmission-remote -a https://academictorrents.com/download/d984f67af9917b214cd8b6048ab5624c7df6a07a.torrent\n\n\ntransmission-remote -l","n":0.378}}},{"i":503,"$":{"0":{"v":"Libp2p","n":1},"1":{"v":"\n\nhttps://libp2p.io/\n\n","n":1}}},{"i":504,"$":{"0":{"v":"Hole Punching","n":0.707},"1":{"v":"\nhttps://libp2p.github.io/rust-libp2p/libp2p/tutorials/hole_punching/index.html","n":1}}},{"i":505,"$":{"0":{"v":"Gbif","n":1},"1":{"v":"\nStarting the process of making a torrent for GBIF occurence snapshot\n\nhttps://sciop.net/datasets/gbif-20250501-occurrence-data\n\nCurrently dling the 214 Gb.\n\nStarted to do so after \n\n![](/assets/images/2025-05-09-22-07-47.png)\n\nand \n\n![](/assets/images/2025-05-09-22-07-04.png)\n\nsciop-cli torrent create -p ./gbif-20250501/ --comment \"That's what we know of the occurrences of our planet's species as of May 2025\" --default-trackers -o ./gbif-20250501-occurrence-data.torrent\n","n":0.151}}},{"i":506,"$":{"0":{"v":"Bittorrent","n":1},"1":{"v":"\n\nhttps://www.bittorrent.org/beps/bep_0003.html","n":1}}},{"i":507,"$":{"0":{"v":"Ool","n":1}}},{"i":508,"$":{"0":{"v":"Reading","n":1},"1":{"v":"\n# 'Impossible' chemistry may reveal origins of life on Earth\n\nhttps://www.nationalgeographic.com/science/article/impossible-chemistry-may-reveal-origins-of-life-on-earth\n\n# He may have found the key to the origins of life. So why have so few heard of him?\n\nhttps://www.nationalgeographic.com/science/article/he-may-have-found-the-key-to-origins-of-life-tibor-ganti-chemoton","n":0.186}}},{"i":509,"$":{"0":{"v":"Luca","n":1},"1":{"v":"\nLast Universal Common Ancestor (LUCA)\nSome authors equate models of the origin of life with LUCA, the Last Universal Common Ancestor of all extant life.[17] This is a serious error resulting from failure to recognize that L refers to the last common ancestor, not to the first ancestor, which is much older: a large amount of evolution occurred before the appearance of LUCA.[18]\n\nGill and Forterre expressed the essential point as follows:[19]\n\nLUCA should not be confused with the first cell, but was the product of a long period of evolution. Being the \"last\" means that LUCA was preceded by a long succession of older \"ancestors.\"\n\n\nsource https://en.wikipedia.org/wiki/Autocatalytic_set\n\n","n":0.098}}},{"i":510,"$":{"0":{"v":"Emergence","n":1},"1":{"v":"\n# EXPLAINING EMERGENCE: TOWARDS AN ONTOLOGY OF LEVELS\nCLAUS EMMECHE, SIMO K0PPE and FREDERIK STJERNFELT\n\n\nThe subject of this paper is the concept of emergence formulated as the idea that there are properties at a certain level of organization which can not be predicted from the properties found at lower levels.\n\n\nAs far as we can see, there is a hidden and mostly unnoticed historical value in this \"coincidence\": the concept of emergence is exactly that reasonable aspect of vitalism which is worth to maintain.\n\n\nThis is a very important difference between the vitalists and the emergentists: the vitalist's creative forces were relevant only in organic substances, not in inorganic matter. Emergence hence is creation of new properties regardless of the substance involved.\n\n\nBut these system builders' discussions are very important, and they are one of the main reasons that the concept of emergence was \"devitalized\", that is, deprived of an immaterial causal agent.\n\n\nEmergence is among other things the concept which relate levels to each other - or to be more precise, the concept which denotes the very passage between them. It does not in itself solve anything, but it poses the problem in a general way, making it visible at the border of every specialized branch of science\n\n\nIn Lloyd Morgan's definition of emergence as \"creation of new properties\" there are three key words: \"properties\", \"new\" and \"creation\". By a more detailed discussion of these key concepts, it is possible to grasp the primary topics in the concept of emergence.\n\n- properties\n\nsecond, and more commonly used definition, tells us that emergence is at stake at the borders between the large sciences: where the explanatory power of one science must give in, another must take over at the level of the hitherto unexplainable - emergent - property. But it is not possible to restrict emergence to these borders. As already Morgan realized, the science usually considered more basic than all others - physics - in itself contains numerous cases of emergence.\n\n\n- novelty\n- creation\n","n":0.055}}},{"i":511,"$":{"0":{"v":"Ontologies","n":1},"1":{"v":"\n# Software\n\nhttps://bio.tools/\n\nhttps://edamontology.org/page\n\n","n":0.707}}},{"i":512,"$":{"0":{"v":"Nginx","n":1},"1":{"v":"\n# Title \n2022-11-02 14:42\n## Context\nLooking into nginx to setup a connection to NocoDB from the commons_lab server \n\nThis was done on the metabomaps server for the graphDB instance with the help of Jo.\nTrying to reproduce here.\n## Need\nsetup a connection to NocoDB from the commons_lab server\n\n## Task (of the note/paragraph/text/paper/project)\nThird, indicate what you have done in an effort to address the need (this is the task).\n- [ ] Watching https://www.youtube.com/watch?v=JKxlsvZXG7c\n\nThey indicate that the conf file is usually under etc/nginx.\nIndeed over there on the metabomaps server.\n\nLets looks at the commonslab server\nNot there.\n\nLets install this\n\nFollowing https://ubuntu.com/tutorials/install-and-configure-nginx#2-installing-nginx\n\n\nWe get the following error when starting nginx \n\n(base) allardpm@biolpc045600:/etc/nginx/sites-enabled$ systemctl status nginx.service\n● nginx.service - A high performance web server and a reverse proxy server\n     Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled)\n     Active: failed (Result: exit-code) since Sun 2022-06-19 09:06:20 CEST; 57s ago\n       Docs: man:nginx(8)\n    Process: 3544101 ExecStartPre=/usr/sbin/nginx -t -q -g daemon on; master_process on; (code=exited, status=0/SUCCESS)\n    Process: 3544102 ExecStart=/usr/sbin/nginx -g daemon on; master_process on; (code=exited, status=1/FAILURE)\n\n\nFollowing https://stackoverflow.com/questions/51525710/nginx-failed-to-start-a-high-performance-web-server-and-a-reverse-proxy-server\n\n\nsudo systemctl reload nginx\n\n\nwe \n sudo service apache2 stop\n\n\n ![](/assets/images/2022-06-19-09-11-18.png)\n\n Amazing !\n\n\n \n- [ ] So this was a first step.\nApparently certbot was used later one. Lets see how this one works\n\nhttps://certbot.eff.org/instructions?ws=nginx&os=ubuntufocal\n\nI added the ip of the commons lab server to the dbgi DNS\nAnd can now vie the previously made placeholder website when serving on port 80\n\n![](/assets/images/2022-06-19-09-43-57.png)\n\nHowever the certbot step is not working \nsudo certbot --nginx\n\nAnd returns \n\n\nhttps://check-your-website.server-daten.de/?q=commons.dbgi.org\n\n\n\n![](/assets/images/2022-06-19-10-53-34.png)\n\nYeah !! But thats on the metabomaps server. Apparently thing will not work that smoothly on the commons server sinc it is behind the university firewall\nrunning (saved as a .sh script)\n certbot --authenticator standalone --installer nginx   -d xxxxxxx.xxxx.org --pre-hook \"service nginx stop\" --post-hook \"service nginx start\"\n\n\n\n\n- [ ] So I can serve the nocodb instance hosted on the commonslab server via a .dbgi.org domains\n\nnginx server file is as follows\n\nserver {\n       listen 80;\n       listen [::]:80;\n\n       server_name xxxxx.dbgi.org;\n\n  # If you would like to gzip your stuff\n  gzip on;\n  gzip_min_length 1;\n  gzip_types *;\n\n  # Setup the proxy\n  # This will forward all requests to the server\n  # and then it will relay the servers response back to the client\n  location / {\n    proxy_pass http://127.0.0.1:8080;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection 'upgrade';\n    proxy_set_header Host $host;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_cache_bypass $http_upgrade;\n  }\n}\n\n\nNode: **v16.15.1**\nArch: **x64**\nPlatform: **linux**\nDocker: **false**\nDatabase: **pg**\nProjectOnRootDB: **true**\nRootDB: **pg**\nPackageVersion: **0.91.10**\n\n\n\n\n\n\n\n## Object (of the note/paragraph/text/paper/project)\nFinally, preview the remainder of the paper to mentally prepare you/readers for its structure, in the object of the document.\n\n\n## Ressources\nSome notes:\nhttps://www.youtube.com/watch?v=JKxlsvZXG7c\n\n\n\n\n## serving the directus interface\n\nport 8055\n\nsudo certbot --authenticator standalone --installer nginx -d directus.dbgi.org --pre-hook \"service nginx stop\" --post-hook \"service nginx start\"\n\nProblem : \n\nSaving debug log to /var/log/letsencrypt/letsencrypt.log\nRequesting a certificate for directus.dbgi.org\n\nCertbot failed to authenticate some domains (authenticator: standalone). The Certificate Authority reported these problems:\n  Domain: directus.dbgi.org\n  Type:   dns\n  Detail: DNS problem: NXDOMAIN looking up A for directus.dbgi.org - check that a DNS record exists for this domain; DNS problem: NXDOMAIN looking up AAAA for directus.dbgi.org - check that a DNS record exists for this domain\n\nHint: The Certificate Authority failed to download the challenge files from the temporary standalone webserver started by Certbot on port 80. Ensure that the listed domains point to this machine and that it can accept inbound connections from the internet.\n\nOf course it doesn't work as we need to declare the DNS first at our DNS provider interface lets go ther \nIt needs to be opened \n\nDone\n\nThen copied the nocodb in /etc/nginx/sites-enabled and changed the server name\n\nCertbox command is still not OK but different error.\nWebsite is accessible\n\n(base) allardpm@biolpc045600:/etc/nginx/sites-enabled$ sudo certbot --authenticator standalone --installer nginx   -d directus.dbgi.org --pre-hook \"service nginx stop\" --post-hook \"service nginx start\"\nSaving debug log to /var/log/letsencrypt/letsencrypt.log\nRequesting a certificate for directus.dbgi.org\n\nCertbot failed to authenticate some domains (authenticator: standalone). The Certificate Authority reported these problems:\n  Domain: directus.dbgi.org\n  Type:   connection\n  Detail: 134.21.20.118: Fetching http://directus.dbgi.org/.well-known/acme-challenge/_3RMgi4TIamOSiw_A2g5iAccqERzpJywraSNUqlFGTc: Timeout during connect (likely firewall problem)\n\nHint: The Certificate Authority failed to download the challenge files from the temporary standalone webserver started by Certbot on port 80. Ensure that the listed domains point to this machine and that it can accept inbound connections from the internet.\n\nSome challenges have failed.\nAsk for help or search for solutions at https://community.letsencrypt.org. See the logfile /var/log/letsencrypt/letsencrypt.log or re-run Certbot with -v for more details.\n\n### Checking nginx status\n\n`systemctl status nginx`\n\non metabomaps it keeps falling.Here is an error message\n\n● nginx.service - A high performance web server and a reverse proxy server\n   Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled)\n   Active: failed (Result: exit-code) since Mon 2022-10-17 19:05:49 UTC; 2 weeks 1 days ago\n     Docs: man:nginx(8)\n  Process: 4655 ExecStartPre=/usr/sbin/nginx -t -q -g daemon on; master_process on; (code=exited, status=0/SUCCESS)\n  Process: 4656 ExecStart=/usr/sbin/nginx -g daemon on; master_process on; (code=exited, status=1/FAILURE)\n\nThis is runned to check the nginy conf\n\nsudo nginx -t\n\n\nnginx: [warn] conflicting server name \"graph.metabomaps.com\" on 0.0.0.0:443, ignored\nnginx: [warn] conflicting server name \"graph.metabomaps.com\" on 0.0.0.0:80, ignored\nnginx: the configuration file /etc/nginx/nginx.conf syntax is ok\nnginx: configuration file /etc/nginx/nginx.conf test is successful\n\n\n## serving the directus interface foor the commons lab\n\nport 8056\n\nsudo certbot --authenticator standalone --installer nginx -d directus.commons-lab.org --pre-hook \"service nginx stop\" --post-hook \"service nginx start\"\n\n## to serve a directory\n\nHere is the used nginx file\n\n```sh\nserver {\n   server_name enpkg.commons-lab.org; # managed by Certbot\n\n   ignore_invalid_headers off;\n   client_max_body_size 1000m;\n   proxy_buffering off;\n\n   gzip on;\n   gzip_proxied any;\n   gzip_vary on;\n   gzip_http_version 1.1;\n   gzip_min_length 1100;\n   gzip_buffers 4 8k;\n   tcp_nopush on;\n   gzip_types application/javascript application/json text/css text/xml image/svg+xml application/svg+xml;\n   tcp_nodelay on;\n   location /sb/ {\n        proxy_pass       http://localhost:3148/; # use httpS here if needed\n        proxy_set_header Host      $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        # add this if nginx is terminating TLS\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n   listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/enpkg.commons-lab.org/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/enpkg.commons-lab.org/privkey.pem; # managed by Certbot\n   include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n   ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n}\n\nserver {\n    if ($host = enpkg.commons-lab.org) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n  server_name enpkg.commons-lab.org;\n    listen 80;\n    return 404; # managed by Certbot\n}\n```\n\nWhat was causing issue was the fact that the style were not found by Graphdb.\nJo send me this SO thread\nhttps://stackoverflow.com/questions/37301169/run-graphdb-behind-apache-proxy_add_x_forwarded_for\nAnd after adding this to the GDB config it went smoothly\n\n```sh\ngraphdb.workbench.external-url = https://enpkg.commons-lab.org/sb/\n```\n\n### dashboard\n\n- Declared the DNS \n- created file in /etc/nginx/sites-enabled\n\n\n\n#### Setting up on the dbgi vm\n\n\nsudo certbot certonly --standalone --preferred-challenges http -d kg.earthmetabolome.org\n","n":0.032}}},{"i":513,"$":{"0":{"v":"Nanopublications","n":1},"1":{"v":"\n\n## genuine semantic publishing\n\n\nhttps://nanodash.knowledgepixels.com/connector/np?id=https://w3id.org/kpxl/ios/ds/np/RAypjyd0XFhaFD1XdZ_IlMniCr-2-RjN9ihfRMUs75TCI&mode=final&journal=ios/ds\n","n":0.5}}},{"i":514,"$":{"0":{"v":"Mkdocs","n":1},"1":{"v":"\n\nhttps://realpython.com/python-project-documentation-with-mkdocs/#:~:text=MkDocs%20is%20a%20Python%20package,pages%20inside%20a%20docs%2F%20folder\n\n","n":1}}},{"i":515,"$":{"0":{"v":"Mcp","n":1},"1":{"v":"[source](https://modelcontextprotocol.io/docs/getting-started/intro)\n# What is the Model Context Protocol (MCP)?\n- open source standard\n- connects AI applications to external systems\n- Can connect an LLM to a data source (such as db), tools, etc, and access key info and do tasks\n![[Pasted image 20251029195911.png]]\n## What can MCP enable?\n- agents can access your google calendar and notion\n- generate web app using figma\n## Why does MCP matter?\n- can reduce development time\n- enhance apps and user experience\n# Architecture Overview\n## Scope\n- **MCP Specification**: specification for MPC\n- **SDK**s: SDKs for programming languages to implement the MCP\n- **MCP Development Tools**: tools for development\n- **MCP Reference Server Implementations**: Reference implementation of MCP servers\n## Concepts of MCP\n### Participants\n- follows a client-server model. \n\t- MCP host - the LLM\n\t- MCP Client - component that connects to MCP server and gets context for MCP host\n\t- MCP Server - Program that provides context to client\nExample: VS Code (Host), connects to Sentry MCP Server (server)\n```mermaid\nflowchart TB\n\tA[MCP Client 1]-- One-to-one connection --->B[MCP Server 1]\n\tC[MCP Client 2]-- One-to-one connection --->D[MCP Server 2]\n\tE[MCP Client 3]-- One-to-one connection --->F[MCP Server 3]\n```\n**server** is the name for the program, regardless of runtime (local/remote). \n### Layers\nConsists of 2 layers:\n1) Data Layer: defines the json-rpc protocol for client-server communication\n2) Transport layer: Defines the communication and channels for data exchange between client and server\n#### Data Layer\nincludes:\n- Lifecycle management: handles connection initialization, capability negotiation, and connection termination \n- Server Features: tools for AI actions, context data, prompts for interaction templates\n- Client features: enables servers to ask client to sample from host LLM, elicit input from user, log messages to client\n- utility features: notifications etc\n#### Transport Layer\nHandles communication/authentication between clients and servers. \nTransport mechanisms:\n- Stdio transport: uses i/o stream for direct process communication between local processes on same machine\n- Streamable HTTP transport: Uses HTTP POST for clinet-to-server messages with optional Server-Sent Events for streaming capabilities. This transport enables rmeote server communication. Supports HTTP standard authentication methods\n#### Data Layer Protocol\nUses [[JSON-RPC 2.0]] for RPC protocol. \n##### Lifecycle management\nMCP is stateful protocol, requires lifecycle management. \n##### Primitives\nThree core primitives that a server can expose:\n1) tools: executable functions that ai apps can invoke to perform actions\n2) resources: data sources that give context to AI apps\n3) prompts: reusable templates that help structure interactions with language models\nEach primitive has associated methods for discovery, retrieval, sometimes execution. The `*/list` method is used to discover available primitives. \n\nPrimitives that the client can expose:\n1) sampling: allows servers to request language model completions from the client's AI application. \n2) Elicitation: allows servers to request additional information from users.\n3) Logging: enables servers to send log messages to clients for debugging and monitoring purposes. \n\n##### Notifications\nthe protocol supports real time notifications to enable dynamic updates between servers and clients. e.g. server tools change (new features added etc). \n\n### Example: \n1) `initialize` handshake to establish connection and negotiate supported features. \nRequest:\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"initialize\",\n  \"params\": {\n    \"protocolVersion\": \"2025-06-18\",\n    \"capabilities\": {\n      \"elicitation\": {}\n    },\n    \"clientInfo\": {\n      \"name\": \"example-client\",\n      \"version\": \"1.0.0\"\n    }\n  }\n}\n```\nResponse:\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"protocolVersion\": \"2025-06-18\",\n    \"capabilities\": {\n      \"tools\": {\n        \"listChanged\": true\n      },\n      \"resources\": {}\n    },\n    \"serverInfo\": {\n      \"name\": \"example-server\",\n      \"version\": \"1.0.0\"\n    }\n  }\n}\n```\nAfter handshake client notifies readiness:\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"method\": \"notifications/initialized\"\n}\n```\n2) Tool discovered - get the list of tools available from server\n3) Tool execution (primitives) - client now able to execute tools\n4) Real-time updates (notifications) - notifications allow server to inform clients about changes without receiving a request. Why this matters:\n\t1) dynamic environment: tools may come and go based on server state ect\n\t2) efficiency: clients don't need to poll for changes\n\t3) consistency: ensures clients always have accurate info about server capabilities \n\t4) real-time collaboration: makes ai apps responsive and adaptive to changing contexts\n# Understanding MCP servers\nMCP servers expose specific capabilities to AI applications through standardized protocol interfaces.\n- file system servers\n- database servers\n- GitHub servers \n- Slack server\n- calendar server\n## Core Server Features\n\n| Feature   | Explanation                                                                       | Examples                                      | Who Controls It |\n| --------- | --------------------------------------------------------------------------------- | --------------------------------------------- | --------------- |\n| Tools     | functions that LLM can call and use                                               | Search, Send mesasges, create calendar events | Model           |\n| Resources | Passive data source, read-only access, such as files or db schemas                | retrieve documents access knowledge bases     | application     |\n| Prompts   | pre-built instruction templates to tell model what to do with tools and resources | plan vacation,                                | user            |\n### Tools\nTools allow ai models to perform actions. Each tool defines specific operation. \n#### How Tools Work\nTools are schema-defined. They are interfaces LLM can invoke. Uses the JSON schema for validation. \n- may require user consent prior to execution\n##### Protocol Operations:\n\n| Method       | Purpose                  | Returns                   |\n| ------------ | ------------------------ | ------------------------- |\n| `tools/list` | Discover available tools | array of tool definitions |\n| `tools/call` | Execute specific tool    | tool execution result     |\n##### Example of TooL Definition:\n```json\n{\n  name: \"searchFlights\",\n  description: \"Search for available flights\",\n  inputSchema: {\n    type: \"object\",\n    properties: {\n      origin: { type: \"string\", description: \"Departure city\" },\n      destination: { type: \"string\", description: \"Arrival city\" },\n      date: { type: \"string\", format: \"date\", description: \"Travel date\" }\n    },\n    required: [\"origin\", \"destination\", \"date\"]\n  }\n}\n```\n##### Example: Travel Booking:\nTools enable AI apps to perform actions on user's behalf. \n###### Flight Search\n`searchFlights(origin: \"NYC\", destination: \"Barcelona\", date: \"2024-06-15\")`\n\n### User Interaction Model\nTools are **model** controlled. But they are on guard rails. user controls can be implemented through:\n- displaying tools in UI, so users can define tool availability\n- approval dialogs for individual tools\n- permission sesttings for pre-approving operations\n- activity logs to show all tool execution\n#### Resources\nprovide structured access to information for AI apps\n##### How resources work\n\nhttps://modelcontextprotocol.io/docs/learn/server-concepts","n":0.033}}},{"i":516,"$":{"0":{"v":"Lod","n":1}}},{"i":517,"$":{"0":{"v":"Tools","n":1}}},{"i":518,"$":{"0":{"v":"Linkml","n":1},"1":{"v":"\nhttps://linkml.io/linkml/intro/overview.html\n\n","n":1}}},{"i":519,"$":{"0":{"v":"Kg","n":1}}},{"i":520,"$":{"0":{"v":"Ressources","n":1},"1":{"v":"\n# PheKnowLator\n\nWhat is PheKnowLator?\nPheKnowLator (Phenotype Knowledge Translator) or pkt_kg is the first fully customizable knowledge graph (KG) construction framework enabling users to build complex KGs that are Semantic Web compliant and amenable to automatic Web Ontology Language (OWL) reasoning, generate contemporary property graphs, and are importable by today’s popular graph toolkits. Please see the project Wiki for additional information.\n\n\nhttps://github.com/callahantiff/PheKnowLator/wiki\n\n\n\n# KG-Hub\n\nWelcome\nKG-Hub: A collection of biological and biomedical Knowledge Graphs, including their component data sources.\n\n\nhttps://knowledge-graph-hub.github.io/\n\n\n\n# NaPDI-KG\n\nNaPDI-KG is a knowledge graph framework to identify and generate mechanistic hypotheses for pharmacokinetic natural product-drug interactions (NPDIs). This repository has been forked from the Knowledge-Graph-Hub. NaPDI-KG uses the PheKnowLator ecosystem to create the ontology-grounded KG and the KG-Hub ecosystem to integrate the nodes and edges extracted from natural product-related biomedical literature. NaPDI-KG includes the following components -\n\nhttps://github.com/sanyabt/np-kg-hub\n\nactually at \n\nhttps://github.com/sanyabt/np-kg\n\n![](/assets/images/2022-09-17-12-52-16.png)\n\n\nBy [[people.sanya-bathla-taneja]]\n\n\n\n\n","n":0.086}}},{"i":521,"$":{"0":{"v":"Endpoint","n":1},"1":{"v":"\n# Your own free, publicly available SPARQL endpoint\n\nBob duCharme\nhttps://www.bobdc.com/blog/ec2fuseki/","n":0.333}}},{"i":522,"$":{"0":{"v":"Formats","n":1},"1":{"v":"\nhttps://www.allotrope.org/\n\nhttps://github.com/TheELNConsortium\n\n","n":1}}},{"i":523,"$":{"0":{"v":"Limesurvey","n":1},"1":{"v":"\nInstallation of Limesurvey on a server\n\nFollowing \n\nhttps://www.youtube.com/watch?v=DSfJXdmnVCM\n\nStart well ! \nToday https://community.limesurvey.org/ is down\n\nFetching a version from https://github.com/LimeSurvey/LimeSurvey/archive/refs/tags/6.8.0+241119.zip","n":0.243}}},{"i":524,"$":{"0":{"v":"Kg","n":1}}},{"i":525,"$":{"0":{"v":"Property Graph","n":0.707},"1":{"v":"\n\n## Property graph\n\nA property graph, labeled property graph, or attributed graph is a data model of various graph-oriented databases,[1] where pairs of entities are associated by directed relationships, and entities and relationships can have properties.\n\nIn graph theory terms, a property graph is a directed multigraph, whose vertices represent entities and arcs represent relationships. Each arc has an identifier, a source node and a target node, and may have properties.\n\nProperties are key-value pairs where keys are character strings and values are numbers or character strings. They are analogous to attributes in entity-attribute-value and object-oriented modeling. By contrast, in RDF graphs, \"properties\" is the term for the arcs. This is why a clearer name is attributed graphs, or graphs with properties.\n\nThis data model emerged in the early 2000s.\n\n\nOn reification https://en.wikipedia.org/wiki/Reification_(knowledge_representation)\n\nOn open/closed world assumption https://en.wikipedia.org/wiki/Open_world_assumption \n","n":0.087}}},{"i":526,"$":{"0":{"v":"Nmdc","n":1},"1":{"v":"\nhttps://github.com/microbiomedata/nmdc-schema\n\n","n":1}}},{"i":527,"$":{"0":{"v":"Biolink","n":1},"1":{"v":"\nhttps://biolink.github.io/biolink-model/understanding-the-model/\n\n![](/assets/images/2025-05-03-16-04-25.png)","n":1}}},{"i":528,"$":{"0":{"v":"Jupyter","n":1},"1":{"v":"\nTo launch a Jupyter notebook on a remote ssh\n\n1. From the local host \n\nssh commons-server -L 12888:localhost:12888\n\n2. On the remote host\n\npython -m jupyter notebook --port 12888\n\nThis can be done also to acess PGadmin \n\n\nex\n\n\nssh commons-server -L PORT:localhost:PORT\n\nthen fromn ","n":0.162}}},{"i":529,"$":{"0":{"v":"Hypergraphs","n":1},"1":{"v":"\nhttps://hypernetx.readthedocs.io/en/latest/index.html\n\n\nhttps://en.wikipedia.org/wiki/Hypergraph\n\n","n":1}}},{"i":530,"$":{"0":{"v":"Hypergraph","n":1}}},{"i":531,"$":{"0":{"v":"Hinode","n":1},"1":{"v":"\nTo upgrade the Hinode package, you can use the following command in your terminal:\n\n```bash\nnpm install && npm run mod:updated\n```\n\nTo launch the website locally\n\n```bash\nnpm run start\n```","n":0.2}}},{"i":532,"$":{"0":{"v":"Freedom","n":1},"1":{"v":"\nLa liberté académique est la base de la recherche et de l'enseignement. Elle consiste en “the right to freely define research questions, choose and develop theories, gather empirical material and employ sound academic research methods, to question accepted wisdom and bring forward new ideas. It entails the right to share, disseminate and publish the results thereof openly, including through training and teaching. It is the freedom of researchers to express their opinion without being disadvantaged by the system in which they work or by governmental or institutional censorship and discrimination.” Bonn declaration on freedom of academic research, Adopted at the Ministerial Conference on the European Research Area on 20 October.\n\nhttps://www.swissuniversities.ch/fr/actualite/publication-guide-collaborations-internationales\n\nhttps://www.bmbf.de/bmbf/shareddocs/downloads/files/_drp-efr-bonner_erklaerung_en_with-signatures_maerz_2021.pdf?__blob=publicationFile&v=1\n\n\n","n":0.095}}},{"i":533,"$":{"0":{"v":"Expanded Np Chemspace","n":0.577},"1":{"v":"\n## Resume\n\nThis project will aim to establish an expanded and pertinent chemical space of NPs through the generation of novel plausible chemical structure.\nFor this we will exploit the initial set of know NPs chemical structure found in LOTUS and employ tools such as Pickaxe to proceed to the in silico metabolization of the initial set of NPs.\n\n## Goals\n\nmove to [[expanded-np-chemspace.goals]]\n\n\n## Log\n\n## Resources\n\n\nmove to [[expanded-np-chemspace.resources]]\n [[expanded-np-chemspace]]","n":0.124}}},{"i":534,"$":{"0":{"v":"Resources","n":1},"1":{"v":"https://minedatabase.ci.northwestern.edu/#/home\n//test\n\nMINE 2.0: enhanced biochemical coverage for peak identification in untargeted metabolomics\nhttps://doi.org/10.1093/bioinformatics/btac331\n\nPickaxe: a Python library for the prediction of novel metabolic reactions\nhttps://doi.org/10.1186/s12859-023-05149-8","n":0.218}}},{"i":535,"$":{"0":{"v":"expanded-np-chemspace-pickaxe","n":1},"1":{"v":"\n# Pickaxe: a Python library for the prediction of novel metabolic reactions \ncurrent Pickaxe: <https://doi.org/10.1186/s12859-023-05149-8>\nolk Pickaxe: <https://github.com/JamesJeffryes/kb_pickaxe/tree/master>\n\n\n## Reaction rules\n\n\n## Filters\nPickaxe provide some filters by default. After the expanding the filters can be used to reduce the large output of possible reactions.\nMostly this filters will need a target list (which has the same structure as the input list). \n\n### Target\nIf the targets are the same as the inputdata, you will not see them in the outputfile (\"compounds.tsv\").\nIf the targets are different from the inputdata, the target compounds will be written to the outputfile and labeled.\nIf the inputdata are a subclass of the targets, the targets will not be written to the outputfile and labeled. But new molecules will be predicted.\nIf the targets are a subclass of the inputdata, the targets will not be written to the outputfile and labeled. But new molecules will be predicted.\n\n.react_targets = False   # This would expand the molecules, because targets are found. (exp. similarity.py, line 856 - 864)\n\n\n\n## Keywords\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.078}}},{"i":536,"$":{"0":{"v":"Information","n":1},"1":{"v":"\n# Information\nAll relevant resources for this project will be found here.\n\n## Websites\n[[expanded-np-chemspace.information.websites]]\n\n\n## Papers\n[[expanded-np-chemspace.information.papers]]","n":0.277}}},{"i":537,"$":{"0":{"v":"Websites","n":1},"1":{"v":"\n# Websites\n\n## Chemical Information System - [daylight.com](daylight.com)\n- provides cheminformatics software technologies\n\n### SMIRKS - A Reaction Transform Language #Tools #Chemistry\nIt is a hybrid of SMILES and SMARTS. \n\nRules for [SMIRKS](https://daylight.com/dayhtml/doc/theory/theory.smirks.html):\n- reactant and product sides of the transfomation need the same amount of Atoms\n- Stoichomestry is defined to be 1-1. \n\n[SMILES and SMARTS](https://daylight.com/dayhtml/doc/theory/theory.smarts.html#RTFrxn7) are also languages for chemical reactions.\nAll SMILES expressions are also valid SMARTS expressions, but the semantics changes because SMILES describes molecules whereas SMARTS describes patterns.\nThe SMARTS can be described as a pattern recognition tool like \"Regex\", which will find molecules (SMILES) with this properties.\nMore about the rules can be found [here](https://www.daylight.com/dayhtml_tutorials/languages/smarts/index.html#INTRO) or with a little bit more theory [here](https://www.daylight.com/dayhtml/doc/theory/theory.smarts.html).  \n\nrecursive SMARTS: detailed specification of an atom's environment  \n\n","n":0.092}}},{"i":538,"$":{"0":{"v":"Papers","n":1},"1":{"v":"\n## Paper's\n### [LOTUS](https://doi.org/10.7554/eLife.70780)\n[LOTUS (LOpen Knowledge Management in Natural Products Research)](https://lotus.naturalproducts.net) is a database of over 750'000+ referenced structure-organism pairs. A structure-organims pairs shows the relationship between organisms and molecules.\nWith the increasing technology, the data for chemical compounds (exp. mass specrometry) and organisms (exp. sequencing machines) also increases exponentialy. To link the data will be more and more beneficial.  \nThe idea of LOTUS is to interconnect the three central objects of the living (metabolites, proteins and genes).  \n\nStep 1 - Data harmonization:  \nThe information comes from different sources, which has to be harmonized/standardized for building the new DB. \nThe scripts involves a comparison with the gathered data to ensure no duplication (SSOT).  \n\nStep 2 - Precessing and Validation:    \nThe tree central objects where taken togheter. Mostly the references was particularly challenging (poor quality). \nAn unit test checked the code after each changes for the same results.\n\n\nStep 3 - Dissemination:  \nThe researchdata should be accessible following the FAIR principles. SPARQL are generic queries to return specific \"tables\". \nTo be find, they have to be in a specific format.\n\n\nFor the biologically interpretation of chemicals is used TMAP. The biological specificity score is calculated as a Jensen-Shannon divergence.\n1 means very specific chemical compound and 0 that they are ubquitous.\nThe same is done in the opposit way (chemically interpretation of biology).\nAim to make more and better data available.\n\n#### Link's\n[KNAPSAck]() 50'000+ structures and 100'000+ structure-organism pairs  \n[NAPRA-LERT dataset]() well documented database but not available for free  \n[NPAtlas]() specificly for microbial NPs.  \n[COCONUT]() COlleCtion of Open NatUral products (similar to LOTUS)  \n[natural products online](https://naturalproducts.net/) - Host for Lotus, Coconut ...  \n\n\n### [MINEs: open access databases of computationally predicted enzyme promiscuity products for untargeted metabolomics](https://doi.org/10.1186/s13321-015-0087-1)\n\nMINEs are an extension for metabolites database, which have been not observed, but very likely can occure. Based on the Biochemical Network Integrated Computational Explorer and enzyme reaction rules it will be calculated. The website is userfriendly and also available as an API: [https://minedatabase.mcs.anl.gov/#/home](https://minedatabase.mcs.anl.gov/#/home)\n\nThis database includes structures for use in untargeted metabolomics. This resulting compounds are rarely found in PubChem but are structurally similar to natural products.\n\nAs an input you can give an MS/MS file, structure, name.... As an output you will get information about the reaction, validated compounds...\n\n\n### [Molecular structure discovery for untargeted metabolomics using biotransformation rules and global molecular networking](https://doi.org/10.1101/2024.02.04.578795)\n\nA big part of the MS/MS spectras are unidentified (exp. GNPS/MassIVE). \nFor this problem they developed BAM (Biotransformation-based Annotation Method).\nIt has the potential to identified new molecules based on previously unknown MS/MS spectra.\nThe predictionrate for the right assignment is 24.x %.  \n\nBAM concist of three steps:\n\n1. determine an annotated anchor spectrum based on high spectral similarity.  \n\n2. Apply biotranformation rules that match the observed mass difference and generate candidate structures  \nThe rules are sourced from RetroRules, KEGG or Metacyc. Out of that, PROXIMALE 2 was employed.\n\n3. Rank the derivatives based on the likelihods of the applied biotransformation.\nGNN-SOM predicts the likelyhood of each atom in a molecule.\n\n\n#### Coding\n[Github - HassounLab](https://github.com/HassounLab/BAM)\nPROXIMAL2  \nGNN-SOM tool (graph neural network-based tool)\n\n\n### [Pickaxe...](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-023-05149-8)\n- prepackaged ruleset (JN1224min - metacyc) with UniProt IDs of enzyms\n- rules provided on Pickaxe do not utilize stereochemistry\n- RDKit: Cheminformatics program applies the SMARTS rules.\n- compounds and reactions can be filtered in the same run.\n\nFilters:\n\n- Similarity Filtering (Tanimoto):\n    Info: filters out the samples, which are not higher than the given similarity treshhold. Similarity is calculated with the Tanimoto distance of the targets and new made molecules.\n    Input:  \n        cutoff_fingerprint_method = \"Morgan\"\n        cutoff_similarity_method = \"Tanimoto\"\n        similarity_threshold = [0, 0.9]\n    Output:  \n\n- Similarity Sampling Filter:\n    Info: samples a specific amount of a given samplespace (made by the simlarity filter). The similarity filter has to be activated!!!\n    Input: \n        cutoff_fingerprint_method = \"Morgan\"\n        cutoff_similarity_method = \"Tanimoto\"\n        similarity_threshold = [0, 0.9]\n    Output: \n        n-samples\n\n- Metabolomics filter:\n    Input: list of experimental mass-to-charge (m/z), list of possible adducts\n    Output: compares the two lists by the m/z values and give back all compounds with a specific treshhold\n\n- Thermodynamic filter:\n    Info: eQuilator (module) biochemical thermodynamic calculator \n    Input: \n\n- Feasibility filter:\n    Info: DeepRFC (<https://​doi.​org/​10.​1002/​biot.​20200​0605>) DeepRFC utilizes substrate-product pairs within KEGG reactions to train a deep neural net to predict a reaction’s feasibility.\n\n![ distancemeters ](expanded-np-chemspace.distancemeters_chemical_moleculs.png)  \n*distancemeters <https://www.sciencedirect.com/science/article/pii/S1046202314002631?via%3Dihub>*\n\n### [A deep learning approach to evaluate the feasibility of enzymatic reactions generated by retrobiosynthesis](https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/10.1002/biot.202000605)\nenzymatic reactions generated by retrobiosynthesis\nDOI: 10.1002/biot.202000605\n\n### [RDP - Filter](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4920114/)\n10.1093/bioinformatics/btw096\n\n\n\n[[expanded_np_chemspace.abbreviations.md]]\n","n":0.038}}},{"i":539,"$":{"0":{"v":"Minedatabase","n":1},"1":{"v":"# minedatabase\nGithub: <https://doi.org/10.1186/s13321-015-0087-1>  \nDocumantation: <https://mine-database.readthedocs.io/en/develop/index.html>\n\n## general information\nThe minedatabase is build with rules and adducts. The main idea is to give some compounds and expand them with the given rules (generalized or intermediat). This result can be filtered with different filters or directly saved in a database (mongodb) or in a csv file. \n\nThe generalized rules are 1224 (JN1224min), which should expand the most out of it. This also showed some testruns from us.\nWe used different fractions of the generealized and indermediate rules and checked the amount of reactions and compounds of the output.  \n\n![compounds](assets/images/expanded-np-chemspace.information.minedatabase.20230506_compounds.png)\n![reaction](assets/images/expanded-np-chemspace.information.minedatabase.20230506_reactions.png)\n![rules](assets/images/expanded-np-chemspace.information.minedatabase.20230506_rules.png)\n![time](assets/images/expanded-np-chemspace.information.minedatabase.20230506_time.png)\n\nWhat we can conclude with the pictures above, that the time goes up with more reactions / compounds / rules. The generelized will produce at +- 0.7 more compounds, at +- 0.8 more reactions and at +- 0.8 more rules.\nThe time is a little bit difficult to interpret. But it seems like, that it's more independant of the reactions than of the compounds.  \nThe rules from the two sets share some rules between and others are different.\n\n![generalized vs. intermediat rules](assets/images/expanded-np-chemspace.information.minedatabase.Venn_generalized_vs_intermediat.png)\n\n\n### Tanimoto coefficient (Jaccard index)\nThe Jaccard coefficient measures similarity between finite sample sets, and is defined as the size of the intersection divided by the size of the union of the sample sets:\n\n![Calculation of Jaccard coefficient](assets/images/expanded-np-chemspace.information.minedatabase_tanimoto_formula.svg)\n\n![set theory explanation](assets/images/expanded-np-chemspace.information.minedatabase_set_theory.png)\n\n$$Tanimoto coefficient = Jaccard distance = 1 - Jaccard coefficient$$\n\n## filters\n### Tanimoto Threshold Filters\n\n\n### Tanimoto Sampling Filters\n\n\n### Metabolomics Filters\n\n\n## Rules\nSMIRKS = represent reactions in a string\n\n\n\n## ","n":0.065}}},{"i":540,"$":{"0":{"v":"Goals","n":1},"1":{"v":"- Generate a set of novel plausible chemical structure from the initial set of know NPs chemical structure found in LOTUS.\n- Generate in silico fragmentation spectra for the generated chemical structures.\n- Serve the generated chemical structure in a web portal using the MINES server as a backend.\n- Attribute plausible biological sources to the generated structures.\n- Explore the possibility of biochemical rules edition / curation.","n":0.125}}},{"i":541,"$":{"0":{"v":"Editor","n":1},"1":{"v":"Just accepted a review Editor role for Frontiers in Natural Products.\nHopefully not a mistake ...\n\nThe Review Editor: The primary role of the Review Editor is to provide an expert review of Frontiers articles in a rigorous, constructive and efficient manner. Frontiers acknowledges the role of the reviewer by naming the person to the Editorial Board and by publishing the name of the Review Editor on every published paper endorsed by him or her. This practice requires Frontiers to have processes in place to transparently deal with conflicts of interest, both real and perceived.\nFrontiers Review Editors should hold, as a minimum, either a PhD with post-doctoral experience, or an equivalent degree with several additional years of academic work, or the equivalent number of years to a recognized qualification in the relevant field of research. Review Editors should have a recognized affiliation and a proven publication record in their specialty area.\n\n\n","n":0.082}}},{"i":542,"$":{"0":{"v":"Duetz System","n":0.707},"1":{"v":"\n\n4 position clamp for deepwell MTPs\n- CR1700:\n\n    Secures up to 4 deepwell MTPs + covers\n    Fits various shaker platforms\n\n720 CHF\n\nLow-evaporation sandwich cover for 96-deepwell MTPs\n- CR1296a:\n\n    For all 96-deepwell MTPs\n    Holes with a 0.8mm diameter\n    Suitable for longer cultivations (4+ days, e.g. CHO-cells)\n    Exchange of headspace air: 0.3 ml / minute\n    Evaporation rate (30ºC, 50% humidity): 8 µl/well/day\n\n94*4 = 376 CHF\n\nPolypropylene square 96-deepwell microplates\n- CR1496:\n\n    Made from polypropylene (by HJ-bioanalytik)\n    Recommended culture volume: 0.5 ml\n    Autoclavable, reusable plate\n    Flattened and detoxified by Enzyscreen\n\n21*4 = 84 CHF\n\nTotal: 1180 CHF","n":0.107}}},{"i":543,"$":{"0":{"v":"Courses","n":1}}},{"i":544,"$":{"0":{"v":"Py_packages","n":1}}},{"i":545,"$":{"0":{"v":"courses-py_packages-polars","n":1},"1":{"v":"\n# Packages : Polars \nPolars is a fast and efficient data manipulation library for Python. It provides a DataFrame-like interface similar to Pandas, but with a focus on performance and memory efficiency.  \n\n<https://docs.pola.rs/>\n\n\n\n## useful functions\n\n*df*.shape - <https://docs.pola.rs/py-polars/html/reference/dataframe/api/polars.DataFrame.shape.html>\n\n## Keywords\n","n":0.162}}},{"i":546,"$":{"0":{"v":"Python and Packages","n":0.577},"1":{"v":"# Python\nTo get start with python is very easy. But to come back to a project and let it run again can hurt.\nThis should be a small introduction how to handle python environements.  \n\nIt is important for the following steps, to have now activated environments. For example if you using conda (you can see it in the terminal - (base) ), then you should deactivate it. Maybe in the past you had some troubles... It can be a good idea to clean the base in conda.\n\nConda deactivate:           `conda deactivate`  \nConda actiavate (base):     `conda activate`  \nConda clean (base):         `conda clean --all`  \n\nFor checking, which pyhton version is in use:   `which python`  \n\n## Python versions\nAs we all, also Python is developping. Some packages are developped for the newest python and a specific time\nbut not updated for the newest python versions. This can be a problem when you want to use this package, but you just installed the newest version.  \n\nThe solution is to use a virtual environment (for example [__conda__](https://anaconda.org/), [__pipenv__](https://pypi.org/project/pipenv/), ect.).  \n\nIn this case we will have a look for **pyenv** (the easier way to work with python versions).  \n\n### Pyenv\n\n#### Installation\nTo install [__pyenv__](https://github.com/pyenv/pyenv) you can use the automatic installer (tested with Ubuntu):  \n`curl https://pyenv.run | bash`  \n\nAfter that you have to add the following lines to your `vim ~/.bashrc` fileend:\n```bash\n#Pyenv loader\nexport PYENV_ROOT=\"$HOME/.pyenv\"\n[[ -d $PYENV_ROOT/bin ]] && export PATH=\"$PYENV_ROOT/bin:$PATH\"\neval \"$(pyenv init -)\"\n\n# Load pyenv-virtualenv automatically\neval \"$(pyenv virtualenv-init -)\"\n\n```   \n\nTo take this changes into effect you have to restart your terminal or run `source ~/.bashrc`. Now it is ready to go.\n\n\n#### Useful commands\n| **command**            \t| **description**                                                                                 \t|\n|---------------------------|-------------------------------------------------------------------------------------------------\t|\n| `pyenv install --list` \t| all possible python versions to install.                                                        \t|\n| `pyenv install <version>` | install the choosen <version> from --list. This can take a while...                             \t|\n|    `pyenv versions`    \t| shows all installed environments and the active one                                             \t|\n|         `pyenv`        \t| help site                                                                                       \t|\n|  `pyenv global <system>` \t| Don't use this, if you not sure what you are doing. We will use poetry for the python versions. \t|\n|  `pyenv local <system>` \t| If poetry can't find your version. Use this to load the rigth version and the use poetry.      \t|\n\n\n\n### Poetry\nPoetry takes care of the python versions and the packages. All this is handled in a single *.toml file.\nChanges can be done in this file, but mainly it is recommended to use the terminal.\n\n#### Installation\nPip is the package manager for python. For poetry it is recommended to install it with pipx, which takes care of the packages globaly.  \n1. Install [pipx](https://pipx.pypa.io/stable/installation/)\n```bash\nsudo apt update\nsudo apt install pipx\npipx ensurepath\n```\n\n2. install [poetry](https://python-poetry.org/docs/#installation)\n```bash\npipx install poetry\n```\n\n#### Useful commands\n| **command**                  \t   | **description**                                                    \t            |\n|----------------------------------|------------------------------------------------------------------------------------|\n|       `poetry install`       \t   | Takes the *.toml file and installs all the packages. Creates the poetry.lock file.\t|\n|         `poetry init`        \t   | This folder will set up to use a virtual environement with poetry. \t            |\n|  `poetry new <projectname>`  \t   | Makes the folder with the files in it.                             \t            |\n| `poetry add <pythonpackage>` \t   | Add a package to your project.                                     \t            |   \n|       `poetry update`       \t   | For added packages, it is recommended to update them after that.     \t            |\n| `poetry env use <pythonversion>` | Change python version.                            \t                                |\n|  `poetry run <python script.py>` | Run your code in poetry.                                            \t            |\n|        `poetry show`             | Poetry show packages from environment.                               \t            |\n                       \n\n\n\n`poetry install` is the same as `poetry update` if there's no *poetry.lock* file. It's only slightly more convenient to install directly from the *poetry.lock* file if you don't want to update dependencies. `poetry lock` creates a *poetry.lock* file, but does not install packages.\nIt can be useful in groupworks, that the poetry.lock stays \"unchanged\". So all collaborators are sure, it works with the defined packages.\n\n","n":0.04}}},{"i":547,"$":{"0":{"v":"courses-keyboardshortcuts","n":1},"1":{"v":"\n## General Shortcuts\n`CTRL + /`: Comment/uncomment line\n`CTRL + Shift + /`: Comment/uncomment a block of code\n`Tab` : Indent line (also multiple lines)\n`Shift + Tab` : Outdent line (also multiple lines)\n\n`CTRL + Z`: Undo (one step back)\n`CTRL + Y`: Redo (if \"Undo\" was made, one step forward)\n\n`CTRL + F`: Find\n`CTRL + H`: Replace\n`CTRL + G`: Go to line\n`CTRL + L`: Clear screen\n`CTRL + T`: New tab\n`CTRL + W`: Close tab\n`CTRL + D`: mark the current word \n\n\nGithub\nCTRL + K : search\n\n\nDendron\nCtrl + L : open new *.md file\n\nVisual Studio / Codium:\nCtrl + ` : open integrated terminal\nCtrl + Shift + C : open terminal outside editor\n\n","n":0.098}}},{"i":548,"$":{"0":{"v":"Documentation","n":1},"1":{"v":"\nDocumentation is an important step for all kind of projects.\nSpecially then, when you want to share it and used by the community.\nMostly the mayority of time is spend for coding and some small part for the documentation.\nTo make the documentation easier and less timeconsuming, some packages are developped.\n\n\n## Mkdocs\n[Mkdocs](https://www.mkdocs.org) is a tool for documentation.\nIt can build out of a markdown (*.md) file a website.\nGithub provides the possibility to add \"Actions\" (actions that would be run after a specific event) and also host this website.\n\n### Installation\nWe recommend to use Poetry for this task. Remember: the best practice would be using one environment for one project.\n```bash\n# basic installation\npoetry add mkdocs\n\n# for more material <https://squidfunk.github.io/mkdocs-material/>\npoetry add mkdocs-material\n```\n\nAlternativaly it can also be done with Pypi:\n```bash\n# basic installation\npip install mkdocs\n\n# for more material <https://squidfunk.github.io/mkdocs-material/>\npip install mkdocs-material\n```\n \n\n### Project layout\nIf you run the first time `mkdocs new <project_name>`, it will create new folders for the documentation and a config file (mkdocs.yml). \n\n    mkdocs.yml    # The configuration file.\n    docs/\n        index.md  # The documentation homepage.\n        ...       # Other markdown pages, images and other files.  \n\n### Configuration\nOpen the configuration file (mkdocs.yml) and customize it. This file has some basic functions, which can be very usefull.\nThis file was used in this project <https://commons-research.github.io/dataset-extractor-lotus/>.\n\n```yaml\nsite_name: Dataset Extractor for LOTUS  #websitename (name of project) \nsite_description: \"Python script to extract data from the LOTUS Database\" #description\nsite_url: https://commons-research.github.io/dataset-extractor-lotus/ #website to mkdocs (will be deployd after running 'mkdocs gh-deploy')\nsite_author: <your-name> #your name\nrepo_url: https://github.com/commons-research/dataset-extractor-lotus #Github repository\nrepo_name: GitHub - Dataset Extractor for LOTUS #name of repository\n\nnav: #links to the documentation files in the \"/docs\" folder.\n  - Home: index.md\n  - About: about.md\nnot_in_nav: #files, which shouldn't be published with mkdocs, but still in the repo.\ntheme: readthedocs #theme\nlanguage: en\n\ntheme: #advanced changes\n  name: material\n  features:\n    - navigation.tabs\n    - navigation.sections\n    - toc.integrate\n    - navigation.top\n    - search.suggest\n    - search.highlight\n    - content.tabs.link\n    - content.code.annotation\n    - content.code.copy\n  language: en\n  palette:\n    - scheme: default\n      toggle:\n        icon: material/toggle-switch-off-outline \n        name: Switch to dark mode\n      primary: teal\n      accent: purple \n    - scheme: slate \n      toggle:\n        icon: material/toggle-switch\n        name: Switch to light mode    \n      primary: teal\n      accent: lime\n\n\ncopyright: |\n  &copy; 2024 <a href=\"https://github.com/pamrein\"  target=\"_blank\" rel=\"noopener\"> YOUR-NAME </a>\n```\n\n### Commands\n* `mkdocs new [dir-name]` - Create a new project.\n* `mkdocs serve` - Start the live-reloading docs server.\n* `mkdocs build` - Build the documentation site.\n* `mkdocs -h` - Print help message and exit.\n* `mkdocs gh-deploy` - Deploy the documentation to GitHub pages and push it with the branch gh-pages.\n* `mkdocs gh-deploy --help` - Print help of gh-deploy\n\nThe easiest way to \"deploy\" the documentation is putting the required files in the **/docs** folder and configuring the **mkdocs.yml** file.\nWith the command `mkdocs gh-deploy` the documentation will be deployed and pushed to Github (uses the branch: gh-deploy). This can takes less than a minute. The website name you can find in the terminal output of this command or < username >.github.io/< repository >.\n\n\n### github - workflows \nFor even make it easier for the documentation, it's possible to do an [\"action\"](https://docs.github.com/en/actions/learn-github-actions/understanding-github-actions?learn=getting_started) on github.\nIt is a `/.github/workflows/*.yml` file, which will be run after a specific event.\nIn this case we will run the command `mkdocs gh-deploy` after a push to the main or master branch.  \n\nCreate the folders and file `/.github/workflows/mkdocs.yml` and put the following content in the file (**ci.yml**):\n```yaml\nname: ci-mkdocs\n\n#if pushed from master or main, this action will be triggered\non:\n  push:\n    branches:\n      - master \n      - main\npermissions:\n  contents: write\n\n#jobs to be executed\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Configure Git Credentials\n        run: |\n          git config user.name github-actions[bot]\n          git config user.email 41898282+github-actions[bot]@users.noreply.github.com\n      - uses: actions/setup-python@v5\n        with:\n          python-version: 3.x\n      - run: echo \"cache_id=$(date --utc '+%V')\" >> $GITHUB_ENV \n      - uses: actions/cache@v4\n        with:\n          key: mkdocs-material-${{ env.cache_id }}\n          path: .cache\n          restore-keys: |\n            mkdocs-material-\n      - run: pip install mkdocs-material\n      - run: pip install pillow cairosvg\n      - run: mkdocs gh-deploy --force\n```\nThe main part for this file comes from the following sourece: <https://squidfunk.github.io/mkdocs-material/publishing-your-site/?h=github#with-github-actions>.  \n\nNow, when you push your documentation with the main branch, it will be automaticaly deployed on github. You even don't have to run anymore `mkdocs gh-deploy`.\n\n","n":0.039}}},{"i":549,"$":{"0":{"v":"Docker Singularity","n":0.707},"1":{"v":" \nThursday 14 October 2021\n\nZoom meetings:\nThe lectures will be streamed on Zoom with the following link:\nhttps://us02web.zoom.us/j/87811184973?pwd=NFRpUzI4QWFQUks0OXJyalN0NS9tQT09\nMeeting ID: 878 1118 4973\nPasscode: 725487\n \nCourse website:\nYou can find the course materials web page in this link:\nhttps://sib-swiss.github.io/containers-introduction-training\n\nPlease make sure to have read the page with the technical requirements previous to the course.\n\nSlack workspace:\nWe will use a Slack workspace to work collaboratively. Please make sure to have connected to this space before the course starts.\n\nGoogle Doc:\nWe have also created a gdoc to simplify the exchanges of information with you during the lectures: Link Google doc. We suggest that you keep this document open during the course.\n\nLink Google doc https://urldefense.com/v3/__https://docs.google.com/document/d/1U-kMm559CtcYL9MB45ZHLmvtQmm_bBS7E8qzyEAD3WQ/edit*__;Iw!!Dc8iu7o!k0lSfOEHZG-2pQf5rv4qdjenqaHDJBiOOyMbCoar9ZIsGb91eeOCNB_VVCLYifckXHa1S58c$\n \n\n\n \n# Concepts\n\n## Image \n\nread-only\nstored on longer term \ncan be used as a base\n\n\n\n\n## Container \n\nbased on the image \nshort lived\nusually for minor adjustements \n\n(Apparently the delay in the suggestion mode should be enough to mange the annoying suggestions.\nAnother option would be to set up the acceptation key to somethinh other than automatic.)\n\n","n":0.08}}},{"i":550,"$":{"0":{"v":"Labbook","n":1},"1":{"v":"Exercice 1\n\ndocker run -it ubuntu\n\n\n\nroot@ed76dc41b28c:/# figlet 'SIB courses are great!'\n ____ ___ ____\n/ ___|_ _| __ )    ___ ___  _   _ _ __ ___  ___  ___    __ _ _ __ ___\n\\___ \\| ||  _ \\   / __/ _ \\| | | | '__/ __|/ _ \\/ __|  / _` | '__/ _ \\\n ___) | || |_) | | (_| (_) | |_| | |  \\__ \\  __/\\__ \\ | (_| | | |  __/\n|____/___|____/   \\___\\___/ \\__,_|_|  |___/\\___||___/  \\__,_|_|  \\___|\n\n                      _   _\n  __ _ _ __ ___  __ _| |_| |\n / _` | '__/ _ \\/ _` | __| |\n| (_| | | |  __/ (_| | |_|_|\n \\__, |_|  \\___|\\__,_|\\__(_)\n |___/\n\n\n \n\ndocker run \\\n-it \\\n--mount type=bind,source=/Users/pma/02_tmp/docker_share,target=/working_dir/ \\\nubuntu-figlet\n\n\ndocker run \\\n-it \\\n-u \"$(id -u):$(id -g)\" \\\n--mount type=bind,source=/Users/pma/02_tmp/docker_share,target=/working_dir/ \\\nubuntu-figlet\n\n\n\nfor the jupyter-lab docker\n\ndocker run \\\n-it \\\n--rm \\\n-p 8888:8888 \\\n--mount type=bind,source=/Users/pma/02_tmp/docker_share,target=/working_dir/ \\\njupyter-lab\n\nssh -i key_pallard.pem pallard@18.192.227.69\n\n\nsingularity pull docker://grndstt/ubuntu-figlet:v2\n\n### Piepline\n\nsnakemake\nnextflow\n\nboth support docker, conda and singularity\n\n\nconda + docker + snakemake \n\n![](/assets/images/2021-10-14-16-28-02.png)\n\n\nsnakemake --containerize\n\nhttps://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html?highlight=conda#containerization-of-conda-based-workflows\n","n":0.08}}},{"i":551,"$":{"0":{"v":"Database_mongo","n":1},"1":{"v":"# databases\nDatabases stores your data. Different solutions are available. Mostly we can here about **noSQL** and **SQL** (Structured Query Language) solutions. **RDBMS** (RDBMS stands for Relational Database Management System) is the basis for all modern database systems based on SQL. The data in RDBMS is stored in database objects called tables. This objects can be accessed with querys.\n\nMongoDB is a document database. It stores data in a type of JSON format called BSON (no tables). It is more flexible, scalable and faster then the RDBMS approach. \n\nThe website (datanyze))[https://www.datanyze.com/market-share/databases--272] showed, that mainly SQL databases has a big market share. The biggest market share with 24.78% has MySQL. MongoDB is on place 6 with 6.19%. [March 2024]\n\n\n## mongodb\nMongoDB is a source-available, cross-platform, document-oriented database program. Classified as a NoSQL database product, MongoDB utilizes JSON-like documents with optional schemas. The initial release was in February 2009. [Source Wikipedia](https://en.wikipedia.org/wiki/MongoDB)\n\nInstead of using querys (like in SQL), they are using CRUD operations.\n\nThis database is used by the [minesdatabase](https://github.com/tyo-nu/MINE-Database).\n\n\n### Intallation (with Ubuntu)\n[Installation of mongodb](https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-ubuntu/#std-label-install-mdb-community-ubuntu)\n\nAfter the installation, the service has to be started.\n\n```bash\n# start service\nsudo systemctl start mongod\n\n# check status\nsudo systemctl status mongod\n\n# if problems accurese, try this\nsudo systemctl daemon-reload\n\n# stop service\nsudo systemctl stop mongod\n```\n\n### mongo shell (CLI)\nTo have a look at the databases use the mongo shell `mongosh`. To use it, the mongod service needs to be running.\nThe MongoDB Shell uses a Node REPL environment. This means that we are able to use JavaScript variable declaration, function declaration, and loops.\n\n```sh\n# start CLI\nmongosh\n\n# show all databases\nshow dbs\n\n# change to database\nuse <db_name>\n\n# show the headers of the database\nshow collections\nshow tables\n\n# find specific coloumns (like Json search)\ndb.<collection_name>.find()\n\n# look at help page\ndb.help\n\n# change store location (default /var/lib/mongodb)\n# it can be changed also in the config file (/etc/mongod.conf)\nmongod --dbpath </path/to/store>\n\n```\n\n### mongo compass (GUI)\nIf the shell is to complicated, it is recommended to use the GUI **mongo compass**. \nIt has the usefull function to show all the entries in one table.\n\nInstallation: <https://www.mongodb.com/docs/compass/master/install/>\n\n### mongo university (learning area)\nMore informations about mongo db can be found here: [Mongo University](https://learn.mongodb.com/learning-paths/introduction-to-mongodb)\n\n\n#### mongodb commands\nsearch: \n`db.sales.find({ <field>: { <operator> : <value> } })`\nexample: `db.sales.find({ \"items.price\": { $gt: 50}})`\n\nfield:  \n$elemMatch - find this element in value\n\n\noperator:  \n$eq - equal  \n$gt - greater than\n$gte - greater than or equal to\n$lt - less than\n$lte - less than or equal to\n$ne - not equal\n\n\ndb.sales.find({\n  items: {\n    $elemMatch: { name: \"laptop\", price: { $gt: 800 }, quantity: { $gte: 1 } },\n  },\n})\n\n","n":0.05}}},{"i":552,"$":{"0":{"v":"Copier","n":1},"1":{"v":"\n\nhttps://copier.readthedocs.io/en/stable/\n\nA MAPP copier template is at https://github.com/mapp-metabolomics-unit/mapp-repo-copier-template.git\n\n```bash\ncopier copy https://github.com/mapp-metabolomics-unit/mapp-repo-copier-template.git ./test-copier-repo\n```\n\nTo copy the template of a MAPP repo\n\n```bash\ncopier copy --trust gh:mapp-metabolomics-unit/mapp-repo-copier-template ~/git_repos/mapp-metabolomics-unit/name-of-group\n```","n":0.218}}},{"i":553,"$":{"0":{"v":"Complexity","n":1}}},{"i":554,"$":{"0":{"v":"Pharmacognosy","n":1},"1":{"v":"\nhttp://www.saber.ula.ve/bitstream/handle/123456789/41035/articulo7.pdf?sequence=1&isAllowed=y\n\n","n":1}}},{"i":555,"$":{"0":{"v":"Click","n":1},"1":{"v":"\n\nhttps://click.palletsprojects.com/en/8.1.x/testing/","n":1}}},{"i":556,"$":{"0":{"v":"Cfm","n":1},"1":{"v":"installing cfm on server mapp\n\nThursday 14 October 2021\n\nSee instructions here https://bitbucket.org/wishartlab/cfm-id-code/src/master/cfm/INSTALL.md\n\n\ntar -zxvf RDKit_2017_09_3.tgz\ncd ../..\nmkdir build\ncd build\ncmake .. \\\n    -DRDK_PGSQL_STATIC=OFF\\\n    -DRDK_BUILD_PYTHON_WRAPPERS=OFF\\\n    -DRDK_BUILD_CPP_TESTS=OFF\\\n    -DRDK_BUILD_DESCRIPTORS3D=OFF\\\n    -DRDK_INSTALL_STATIC_LIBS=OFF\\\n    -DRDK_INSTALL_INTREE=OFF\\\n    -DRDK_BUILD_INCHI_SUPPORT=ON\\\n    -DRDK_OPTIMIZE_NATIVE=ON\\\n    -DCMAKE_CXX_STANDARD=11\\\n    -DCMAKE_BUILD_TYPE=Release\nmake install\n\n\n\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH::~/Programs/rdkit-Release_2017_09_3/lib:~/Programs/lp_solve_5.5/lpsolve55/bin/ux64\n\n\nbeware no spaces across equal sign\n\n\n\ncmake  ..  \n    -DINCLUDE_TESTS=${BUILD_CFM_TEST}\\\n    -DINCLUDE_TRAIN=${BUILD_CFM_TRAIN}\\\n    -DLPSOLVE_INCLUDE_DIR=/usr/local/include/lp_solve\\\n    -DLPSOLVE_LIBRARY_DIR=/usr/local/lib\\\n    -DRDKIT_INCLUDE_DIR=/usr/local/include/rdkit\\\n    -DRDKIT_INCLUDE_EXT_DIR=/usr/local/include/rdkit/External\\\n    -DRDKIT_LIBRARY_DIR=/usr/local/lib\\\n    -DCMAKE_CXX_STANDARD=11;\\\n\n\n\ncmake  .. \\\n    -DINCLUDE_TESTS=${BUILD_CFM_TEST}\\\n    -DINCLUDE_TRAIN=${BUILD_CFM_TRAIN}\\\n    -DLPSOLVE_INCLUDE_DIR=/home/allardpm/Programs/lp_solve_5.5\\\n    -DLPSOLVE_LIBRARY_DIR=/home/allardpm/Programs/lp_solve_5.5/lpsolve55/bin/ux64\\\n    -DRDKIT_INCLUDE_DIR=/home/allardpm/Programs/rdkit-Release_2017_09_3/Code\\\n    -DRDKIT_INCLUDE_EXT_DIR=/home/allardpm/Programs/rdkit-Release_2017_09_3/External\\\n    -DRDKIT_LIBRARY_DIR=/home/allardpm/Programs/rdkit-Release_2017_09_3/lib\\\n    -DCMAKE_CXX_STANDARD=11;\\\n\n\ncmake  .. \\\n    -DLPSOLVE_INCLUDE_DIR=/home/allardpm/Programs/lp_solve_5.5 \\\n    -DLPSOLVE_LIBRARY_DIR=/home/allardpm/Programs/lp_solve_5.5/lpsolve55/bin/ux64 \\\n    -DRDKIT_INCLUDE_DIR=/home/allardpm/Programs/rdkit-Release_2017_09_3 \\\n    -DRDKIT_INCLUDE_EXT_DIR=/home/allardpm/Programs/rdkit-Release_2017_09_3/External \\\n    -DRDKIT_LIBRARY_DIR=/home/allardpm/Programs/rdkit-Release_2017_09_3/lib \\\n    -DCMAKE_CXX_STANDARD=11; \\\n\n\n\n    export RDBASE=~/Programs/rdkit-Release_2017_09_3/\n\n\n    CMake Error: The following variables are used in this project, but they are set to NOTFOUND.\nPlease set them or make sure they are set and tested correctly in the CMake files:\nINCHI_LIB (ADVANCED)\n    linked by target \"cfm-code\" in directory /home/allardpm/Programs/cfm-id-code/cfm/cfm-code\nRDINCHI_LIB (ADVANCED)\n    linked by target \"cfm-code\" in directory /home/allardpm/Programs/cfm-id-code/cfm/cfm-code\n\n\n/usr/local/include/rdkit/\n\n\ncmake  .. \\\n    -DINCLUDE_TESTS=${BUILD_CFM_TEST}\\\n    -DINCLUDE_TRAIN=${BUILD_CFM_TRAIN}\\\n    -DLPSOLVE_INCLUDE_DIR=/home/allardpm/Programs/lp_solve_5.5\\\n    -DLPSOLVE_LIBRARY_DIR=/home/allardpm/Programs/lp_solve_5.5/lpsolve55/bin/ux64\\\n    -DRDKIT_INCLUDE_DIR=/usr/local/include/rdkit\\\n    -DRDKIT_INCLUDE_EXT_DIR=/usr/local/include/rdkit/External\\\n    -DRDKIT_LIBRARY_DIR=/usr/local/lib\\\n    -DCMAKE_CXX_STANDARD=11;\\\n","n":0.088}}},{"i":557,"$":{"0":{"v":"Canopus","n":1}}},{"i":558,"$":{"0":{"v":"Logbook","n":1},"1":{"v":"\nfollowing http://localhost:8888/notebooks/Tutorial.ipynb\n\n(installed cli on laptop but too slow)\nworking on commons_server\n\nMassive files can be fetched with \n\n`wget -r ftp://massive.ucsd.edu/MSV000080553/peak/Rosumarinus`\n\n\n\n\n","n":0.236}}},{"i":559,"$":{"0":{"v":"Blogs","n":1},"1":{"v":"\nhttps://simonwillison.net/\n\n","n":1}}},{"i":560,"$":{"0":{"v":"Bioregistry","n":1},"1":{"v":"\nhttps://fosstodon.org/@bioregistry/114309093687157895\n\nThe summary of our workshop lead by @cthoyt and Ben Gyori at #biocuration2025 is now live at https://biopragmatics.github.io/workshops/biocuration2025.html\n\n📖 Slides: https://doi.org/10.5281/zenodo.15184414\n\n📺 Recording: https://www.youtube.com/watch?v=jmWfbH-TtkE\n\nthanks to @biocurator and the conference organizers!","n":0.189}}},{"i":561,"$":{"0":{"v":"Best Practices","n":0.707},"1":{"v":"\nHave a look at http://berkeleybop.github.io/best_practice/\n\n\nThis is the best practice / house style guide for the BBOP group. Inspired by / cribbed from Knocean practice and other sources.\n\nSource: berkeleybop/berkeleybop.github.io/blob/master/best_practice\n\nWe are a diverse group working on many different projects with different stakeholders and sets of collaborators. Nevertheless we strive to follow a set of core best practices so we can be most efficient and develop the highest quality code, ontologies, standards, schemas, and analyses.\n\nThis document may be overwhelming at first but as you become more familiar with projects it should become second nature. If there is anything you don’t understand, ask on slack!\n\nGit and GitHub\nuse git ubiquitously\ncommit early, commit often\nperfect later!\nyou should always be working on a branch, so don’t worry about breaking things\nmake a PR for your branch - mark as draft if not ready\nMake repos public by default\nUse standard repo layouts\nchoose a cookiecutter\nmonarch-project-template for code-oriented projects\ndon’t reinvent\nlook at exemplars\nInclude standard files:\nREADME.md\nLICENSE (BSD3 or Apache preferred for software)\nCONTRIBUTING.md\nCODE_OF_CONDUCT.md (see for example kgx CoC\nChanges.md\n.gitignore\nMakefile or equivalent\nsee below for more specific recommendations for specific kinds of repos\nuse GitHub\nLike GitLab in principle, but GitHub has network effect\nprefer to work on the main repo, not forks, but defer to project-specific guidelines\nRead our GitHub Overview\nUse GitHub issues\nin general you should always be working to a ticket assigned to you\ntry to assign every issue to somebody\ntry to have a single assignee / responsible person\ntag people if necessary\nnote: if you tag me with @cmungall it’s likely I won’t see it. alert me to a ticket via slack if I am required\nuse GitHub’s default labels: bug, question, enhancement, good first issue, etc.\nset up standard issue templates (helps ensure tickets are auto-assigned)\nWhen creating issues:\ngive a meaningful issue title\nword title as a bug, e.g. “under condition X, Y fails” or a request, e.g. “add option A to method B”\ngive issue actionable descriptions, make it clear when an issue can be closed\nsee Seth’s suggestions for creating awesome issues\nuse GitHub Pull Requests\nread the obook PR review guide\nmark as draft until ready for review, then assign reviewers\ndescription should link to an issue (“Resolves #1234”) to automatically close issue when PR is merged\notherwise you have to clean up issues manually\nupdate description as needed\nalways look over your commits before making a PR\nare there unexpected changes? You should only see YOUR changes\nIs it adding files unexpectedly? Some git clients are eager to do this\nare some changes not recognizable as yours? Be careful not to clobber\nfollow repo-standard practice for rebase etc\nAVOID:\nmaking PRs too large\nmixing orthogonal concerns in one PR. Generally 1 PR = 1 issue\nmixing in formatting changes on sections of the code unrelated to the semantic changes you are making\nworking on a PR for too long a time without feedback from others\nworking on “invisible” branches. ALWAYS make a PR, ALWAYS push. You can mark as draft!\ngive PRs a meaningful title and description\nremember: titles will be used when auto-making release notes\nuse GitHub Milestones to plan releases\nuse GitHub Releases to tag versions and attach binaries\nuse semver (except for ontologies)\nuse the auto-generate release notes feature\ncorollary: write informative PR titles and never commit on main\nif making a non-patch release, select the previous minor/major to diff from\nuse GitHub Pages for simple static content and documentation\nprefer the docs/ directory option\nSee exemplars: OAK, Biolink Model\nuse GitHub Projects (“project boards”) for coordinating issues and PRs\nthree columns:\nTo do: for manager to fill and prioritize\nIn progress: for developer to keep up-to-date\nReady for review: for manager to empty\norder of preference for cards: PR link, issue link, text\nset up GitHub actions to do CI\nMigrate if you are on an old travis repo\nAll changes should be on PRs thus validated\nmain branch should never ever be failing\nEVERY repo should have actions and PR checking\nset up GitHub teams\ndefault to public membership\nmake sure it is clear who has permission to merge PRs\nset up badges\nalways: CI\npypi, downloads, codecov, zenodo, …\nConfigure the “About” (see gear icon on right)\nuse standard topics\nbiolink\nlinkml\nobofoundry\nmonarchinitiative\ngeneontology\nOrgs\ndefine a standard topic (see above)\ninclude a .github\nexamplar: github.com/linkml\npin repos\nmake sure all relevant artefacts are checked in\nuse git status and .gitignore\nin general avoid checking in derived products (but see below)\navoid checking in .xslx files (use TSVs; or consider cogs instead)\nversioning\ndo not check in files with version numbers e.g. foo.v1.txt into GitHub - git does versioning for you\nuse the GitHub release mechanism\nuse ISO-8601 or semver schemes (see guidelines on specific repo types below)\ntend your repos\nremove cruft such as obsolete files (GitHub preserves history)\navoid random stuff at top level\nkeep README in sync\navoid using spaces in filenames\nalways use standard suffixes (e.g. .tsv, .txt, .md)\nkabob-case-is-a-good-default.txt. See filenames in google developer guide\nDon’t rename files and commit - use “git mv” instead, so that the history of the file is preserved\nuse topics and “star” relevant repos\nhttps://github.com/topics/linkml\nhttps://github.com/topics/obofoundry\nhttps://github.com/topics/geneontology\nhttps://github.com/topics/monarchinitiative\nalways star your own repos\nstar your colleagues and collaborator’s repos\ntips\nthe gh github cli client is very useful, e.g. gh pr Software:\nNico recommends gh Desktop\nCode-centric Repos\nUse an existing repo from a group member as template for best practice, e.g.,\nkgx\nlinkml\nOAK\nOr better: monarch project cookiecutter\nInclude a README.md\nprovide sufficient context\ndon’t boil the ocean - put reference material in a separate reference guide\ninclude examples and use examples as tests\nCreate reference documentation using RTD/Sphinx\nlet inline docstrings in Python do most of the work for you\nread writethedocs\nInclude installation instructions\nuse an OSI approved LICENSE, BSD3 preferred\nUse unit tests\nconsult others on framework\nUse GitHub-integrated CI\nformerly Travis\nuse GitHub actions\nRelease code to PyPI or appropriate repo\nuse GitHub releases\nuse GitHub actions to trigger releases to PyPI\nuse GitHub actions to trigger releases to PyPI\nsee nmdc-schema as exemplar\nmake release notes automatically see github guide\nrelies on using PRs with well-described titles\nalways have multiple owners of a pypi package on the pypi site\nuse standard semver, start from 0.1.0, move to 1.0.0 when stable\nConsider a Dockerfile\nFor ETL repos, follow standard templates for\nkg-hub\nkoza\nFor ETL repos\nUse Jenkins pipelines\nBadges\nCI\nCode coverage\nPyPI\nTODO: ADD MORE\nSchema/Standards-centric Repos, Data and metadata repos\nUse LinkML\nCreate repo from LinkML template\nExamples:\nNMDC\nMIxS\nGFF3 linkml\nchemkg/chemrof\nRegister with w3id.org\nInclude comprehensive examples\nUse LinkML mkdocs framework\nUnderstand the difference between OWL-centric and KG-centric modeling\ninclude mappings to Biolink Model\nalways include examples\nintegrate these with documentation\nintegrate these with unit tests\nalso include counter-examples\ndata deliberately designed to fail validation\ncheck validation correctly identifiers these in github actions\nenable zenodo syncing\nFor repos that have data:\nconsider a dashboard (see semantic dashbaord patterns)\nOntology-centric Repos\nUse ODK seed\nRegister ontology with OBO if appropriate\ninclude detailed metadata\ninclude all products\ninclude descriptive material in markdown\nExceptions:\napplication ontologies\nontologies that deliberately not OBO-esque\nRegister non OBOs with Bioportal + w3id\nUse GitHub for .owl distribution unless ontology is large, then consider:\nGitHub releases\nS3\nSee Nico’s application ontology tutorial\nFollow group exemplars: Uberon, Mondo, GO, ENVO, CL, PATO, BERO, PhenIO\nbut be aware each has their quirks\ndistribute useful products\ndistribute SSSOM\nalways distribute an .obo\nalways distribute a obo .json\ndistribute a kgx file (NEW)\ndistribute a rdftab/semsql sqlite file (NEW)\nuse a sensible source format (foo-edit.owl)\n.obo is best for diffs but less expressive and gotchas for CURIEs\nfunctional syntax is often preferred\nfor template-based ontologies, much of the source may be TSVs\nenable zenodo syncing\nUnderstand issues relating to git conflicts with ontologies\n.obo as source mitigates some of these\nSee this thread\nSee this post\nmany issues have since been resolved but unfortunately some remain\nAnalysis/Paper-centric Repos\nOne repo per paper\nEntire analysis must be reproducible via Makefile\nAll steps:\ndownload\nclean/pre-process\ntransform\ntraining\nevaluation\ncheck with Chris before using snakemake/CWL/alternatives\nUse TSVs as default\nmake pandas-friendly\nuse unix newline characters, not dos\nuse human readable but computationally friendly column headers\nNO ALL CAPS\nalphanumeric characters preferred\nspaces or underscores as word separators OK, but underscores preferred for formal formats\ncsvkit is your friend\nALL TSVs MUST have data dictionaries\nuse LinkML (see above)\ncheck in small-mid size data files (<10m)\nconsider cogs if TSVs must be managed in google sheets\nuse JSON for complex data\nuse KGX for anything that should be modeled as a KG\nuse descriptive filenames\nmanage metadata in GitHub\nenable zenodo syncing\nuse S3 for larger files\nrelease files to Zenodo\nDockerize\nUse Jupyter notebooks\nConsider Manubot\nOther recommended best practices\ndatadryad\nDevelopment Environment Setup\nCode Editors:\nvscode\npycharm\nget professional, we will pay\nGitHub copilot can be purchased as well, and is an excellent addition to a pycharm environment.\nKeyboard Shortcuts\nCommand palette: Cmd/Ctrl + Shift + P\nSearch for file in project: Cmd/Ctrl + P\nOpen integrated terminal in VSCode: Cmd/Ctrl + ~\nOpen settings page: Cmd/Ctrl + ,\nSet up custom keymap bindings\nMac\nCode > Preferences > Keyboard Shortcuts > +`\nType in the key combination you want to use and assign it to an action of your choice\nFor ex., Cmd/Ctrl + i as a shortcut for selecting the Python interpreter\nEssentials\nGit configuration\nSet username: git config --global user.name \"YOUR_USERNAME\"\nSet password: git config --global user.email \"YOUR_EMAIL@EXAMPLE.COM\"\nWorkspace setup\nMake sure you have correctly selected the Python interpreter\nSave workspace in order to open a specific view of the project directory\nFile > Save Workspace As\nFile > Open Workspace From File\nUseful Extensions\nPython\nPython IntelliSense\nLinting\nDebugging\nCode navigation\nFormatting\nRefactoring\nAutoDocstring\nDocstring for Python methods\nblack\nOpinionated Python code formatter\nGitLens\nVisualize code authorship\nBetter Comments\nHuman friendly comments\nRainbow CSV\nHighlight columns in csv and tsv files\nTransforms and filtering using querying language\nMarkdown All in One\nKeyboard shortcuts\nTable of contents\nAuto preview\nPrettier\nFormatting YAML, JSON\nBut primarily an opinionated formatter for frontend web code like JS, TS, etc.\nYAML\nYAML validation\nAuto completion\nHover support\nUseful while writing LinkML schemas\nvs-code-icons\nBeautiful icons\nAustin VS Code\nCode profiler\nCan be used when trying to optimize Python codebase\nSimple Websites\nGitHub pages favored over google sites over wikis\nManage and author content as markdown, managed in github, with PRs as for code\nGoogle Analytics\nExample GA 4 conversion and walkthrough info at https://github.com/berkeleybop/bbops/issues/28#issuecomment-1712154894\navoid manually authoring anything that can be derived from metadata\nexamplars: obofoundry.github.io, this site\nuse CC-BY 4.0 or the CC0 public domain declaration\nExamplars:\nLinkML splash page\nPhenopackets splash page\nCell Ontology splash page\nDocumentation\nSee google guide on Writing inclusive documentation\nAvoid ableist language\nAvoid unnecessarily gendered language\nAvoid unnecessarily violent language\nall code, schemas, analyses, ontologies, MUST be documented\ndocumentation is a love-letter to your future self\nunderstand the Diataxis four-way distinction: tutorial, how-to, reference, explanation\nexemplar: OBOOK\nexemplar: LinkML docs\ngoogle API documentation guide\nhave strategies to avoid staleness and documentation getting out of sync\nuse inline documentation\npublish via appropriate framework (RTD for code, mkdocs for schema, etc)\nfollow appropriate style guide\nuse and test docstring in python\nhttps://docs.python.org/3/library/doctest.html\nexamples, examples, examples\nfenced examples in markdown docs\nexample standalone scripts\nexample Jupyter notebooks\ndouble up: unit tests can serve as examples and vice versa\nSee linkml-run-examples framework\nUse existing templates\nmonarch-project-template for code-oriented projects\nlinkml cookiecutter for schema projects\nODK for ontology projects\nkghub template for KG projects\nuse Markdown as default\nRST for Sphinx/Code projects\nGoogle docs acceptable for initial brainstorming\nDon’t use Wikis (mediawiki, GitHub wiki)\nManage markdown docs as version control\npublish as static site (RTD, mkdocs, etc)\nCoding/Python\nPython is the default language; use others as appropriate\njavascript/typescript for client-side\ndon’t implement domain/business logic in js. use python + APIs\nuse typescript\ngenerate typescript datamodels using linkml gen-typescript\nRust for speed\nshould always have PyO3 wrappers\nfollow semsimian GH actions for wheels\nScala for performance reasoners or anything requiring owlapi\nHistorically we used Java for anything requiring OWLAPI but being phased out\nWhy Python?\nubiquitous, cross-platform\ngood for scripting, interactive development\nstrong ecosystem of libraries for almost anything\nEasy for developers to pick up\nMost bioinformaticians know it\nuse for anything more than about 10 lines of Bash/Perl\nuse Python 3.8+\nEnsure github actions tests 3.9, 3.11\nConform to the group style guide, or at least some style guide\npep-0008 for Python\nuse type annotations PEP484\ngoogle style guide\nWe are inspired by knocean/practices/python but differ in some places\nWe make use of OO as appropriate - just don’t go overboard like in java\nFollow conventional variable naming\nExample: https://docs.fast.ai/dev/abbr.html\nSee the Working with Python Environments guide for details on installing Python versions and managing virtual environments.\nAll repos should use poetry\nSet up this way: poetry new --src my-project-name\nOR use linkml-ws new for schema-centric repos\nfollow standard layouts, with code in src/\nLinting/formatting:\nUse black and flake8 and ruff\nTest Runners\nTo automate building and testing distributions in multiple Python versions\ntox\nDE FACTO: Github hosted runner via Github Actions\nCLI development\nclick\nTesting\nunittest\nDE FACTO: pytest\nTest coverage\nCoverage.py\ncodecov\ndocument all public classes, methods, functions\nAlways Use type annotations\nAlways provide docstrings\nReST (reStructuredText) » numpy-style docstrings or google style » nothing\nSOME standard is always better than none\nBe sure to set up your IDE for automatic docstring generation\nuse flask/fastAPI for web apps\nNEVER author OpenAPI directly; ALWAYS derive\nwe are exploring GraphQL frameworks like strawberry.rocks\nuse dataclasses or pydantic\nfor DAOs, ALWAYS derive from linkml\navoid authoring data models directly in python\nlist comprehensions » lambdas\nuse fstrings; never write java-style python\nALWAYS use typing\nmakes code more understandable\nallows code completion in PyCharm etc\nhelps find bugs\nuse an IDE\nPyCharm or VS is equally popular in the group\nETL/ingest\nfollow existing exemplar repos\nRead Chris’ 10 simple rules for semantic ETL\nuse requests for URL calls\nAlways provide a CLI\nseparate CLI logic from core logic\nRead CLIG guidelines\nSee also [Documenting command-line syntax ]https://developers.google.com/style/code-syntax) in google style guide\nPython: use click\ndesign for composability\nprovide shortforms for common options\nDisplay help text when passed no options, the -h flag, or the –help flag\nuse de-facto standards\n-i, --input\n-o, --output\n-h, --help\nalways use dashes as separators, NOT underscores\nclick will make corresponding python vars with underscores\nFollow exemplars\nROBOT\nSSSOM\nOAK\nlinkml\nAlways write unittests for CLIs\nsee OAK for examples\nProfiling:\ncProfile and SnakeViz are useful for profiling Python code ```bash\nGenerate the profile results:\npython -m cProfile -o output.prof my_program.py\n\nView them:\npipx run snakeviz output.prof ```\n\nExamplars:\nsssom-py\nlinkml\nOAK\nLearning resources\nCharlie’s Recommended Python Programming Videos\nOBOOK - Open Biological and Biomedical Ontologies Organized Knowledge\nWeb APIs\nAuthoring\nFastAPI » Flask\nSeperate business logic from API code\nthis should be independently testable\nTesting\nuse fastapi.testclient\nfollow GO exemplar\nAccessing\nUse python requests library (unless a higher level lib is available)\nDo not construct URL strings yourself - use params instead\nfor non-trivial tasks consider building a reusable client library\nuse a client library if it already exists!\nexamplars: OAK bioportal implementation\nwhen querying a sparql endpoint\nsparqlfun > sparqlwrapper > requests > curl\nif constructing sparql is necessary\nuse a query builder rather than string manipulation\nShell\nProgramming\nbash/sh\nPersonal\nUse ohmyz\nDatabase Engines\nCurrent preferred stack\nsqlite or postgres (normalized/write)\nsolr (denormalized/read)\nthat’s it\nBUT: use whatever is appropriate for the job\nblazegraph/joseki for ttl\nneo4j for KGs\nPostgresql for SQL db server\nnever use non-open SQL db solutions\nSome legacy apps may use MySQL but Pg is preferred\nsqlite for lightweight tabular\nmongo for docs\navoid vendor lock-in\nuse generic sparql 1.1 API vs triplestore specific APIs\nsolr for searchable / denormalized / analytics\nalways use golr patterns\nread semantic columnar store patterns\nalways have a schema no matter what the task\nalways author in LinkML\ntranslate to SQL schema, JSON-Schema, Solr schema etc\nfamiliarize yourself with the tools to do this\nSQL vs other DB engines\nthis is an evolving area\nsee Knocean SQL guide\nLLMs\nontogpt\ncurategpt\nFor command line usage and direct Python usage:\nhttps://llm.datasette.io/en/stable/\nalso follow Simon’s blog for practical guides to LLMs for engineers:\nhttps://simonwillison.net/\ncode assistance\nmany of us use copilot + vscode/pycharm; see onboarding for how to charge\ngpt-4 works better for de-novo\nOpenAI accounts\nsee onboarding doc on how to get added to Mungall group account\nHandy developer and command line tools\nrunoak\nGNU Make – see Knocean guide\ncogs\nodk\nq – query TSVs via SQL\ncsvkit\njq/yq\nrobot\nbash; small scripts only\npandoc\nDocker\neditor of your choice\nProgramming Libraries\nData science\nthis is a fast changing field so recommendations here are general/loose\ngenerally prefer Python » R » other languages for data sciences\nwe frequently use tensorflow, scikitlearn, keras\nscikit-learn\ncatboost, xgboost\npandas\nTSV » CSV\nparquet or sqlite for large files\nuse # for header comments\nalways have a data dictionary in LinkML\nalways be working in a github repo (see below)\nnotebooks:\nseaborn for plotting\nUse notebooks for:\ngenerating figs for paper\nexploration\nNEVER use notebooks for\ncore logic (extract into separate lib with tests)\nETL\nanything that should be run in a pipeline\nall notebooks MUST be reproducible\ncheck small files into github\nreproducible Makefile or snakemake for obtaining other files\nideally test all notebooks via gh-actions\nKGs\nkgx\nBMT\nEnsmallenGraph, (Rust + Python bindings), fast graph ML\nEmbiggen graph ML (e.g. node2vec), and some other things like word2vec\nNEAT is a Python wrapper for reproducible graph ML in a YAML-driven way\nalso exploring pykeen ampligraph\nFollow FAIR in a meaningful way\ndata dictionaries with LinkML\nfollow identifier best practice\nOntologies\nRead the OAK guide\nUse OAK for everything\nontobio is deprecated for non-GO specific tasks\nOWLAPI (JVM) – only where absolutely necessary\nbeware of using rdflib and RDF-level libraries for working with OWL files, too low level (and slow)\naccess Ubergraph through OAK\naccess semsql through OAK\nobographviz (js)\nnever, ever use XML parsers to parse RDF/XML\ndon’t every write a new obo format parser\nobographs json direct access sometimes OK\nNER/NLP\nRead Harry’s awesome caufieldjh/awesome-bioie list\nfast changing but some tools to consider:\nontorunNER (which wraps OGER)\nBERT for language models (experimental)\nNote we are now wrapping more of this functionality in OAK\nnow subsumed by LLMs\njoin the monarch nlp slack channel\nShell commands\nsh > subprocess\nFile formats, languages, and standards\nGeneral\nTSVs for columnar data\nalways have a data dictionary (use LinkML)\nmake it pandas-friendly\nmeaningful column names\nSSSOM is an exemplar\nunderstand TidyData and Codd’s normal forms and when to use them\nhand-author YAML over JSON (+ follow schema)\nUse JSON-LD / YAML-LD as appropriate\nunderstand JSON-LD contexts\nget context for free with LinkML\nTurtle for some purposes\nRDF/XML as default for OWL\nOntologies\nUse OAK to access everything\nOWL\nOBO JSON\nconsider obo format deprecated. Exception: easier to maintain edit file as obo for git diff/PR purposes\nCOB as upper ontology, but also pay attention to biolink\nAlways use official PURLs for downloads\nthe OBO page gives the list of products. E.g. obofoundry.org/ontology/pato\nMappings (ontology or otherwise)\nSSSOM with skos predicates\nCookiecutters for starting a new project.\nGeneral-purpose projects using monarch-project-template\nLinkML based projects using linkml-project-cookiecutter\nOntology Access Kit (oaklib) plugin projects using `oakx-plugin-cookiecutter\nKGs\nbiolink\nkgx » rdf* » rdf\nmake available as:\nRDF dump\nNeo4J dump\nsparql endpoint (consider putting into larger endpoint and segregating with NGs)\nneo4j endpoint\nKGX dump\nKGX summary stats\nSchemas\neverything must have a schema, including:\nall TSVs should have data dictionary\nJSON/YAML\nKGs\nOWL ontologies and OWL instance graphs\nUnderstand basic concepts:\nnormalized vs de-normalized\nidentifiers and URIs\nclosed-world vs open-world\nschema vs ontology\nAlways author schemas in linkml\nderive alternate representations (e.g. json-schema)\nJSON-schema for JSON-centric projects (never author, always derive from LinkML)\nShEx or SHACL for ontology-centric (try and derive from LinkML)\nDon’t use kwalify any more\nAlways have a LinkML schema even when using:\npython dicts\nopen-ended JSON/YAML\nRDF\nNeo4J\nad-hoc TSVs\nInclude mappings:\nmap to biolink\nVersioning\nSemantic Versioning (semver) by default\nsoftware MUST use semver\nschemas SHOULD use semver, but OBO-style may sometimes be appropriate\nISO-8601 OBO style for OBO ontologies\nuse GitHub releases for versioning as appropriate\nalways use the autofill feature to make release notes and to name releases\nfor software follow the group github-action best practice to auto-release to pypi\nrelease versions to appropriate repository/archive\nCompression\nuse .gz instead of .zip\nif compressing multiple files in an archive, use .tar.gz, not .zip\nRememeber compressed files are not diffable in git\nFor very large files consider distributing gz files via S3 or zenodo rather than in GitHub\nremember: if a repo has 10 x 50m files that change every release, the repo will be 10g in size in 20 releases\nAs a general rule of thumb, think very carefully before committing files > 1m to github\nexceptions for existing best practice e.g. odk\nask if unsure\nText\nmarkdown by default\nfrontmatter metadata where appropriate\ntrack in version control\nuse .rst for sphinx sites where autodoc features are needed\ndon’t use wikis or github wikis except where precedent is set\nAPIs\nRESTfulness\ntrue REST may be too high a barrier\nRPC-style (i.e. swagger/openAPI) may be fine\nAll web APIs should have OpenAPI exploration interface\nderive OpenAPI from Python code\nfastapi > flask »> others\nconsidering GraphQL\nMust have Docker container\nDeprecated: Use grlc or sparqlfun to make APIs from sparql endpoints\nCURIEs and IRIs\nRead McMurry et al.\nPrefixmaps (a Python library for retrieving semantic prefix maps) is now our source of truth for all things prefix/namespace related\nTake the time to read ALL docs on bioregistry.io\nalways use CURIEs for IDs\nCURIEs + prefixmap » URIs »» ad-hoc\nalways use prefixes registered in bioregistry.io\nunderstand at a broad level the different registries:\nhttp://identifiers.org\nhttp://n2t.net – synced(?) with identifiers.org but broader context\nhttp://bioregistry.io/\nhas a lot of advantages over id.org: more transparent, github metadata based, lightweight\nhttps://github.com/prefixcommons/biocontext\nwe developed this as an “overlay” on existing registries\nhave an explicit JSON-LD context or prefixes yaml file\nUse the prefixcommons curie util library\nRead the identifiers guides closely, even for projects you are not on\nTranslator SRI/biolink identifiers\nIdentifiers in NMDC\nIdentifiers in GO\nGenomics\nGFF3\nSO\nAnnotation\nGAF\nGPAD\nPhenopackets\nDates\nuse ISO-8601\nuse ISO-8601\nuse ISO-8601\nuse ISO-8601\nnever, ever write a date in non-ISO-8601\nPortability\nit should be easy for anyone to install from any of our repos\neverything should run on macos or linux\nprovide a Docker image for anything complex\nuse standard installation idioms\nKey specialized libraries and command line tools\nOAK, for ontologies\nkgx\nODK and ROBOT, for ontologies\nontorunNER for NER\nBuilding Ontologies\nontologies are for users, not ontologists\nOWL and description logic is necessary for building robust ontologies, but needn’t be exposed\nMinimize philosophy\navoid unnecessary abstractions\nontologies should have annotations\nannotations, as in the sense used by curators\nontologies without annotations are generally of limited use, avoid working on them\nlearn tools and best practice for robust ontology engineering\nRead Onto-Tips\nUse and understand ODK\nUse ROBOT\nTake the OBO Academy training\nwork on the components on your own\nattend the Monarch tutorials\nuse the ontologies we work on as examplars\nGO\nUberon\nMondo\nPhenotype Ontologies\nENVO\nRO\nCL\nfollow OBO best practice and principles\nontologies should be open\nif OBO is underspecified, follow the examples of projects done in this group\nNEW: see ontology-metadata in OAK\noio » IAO\nliberal axiom annotations\nkey annotation properties: synonyms, definitions, mappings\nSee documentation on uberon synonyms, this is an exemplar for us\nProgrammatic generation\nlinkml-owl\ndosdp OR robot template\nalways use the more appropriate tool for the job\ninclude comprehensive definitions clear to biologists\nread definitions guide\nunderstand compositional patterns\navoid overmodeling\nDocument ontologies\ndocument design decisions\nwrite clear operational definitions\ndocument your design patterns\nWatch design pattern presentation\nDOSDP repo\nMondo is our exemplar\nunderstand limitations\nuse ontologies only where appropriate\nvocabularies\ndescriptors\ndon’t use an ontology where a schema is more appropriate\ndon’t use an ontology where a KG is more appropriate. See KG vs ontology DPs\nmake best effort attempt to provide mappings\nuse SSSOM\nuse boomer\nuse oak lexmatch\nCollaboration\nwe are a collaborative group, reach out if you have issues\njoin relevant channels on bbop and other Slack workspaces\nquestions always welcome but make best effort to see if information available in group reference guides\ndon’t struggle alone!\nothers are likely to either have similar questions/frustrations to you, or will have faced them in the past\nquestions are always welcome but always check standard sources first\nfor programming questions, search Stack Overflow\nfor questions regarding group or collaborator tools, is it in the FAQ?\nmake it easy for people to help you\nbe concise, yet provide sufficient relevant context\nmake it actionable\nDiscouraged: X doesn’t work\nEncouraged: when I do A, I get result B, but I expect C\ncreate issues with concise, actionable titles\nyour problem should be reproducible as far as possible\nideally contribute a a test case following idioms of appropriate repo (learn how to do this)\nmake things easier for those who follow you\nthe same questions often come up repeatedly\nif someone answers a question for you, update the relevant guide (FAQ etc) to make it clearer for others\nupvote answers on Stack Overflow you find useful\ngive thumbs up to helpful comments\nstar repos you find useful\nfollow codes of conduct\nbe constructive in any criticism\nuse your Berkeley Lab account for email, calendars\nkeep your calendar up to date, this facilitates scheduling meetings\nSlack\navoid @channel unless necessary\ndiscussion about tickets OK but decisions and key points must be recorded in ticket\nuse GitHub for requests\nUse GitHub for requesting terms from ontologies etc\nData mapping guide: selecting and requesting terms from ontologies, data models, and standards\nGoogle docs/slides/sheets hygiene\nRead Julie’s awesome intro to Google Drive\nRead [Data Organization in Spreadsheets for Ecologists](https://datacarpentry.org/spreadsheet-ecology-lesson/ from datacarpentry\nRead Data Organization in Spreadsheets by Bronan and Woo\nbe consistent\nwrite dates like YYYY-MM-DD\nput just one thing in a cell\nno not merge cells\norganize the data as a single rectangle (with subjects as rows and variables as columns, and with a single header row)\ncreate a data dictionary\ndo not include calculations in the raw data files\ndo not use font color or highlighting as data\nchoose good names for things\nmake backups\nuse data validation to avoid data entry errors\nsave the data in plain text files\nUse google docs/slides over Microsoft/Apple/Desktop\nbut sometimes markdown+git is more appropriate than either\nfor grants, papers, and other collaborative documents, move to Word at last possible minute (if at all)\npandocs can be used to make markdown\navoid latex/beamer unless it is really called for\nUse tagging/comments/modes appropriately\nIf it’s not your doc, default to Suggesting mode\nuse your judgment; minor direct edits to correct typos usually OK\nrespect conventions of document owner\nuse comment feature to make comments, don’t write your comment in a different color\navoid use of text color as semantics\nassign/tag people appropriately\navoid comment wars\nMake the doc outline-mode-friendly\nuse H1/H2/etc. for headers (don’t just style normal text)\nalways have outline mode on (list-like icon near top left)\nassume the reader has outline mode on\nrarely need for a TOC\nFor google sheets / excel\nnever manually color code or use font/strikethrough. Always add an explicit field and use conditional formatting\nalways have a schema, even if it is a flat data dictionary. linkml-model-enrichment will derived one\nfavour TSV+github over google sheets\nworkflows clearly favor sheets\nwhen using sheets, use cogs\nfollow TSV guidelines for google sheets\nUse formatted templates where appropriate (grants, papers)\nUse Paperpile for citations / reference management (you have access via the Lab)\nGive documents meaningful names (e.g., not just “meeting”)–assume that most people will find the doc via search rather than by going through the folder hierarchy\ndon’t use camelcase or underscores in google doc names, it hinders search\norganize google docs in the relevant folder depending on what project is funding the work\nunderstand how navigation works for google docs\nmake docs and folders viewable by all by default, unless sensitive\ninclude links to slides of general relevance from project repos\nreuse slides from existing slide decks, but provide attribution\nTips\nsearch operators\nBest practices for meetings\nSee Best practices for writing a good meeting reminder\nUse a rolling agenda/notes doc, rather than one doc per meeting\nmost recent first\nISO-8601 » human readable dates » anything else\nThe auto @today feature is useful\nalways have a google doc for every meeting you are in\nrecord decisions\ninclude a link to the rolling doc in calendar invites\ninclude the Zoom / videoconference link in the rolling notes doc\nDevOps\n12 factor app\nGeneral Principles\nDRY: Don’t Repeat Yourself\nbut avoid over-abstraction and frameworkitis\nvarious 10 simple guides:\n10 simple rules of quick and dirty scientific programming\nAlways reuse\nwe probably have a Python library for it\nreuse general design patterns\nGitHub templates\nfollow exemplar repos\nkgx and linkml for general python\nkg-covid-19 for ETL\ntry especially hard not to reinvent what someone in the group or our collaborator has done\nAvoid perfectionism\niterate on solutions\nsmaller batches of incremental progress » long delays on perfect solution (that may turn out to be flawed)\nFor many tasks, the 80/20 rule may suffice\nDon’t boil the ocean\nbeware of rabbit holes\nMore to come…\n","n":0.016}}},{"i":562,"$":{"0":{"v":"Awk","n":1},"1":{"v":"\n# Sirius outputs formatting\n\nThese commands require to have [awk](https://en.wikipedia.org/wiki/AWK#:~:text=AWK%20(awk)%20is%20a%20domain,data%20extraction%20and%20reporting%20tool.) and [csvcut](https://csvkit.readthedocs.io/en/latest/scripts/csvcut.html) installed on your system.\n\n\nThe code processes a file named canopus_compound_summary.tsv. It searches for a field called \"id\" in the file's header. If found, it splits the values in that field by underscores and adds a new column called \"feature_id\". It then modifies the header by appending \"_canopus\" to each field name and prints the modified header. After that, it extracts specific columns and saves the extracted data. Finally, the extracted data is formatted as tab-delimited and saved in a file called canopus_compound_summary_id.tsv.\n\n\n`awk 'BEGIN{FS=\"\\t\"; OFS=\"\\t\"} NR==1{for(i=1;i<=NF;i++){if($i==\"id\"){split_field_index=i;break}} if(split_field_index==0){print\"Field not found: field_name_to_split\">\"/dev/stderr\";exit 1}print $0,\"feature_id\";next}{split($split_field_index,arr,\"_\");print $0,arr[length(arr)]}' canopus_compound_summary.tsv | awk 'BEGIN {FS=OFS=\"\\t\"} NR==1 {for (i=1; i<=NF; i++) $i = $i \"_canopus\"} {print}' | csvcut -t -c \"feature_id_canopus,id_canopus,molecularFormula_canopus,adduct_canopus,NPC#pathway_canopus,NPC#superclass_canopus,NPC#class_canopus\" | csvformat -T > canopus_compound_summary_id.tsv`\n\n\nThe code processes a file named compound_identifications.tsv. It searches for a field called \"id\" in the file's header. If found, it splits the values in that field by underscores and adds a new column called \"feature_id\". It then modifies the header by appending \"_sirius\" to each field name and prints the modified header. After that, it extracts specific columns and saves the extracted data. Finally, the extracted data is formatted as tab-delimited and saved in a file called compound_identifications_id.tsv.\n\n\n`awk 'BEGIN{FS=\"\\t\"; OFS=\"\\t\"} NR==1{for(i=1;i<=NF;i++){if($i==\"id\"){split_field_index=i;break}} if(split_field_index==0){print\"Field not found: field_name_to_split\">\"/dev/stderr\";exit 1}print $0,\"feature_id\";next}{split($split_field_index,arr,\"_\");print $0,arr[length(arr)]}' compound_identifications.tsv | awk 'BEGIN {FS=OFS=\"\\t\"} NR==1 {for (i=1; i<=NF; i++) $i = $i \"_sirius\"} {print}' | csvcut -t -c \"feature_id_sirius,id_sirius,molecularFormula_sirius,adduct_sirius,InChIkey2D_sirius,InChI_sirius,name_sirius,smiles_sirius,xlogp_sirius,ionMass_sirius\" | csvformat -T > compound_identifications_id.tsv`\n\nSame with score\n\n`awk 'BEGIN{FS=\"\\t\"; OFS=\"\\t\"} NR==1{for(i=1;i<=NF;i++){if($i==\"id\"){split_field_index=i;break}} if(split_field_index==0){print\"Field not found: field_name_to_split\">\"/dev/stderr\";exit 1}print $0,\"feature_id\";next}{split($split_field_index,arr,\"_\");print $0,arr[length(arr)]}' compound_identifications.tsv | awk 'BEGIN {FS=OFS=\"\\t\"} NR==1 {for (i=1; i<=NF; i++) $i = $i \"_sirius\"} {print}' | csvcut -t -c \"feature_id_sirius,id_sirius,ConfidenceScore_sirius,CSI:FingerIDScore_sirius,ZodiacScore_sirius,SiriusScore_sirius,molecularFormula_sirius,adduct_sirius,InChIkey2D_sirius,InChI_sirius,name_sirius,smiles_sirius,xlogp_sirius,ionMass_sirius\" | csvformat -T > compound_identifications_id.tsv`\n\n\nTo add suffix/prefix\n\nThis will suffix\n`awk -F'\\t' 'BEGIN {OFS=\"\\t\"} NR==1 {for (i=1; i<=NF; i++) $i = $i \"_suffix\"} {print}' input.tsv > output.tsv`\n\nThis will prefix\n`awk -F'\\t' 'BEGIN {OFS=\"\\t\"} NR==1 {for (i=1; i<=NF; i++) $i = \"prefix_\" $i} {print}' input.tsv > output.tsv`\n\n\nCSV to TSV conversion \n\nawk -v OFS='\\t' '{ $1=$1; print }' input.csv > output.tsv\n\n\n","n":0.055}}},{"i":563,"$":{"0":{"v":"RO","n":1}}},{"i":564,"$":{"0":{"v":"R","n":1},"1":{"v":"\n\n## Peak into a dataframe\n\nhttps://dplyr.tidyverse.org/reference/glimpse.html\nglimpse(df)\n\n","n":0.447}}},{"i":565,"$":{"0":{"v":"Crosstalk","n":1},"1":{"v":"\nhttps://logarithmic.net/langevitour/articles/crosstalk.html\n\n\nhttps://emilyriederer.github.io/demo-crosstalk/tutorial/tutorial-rmd.html\n\n\nhttps://stackoverflow.com/questions/73390527/make-selection-of-plotly-appear-in-a-datatable-flexdashboard","n":1}}},{"i":566,"$":{"0":{"v":"Bachelor-project-jade","n":1},"1":{"v":"<p align=\"left\">\n  <img src=\"https://upload.wikimedia.org/wikipedia/commons/9/9c/Universit%C3%A4t_Freiburg_%28Schweiz%29_logo.svg\" width=\"100\">\n</p>\n\n<p align=\"center\"><strong>UNIVERSITY OF FRIBOURG</strong></p>\n<p align=\"center\"><strong>COMMONS LAB</strong></p>\n<p align=\"center\"><strong>DEPARTMENT OF BIOLOGY</strong></p>\n\n<br><br>\n\n<h1 align=\"center\">\nGeophytes collection, comparison of extraction solvents  \nand modeling of data loss in mass spectrometry\n</h1>\n\n<br><br>\n\n<em>Author :</em> <strong style=\"color:#800000\">Jade Dandois</strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<em>Supervisor :</em> <strong style=\"color:#800000\">Dr. Pierre–Marie Allard</strong>\n\n<br><br>\n\n<p align=\"center\"><strong>Submitted in fulfillment of the requirements for the Bachelor's degree.</strong></p>\n<p align=\"center\"><strong>June 27th, 2025</strong></p>\n\n# Acknowledgements \n\nI would like to extend my heartfelt thanks to Pierre-Marie Allard, my supervisor during these three months of academic work. I am deeply grateful for his unwavering dedication, his genuine interest in this remarkable project, and the invaluable guidance he has provided throughout. I hold great admiration for both his work and the inspiring project he initiated and continues to nurture with such commitment.\n\nThank you to the entire COMMONS LAB team. My warm thanks go to Héloïse Coen, who greatly supported me during the collection of geophytes and extraction processes—your help and our shared moments of collaboration were truly appreciated. Edouard Brülhart, thank you for patiently introducing me to the sampling techniques and the functioning of the laboratory. Colin Volet, for your guidance with the technical aspects of mass spectrometry, your expertise was essential. And finally, Marco Visani, for your remarkable patience and guidance in bioinformatics—thanks to you, I was able to significantly deepen my understanding of coding, an invaluable tool for the work I was entrusted with.\n\n# Abstract \n\nAt a time when the molecular diversity and metabolomic references of living organisms remain largely under-characterized—despite being essential for understanding biodiversity and developing conservation strategies grounded in molecular evidence—existing databases are often fragmented, focused on model organisms or biomedical applications, and poorly suited to large-scale interdisciplinary and ecosystem-level integration. In this context, open initiatives such as LOTUS have emerged, aiming to reference, standardize, and interlink molecule–organism pairs via Wikidata, thereby making chemical knowledge of life more accessible, interoperable, and reusable. Aligned with this vision, the Earth Metabolome Initiative (EMI) sets out to map the entirety of Earth’s metabolome by generating molecular profiles for every known species. My Bachelor’s thesis contributes to this effort through three complementary axis: (1) the collection and metabolomic profiling of geophyte species from the Botanical Garden of Fribourg, as part of the Digital Botanical Gardens pilot initiative; (2) the evaluation of alternative extraction solvents, notably DMSO, to improve compatibility with downstream biological assays; and (3) the modeling of analytical data loss in mass spectrometry using a “fake extract” composed of reference metabolites. \nBy improving some of the key elements of existing workflows and, through the “false extract” project, laying the foundations for anticipating analytical losses in mass spectrometry, this work has helped to initiate a more accurate representation of the chemistry of natural extracts, as well as improving the reuse of extracts for the discovery of new bioactive compounds.\n\n# Introduction \n\nA large number of databases are currently available to the public for biological elements such as proteins (UniProt, https://www.uniprot.org), RNA (Rfam, https://rfam.org/), DNA (NCBI GenBank, https://www.ncbi.nlm.nih.gov/genbank/) or genomes (Ensembl, https://www.ensembl.org/). \n\nHowever, some of the databases currently available for metabolomics remain quite limited , focusing mainly on specific types of organism, such as humans (HMDB, https://www.hmdb.ca), for medical purposes and centered on known metabolites, or simply on raw analytical data (MassBank, https://massbank.eu/MassBank/). Another accessible database in metabolomics is the Global Natural Products Social Molecular Networking ([GNPS](https://gnps.ucsd.edu/ProteoSAFe/static/gnps-splash.jsp?redirect=auth)), a collaborative platform for the processing and analysis of mass spectrometry data. GNPS includes both known metabolites and unknown metabolomic profiles. <sup><a href=\"#ref1\" id=\"note1\">1</a></sup>\n\nNatural products (NPs), defined as any chemical entity found in a living organism, are the focus of the open, interoperable, and interdisciplinary database [LOTUS](https://lotus.naturalproducts.net/), which is continuously expanding. To meet the goals of an open-source project for the research, storage, and sharing of data on natural products and their source organisms, the data are centralized on [Wikidata](https://www.wikidata.org/wiki/Wikidata:Main_Page). LOTUS serves as a reference resource, comprising over 750,000 referenced structure-organism pairs, standardized at the chemical (structure), biological (organism), and bibliographic (reference) levels. The project is fully aligned with open science principles and adheres to the FAIR guidelines (Findable, Accessible, Interoperable, Reusable) to promote data reuse and integration by the scientific community. <sup><a href=\"#ref2\" id=\"note2\">2</a></sup>\n\nThe [Earth Metabolome Initiative](https://www.earthmetabolome.org/) (EMI) consortium, conceived in 2022 and formally launched in 2024 by Pierre-Marie Allard and Emmanuel Defossez, is a collective open science endeavor aimed at addressing the critical lack of comprehensive metabolomic data for the species of our planet. The initiative set out to build a knowledge graph designed to gather the full spectrum of metabolites across all known living species—approximately 2.3 million—thus encompassing the entirety of life, from microbes to mammals, within an integrated and ecosystem-level perspective. Unlike existing databases, EMI stands out for its clear ambition to cover the full diversity of life across all kingdoms on a global scale. It focuses on the analysis of unknown metabolomic profiles from Earth’s organisms, while aiming to address gaps observed in existing resources such as GNPS, Massbank or HMDB. In particular, EMI sets itself apart by explicitly recovering detailed metadata associated with the profiled organisms—an aspect that remains a notable limitation in GNPS.<sup><a href=\"#ref3\" id=\"note3\">3</a></sup>\n\n## Earth Metabolome Initiative \n\nAs mentioned above, the EMI consortium is an open science initiative with a global scope, whose aim is to draw up metabolomic profiles of all known species on this planet, with 3 main objectives, which are the protection of biodiversity, the benefit to human society and a deeper understanding of the chemical foundations of the biosphere. <sup><a href=\"#ref3\" id=\"note3\">3</a></sup>\n\nBiodiversity is currently facing an unprecedented crisis, primarily driven by the intensification of human activities over the past century. This decline has accelerated dramatically in recent decades. Alarmingly, the current rate of species extinction is estimated to be at least 100 times higher than the natural background rate, underscoring the severity of human impact on the planet's ecosystems. <sup><a href=\"#ref4\" id=\"note4\">4</a></sup> \nIn this context, acquiring comprehensive metabolic data becomes critically important. Such data can provide molecular-level insights into ecosystem functioning and the roles of natural products within them. By deepening our understanding of molecular diversity and its ecological relevance, we can develop informed strategies for conserving biodiversity and sustaining the natural resources upon which human well-being depends.\n\nEstablishing a comprehensive, publicly accessible database of species-specific metabolomic profiles is of paramount importance for advancing research across generations. Such a resource will provide open access to molecular-level data, facilitating a wide spectrum of scientific inquiry—from fundamental biological and biomedical research to the discovery of novel bioactive compounds and innovations in agri-food systems. By enabling a deeper understanding of natural metabolites that underpin ecosystem dynamics, nutritional quality, and agricultural resilience, this database will serve as a critical foundation for interdisciplinary efforts aimed at sustaining both human health and environmental integrity.\n\nThe establishment of a global metabolomic map by the Earth Metabolome Initiative (EMI) will also enable the integration of existing biological datasets with newly generated molecular data. This will facilitate the development of novel insights, such as evolutionary models of the metabolome, and may even allow for the prediction of the chemistry of yet-undiscovered organisms by identifying specific natural product patterns linked to molecular and ecological contexts.\n\nThis project is highly ambitious, and although a significant amount of data has already been collected, the establishment of a global metabolomic database is likely to take decades to fully materialize. For this reason, several pilot projects have been initiated to test data acquisition methodologies and to focus on specific components of the broader initiative, avoiding unnecessary dispersion.\n\nThree of these EMI pilot projects formed the core of my bachelor's thesis and were specifically designed to address key objectives of the Earth Metabolome Initiative.\n\n* The first project falls within the scope of the [Digital Botanical Gardens Initiative](https://www.dbgi.org), a botanical-scale precursor to EMI, in which I participated by collecting samples from the geophyte section of the Fribourg Botanical Garden.\n* The second project aimed to refine our extraction methods by comparing the currently used methanol-based solvent with dimethyl sulfoxide (DMSO), thereby improving the biocompatibility of our extracts for subsequent bioassays.\n* The third project is part of the PhD research of Marco Visani and focuses on modeling molecular data loss in mass spectrometry, with the goal of predicting the chemistry of living organisms based on unknown natural extracts, aligned with [EMI](https://www.earthmetabolome.org/) and [LOTUS](https://lotus.naturalproducts.net/) objectives. \n\n## Digital Botanical Gardens Initiative \n\nThe Earth Metabolome Initiative (EMI) is a globally oriented project, and as such, required the development of a pilot version—a scaled-down implementation designed to be applied to nearby, easily accessible, and manipulable living organisms. The Digital Botanical Gardens Initiative was conceived precisely with this objective in mind. \n\nThe initiative aims to digitize the chemical diversity of Swiss botanical gardens by creating extract libraries, analyzing them via mass spectrometry, and organizing the data into accessible, interoperable knowledge systems. It also seeks to develop scalable workflows and provide molecular insights to support biodiversity conservation and open science. \nThese aspects of DGBI are fundamental for ensuring reproducibility of laboratory processes and facilitating automatisation, both of which are critical for the large-scale EMI project, which will handle millions of samples.\n\nSwiss botanical gardens offer several key advantages for this pilot, foremost among them the remarkable diversity of plant species they host, as well as the ease of sampling. \n\nThe [Fribourg Botanical Garden](http://www.unifr.ch/jardin-botanique/fr/), on which I focused my fieldwork, cultivates and conserves approximately 5,000 species, providing a rich and well-documented resource for metabolomic studies. Its location on the University of Fribourg campus is particularly advantageous, offering immediate proximity to laboratories for subsequent analytical work. Moreover, the plants are especially suited for experimental research: they are stationary, easily accessible, available in sufficient quantity for sampling, and can be revisited repeatedly for collections from the same individuals or specific locations when necessary.\n\nWhile the plants are cultivated rather than growing in their natural habitats—an aspect that may slightly influence their metabolic profiles—the primary objective here is not ecological fidelity, but rather the establishment of a solid reference framework. The garden setting provides an ideal platform for testing physical and bioinformatic tools involved in building a curated chemical library, and for evaluating the feasibility of a large-scale digitization project.\n\n# Collection of Geophytes - Digital Botanical Gardens Initiative \n\nThe current data from the Botanical Garden of the University of Fribourg record 1,679 collected plant species (42.7%), 1,250 species extracted beyond the core collection (31.8%), and 691 species for which metabolomic profiles have been generated (17.6%) https://emi-collection.unifr.ch/. While the garden conserves approximately 5,000 individual plants, these represent around 4,000 distinct species, as some are present in multiple specimens.\n\nThe harvest from the geophyte section proved particularly relevant, as this sector had not yet been covered by DGBI. Moreover, collecting additional data from this group contributed meaningfully to the advancement of the project.\n\nGeophytes are perennial plants that exhibit resilience to both severe drought and extreme cold, primarily due to nutrient reserves stored in their underground organs (tubers, bulbs, rhizomes). These reserves enable them to enter a dormant state and persist in the soil until environmental conditions become favorable for growth. <sup><a href=\"#ref5\" id=\"note5\">5</a></sup>\n\n![Map Botanical Garden Fribourg](/bachelor_project_jade/E31D72E1-F056-4554-A0E7-D976B920E21E_1_105_c.jpeg)\n*Figure 1 – Map of Fribourg botanical garden. The location of the geophyte sector is indicated by point number 10*\n\nSeveral plant families were collected, including Amaryllidaceae, Liliaceae, Iridaceae and many others, enabling metabolomic patterns to be drawn up for these families, and for all geophyte-type plants.\n\nWith the help of Héloïse Coen, 185 samples were collected (including leaves and flowers samples) from 150 species. 128 species remain to be collected (46%), meaning that a substantial portion of the target species has already been covered for this part of the project. \n\nBelow are the respective lists of samples collected by myself and Héloïse Coen, as well as the complete list of species in the geophyte section of the Fribourg Botanical Garden. \n* [Geophytes collected by Jade Dandois](https://github.com/jade147/jade_bachelor_work_repo/blob/a4491cbe601b38fbaab3b5437008505f01ea06e1/field_data_trimmed.csv)\n* [Geophytes collected by Heloïse Coen](https://github.com/jade147/jade_bachelor_work_repo/blob/fe70e103e4634caacbb3a798a4f7b7fe4c3beaef/Field_Data%2020250618-12257.csv)\n* [Complete list of geophytes](https://github.com/jade147/jade_bachelor_work_repo/blob/fe70e103e4634caacbb3a798a4f7b7fe4c3beaef/geophytes_extrait.csv)\n\nTo cover this sector, a dedicated protocol for sample collection, extraction, and analysis was required.\n\n## Materials and methods\n\n### Collection \n\nThe [standard DBGI sampling protocol](https://www.dbgi.org/dendron-dbgi/notes/i6scy8dy7a9appqdqvxas6j/) was followed throughout the collection process. Leaf or flower tissues were directly sampled from the target individual. Each specimen was placed in a coffee filter paper, inserted into a pre-labelled Falcon tube, and immediately flash-frozen in liquid nitrogen at -196 °C. Samples remained in liquid nitrogen until the end of the field session, after which they were stored at -80 °C pending lyophilization.\n\nEach Falcon tube was pre-labelled with a unique QR code that links the sample to its associated metadata, selected via the QField application (https://qfield.org). For every collected sample, a georeferenced point was recorded on the QField map, accompanied by key identification data including precise location, taxon name, sample ID (matching the QR code), and a set of at least five descriptive photographs: (1) the species identification label, (2) the labelled Falcon tube next to the identification label, (3) a general view of the plant, (4) a close-up of key morphological features, and (5) a photo of the cutting site with the scalpel in place.\n\nThe QR code–linked identification key plays a critical role, providing a unique identifier for each sample and enabling efficient tracking of its metadata across all steps of the workflow—from collection to extraction and analysis. At each successive stage, the same QR code is transferred onto the resulting tube, with newly generated metadata—such as extracted weight, number of extractions, or storage container—systematically appended to the sample’s record.\n\n### Extraction\n\nSamples retrieved from the freezer were placed in a freeze-dryer for 72 hours. After lyophilization, they were transferred into Falcon tubes sealed with non-perforated caps. A mass of 50 milligrams of dried sample was weighed out, allowing for a tolerance of ±5% (±2.5 milligrams), and placed into 2 milliliters round-bottom Eppendorf tubes. Three 4 mm stainless steel beads were added to each tube to facilitate grinding of the extract. The remaining material was returned to its original Falcon tube and stored in a labeled container.\n\nThe weighed samples were ground using a Retsch shaker for 2.5 minutes at 25 Hz. Subsequently, 1.5 milliliters of the DGBI extraction solvent—composed of 80% methanol, 20% distilled water, and 0.1% formic acid—was added to each powdered sample. The tubes were shaken again in the Retsch machine under the same conditions (2.5 minutes at 25 Hz). Following this, the samples were centrifuged for 2 minutes at 13,000 RPM to separate the supernatant from residual plant debris. The supernatant was carefully collected and transferred into labeled vials (2 milliliters) equipped with hermetically sealed caps. These vials were then stored in labeled containers and kept at –80°C until further analysis.\n\n### Aliquoting and analysis in mass spectrometry \n\nFrom the previously prepared vials, 120 microlitres of liquid extract were transferred into new vials equipped with inserts to create aliquots. The vials were carefully sealed using slipped caps. The resulting aliquots were then subjected to liquid chromatography–mass spectrometry (LC-MS), and the spectra were analyzed using appropriate tools and software (further details are provided in the subsequent sections of the project).\n\n### Untargeted mass spectrometry \n\nUntargeted mass spectrometry was used, as we did not know the contents of the extract in advance. Therefore, no specific molecules were targeted. The aim was to analyze as many compounds as possible in the extract and recover as much data as possible.\n\nSamples were first analyzed using High-Performance Liquid Chromatography (HPLC), which separates components based on their polarity and hydrophobicity, employing a non-polar stationary phase and a polar mobile phase. The separated molecules then undergo ionization via electrospray ionization (ESI) in either positive or negative mode, before being detected by an Orbitrap mass spectrometer, offering high mass resolution and accuracy. All molecules are initially detected in MS1, followed by data-dependent acquisition (DDA) where the most intense ions are fragmented in MS2 to generate fragmentation spectra for molecular identification.<sup><a href=\"#ref6\" id=\"note6\">6</a></sup>\n\n![alt text](bachelor_project_jade/8C3C38C9-A936-43D3-BBB6-FE08B5C6EFF8_4_5005_c.jpeg)\n\n*Figure 2 : Schematic representation of the sample analysis workflow using mass spectrometry.*\n*The process includes separation via High-Performance Liquid Chromatography (HPLC), ionization and detection using an Orbitrap high-resolution mass analyzer, followed by Data-Dependent Acquisition (DDA) for MS/MS fragmentation. The diagram was created using MZmine, with parameters configured through the integrated mWizard assistant.* \n\n### Inaturalist \n\nPhotographs associated with each collected species, taken during the field collection process, are uploaded to the iNaturalist platform (https://www.inaturalist.org/). This allows the iNaturalist community—including taxonomic experts—to verify species identities based on detailed images, and provides an opportunity to revise any incorrect or incomplete identifications. In turn, the community also benefits from these data, contributing to the ongoing expansion of the iNaturalist database. [The following map delineates the geographic range corresponding to the geolocated geophyte observations recorded on iNaturalist.](https://www.inaturalist.org/observations?nelat=46.79293526196035&nelng=7.156343175796218&subview=map&swlat=46.792731427890715&swlng=7.155914022353835&user_id=dbgi&verifiable=any)\n\n## Conclusion \n\nI was therefore able to contribute to the progress of the DGBI pilot by collecting a number of samples from the geophyte sector. Although 46% of this sector still remains to be sampled, metabolomic profiles can already be generated for many of the collected species, with more to follow once sampling is complete. This may eventually enable the identification of metabolomic patterns specific to geophyte plants, and help uncover links or characteristic natural product signatures within certain plant families.\n \n## Perspectives \n\nThe initial objective of the Swiss Digital Botanical Gardens Initiative (DGBI) was to establish metabolomic profiles of plant species growing in Swiss botanical gardens. To this end, species from the [Botanical Garden of Fribourg](https://www.unifr.ch/jardin-botanique/fr/) were first collected. Since then, several other botanical gardens in Switzerland have expressed interest in participating in the initiative, including the [Botanical Garden of Neuchâtel](https://www.jbneuchatel.ch)—where a number of species have already been sampled ([more details below](#progress-of-the-neuchâtel-botanical-garden-collection))—as well as the [Conservatory and Botanical Garden of Geneva](https://www.cjbg.ch/) and the [Alpine Botanical Garden Flore-Alpe in Champex-Lac](https://www.flore-alpe.ch/fr/).\n\nAlthough DGBI began in Switzerland, the project is designed to expand internationally. It will remain open as an open science database, not solely as an EMI pilot project. The initiative has already started extending beyond Switzerland, notably with the involvement of the [Royal Botanic Gardens, Kew](https://www.kew.org)—a significant development, given that Kew holds around 68,000 specimens representing approximately 18,000 species.\n\n### Progress of the Neuchâtel botanical garden collection\n\nRegarding the Neuchâtel Botanical Garden, a few figures can be mentioned. Currently 1,300 samples have been collected, of which 880 have been matched with the botanical garden's database. This has made it possible to link them to their IPEN (International Plant Exchange Network) codes.\n\nAccording to the database, the garden contains approximately 2,600 different plant species. At first glance, this may suggest a significant gap ; however, many of these plants are still under cultivation (in greenhouses or outdoors) and are therefore too small to be sampled. Others are not yet labeled, which also complicates the sampling process.\n\nSeveral of the diagrams below illustrate the situation of the Neuchâtel Botanic Garden in terms of diversity and in comparison with global diversity.\n\n![alt text](bachelor_project_jade/area_point_layer_directus.png)\n*Figure 3 : Location and organization of plant species in the Neuchâtel Botanical Garden. Each point represents a georeferenced individual plant, colored according to the garden zone to which it belongs.*\n\n![alt text](bachelor_project_jade/Barplot_genus_family_2025-06-26.png)\n*Figure 4 : Barplot showing the Neuchâtel garden's coverage of families, genus and species in relation to global diversity*\n\n![alt text](<bachelor_project_jade/Image 26.06.25 à 19.21.jpg>)\n*Figure 5 : Phylogenetic tree of plant families available at the Neuchâtel Botanic Garden*\n\n![alt text](bachelor_project_jade/whit_full_plot_2025-06-26.png)\n*Figure 6 : Whittaker diagram illustrating the environmental coverage of plant species sampled at the Neuchâtel Botanical Garden.*\n\n# DMSO Project \n\n## Actual DBGI extraction and issues \n\nAs outlined in the [introduction](#introduction), DGBI is a recent pilot project, one of whose objectives is to evaluate and refine current collection and extraction methodologies, with the aim of improving them where necessary.\n\nOne of the long-term objectives of both EMI and DGBI is to generate libraries of molecules obtained through sample extractions, with the aim of enabling their reuse and distribution to other laboratories for further bioanalysis, including high-throughput biological screening.\n\nHigh-throughput screening (HTS) enables the automated testing of compound libraries to assess their activity against various biological targets. HTS is now extensively used in drug discovery, medical diagnostics, stem cell research, and genetic studies<sup><a href=\"#ref7\" id=\"note7\">7</a></sup>.\n\nThe extraction mixture currently used as a solvent for molecule extraction in the DGBI project consists of 80% methanol, 20% distilled water, and 0.1% formic acid, for a total volume of 200 mL. This composition has proven to be highly effective in extracting metabolites from our samples. However, the solvent currently used in the DGBI project for samples extraction is not compatible with downstream analyses in biological or biochemical laboratories, as methanol can damage cells and formic acid can inhibit enzymatic reactions.\n\n## An alternative to methanol-based extraction \n\nAnother solvent currently widely used in biology laboratories is dimethyl sulfoxide (DMSO), a highly stable, soluble, polar, aprotic, and low-toxicity compound, compatible with biological systems<sup><a href=\"#ref8\" id=\"note8\">8</a></sup>. These properties make DMSO an excellent solvent for biological applications.\n\nWithin this context, an additional pilot study was conducted to explore potential enhancements to both the extraction protocol and the solvent used. Specifically, three extraction methods were tested and compared to address the following question: is the extraction method using dimethyl sulfoxide (DMSO) as effective as the methanol-based protocol for recovering our target metabolites?\n\nThis study therefore aims to assess whether DMSO could serve as a suitable alternative to the current extraction mixture. If the results prove promising and DMSO performs as effectively as the methanol–water–formic acid mixture in extracting target molecules, it could be adopted in future protocols—thus enabling the reuse of extracted samples for pharmacological research purposes.\n\n## Material and methods \n\nThe [standard DBGI extraction protocol](#extraction) described above was followed for this pilot study, with the exception of the extraction solvent, which was modified for comparative purposes.\n\nIn this experiment, six well-documented plant samples (*Valeriana officinalis*, *Echinacea purpurea*, *Cannabis sativa*, *Erythroxylum coca*, *Salvia officinalis*, and *Nicotiana tabacum*) were tested using three extraction methods: the standard DBGI protocol with its usual solvent (80% methanol, 20% distilled water, 0.1% formic acid), a pure DMSO extraction (99.8%), and a DMSO extraction followed by sonication (5 minutes of high-frequency sound wave pulses generating bubbles that promote cell lysis).<sup><a href=\"#ref9\" id=\"note9\">9</a></sup>\n\nFor each method, one Eppendorf tube was prepared per sample. Two blanks were also included in the experiment, using the methanol-water-formic acid mixture and pure DMSO, respectively.\n\n![alt text](bachelor_project_jade/703ef64f-355e-430f-a742-e511a483a0db.jpg)\n*Figure 7 : Eppendorf tubes after centrifugation with supernatant ready for recovery. The 6 samples per extraction method (A, B, C) are shown. A: Methanol-water-formic acid extraction method; B: Simple DMSO extraction; C: DMSO extraction with sonication.* \n\nThe resulting 20 samples were then transferred to vials for mass spectrometry and subsequent analysis.\n\n### Evaluation of extractions\n\nThe files generated from mass spectrometry analysis of the samples were processed using MZmine for the interpretation of the resulting chromatograms, applying the [following mzBatch configuration](https://github.com/digital-botanical-gardens-initiative/dmso-meoh-extraction-evaluation/blob/9d98ba18332c9316a3f8d11c8f3bf25549dc62b8/docs/mapp_project_00067/mapp_batch_00173/results/mzmine/mapp_batch_00173_maclocal.mzbatch)\n\n## Results \n\n### Principal Component Analysis \n\nAs a first step, a Principal Component Analysis (PCA) was performed to reduce the dimensionality of the dataset and to explore the main sources of variance among the samples.\n\n![alt text](<bachelor_project_jade/Image 26.06.25 à 23.53.jpg>)\n*Figure 8 : PC1 (x-axis) accounts for 31.8% of the total variance in the dataset, while PC2 (y-axis) explains 15.5%. Each point represents one of the three methods applied to each of the six samples, with one color per species.* \n\n### Chromatograms analysis\n\nAs previously mentioned, the chromatograms of the samples tested using the three different methods were analyzed. However, given that the sonicated DMSO method did not yield significantly improved results compared to the simple DMSO extraction, only the chromatograms obtained from the methanol–water and simple DMSO methods are presented here for clarity.\n\nChromatographic profiles of extracts from the six species, obtained using methanol–water and DMSO extraction methods (represented by two colors), are superimposed to compare signal intensities and metabolic patterns as a function of retention time. The annotated peaks correspond to the majority compounds detected. \nFor each species, data from both positive and negative ionization modes are displayed. A single blank chromatogram is included for each ionization mode, serving as a reference for both extraction methods. \nThe annotated peaks correspond to the majority compounds detected. \n\n![alt text](<bachelor_project_jade/Image 24.06.25 à 17.28.jpg>)\n*Figure 9 : Positive ionization chromatograms obtained for Valeriana officinalis after extraction by two separate methods. 20250506_CVOL_dbgi_002560_02_01.mzML (magenta): methanol-water-formic acid method; 20250506_CVOL_dbgi_002560_03_01.mzML (blue): DMSO extraction method.*\n\n![alt text](<bachelor_project_jade/Image 24.06.25 à 18.00.jpg>)\n*Figure 10 : Negative ionization chromatograms obtained for Valeriana officinalis after extraction by two separate methods. 20250506_CVOL_dbgi_002560_02_01_neg.mzML (green): methanol-water-formic acid method; 20250506_CVOL_dbgi_002560_03_01_neg.mzML (orange): DMSO extraction method.*\n\n![alt text](<bachelor_project_jade/Image 24.06.25 à 17.32.jpg>)\n*Figure 11 : Positive ionization chromatograms obtained for Echinacea purpurea after extraction by two separate methods. 20250506_CVOL_dbgi_002976_02_01.mzML (magenta): methanol-water-formic acid method; 20250506_CVOL_dbgi_002976_03_01.mzML (blue): DMSO extraction method.*\n\n![alt text](<bachelor_project_jade/Image 24.06.25 à 18.02.jpg>)\n*Figure 12 : Negative ionization chromatograms obtained for Echinacea purpurea after extraction by two separate methods. 20250506_CVOL_dbgi_002976_02_01_neg.mzML (green): methanol-water-formic acid method; 20250506_CVOL_dbgi_002976_03_01_neg.mzML (orange): DMSO extraction method.*\n\n![alt text](<bachelor_project_jade/Image 24.06.25 à 17.36.jpg>)\n*Figure 13 : Positive ionization chromatograms obtained for Cannabis sativa after extraction by two separate methods. 20250506_CVOL_dbgi_002251_02_01.mzML (magenta): methanol-water-formic acid method; 20250506_CVOL_dbgi_002251_03_01.mzML (blue): DMSO extraction method.*\n\n![alt text](<bachelor_project_jade/Image 24.06.25 à 18.05 2.jpg>)\n*Figure 14 : Negative ionization chromatograms obtained for Cannabis sativa after extraction by two separate methods. 20250506_CVOL_dbgi_002251_02_01_neg.mzML (green): methanol-water-formic acid method; 20250506_CVOL_dbgi_002251_03_01_neg.mzML (orange): DMSO extraction method.*\n\n![alt text](<bachelor_project_jade/Image 24.06.25 à 17.42.jpg>)\n*Figure 15 : Positive ionization chromatograms obtained for Erythroxylum coca after extraction by two separate methods. 20250506_CVOL_dbqi_002893_02_01.mzML (magenta): methanol-water-formic acid method; 20250506_CVOL_dbqi_002893_03_01.mzML (blue): DMSO extraction method.*\n\n![alt text](<bachelor_project_jade/Image 24.06.25 à 18.07.jpg>)\n*Figure 16 : Negative ionization chromatograms obtained for Erythroxylum coca after extraction by two separate methods. 20250506_CVOL_dbgi_002893_02_01_neq.mzML (green): methanol-water-formic acid method; 20250506_CVOL_dbgi002893_03_01_neg.mzML (orange): DMSO extraction method.*\n\n![alt text](<bachelor_project_jade/Image 24.06.25 à 17.46.jpg>)\n*Figure 17 : Positive ionization chromatograms obtained for Salvia officinalis after extraction by two separate methods. 20250506_CVOL_dbgi_002605_02_01.mzML (magenta): methanol-water-formic acid method; 20250506_CVOL_dbgi_002605_03_01.mzML (blue): DMSO extraction method.*\n\n![alt text](<bachelor_project_jade/Image 24.06.25 à 18.09.jpg>)\n*Figure 18 : Negative ionization chromatograms obtained for Salvia officinalis after extraction by two separate methods. 20250506_CVOL_dbgi_002605_02_01_neg.mzML (green): methanol-water-formic acid method; 20250506_CVOL_dbgi_002605_03_01_neg.mzML (orange): DMSO extraction method.*\n\n![alt text](<bachelor_project_jade/Image 24.06.25 à 17.52.jpg>)\n*Figure 19 : Positive ionization chromatograms obtained for Nicotiana tabacum after extraction by two separate methods. 20250506_CVOL_dbgi_002414_02_01.mzML (magenta): methanol-water-formic acid method; 20250506_CVOL_dbgi_002414_03_01.mzML (blue): DMSO extraction method.*\n\n![alt text](<bachelor_project_jade/Image 24.06.25 à 18.14.jpg>)\n*Figure 20 : Negative ionization chromatograms obtained for Nicotiana tabacum after extraction by two separate methods. 20250506 CVOL dbgi 002414 02 01 neg.mzML (green): methanol-water-formic acid method; 20250506_CVOL_dbgi_002414_03_01_neg.mzML (orange): DMSO extraction method.*\n\n![alt text](<bachelor_project_jade/Image 24.06.25 à 17.55.jpg>)\n*Figure 21 : Positive ionization chromatograms obtained for the blank.20250506_CVOL_dbgi_bk_MeOH-H20_53.mzML (green): methanol-water-formic acid method; 20250506_CVOL_dbgi_bk_DMSO_58.mzML (yellow): DMSO extraction method.*\n\n![alt text](<bachelor_project_jade/Image 24.06.25 à 18.15.jpg>)\n*Figure 22 : Negative ionization chromatograms obtained for the blank.20250506_CVOL_dbgi_bk_MeOH-H20_53_neg.mzML (blue): methanol-water-formic acid method; 20250506 CVOL dbgi bk DMSO 58 neg.mzML (red): DMSO extraction method.*\n\nComparative chromatograms of the two extraction methods show nearly superimposed results. In some cases, there are slight differences in detection, and the peaks don't overlap perfectly, if at all.\n\nThe comparative chromatograms differ according to the ionization mode. \n\n## Discussion \n\n### Principal Component Analysis\n\nThe PCA shows that the variance between samples is mainly explain by taxon identity rather than by extraction method. For example, PC1, which explains 31.8% of the total variability, clearly separates *Erythroxylum coca* from the other species, while PC2, accounting for 15.5% of the variability, distinguishes *Valeriana officinalis* from the rest of the samples. Samples from the same species cluster together regardless of the extraction protocol used, suggesting that differences between methods have minimal impact on the overall variance. This similarity of chemical profiles within the same species confirms that the three extraction methods give comparable results for each species.\n\n### Chromatograms comparison \n\nThe regions where peaks overlap indicate that the same molecules were extracted at specific retention times. The vast majority of peaks are superimposed, suggesting a high similarity between the two extraction methods. Some molecules are better detected with DMSO, while others show improved detection with methanol; however, overall, the chromatograms are largely comparable and overlap with high precision.\n\nChromatograms obtained in positive and negative ionization modes are not directly comparable, as each mode favors the ionization of different molecules. Indeed, some molecules ionize better in positive mode, while others do so in negative mode, meaning that each mode detects a distinct subset of compounds present in the sample. \n\nThe detection of compounds is overall better in positive ionization mode, in terms of signal intensity , likely due to the nature of the molecules present, which often contain basic functional groups (such as amines) that favor positive ionization. However, negative mode should not be overlooked: although the signals are generally less intense, this mainly reflects a lower ionization efficiency rather than an intrinsically lower sensitivity of this mode. In addition, negative mode enables the detection of certain compounds absent in positive mode, highlighting the importance of using both ionization modes complementarily to obtain a complete and accurate profile of the molecules present in the extracts and achieve optimal metabolomic coverage.<sup><a href=\"#ref10\" id=\"note10\">10</a></sup>\n\n### Sample characteristics and preparation\n\nSeveral notable differences were observed between samples extracted with dimethyl sulfoxide (DMSO) and those extracted with methanol. First, DMSO freezes at 19°C and is solid at -80°C, whereas methanol freezes at around -98°C and remains liquid at -80°C. Using DMSO as the extraction liquid requires additional thawing time, since samples can only be handled in the liquid phase. Furthermore, extracts obtained with DMSO foam after shaking and are significantly darker in color. However, almost all of the foam disappears during centrifugation. This enables the correct extraction of the supernatant without aspirating foam along with it.\n\n![alt text](<bachelor_project_jade/Image 25.06.25 à 12.05.jpg>)\n*Figure 23 : Eppendorf tubes before centrifugation containing 2 extracts of Erythroxylum coca by 2 extraction methods; Left: DMSO extraction: Right: methanol-water-formic acid extraction.*\n\nSonication was employed in combination with DMSO for the third extraction method, as it enables the release of intracellular metabolites by lysing cell membranes. It relies on ultrasonic waves to generate bubbles in a liquid, which, upon implosion, produce high localized pressures and temperatures, thereby disrupting biological structures such as cellular membranes.<sup><a href=\"#ref9\" id=\"note9\">9</a></sup>\n\nThe initial hypothesis was that DMSO combined with sonication would yield mass spectrometry outputs of comparable quality to those obtained with methanol-based solvents, since sonication facilitates extensive cell disruption and maximizes compound recovery for analysis. However, sonicated DMSO produced results of similar—or even lower—quality than DMSO alone. This suggests, on one hand, that DMSO is highly effective as a standalone extraction solvent, and on the other hand, that combining sonication with DMSO may potentially damage biological structures beyond the cell membranes in our extracts. Further analyses or a reduction in sonication time could be considered for the protocol, to observe whether results are better, similar, or again of poorer quality.\n\n## Perspectives\n\n### Conversion of libraries to 96-well format\n\nIn order to submit our natural product extracts to bioassay screening by external bioanalytical laboratories, it is essential to provide the samples in a format compatible with such analyses. To this end, we are currently reformatting our extract libraries in a 69-well configuration.\n\nThis reformatting step will be integrated with our ongoing results on DMSO-based extraction, thereby enabling us to refine our methodologies and improve sample compatibility for downstream bioassays and bioactive compound discovery.\n\nThe currently considered format for the 96-well libraries is the [AlteTube™ Screw Cap 2D Barcoded Tubes – External Thread – 96 SBS Rack](https://www.altemislab.com/2d-barcoded-tubes/external-thread-tubes-96-sbs-rack/). Further evaluation will determine its suitability for both our sample types and the subsequent bioanalytical workflows.\n\n## Conclusion \n\nThe comparison of chromatograms obtained from the two extraction methods enabled the evaluation of the compounds detected using both DMSO- and methanol-based protocols. The results are highly promising: the near-perfect overlap of peaks indicates that simple DMSO extraction is as effective as the conventional methanol/water/formic acid mixture in recovering the molecules in our extracts. This finding opens the possibility of replacing the current solvent with DMSO in the extraction protocol. Combined with a 96-well format, this approach would allow for the reuse of extracted samples in high-throughput screening and facilitate the sharing of these extracts with other laboratories for bioactive compound discovery, thus aligning with one of EMI’s key objectives.\n\n# Fake extract project \n\nThe \"Fake Extract Project\" originated within the framework of Marco Visani’s doctoral thesis, with whom I worked during my bachelor’s degree. The doctoral project, rooted in the LOTUS and EMI initiatives, aims to anticipate the chemistry of life on Earth by modeling metabolites produced by living organisms and associating certain molecular patterns with biological characteristics. The study’s objective aligns with the goals of the open science LOTUS initiative, which seeks to construct referenced pairs between natural products and their source organisms, as well as with the objectives of EMI, one of which is to explore the yet unknown chemistry of life. The primary aim of this thesis, situated in a bioinformatics context, is to predict the chemical composition of living organisms across the tree of life in advance.\n\nOne of the major current challenges in metabolomic profiling of organisms within the EMI framework is that the molecular profile obtained by untargeted mass spectrometry from the natural extract does not allow for certainty regarding whether certain compounds were lost during the process. Without accurate, exhaustive, and well-referenced data throughout the extraction and profiling steps, it becomes difficult to anticipate the occurrences of natural products. This uncertainty limits the ability to model the chemical composition of living organisms according to their phylogenetic position.\n\nIonization in mass spectrometry is intrinsically competitive: only molecules with favorable physicochemical properties—such as polarity, basicity, acidity, molecular weight, or certain structural features—ionize efficiently. Others may be strongly disadvantaged by phenomena like ion suppression<sup><a href=\"#ref11\" id=\"note11\">11</a></sup>, leading to decreased or even absent signals in complex natural mixtures.\n\nTo model these losses and anticipate the missing chemistry within natural extracts, we designed the *Fake Extract Project*. This approach relies on the analysis of an artificial mixture composed of well-characterized reference compounds, processed through mass spectrometry. By comparing the output signal to the known initial composition, it becomes possible to quantify compound-specific detection losses. This strategy allows for the calibration and correction of experimental outputs by accounting for ionization biases, with the ultimate aim of more faithfully approximating the complete chemical composition of natural extracts.\n\n## ApexBio natural products library\n\nFirst, we considered using a well-characterized model plant from plant biology, such as Arabidopsis thaliana, for our known extract. However, we realized that even the metabolome of such a plant is neither well characterized nor well understood. Moreover, it is very complex. To overcome this problem, we created a \"fake extract\": a mixture of well-cataloged natural products whose chemical characteristics are known. This allows us to obtain an exact result of what was lost during the mass spectrometry run since the exact composition of the mixture is known from the beginning.\n\nTo this end, a natural product library from ApexBio ([DiscoveryProbe™ Natural Product Library](https://www.apexbt.com/discoveryprobetm-natural-product-library.html)), comprising 550 compounds, was selected. An accompanying Excel file containing key chemical properties was provided. Before using this library for our analyses and mixture preparation, we first verified the accuracy of the provided data, an essential step for reliable downstream work. In metabolomics, precise knowledge of molecular properties such as exact mass, SMILES, and other associated chemical data is crucial, as molecule detection and identification rely heavily on these parameters.\n\n## Material and methods \n\n### Data cleaning with python \n\nThe following [Excel file](https://github.com/jade147/jade_bachelor_work_repo/blob/c415e7ddad3ff961c79f32927e89771cff457f0c/apex_bio.xlsx) was provided to us, and an automated cleaning process using the Python programming language was necessary to ensure the accuracy of all chemical data associated with the molecules before further analysis.\n\nInitially, a [Molecule](https://github.com/commons-research/apex_bio_data_cleaning/blob/d5994545b8830bd76031a3fe6423795bff2624af/molecules.py) class was developed to compare the submitted data for each molecule against the [PubChem chemical database](https://pubchem.ncbi.nlm.nih.gov/ ), and to extract additional chemical information related to each compound of interest. This class was then imported in the [cleaned_dataframe.ipynb Jupyter Notebook](https://github.com/commons-research/apex_bio_data_cleaning/blob/d5994545b8830bd76031a3fe6423795bff2624af/cleaned_dataframe.ipynb) to generate TSV files corresponding to molecules that could not be retrieved from PubChem, specifically, [20 molecules not found using their CAS number](https://github.com/jade147/jade_bachelor_work_repo/blob/c415e7ddad3ff961c79f32927e89771cff457f0c/failed_cas.csv), [3 not found using their item name](https://github.com/jade147/jade_bachelor_work_repo/blob/c415e7ddad3ff961c79f32927e89771cff457f0c/failed_iname.csv), and [1 not found using its SMILES representation](https://github.com/jade147/jade_bachelor_work_repo/blob/c415e7ddad3ff961c79f32927e89771cff457f0c/failed_smiles.csv). These three identifiers were selected because they are considered to have the highest likelihood of matching a unique entry in the database.\n\nDue to the significant amount of time required to clean our molecular data, and the notable inconsistencies in the associated chemical information, we only had time to analyze a single plate. This experiment therefore served as a pilot for the \"fake extract project,\" allowing us to test the planned methodologies and dilutions, and refine them if necessary.\n\nFor this purpose, a plate with accurate and reliable associated data was selected, here [plate number 3](https://github.com/commons-research/fake-extract-plate-3-mix/blob/31e0a5dc0a8b001220e97089405a5284476099be/plate_3_targets.csv), whose information proved to be correct. While a standard 96-well plate contains 88 molecules (with one column left empty), 89 molecules were analyzed in total, as picrotoxin is an equimolar mixture of two compounds. These molecules were first detected individually. Then, a mixture of the 89 molecules was created and designated as the \"fake extract.\" \n\nSubsequently, a [revised file](https://github.com/commons-research/apex_bio_data_cleaning/blob/d5994545b8830bd76031a3fe6423795bff2624af/apex_bio_revised.tsv) was provided, from which the [apex_bio_cleaned.tsv](https://github.com/commons-research/apex_bio_data_cleaning/blob/d5994545b8830bd76031a3fe6423795bff2624af/apex_bio_cleaned.tsv) file was generated. The chemical data in this file are accurate and will serve as a reference for analyzing the other plates in the next stages of the project.\n\n### Preparation of diluted samples for mass spectrometry analysis\n\nAll 96-well V-bottom plates from the natural product library are stored at -80°C with a heat-sealed aluminum foil. Once the seal is removed, a reusable silicone lid is applied to keep the plate closed and allow further storage at -80°C for subsequent analyses. Dilutions were carried out from the source plate into an identically formatted 96-well V-bottom plate.\n\nThe initial concentration of the received samples was 10 millimolar (10,000 micromolar). Therefore, several test dilutions were required prior to mass spectrometry analysis to determine the optimal concentration for molecule detection. The first column (well positions 01A–01H) of source plate number 3 was diluted in DMSO at various concentrations on a daughter plate as follows:\n\n* Row 01A–H (Samples 1): 100 µM (1 µL of original sample + 99 µL DMSO)\n* Row 02A–H (Samples 2): 10 µM (10 µL of Sample 1 + 90 µL DMSO)\n* Row 03A–H: 1 µM (10 µL of Sample 2 + 90 µL DMSO)\n* Row 04A–H: Blank control, DMSO only\n\nThe relative well positions from the source plate were preserved on the daughter plate (e.g., sample from well 01A in the source plate was diluted into well 01A of the daughter plate, and so on). The source plate was then resealed with a silicone lid and stored at −80 °C.\n\nFollowing mass spectrometry analysis, a concentration of 10 µM was selected as optimal. To dilute the 10 mM stock solutions directly to 10 µM, a 0.1 µL aliquot would have been needed for dilution into 99.9 µL of DMSO. However, such a small volume is prone to pipetting error and reduced accuracy.\n\nTo mitigate this, a two-step dilution protocol was adopted, involving the preparation of two daughter plates: one at 100 µM and another at 10 µM. The first daughter plate (100 µM) was obtained by diluting the source plate samples, and the second (10 µM) was prepared by diluting the 100 µM daughter plate samples. An 8-channel multichannel pipette was used, as a total of 88 wells were processed.\n\nFor the first daughter plate (100 µM), 99 µL of DMSO was dispensed into each of the 88 wells. Then, 1 µL of each sample from source plate 3 was transferred into the corresponding well, starting from column 11 to column 01 to avoid cross-contamination. Each transfer was followed by mixing via pipetting. The source plate was then resealed with a silicone lid and stored again at −80 °C.\n\nFor the second daughter plate (10 µM), 90 µL of DMSO was dispensed into each well, followed by 10 µL of sample from the 100 µM daughter plate. Samples were transferred from left to right, maintaining well-to-well correspondence and mixing after each transfer. Both daughter plates were sealed with silicone lids and stored at −80 °C.\n\nThe 10 µM daughter plate was then used for mass spectrometry analysis to detect individual compounds from source plate 3.\n\nFor the preparation of a mixed sample (our \"fake\" extract), the 100 µM daughter plate was reused. A 10 µL aliquot from each well was pooled and combined with 120 µL of DMSO in a reagent trough. The resulting mixture was transferred into a 2 mL vial, and then into a second vial equipped with an insert, for subsequent mass spectrometry analysis. This yielded a final concentration of 1 µM per compound, which was sufficient for detection by mass spectrometry.\n\n### Targeted mass spectrometry \n\nThe samples (both individual compounds and the mixture of 89 molecules) were analyzed by mass spectrometry to determine which compounds were detected. The workflow was identical to that [described above](#untargeted-mass-spectrometry), using high-performance liquid chromatography (HPLC) coupled to high-resolution Orbitrap mass spectrometry with data-dependent acquisition (DDA). However, unlike the analysis of unknown natural product extracts, this process was performed in a targeted manner. In this case, the identities of the compounds present at the outset were already known, and the goal was specifically to assess whether these known molecules could be detected after the mass spectrometry run, hence the targeted approach.\n\n### Evaluation of extractions\n\nFor the detection of specific individual molecules and the mixture, the raw data files generated from the mass spectrometry runs were processed using MZmine, applying the appropriate mzBatch configurations for both [positive](https://github.com/commons-research/fake-extract-plate-3-mix/blob/31e0a5dc0a8b001220e97089405a5284476099be/rt_extraction_pos_new.mzbatch) and [negative](https://github.com/commons-research/fake-extract-plate-3-mix/blob/31e0a5dc0a8b001220e97089405a5284476099be/rt_extraction_neg_new.mzbatch) ionization modes.\n\n## Results \n\nThe results for molecule detection in the mixture are presented here as a Venn diagram showing the molecules detected exclusively in positive ionization mode, exclusively in negative ionization mode, in both modes, or in neither. The corresponding [CSV file](https://github.com/commons-research/fake-extract-plate-3-mix/blob/31e0a5dc0a8b001220e97089405a5284476099be/plate_3_targets_detected.csv), from which the Venn diagram was generated, is also provided.\n\n![alt text](bachelor_project_jade/output.png)\n\n*Figure 24. Venn diagram showing the number of molecules detected from the mix of 89 compounds across the two ionization modes. Thirty-four molecules were detected exclusively in positive ionization mode, seven exclusively in negative mode, and twenty-nine in both modes. Nineteen molecules were not detected in either mode.*\n\nThe results show that, after analysis of the fake extract by mass spectrometry for natural product detection, 38.2% of the molecules were detected exclusively in positive ionization mode, 7.8% exclusively in negative mode, and 32.5% in both modes. A total of 21.5% of the molecules were not detected in either ionization mode. Overall, 78.5% of the compounds in the mix were detected at least once, depending on the ionization mode used during mass spectrometric analysis.\n\n## Discussions and conclusion\n\nThe 21.5% of molecules that were not detected even once in the mix confirm a significant ion suppression effect in extracts composed of multiple natural products. As a result, a certain amount of data is inevitably lost during the workflow for molecule extraction and metabolomic profiling, highlighting the need for modeling and characterization of these missing data. This would allow such biases to be integrated into the final outputs, bringing the predicted chemistry of living organisms closer to reality.\n\nHowever, these results should be interpreted with caution, as considerable variability was observed depending on the different MzMine parameter settings tested—particularly due to tolerance thresholds. Further in-depth analyses will be required in the next steps of the project in order to construct a mzBatch pipeline that is as accurate as possible for the detection of individual molecules, both alone and in mixtures, and that best reflects the true number of detectable compounds. A sufficiently high detection threshold is essential to ensure the detection of relevant compounds, but an excessively high threshold may result in the loss of weakly ionizable molecules.\n\nA major difference in detection was also observed between positive and negative ionization modes, again indicating a higher detection rate for positively ionized compounds (28.2%). Nonetheless, 7.8% of molecules were detected exclusively in negative mode, underlining its essential role in ensuring the broadest possible compound coverage. This observation is consistent with earlier discussions related to the results of the \"[DMSO project](#chromatograms-comparison).\"\n\n## Perspectives \n\nPlate 3 and its 88 wells were analyzed in this study, enabling the quantification of data loss during the workflow for a mixture of 89 molecules. In the next stages of the project, it will be essential to analyze the remaining individual plates to continue assessing data loss. Initially, each plate will be analyzed separately; subsequently, a combined mixture of all samples will be prepared and analyzed to cover the entire ApexBio library received—comprising 550 molecules—and evaluate the behavior of the full mixture.\n\nIn the future, a reliable and comprehensive characterization of data loss in mass spectrometry could allow for more precise identification of the types of molecules that systematically go undetected, particularly those that are weakly ionizable. This would pave the way for reconstructing the theoretical complete metabolomic profile of an extract—integrating not only the compounds that were detected but also those that may have been absent from the signal due to their physicochemical properties. Such an approach would make it possible to adjust and correct experimental profiles by incorporating the \"missing\" component, ultimately leading to a more accurate representation of the true chemical composition of organisms.\n\nThe results of this pilot project, once finalized, could be reused in the context of Marco Visani’s doctoral thesis. Indeed, this more accurate evaluation of the metabolomic profiles of the studied organisms would significantly improve the ability to anticipate the chemical composition of living organisms across the tree of life. Complete metabolomic profiles would allow the development of predictive models: based on a detailed chemical profile of a given organism, it would be possible, through extrapolation, to predict the likely chemistry of phylogenetically related organisms, even if they have not yet been experimentally studied. These enriched data could subsequently be integrated into the EMI and LOTUS initiatives, to refine the association between natural products and their source organisms, and thus contribute to a more complete and realistic characterization of the chemistry of life.\n\n# Bibliography \n\n<p id=\"ref1\">1. : Aron, A. T., Gentry, E. C., McPhail, K. L., Nothias, L. F., Nothias-Esposito, M., Bouslimani, A., Petras, D., Gauglitz, J. M., Sikora, N., Vargas, F., van der Hooft, J. J. J., Ernst, M., Kang, K. bin, Aceves, C. M., Caraballo-Rodríguez, A. M., Koester, I., Weldon, K. C., Bertrand, S., Roullier, C., … Dorrestein, P. C. (2020). Reproducible molecular networking of untargeted mass spectrometry data using GNPS. Nature Protocols, 15(6), 1954–1991. https://doi.org/10.1038/s41596-020-0317-5\n\n<p id=\"ref2\">2. : Rutz, A., Sorokina, M., Galgonek, J., Mietchen, D., Willighagen, E., Gaudry, A., Graham, J. G., Stephan, R., Page, R., Vondrášek, J., Steinbeck, C., Pauli, G. F., Wolfender, J. L., Bisson, J., & Allard, P. M. (2022). The LOTUS initiative for open knowledge management in natural products research. ELife, 11. https://doi.org/10.7554/eLife.70780\n\n<p id=\"ref3\">3. : Allard, P.-M. (2023). The Digital Botanical Gardens Initiative repository. https://doi.org/10.5281/zenodo.7662428 </p>\n\n<p id=\"ref4\">4. : Shivanna, K. R. (2020). The Sixth Mass Extinction Crisis and its Impact on Biodiversity and Human Welfare. Resonance, 25(1), 93–109. https://doi.org/10.1007/s12045-019-0924-z </p>\n\n<p id=\"ref5\">5. : Tribble, C. M., Martínez-Gómez, J., Howard, C. C., Males, J., Sosa, V., Sessa, E. B., Cellinese, N., & Specht, C. D. (2021). Get the shovel: morphological and evolutionary complexities of belowground organs in geophytes. In American Journal of Botany (Vol. 108, Issue 3, pp. 372–387). John Wiley and Sons Inc. https://doi.org/10.1002/ajb2.1623\n\n<p id=\"ref6\">6. : Hilaire, P. B. saint, Rousseau, K., Seyer, A., Dechaumet, S., Damont, A., Junot, C., & Fenaille, F. (2020). Comparative evaluation of data dependent and data independent acquisition workflows implemented on an orbitrap fusion for untargeted metabolomics. Metabolites, 10(4). https://doi.org/10.3390/metabo10040158\n\n<p id=\"ref7\">7. : Rodríguez-Dévora, J. I., Shi, Z. D., & Xu, T. (2011). Direct assembling methodologies for high-throughput bioscreening. In Biotechnology Journal (Vol. 6, Issue 12, pp. 1454–1465). https://doi.org/10.1002/biot.201100100 \n\n<p id=\"ref8\">8. : Balakin, K. v., Ivanenkov, Y. A., Skorenko, A. v., Nikolsky, Y. v., Savchuk, N. P., & Ivashchenko, A. A. (2004). In silico estimation of DMSO solubility of organic compounds for bioscreening. Journal of Biomolecular Screening, 9(1), 22–31. https://doi.org/10.1177/1087057103260006\n\n<p id=\"ref9\">9. : Sonication: définition, principe, exemples d'applications. SinapTec, www.sinaptec.fr/sonication-definition-principe-exemples/. Accessed 25 June 2025.\n\n<p id=\"ref10\">10. : Warnes, B., Chihabi, J., & Manthorpe, J. (2023). Unveiling the Power of Negative Ion Mode ESI-MS: Identifying Species with Remarkable Signal Intensity and Collisional Stability. https://doi.org/10.26434/chemrxiv-2023-85mkn-v3\n\n<p id=\"ref11\">11. : Annesley, T. M. (2003). Ion Suppression in Mass Spectrometry. Clinical Chemistry, 49(7), 1041–1044. https://doi.org/10.1373/49.7.1041\n\n\n\n","n":0.011}}}]}
