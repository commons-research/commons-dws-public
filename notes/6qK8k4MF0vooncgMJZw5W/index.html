<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/commons-dws-public/favicon.ico"/><title>Isfrag</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="Isfrag"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://commons-research.github.io/commons-dws-public/notes/6qK8k4MF0vooncgMJZw5W/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="5/14/2021"/><meta property="article:modified_time" content="10/25/2021"/><link rel="canonical" href="https://commons-research.github.io/commons-dws-public/notes/6qK8k4MF0vooncgMJZw5W/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/commons-dws-public/_next/static/css/47f58a23998994fc.css" as="style"/><link rel="stylesheet" href="/commons-dws-public/_next/static/css/47f58a23998994fc.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/commons-dws-public/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/commons-dws-public/_next/static/chunks/webpack-18f1eb2dd0aac0df.js" defer=""></script><script src="/commons-dws-public/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/commons-dws-public/_next/static/chunks/main-1bd061c8c8d18148.js" defer=""></script><script src="/commons-dws-public/_next/static/chunks/pages/_app-8bc9d81129a787a1.js" defer=""></script><script src="/commons-dws-public/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/commons-dws-public/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/commons-dws-public/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/commons-dws-public/_next/static/KWnqrj5vUmxn1r58uXWxO/_buildManifest.js" defer=""></script><script src="/commons-dws-public/_next/static/KWnqrj5vUmxn1r58uXWxO/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="isfrag"><a aria-hidden="true" class="anchor-heading icon-link" href="#isfrag"></a>Isfrag</h1>
<p>Pasting an old recipee from ZettelKasten</p>
<p>Linked to <a title="Private" href="https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html" target="_blank" class="private">202002251433 (Private)</a> in silico fragmentation worflow.</p>
<p>Children workflow on the beast MAPP </p>
<p>Side notes : try to write everything as scripts so that they can be launched without a GUI (ex on X2Go or directly Boabab).</p>
<h1 id="tutorial-for-npatlas-in-silico-fragmentation-data-treatment"><a aria-hidden="true" class="anchor-heading icon-link" href="#tutorial-for-npatlas-in-silico-fragmentation-data-treatment"></a>Tutorial for NPatlas in silico fragmentation data treatment</h1>
<h2 id="prior-to-fragmentation"><a aria-hidden="true" class="anchor-heading icon-link" href="#prior-to-fragmentation"></a>Prior to fragmentation</h2>
<h3 id="prepare-space-delimited-input-file"><a aria-hidden="true" class="anchor-heading icon-link" href="#prepare-space-delimited-input-file"></a>Prepare space delimited input file</h3>
<p>Complete metadate file is converted to list of Unique ID and smiles space separated (for cfm id input)</p>
<p>python frag_list_preparator.py ../npatlas_data/np_atlas_2019_12.tsv ../npatlas_data/np_atlas_2019_12_for_frag.tsv NPAID SMILES</p>
<p>python frag_list_preparator.py ../open_np_db_data/open_NP_db.tsv ../open_np_db_data/open_NP_db_tofrag.txt shortinchikey shortinchikey smiles</p>
<h3 id="split-the-file"><a aria-hidden="true" class="anchor-heading icon-link" href="#split-the-file"></a>Split the file</h3>
<p>(Works on Linux based shells)</p>
<p>split -a 5 -l 500 -d ../open<em>np_db_data/open_NP_db_tofrag.txt ../open_np_db_data/opennpdb_tofrag/opennpdb</em>
split -a 5 -l 500 -d ./lotus<em>data/lotus_data_for_frag.txt ./lotus_data/lotus_data_for_frag/lotus_data</em></p>
<p>split -a 5 -l 500 -d ./ ./lotus<em>data/lotus_data_for_frag/lotus_data</em>
split -a 5 -l 500 -d cfm/cfm<em>input/platinum_tofrag.tsv cfm/cfm_input/splitted/lotus_to_frag</em></p>
<p>This one allows to preserve extensions and is build on number of desired chunks without splitting lines
split -a 5 -n l/199 -d --additional-suffix=.txt  cfm<em>input/sub_platinum_tofrag.tsv cfm_input/splitted/lotus_to_frag</em></p>
<h3 id="when-using-the-docker-cli-files-need-to-have-an-extension-or-taken-as-folder-"><a aria-hidden="true" class="anchor-heading icon-link" href="#when-using-the-docker-cli-files-need-to-have-an-extension-or-taken-as-folder-"></a>When using the docker cli files need to have an extension (or taken as folder ?)</h3>
<p>for f in *; do mv "<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mi mathvariant="normal">"</mi><mi mathvariant="normal">"</mi></mrow><annotation encoding="application/x-tex">f" "</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord">""</span></span></span></span></span>f.txt"; done</p>
<p>if you made a mistacke </p>
<p>find / -type f -name '*.txt' -exec sh -c 'mv -- "<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mi mathvariant="normal">"</mi><mi mathvariant="normal">"</mi></mrow><annotation encoding="application/x-tex">0" "</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">0""</span></span></span></span></span>{0%.txt}"' {} \;</p>
<h3 id="prepare-mutilple-bash-file-to-launch-on-baobab"><a aria-hidden="true" class="anchor-heading icon-link" href="#prepare-mutilple-bash-file-to-launch-on-baobab"></a>Prepare mutilple bash file to launch on baobab</h3>
<p>(strangely enough the .sh incrementer script return an error on Linux, runned OK on MacOS command line )</p>
<p>Note: apparently sbatch as been replaced by srun on the boabab server side. Be sure to update the scripts accordingly</p>
<h2 id="fetching-cfm-predict-results"><a aria-hidden="true" class="anchor-heading icon-link" href="#fetching-cfm-predict-results"></a>Fetching cfm-predict results</h2>
<p>Download cfm-predict fragmentation results from the baob server using rsync command</p>
<p>rsync -rvz -e 'ssh' --progress <a href="/commons-dws-public/mailto:allardp@baobab2.unige.ch">allardp@baobab2.unige.ch</a>:/home/allardp/CFM_results/npatlas ./results
rsync -rvz -e 'ssh' --progress <a href="/commons-dws-public/mailto:allardp@baobab2.unige.ch">allardp@baobab2.unige.ch</a>:/home/allardp/CFM_results/coconut/ .</p>
<p>find ./ -type f -name '*.mgf' | wc  </p>
<p>allows to count all file in a folder
Here 25090 files for NPatalas</p>
<p>Coconut 384222 .log files</p>
<p> 384150 mgf files</p>
<h2 id="we-might-eventually-need-to-move-all-files-from-subfolders-recursively-to-a-superior-folder"><a aria-hidden="true" class="anchor-heading icon-link" href="#we-might-eventually-need-to-move-all-files-from-subfolders-recursively-to-a-superior-folder"></a>We might eventually need to move all files from subfolders recursively to a superior folder</h2>
<p>find ./bacasable -type f -print0 | xargs -0 mv -t ./bacasable</p>
<p>find ./results_coconut -type f -print0 | xargs -0 mv -t ./results_coconut</p>
<h2 id="pruning-the-raw-log-files"><a aria-hidden="true" class="anchor-heading icon-link" href="#pruning-the-raw-log-files"></a>Pruning the raw log files</h2>
<p>The output of cfm-predict consist of .log file containing mass spectra, where each fragments are individually labelled and eventually linked to a substrcture. Such information might be usefull later but for now we only want to keep the raw ms data</p>
<p>(need to define a help function here)</p>
<p>python raw_log_treater_npatlas.py ../npatlas_data/results_npatlas/npatlas/ .log
python raw_log_treater.py ../coconut_data/results_coconut/ .log</p>
<p>At this step .log file should be pruned and contains only digits (m/z and intensities)</p>
<p>for coconut Parsing directory../coconut_data/results_coconut/ with file extension :.log</p>
<p>'mass' ../coconut_data/results_coconut/CNP0402147.log
'mass' ../coconut_data/results_coconut/CNP0153817.log
'mass' ../coconut_data/results_coconut/CNP0155980.log
'mass' ../coconut_data/results_coconut/CNP0086807.log
'mass' ../coconut_data/results_coconut/CNP0199206.log
'mass' ../coconut_data/results_coconut/CNP0334817.log
'mass' ../coconut_data/results_coconut/CNP0366374.log
'mass' ../coconut_data/results_coconut/CNP0232712.log
'mass' ../coconut_data/results_coconut/CNP0370068.log
'mass' ../coconut_data/results_coconut/CNP0055178.log
'mass' ../coconut_data/results_coconut/CNP0228597.log
'mass' ../coconut_data/results_coconut/CNP0119974.log
'mass' ../coconut_data/results_coconut/CNP0132139.log
'mass' ../coconut_data/results_coconut/CNP0145457.log
'mass' ../coconut_data/results_coconut/CNP0230801.log
'mass' ../coconut_data/results_coconut/CNP0310370.log
'mass' ../coconut_data/results_coconut/CNP0149436.log
'mass' ../coconut_data/results_coconut/CNP0396848.log
'mass' ../coconut_data/results_coconut/CNP0401434.log
'mass' ../coconut_data/results_coconut/CNP0101561.log
'mass' ../coconut_data/results_coconut/CNP0390928.log
'mass' ../coconut_data/results_coconut/CNP0405256.log
'mass' ../coconut_data/results_coconut/CNP0395006.log
'mass' ../coconut_data/results_coconut/CNP0159145.log
'mass' ../coconut_data/results_coconut/CNP0131085.log
'mass' ../coconut_data/results_coconut/CNP0230696.log
'mass' ../coconut_data/results_coconut/CNP0014450.log
'mass' ../coconut_data/results_coconut/CNP0214739.log
'mass' ../coconut_data/results_coconut/CNP0302005.log
'mass' ../coconut_data/results_coconut/CNP0279314.log
'mass' ../coconut_data/results_coconut/CNP0177036.log
'mass' ../coconut_data/results_coconut/CNP0274256.log
'mass' ../coconut_data/results_coconut/CNP0403745.log
'mass' ../coconut_data/results_coconut/CNP0039287.log
'mass' ../coconut_data/results_coconut/CNP0238803.log
'mass' ../coconut_data/results_coconut/CNP0014261.log
'mass' ../coconut_data/results_coconut/CNP0077076.log
'mass' ../coconut_data/results_coconut/CNP0125300.log
'mass' ../coconut_data/results_coconut/CNP0228582.log
'mass' ../coconut_data/results_coconut/CNP0393136.log
'mass' ../coconut_data/results_coconut/CNP0338003.log
'mass' ../coconut_data/results_coconut/CNP0070182.log
'mass' ../coconut_data/results_coconut/CNP0230961.log
'mass' ../coconut_data/results_coconut/CNP0001326.log
'mass' ../coconut_data/results_coconut/CNP0088652.log
'mass' ../coconut_data/results_coconut/CNP0045797.log
'mass' ../coconut_data/results_coconut/CNP0175458.log
'mass' ../coconut_data/results_coconut/CNP0300969.log
'mass' ../coconut_data/results_coconut/CNP0030335.log
'mass' ../coconut_data/results_coconut/CNP0126194.log
'mass' ../coconut_data/results_coconut/CNP0334816.log
'mass' ../coconut_data/results_coconut/CNP0290616.log
'mass' ../coconut_data/results_coconut/CNP0386127.log
'mass' ../coconut_data/results_coconut/CNP0406328.log
'mass' ../coconut_data/results_coconut/CNP0127289.log
'mass' ../coconut_data/results_coconut/CNP0032755.log
'mass' ../coconut_data/results_coconut/CNP0258640.log
'mass' ../coconut_data/results_coconut/CNP0199475.log
'mass' ../coconut_data/results_coconut/CNP0350989.log
'mass' ../coconut_data/results_coconut/CNP0333350.log
'mass' ../coconut_data/results_coconut/CNP0213544.log
'mass' ../coconut_data/results_coconut/CNP0204567.log
'mass' ../coconut_data/results_coconut/CNP0148525.log
'mass' ../coconut_data/results_coconut/CNP0053639.log
'mass' ../coconut_data/results_coconut/CNP0118368.log
'mass' ../coconut_data/results_coconut/CNP0226584.log
'mass' ../coconut_data/results_coconut/CNP0254221.log
'mass' ../coconut_data/results_coconut/CNP0241364.log
'mass' ../coconut_data/results_coconut/CNP0348684.log
'mass' ../coconut_data/results_coconut/CNP0053255.log
'mass' ../coconut_data/results_coconut/CNP0167909.log
'mass' ../coconut_data/results_coconut/CNP0142603.log
Treated 384150 files, skipped 72</p>
<h2 id="populating-the-mgf-headers"><a aria-hidden="true" class="anchor-heading icon-link" href="#populating-the-mgf-headers"></a>Populating the mgf headers</h2>
<h3 id="preparation-of-the-adducted-metadata-table"><a aria-hidden="true" class="anchor-heading icon-link" href="#preparation-of-the-adducted-metadata-table"></a>Preparation of the adducted metadata table</h3>
<p>We need to prepare and adducted dataframe containing the protonated and deprotonated masses</p>
<p>This script recquire rdkit so we build a environment.yml file from a dedicated conda env</p>
<p>conda env export -n conda-env -f /path/to/environment.yml</p>
<p>Eventually you need to fetch the file from the internet (use wget )</p>
<p>wget <a href="https://zenodo.org/record/3547718/files/COCONUT4MetFrag.csv?download=1">https://zenodo.org/record/3547718/files/COCONUT4MetFrag.csv?download=1</a></p>
<p>Sometimes since SMILES or INchi can yield error and since there is a MF field, the emass can be calculated directly form the MF as described here
<a href="https://bioinformatics.stackexchange.com/a/9273">https://bioinformatics.stackexchange.com/a/9273</a>. Noooop actually not working since the GetMass() function yield a molecular weight and not and exact mass ....</p>
<p>Script table_adducter_script.py is adapted to cope with different delimiters ... beware and note that $ is mandatory to input the tab delim</p>
<p>python table_adducter_npatlas_script.py ../npatlas_data/np_atlas_2019_12.tsv ../npatlas_data/np_atlas_2019_12_adducted.tsv</p>
<p>python table_adducter_script.py ../coconut_data/COCONUT4MetFrag.csv ',' ../coconut_data/COCONUT4MetFrag_adducted.csv $'\t'</p>
<h3 id="addition-of-the-metadata-to-the-individual-mgf-headers"><a aria-hidden="true" class="anchor-heading icon-link" href="#addition-of-the-metadata-to-the-individual-mgf-headers"></a>Addition of the metadata to the individual mgf headers</h3>
<p>We can now populate each raw mgf with its corresponding metadata. For this we use the treat_npatlas.py script</p>
<p>python treat_npatlas.py ../npatlas_data/np_atlas_2019_12_adducted.tsv ../npatlas_data/results_npatlas/npatlas/</p>
<p>python mgf_header_populater.py ../coconut_data/COCONUT4MetFrag_adducted.csv ../coconut_data/results_coconut/ Identifier</p>
<p>on coconut </p>
<p>Treated 384150 files, skipped 28161.</p>
<h2 id="generating-the-final-spectral-file"><a aria-hidden="true" class="anchor-heading icon-link" href="#generating-the-final-spectral-file"></a>Generating the final spectral file</h2>
<p>We concatenate each documented mgf files to a single spectral mgf file.</p>
<p>find ./ -type f -name '<em>.mgf' | while read F; do cat ${F} >> ../../npatlas_ISDB_pos.mgf; done
find ./ -type f -name '</em>.mgf' | while read F; do cat ${F} >> ../../coconut_ISDB_pos.mgf; done</p>
<h2 id="outputting-non-fragmented-entries"><a aria-hidden="true" class="anchor-heading icon-link" href="#outputting-non-fragmented-entries"></a>Outputting non-fragmented entries</h2>
<p>For several reasons (charged compounds, some tautomers, structures too heavy to be fragmented in a reasonable amount of time) some entries might not have been fragmented. </p>
<p>To find them we will first list all correctly converted mgf</p>
<p>find ./ -type f -name '<em>.mgf' | sed 's!.</em>/!!' | sed 's!^!!' >  list_mgf.txt</p>
<p>%%here eventually without the extension</p>
<p>find ./ -type f -name '<em>.mgf' | sed 's!.</em>/!!' | sed 's!.mgf!!' >  ../../list_mgf.txt</p>
<p>And then the list is compared to the initial input using the table_comparator.py </p>
<p>python table_comparator.py ../npatlas_data/npatlas_for_frag.txt ../npatlas_data/list_mgf.txt ../npatlas_data/unfragged_list.txt</p>
<h3 id="check-molvs-for-structure-standardization"><a aria-hidden="true" class="anchor-heading icon-link" href="#check-molvs-for-structure-standardization"></a>check molVS for structure standardization</h3>
<p><a href="https://molvs.readthedocs.io/en/latest/index.html">https://molvs.readthedocs.io/en/latest/index.html</a></p></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#tutorial-for-npatlas-in-silico-fragmentation-data-treatment" title="Tutorial for NPatlas in silico fragmentation data treatment">Tutorial for NPatlas in silico fragmentation data treatment</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#prior-to-fragmentation" title="Prior to fragmentation">Prior to fragmentation</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#prepare-space-delimited-input-file" title="Prepare space delimited input file">Prepare space delimited input file</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#split-the-file" title="Split the file">Split the file</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#when-using-the-docker-cli-files-need-to-have-an-extension-or-taken-as-folder-" title="When using the docker cli files need to have an extension (or taken as folder ?)">When using the docker cli files need to have an extension (or taken as folder ?)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#prepare-mutilple-bash-file-to-launch-on-baobab" title="Prepare mutilple bash file to launch on baobab">Prepare mutilple bash file to launch on baobab</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#fetching-cfm-predict-results" title="Fetching cfm-predict results">Fetching cfm-predict results</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#we-might-eventually-need-to-move-all-files-from-subfolders-recursively-to-a-superior-folder" title="We might eventually need to move all files from subfolders recursively to a superior folder">We might eventually need to move all files from subfolders recursively to a superior folder</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#pruning-the-raw-log-files" title="Pruning the raw log files">Pruning the raw log files</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#populating-the-mgf-headers" title="Populating the mgf headers">Populating the mgf headers</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#preparation-of-the-adducted-metadata-table" title="Preparation of the adducted metadata table">Preparation of the adducted metadata table</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#addition-of-the-metadata-to-the-individual-mgf-headers" title="Addition of the metadata to the individual mgf headers">Addition of the metadata to the individual mgf headers</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#generating-the-final-spectral-file" title="Generating the final spectral file">Generating the final spectral file</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#outputting-non-fragmented-entries" title="Outputting non-fragmented entries">Outputting non-fragmented entries</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#check-molvs-for-structure-standardization" title="check molVS for structure standardization">check molVS for structure standardization</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"6qK8k4MF0vooncgMJZw5W","title":"Isfrag","desc":"","updated":1635171184446,"created":1621006125043,"custom":{},"fname":"tools.chemoinformatics.isfrag","type":"note","vault":{"fsPath":"vault"},"contentHash":"911c3f1effa29164cae59d45a61e8b08","links":[{"type":"wiki","from":{"fname":"tools.chemoinformatics.isfrag","id":"6qK8k4MF0vooncgMJZw5W","vaultName":"vault"},"value":"202002251433","position":{"start":{"line":6,"column":11,"offset":55},"end":{"line":6,"column":27,"offset":71},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"202002251433"}}],"anchors":{"tutorial-for-npatlas-in-silico-fragmentation-data-treatment":{"type":"header","text":"Tutorial for NPatlas in silico fragmentation data treatment","value":"tutorial-for-npatlas-in-silico-fragmentation-data-treatment","line":20,"column":0,"depth":1},"prior-to-fragmentation":{"type":"header","text":"Prior to fragmentation","value":"prior-to-fragmentation","line":23,"column":0,"depth":2},"prepare-space-delimited-input-file":{"type":"header","text":"Prepare space delimited input file","value":"prepare-space-delimited-input-file","line":25,"column":0,"depth":3},"split-the-file":{"type":"header","text":"Split the file","value":"split-the-file","line":33,"column":0,"depth":3},"when-using-the-docker-cli-files-need-to-have-an-extension-or-taken-as-folder-":{"type":"header","text":"When using the docker cli files need to have an extension (or taken as folder ?)","value":"when-using-the-docker-cli-files-need-to-have-an-extension-or-taken-as-folder-","line":46,"column":0,"depth":3},"prepare-mutilple-bash-file-to-launch-on-baobab":{"type":"header","text":"Prepare mutilple bash file to launch on baobab","value":"prepare-mutilple-bash-file-to-launch-on-baobab","line":54,"column":0,"depth":3},"fetching-cfm-predict-results":{"type":"header","text":"Fetching cfm-predict results","value":"fetching-cfm-predict-results","line":62,"column":0,"depth":2},"we-might-eventually-need-to-move-all-files-from-subfolders-recursively-to-a-superior-folder":{"type":"header","text":"We might eventually need to move all files from subfolders recursively to a superior folder","value":"we-might-eventually-need-to-move-all-files-from-subfolders-recursively-to-a-superior-folder","line":81,"column":0,"depth":2},"pruning-the-raw-log-files":{"type":"header","text":"Pruning the raw log files","value":"pruning-the-raw-log-files","line":90,"column":0,"depth":2},"populating-the-mgf-headers":{"type":"header","text":"Populating the mgf headers","value":"populating-the-mgf-headers","line":185,"column":0,"depth":2},"preparation-of-the-adducted-metadata-table":{"type":"header","text":"Preparation of the adducted metadata table","value":"preparation-of-the-adducted-metadata-table","line":187,"column":0,"depth":3},"addition-of-the-metadata-to-the-individual-mgf-headers":{"type":"header","text":"Addition of the metadata to the individual mgf headers","value":"addition-of-the-metadata-to-the-individual-mgf-headers","line":210,"column":0,"depth":3},"generating-the-final-spectral-file":{"type":"header","text":"Generating the final spectral file","value":"generating-the-final-spectral-file","line":227,"column":0,"depth":2},"outputting-non-fragmented-entries":{"type":"header","text":"Outputting non-fragmented entries","value":"outputting-non-fragmented-entries","line":235,"column":0,"depth":2},"check-molvs-for-structure-standardization":{"type":"header","text":"check molVS for structure standardization","value":"check-molvs-for-structure-standardization","line":252,"column":0,"depth":3}},"children":[],"parent":"ppdn5ur1i340bqhfyvnk1yt","data":{}},"body":"\u003ch1 id=\"isfrag\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#isfrag\"\u003e\u003c/a\u003eIsfrag\u003c/h1\u003e\n\u003cp\u003ePasting an old recipee from ZettelKasten\u003c/p\u003e\n\u003cp\u003eLinked to \u003ca title=\"Private\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\" class=\"private\"\u003e202002251433 (Private)\u003c/a\u003e in silico fragmentation worflow.\u003c/p\u003e\n\u003cp\u003eChildren workflow on the beast MAPP \u003c/p\u003e\n\u003cp\u003eSide notes : try to write everything as scripts so that they can be launched without a GUI (ex on X2Go or directly Boabab).\u003c/p\u003e\n\u003ch1 id=\"tutorial-for-npatlas-in-silico-fragmentation-data-treatment\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#tutorial-for-npatlas-in-silico-fragmentation-data-treatment\"\u003e\u003c/a\u003eTutorial for NPatlas in silico fragmentation data treatment\u003c/h1\u003e\n\u003ch2 id=\"prior-to-fragmentation\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#prior-to-fragmentation\"\u003e\u003c/a\u003ePrior to fragmentation\u003c/h2\u003e\n\u003ch3 id=\"prepare-space-delimited-input-file\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#prepare-space-delimited-input-file\"\u003e\u003c/a\u003ePrepare space delimited input file\u003c/h3\u003e\n\u003cp\u003eComplete metadate file is converted to list of Unique ID and smiles space separated (for cfm id input)\u003c/p\u003e\n\u003cp\u003epython frag_list_preparator.py ../npatlas_data/np_atlas_2019_12.tsv ../npatlas_data/np_atlas_2019_12_for_frag.tsv NPAID SMILES\u003c/p\u003e\n\u003cp\u003epython frag_list_preparator.py ../open_np_db_data/open_NP_db.tsv ../open_np_db_data/open_NP_db_tofrag.txt shortinchikey shortinchikey smiles\u003c/p\u003e\n\u003ch3 id=\"split-the-file\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#split-the-file\"\u003e\u003c/a\u003eSplit the file\u003c/h3\u003e\n\u003cp\u003e(Works on Linux based shells)\u003c/p\u003e\n\u003cp\u003esplit -a 5 -l 500 -d ../open\u003cem\u003enp_db_data/open_NP_db_tofrag.txt ../open_np_db_data/opennpdb_tofrag/opennpdb\u003c/em\u003e\nsplit -a 5 -l 500 -d ./lotus\u003cem\u003edata/lotus_data_for_frag.txt ./lotus_data/lotus_data_for_frag/lotus_data\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003esplit -a 5 -l 500 -d ./ ./lotus\u003cem\u003edata/lotus_data_for_frag/lotus_data\u003c/em\u003e\nsplit -a 5 -l 500 -d cfm/cfm\u003cem\u003einput/platinum_tofrag.tsv cfm/cfm_input/splitted/lotus_to_frag\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eThis one allows to preserve extensions and is build on number of desired chunks without splitting lines\nsplit -a 5 -n l/199 -d --additional-suffix=.txt  cfm\u003cem\u003einput/sub_platinum_tofrag.tsv cfm_input/splitted/lotus_to_frag\u003c/em\u003e\u003c/p\u003e\n\u003ch3 id=\"when-using-the-docker-cli-files-need-to-have-an-extension-or-taken-as-folder-\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#when-using-the-docker-cli-files-need-to-have-an-extension-or-taken-as-folder-\"\u003e\u003c/a\u003eWhen using the docker cli files need to have an extension (or taken as folder ?)\u003c/h3\u003e\n\u003cp\u003efor f in *; do mv \"\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ef\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e\"\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e\"\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ef\" \"\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10764em;\"\u003ef\u003c/span\u003e\u003cspan class=\"mord\"\u003e\"\"\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003ef.txt\"; done\u003c/p\u003e\n\u003cp\u003eif you made a mistacke \u003c/p\u003e\n\u003cp\u003efind / -type f -name '*.txt' -exec sh -c 'mv -- \"\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmi mathvariant=\"normal\"\u003e\"\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e\"\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e0\" \"\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\"\"\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e{0%.txt}\"' {} \\;\u003c/p\u003e\n\u003ch3 id=\"prepare-mutilple-bash-file-to-launch-on-baobab\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#prepare-mutilple-bash-file-to-launch-on-baobab\"\u003e\u003c/a\u003ePrepare mutilple bash file to launch on baobab\u003c/h3\u003e\n\u003cp\u003e(strangely enough the .sh incrementer script return an error on Linux, runned OK on MacOS command line )\u003c/p\u003e\n\u003cp\u003eNote: apparently sbatch as been replaced by srun on the boabab server side. Be sure to update the scripts accordingly\u003c/p\u003e\n\u003ch2 id=\"fetching-cfm-predict-results\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#fetching-cfm-predict-results\"\u003e\u003c/a\u003eFetching cfm-predict results\u003c/h2\u003e\n\u003cp\u003eDownload cfm-predict fragmentation results from the baob server using rsync command\u003c/p\u003e\n\u003cp\u003ersync -rvz -e 'ssh' --progress \u003ca href=\"/commons-dws-public/mailto:allardp@baobab2.unige.ch\"\u003eallardp@baobab2.unige.ch\u003c/a\u003e:/home/allardp/CFM_results/npatlas ./results\nrsync -rvz -e 'ssh' --progress \u003ca href=\"/commons-dws-public/mailto:allardp@baobab2.unige.ch\"\u003eallardp@baobab2.unige.ch\u003c/a\u003e:/home/allardp/CFM_results/coconut/ .\u003c/p\u003e\n\u003cp\u003efind ./ -type f -name '*.mgf' | wc  \u003c/p\u003e\n\u003cp\u003eallows to count all file in a folder\nHere 25090 files for NPatalas\u003c/p\u003e\n\u003cp\u003eCoconut 384222 .log files\u003c/p\u003e\n\u003cp\u003e 384150 mgf files\u003c/p\u003e\n\u003ch2 id=\"we-might-eventually-need-to-move-all-files-from-subfolders-recursively-to-a-superior-folder\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#we-might-eventually-need-to-move-all-files-from-subfolders-recursively-to-a-superior-folder\"\u003e\u003c/a\u003eWe might eventually need to move all files from subfolders recursively to a superior folder\u003c/h2\u003e\n\u003cp\u003efind ./bacasable -type f -print0 | xargs -0 mv -t ./bacasable\u003c/p\u003e\n\u003cp\u003efind ./results_coconut -type f -print0 | xargs -0 mv -t ./results_coconut\u003c/p\u003e\n\u003ch2 id=\"pruning-the-raw-log-files\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#pruning-the-raw-log-files\"\u003e\u003c/a\u003ePruning the raw log files\u003c/h2\u003e\n\u003cp\u003eThe output of cfm-predict consist of .log file containing mass spectra, where each fragments are individually labelled and eventually linked to a substrcture. Such information might be usefull later but for now we only want to keep the raw ms data\u003c/p\u003e\n\u003cp\u003e(need to define a help function here)\u003c/p\u003e\n\u003cp\u003epython raw_log_treater_npatlas.py ../npatlas_data/results_npatlas/npatlas/ .log\npython raw_log_treater.py ../coconut_data/results_coconut/ .log\u003c/p\u003e\n\u003cp\u003eAt this step .log file should be pruned and contains only digits (m/z and intensities)\u003c/p\u003e\n\u003cp\u003efor coconut Parsing directory../coconut_data/results_coconut/ with file extension :.log\u003c/p\u003e\n\u003cp\u003e'mass' ../coconut_data/results_coconut/CNP0402147.log\n'mass' ../coconut_data/results_coconut/CNP0153817.log\n'mass' ../coconut_data/results_coconut/CNP0155980.log\n'mass' ../coconut_data/results_coconut/CNP0086807.log\n'mass' ../coconut_data/results_coconut/CNP0199206.log\n'mass' ../coconut_data/results_coconut/CNP0334817.log\n'mass' ../coconut_data/results_coconut/CNP0366374.log\n'mass' ../coconut_data/results_coconut/CNP0232712.log\n'mass' ../coconut_data/results_coconut/CNP0370068.log\n'mass' ../coconut_data/results_coconut/CNP0055178.log\n'mass' ../coconut_data/results_coconut/CNP0228597.log\n'mass' ../coconut_data/results_coconut/CNP0119974.log\n'mass' ../coconut_data/results_coconut/CNP0132139.log\n'mass' ../coconut_data/results_coconut/CNP0145457.log\n'mass' ../coconut_data/results_coconut/CNP0230801.log\n'mass' ../coconut_data/results_coconut/CNP0310370.log\n'mass' ../coconut_data/results_coconut/CNP0149436.log\n'mass' ../coconut_data/results_coconut/CNP0396848.log\n'mass' ../coconut_data/results_coconut/CNP0401434.log\n'mass' ../coconut_data/results_coconut/CNP0101561.log\n'mass' ../coconut_data/results_coconut/CNP0390928.log\n'mass' ../coconut_data/results_coconut/CNP0405256.log\n'mass' ../coconut_data/results_coconut/CNP0395006.log\n'mass' ../coconut_data/results_coconut/CNP0159145.log\n'mass' ../coconut_data/results_coconut/CNP0131085.log\n'mass' ../coconut_data/results_coconut/CNP0230696.log\n'mass' ../coconut_data/results_coconut/CNP0014450.log\n'mass' ../coconut_data/results_coconut/CNP0214739.log\n'mass' ../coconut_data/results_coconut/CNP0302005.log\n'mass' ../coconut_data/results_coconut/CNP0279314.log\n'mass' ../coconut_data/results_coconut/CNP0177036.log\n'mass' ../coconut_data/results_coconut/CNP0274256.log\n'mass' ../coconut_data/results_coconut/CNP0403745.log\n'mass' ../coconut_data/results_coconut/CNP0039287.log\n'mass' ../coconut_data/results_coconut/CNP0238803.log\n'mass' ../coconut_data/results_coconut/CNP0014261.log\n'mass' ../coconut_data/results_coconut/CNP0077076.log\n'mass' ../coconut_data/results_coconut/CNP0125300.log\n'mass' ../coconut_data/results_coconut/CNP0228582.log\n'mass' ../coconut_data/results_coconut/CNP0393136.log\n'mass' ../coconut_data/results_coconut/CNP0338003.log\n'mass' ../coconut_data/results_coconut/CNP0070182.log\n'mass' ../coconut_data/results_coconut/CNP0230961.log\n'mass' ../coconut_data/results_coconut/CNP0001326.log\n'mass' ../coconut_data/results_coconut/CNP0088652.log\n'mass' ../coconut_data/results_coconut/CNP0045797.log\n'mass' ../coconut_data/results_coconut/CNP0175458.log\n'mass' ../coconut_data/results_coconut/CNP0300969.log\n'mass' ../coconut_data/results_coconut/CNP0030335.log\n'mass' ../coconut_data/results_coconut/CNP0126194.log\n'mass' ../coconut_data/results_coconut/CNP0334816.log\n'mass' ../coconut_data/results_coconut/CNP0290616.log\n'mass' ../coconut_data/results_coconut/CNP0386127.log\n'mass' ../coconut_data/results_coconut/CNP0406328.log\n'mass' ../coconut_data/results_coconut/CNP0127289.log\n'mass' ../coconut_data/results_coconut/CNP0032755.log\n'mass' ../coconut_data/results_coconut/CNP0258640.log\n'mass' ../coconut_data/results_coconut/CNP0199475.log\n'mass' ../coconut_data/results_coconut/CNP0350989.log\n'mass' ../coconut_data/results_coconut/CNP0333350.log\n'mass' ../coconut_data/results_coconut/CNP0213544.log\n'mass' ../coconut_data/results_coconut/CNP0204567.log\n'mass' ../coconut_data/results_coconut/CNP0148525.log\n'mass' ../coconut_data/results_coconut/CNP0053639.log\n'mass' ../coconut_data/results_coconut/CNP0118368.log\n'mass' ../coconut_data/results_coconut/CNP0226584.log\n'mass' ../coconut_data/results_coconut/CNP0254221.log\n'mass' ../coconut_data/results_coconut/CNP0241364.log\n'mass' ../coconut_data/results_coconut/CNP0348684.log\n'mass' ../coconut_data/results_coconut/CNP0053255.log\n'mass' ../coconut_data/results_coconut/CNP0167909.log\n'mass' ../coconut_data/results_coconut/CNP0142603.log\nTreated 384150 files, skipped 72\u003c/p\u003e\n\u003ch2 id=\"populating-the-mgf-headers\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#populating-the-mgf-headers\"\u003e\u003c/a\u003ePopulating the mgf headers\u003c/h2\u003e\n\u003ch3 id=\"preparation-of-the-adducted-metadata-table\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#preparation-of-the-adducted-metadata-table\"\u003e\u003c/a\u003ePreparation of the adducted metadata table\u003c/h3\u003e\n\u003cp\u003eWe need to prepare and adducted dataframe containing the protonated and deprotonated masses\u003c/p\u003e\n\u003cp\u003eThis script recquire rdkit so we build a environment.yml file from a dedicated conda env\u003c/p\u003e\n\u003cp\u003econda env export -n conda-env -f /path/to/environment.yml\u003c/p\u003e\n\u003cp\u003eEventually you need to fetch the file from the internet (use wget )\u003c/p\u003e\n\u003cp\u003ewget \u003ca href=\"https://zenodo.org/record/3547718/files/COCONUT4MetFrag.csv?download=1\"\u003ehttps://zenodo.org/record/3547718/files/COCONUT4MetFrag.csv?download=1\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSometimes since SMILES or INchi can yield error and since there is a MF field, the emass can be calculated directly form the MF as described here\n\u003ca href=\"https://bioinformatics.stackexchange.com/a/9273\"\u003ehttps://bioinformatics.stackexchange.com/a/9273\u003c/a\u003e. Noooop actually not working since the GetMass() function yield a molecular weight and not and exact mass ....\u003c/p\u003e\n\u003cp\u003eScript table_adducter_script.py is adapted to cope with different delimiters ... beware and note that $ is mandatory to input the tab delim\u003c/p\u003e\n\u003cp\u003epython table_adducter_npatlas_script.py ../npatlas_data/np_atlas_2019_12.tsv ../npatlas_data/np_atlas_2019_12_adducted.tsv\u003c/p\u003e\n\u003cp\u003epython table_adducter_script.py ../coconut_data/COCONUT4MetFrag.csv ',' ../coconut_data/COCONUT4MetFrag_adducted.csv $'\\t'\u003c/p\u003e\n\u003ch3 id=\"addition-of-the-metadata-to-the-individual-mgf-headers\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#addition-of-the-metadata-to-the-individual-mgf-headers\"\u003e\u003c/a\u003eAddition of the metadata to the individual mgf headers\u003c/h3\u003e\n\u003cp\u003eWe can now populate each raw mgf with its corresponding metadata. For this we use the treat_npatlas.py script\u003c/p\u003e\n\u003cp\u003epython treat_npatlas.py ../npatlas_data/np_atlas_2019_12_adducted.tsv ../npatlas_data/results_npatlas/npatlas/\u003c/p\u003e\n\u003cp\u003epython mgf_header_populater.py ../coconut_data/COCONUT4MetFrag_adducted.csv ../coconut_data/results_coconut/ Identifier\u003c/p\u003e\n\u003cp\u003eon coconut \u003c/p\u003e\n\u003cp\u003eTreated 384150 files, skipped 28161.\u003c/p\u003e\n\u003ch2 id=\"generating-the-final-spectral-file\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#generating-the-final-spectral-file\"\u003e\u003c/a\u003eGenerating the final spectral file\u003c/h2\u003e\n\u003cp\u003eWe concatenate each documented mgf files to a single spectral mgf file.\u003c/p\u003e\n\u003cp\u003efind ./ -type f -name '\u003cem\u003e.mgf' | while read F; do cat ${F} \u003e\u003e ../../npatlas_ISDB_pos.mgf; done\nfind ./ -type f -name '\u003c/em\u003e.mgf' | while read F; do cat ${F} \u003e\u003e ../../coconut_ISDB_pos.mgf; done\u003c/p\u003e\n\u003ch2 id=\"outputting-non-fragmented-entries\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#outputting-non-fragmented-entries\"\u003e\u003c/a\u003eOutputting non-fragmented entries\u003c/h2\u003e\n\u003cp\u003eFor several reasons (charged compounds, some tautomers, structures too heavy to be fragmented in a reasonable amount of time) some entries might not have been fragmented. \u003c/p\u003e\n\u003cp\u003eTo find them we will first list all correctly converted mgf\u003c/p\u003e\n\u003cp\u003efind ./ -type f -name '\u003cem\u003e.mgf' | sed 's!.\u003c/em\u003e/!!' | sed 's!^!!' \u003e  list_mgf.txt\u003c/p\u003e\n\u003cp\u003e%%here eventually without the extension\u003c/p\u003e\n\u003cp\u003efind ./ -type f -name '\u003cem\u003e.mgf' | sed 's!.\u003c/em\u003e/!!' | sed 's!.mgf!!' \u003e  ../../list_mgf.txt\u003c/p\u003e\n\u003cp\u003eAnd then the list is compared to the initial input using the table_comparator.py \u003c/p\u003e\n\u003cp\u003epython table_comparator.py ../npatlas_data/npatlas_for_frag.txt ../npatlas_data/list_mgf.txt ../npatlas_data/unfragged_list.txt\u003c/p\u003e\n\u003ch3 id=\"check-molvs-for-structure-standardization\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#check-molvs-for-structure-standardization\"\u003e\u003c/a\u003echeck molVS for structure standardization\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://molvs.readthedocs.io/en/latest/index.html\"\u003ehttps://molvs.readthedocs.io/en/latest/index.html\u003c/a\u003e\u003c/p\u003e","noteIndex":{"id":"QvYK9hGbCvPpEfSRYhV8j","title":"Welcome to the COMMONS Lab Open Dendron","desc":"","updated":1693056226815,"created":1630130450048,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"20f67df3dd870fc450a162c202c9ff41","links":[{"type":"wiki","from":{"fname":"root","id":"QvYK9hGbCvPpEfSRYhV8j","vaultName":"vault"},"value":"open-notebook.commons.setup","position":{"start":{"line":43,"column":118,"offset":1871},"end":{"line":43,"column":149,"offset":1902},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"open-notebook.commons.setup"}}],"anchors":{"what-is-this-note":{"type":"header","text":"What is this note","value":"what-is-this-note","line":16,"column":0,"depth":2},"tutorial":{"type":"header","text":"Tutorial","value":"tutorial","line":20,"column":0,"depth":2},"dendron":{"type":"header","text":"Dendron.","value":"dendron","line":22,"column":0,"depth":3},"what-is-dendron-":{"type":"header","text":"What is Dendron ?","value":"what-is-dendron-","line":24,"column":0,"depth":4},"where-to-get-more-info-on-dendron-":{"type":"header","text":"Where to get more info on Dendron ?","value":"where-to-get-more-info-on-dendron-","line":30,"column":0,"depth":4},"concrete-steps-to-access-and-contribute-to-the-dbgi-dendron":{"type":"header","text":"Concrete steps to access and contribute to the DBGI Dendron","value":"concrete-steps-to-access-and-contribute-to-the-dbgi-dendron","line":35,"column":0,"depth":4},"questions-comments-suggestions-":{"type":"header","text":"Questions, comments, suggestions ?","value":"questions-comments-suggestions-","line":52,"column":0,"depth":2}},"children":["5o0tvzf4l6t6moau7en1v48","e4ul30admmxm9ilxfq275cq","h78qbvh1fd9bwcykmcm9uo3","6ooxuf27zzf3grb14o18qf2","tiqo5upbg6224t7i8p87iok","ltq8wcrabmq6mlescrdi4m0","bdq3suiz8yriznljea2zpug","ih6vyup3yre4m9woc9ldl7k","vDTgZL9UHWqYtBFdtD3vK","69ekb2qhuwukr0jwrzy6tnw","373694o1o6ocqohko4um7c9","jldFUSJGjDf1mFH8c2yUI","dh2qp7w4tl6otf89xrmxitv","2rvdf4t5qnx5hqjj29bojcc","stj9lq0lxhfuk5ntomiozz0","gvdyfgvq0z08fcfaqzmhtjo","2rvclk21kfedpvxuzjpizi7","dcwgamgyghrlyau1avlh6ug","432qdutuo1i8h5pcuh39ytt","2npxodkvs5jk6p1eksi551b","h81rw16zzgh9kix8ti1mbam","lco50o42dfeph5i5f2k981w","46d1odkovrpdi6g16992phy","s9gzk7nphtjzmpdqvk5y4vj","82ra6p4ykf814hp8yfw4wp6","hpnaglyhnb48vuiniqecnqf","y7nk7xmiht44neo0q7cl5cs","2cxr093kvrg4jojokwgqrbj","8vfu5h3617jbzy78xr2hlo1","w75krbmkkvla3hwd66hn5bh","40po5od17ekcr1e77dluxao","4pqppog2u66rx1tkc8jy5v9","ektni5nfulyro7dkrbtek7j","vfsp2aci6vy7kg2jsyy8tzu","0wm4geq40t6nscn88rcwu47","ib4jmxy1x3l1r0ewe6hln4j","0h57aw0be2jnc3dxcpn3ajn","4789z8f1dqdh5k3nmgr1m4z","p5dszyuhj1klgje0brtv0xj","sk4m9gq7vz2t9phcxlxvqpw","43p60vv8btyhaclugl93jok","zhc9hhpaobkbo4e2votv6wr","ylulfzi7ra5yv6ja7j78t6e","wj0i9czxvt4v0b674nb8501","ovslc641d0h00s16tf6kl8w","4zmlbmcp6q4q69ycvhavzr6","59ftsVxFXXM9bB43vfKwK","nmnpsy2e1rwqnqgurogi2u6","6b5uf8hv44mbgircddcb46i","s9j6c26u6qgl5dvnqv8opam","je0ksq927btmorptaje6a4p","xm4a1smh9gcahxda5bssxfi","3cgqlppr4es3iuoa2o3mhn8","d6edcr5j5kjgdt791uujpn0","zfu2gniwqhgo1j44r3yfx7y","gap1pjhvt94m5izg0zlef0w","o3y0vguickctv1yx4z42qev","g78c0e4ts7wgkof1ykkgzbl","hsqldiv7revakz0fqay51eu","99wwtyhexdqu5bxrtgn9whw","m8e37qw6n4i3cfv9ohq7e82","ds1s2fjqhwvw1zqst8l4z4f","ec4pkybo5iwljo3zdr9894x","cbikmu2vjnxulf5tf9xfist","1icb0ka0yjwpoerg4zym9la"],"parent":null,"data":{},"body":"\n![](/assets/images/allard-lab.jpg)\n\nWelcome the the COMMONS Lab Open Dendron !\n\nIn the [COMMONS Lab](https://www.unifr.ch/bio/en/groups/allard/) we intent to follow the [Open Notebook Science](https://en.wikipedia.org/wiki/Open-notebook_science) approach to document our research.\n\nFor this we use the [Dendron](https://www.dendron.so/) system as a mean to efficiently capture notes and publish them.\n\n## What is this note\n\nThis note is a succinct tutorial note aiming to get you started in the use of the COMMONS Lab Dendron.\n\n## Tutorial\n\n### Dendron. \n\n#### What is Dendron ?\n\n\u003e Dendron is an open-source, local-first, markdown-based, note-taking tool. Think of it as a cache for everything that you care about - if you've spent more then five minutes solving a problem, you should never spent any more time solving the same exact problem.\n\u003e \n\u003e Dendron is a knowledge base built by and for developers and integrates natively with IDEs like VS Code and VSCodium.\n\n#### Where to get more info on Dendron ?\n\n- You can get more information in the Dendron system at the official website www.dendron.so\n- All the Dendron documentation is hosted here https://wiki.dendron.so/. It is, obviously, a Dendron itself.\n\n#### Concrete steps to access and contribute to the DBGI Dendron\n\n1. Install [VSCode](https://code.visualstudio.com/download)\n2. Install [Dendron](https://marketplace.visualstudio.com/items?itemName=dendron.dendron) from the VSCode marketplace \n3. Clone the COMMONS Dendron repo\n\n    In your terminal\n    ```\n    git clone https://github.com/commons-research/commons-dws-public.git\n    ```\n4. In VSCode open (File/Open) the cloned repository.\n5. Voila ! You should now be in the COMMONS Lab Open Dendron.\n\nFeel free to explore and contribute.\nA first, important step could be to configure VSCode so that you can easily add a daily note. See steps described at [[open-notebook.commons.setup]]\n\n\n## Questions, comments, suggestions ?\n\nFeel free to contribute here https://github.com/orgs/commons-research/discussions\n\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"vaultSelectionModeOnCreate":"smart","fuzzThreshold":0.2}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.112.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"assetsPrefix":"/commons-dws-public","copyAssets":true,"siteHierarchies":["root"],"enableSiteLastModified":true,"siteRootDir":"docs","siteUrl":"https://commons-research.github.io","enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"writeStubs":false,"seo":{"title":"COMMONS DWS Public","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Click here to edit this page on Github !","editBranch":"main","editViewMode":"edit","editRepository":"https://github.com/commons-research/commons-dws-public"},"enablePrettyLinks":true,"enableTaskNotes":true,"siteFaviconPath":"favicon.ico","siteIndex":"root","searchMode":"lookup"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"6qK8k4MF0vooncgMJZw5W"},"buildId":"KWnqrj5vUmxn1r58uXWxO","assetPrefix":"/commons-dws-public","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>