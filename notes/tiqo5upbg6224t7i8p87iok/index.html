<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/commons-dws-public/favicon.ico"/><title>Best Practices</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="Best Practices"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://commons-research.github.io/commons-dws-public/notes/tiqo5upbg6224t7i8p87iok/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="5/2/2024"/><meta property="article:modified_time" content="5/2/2024"/><link rel="canonical" href="https://commons-research.github.io/commons-dws-public/notes/tiqo5upbg6224t7i8p87iok/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/commons-dws-public/_next/static/css/47f58a23998994fc.css" as="style"/><link rel="stylesheet" href="/commons-dws-public/_next/static/css/47f58a23998994fc.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/commons-dws-public/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/commons-dws-public/_next/static/chunks/webpack-18f1eb2dd0aac0df.js" defer=""></script><script src="/commons-dws-public/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/commons-dws-public/_next/static/chunks/main-1bd061c8c8d18148.js" defer=""></script><script src="/commons-dws-public/_next/static/chunks/pages/_app-8bc9d81129a787a1.js" defer=""></script><script src="/commons-dws-public/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/commons-dws-public/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/commons-dws-public/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/commons-dws-public/_next/static/KWnqrj5vUmxn1r58uXWxO/_buildManifest.js" defer=""></script><script src="/commons-dws-public/_next/static/KWnqrj5vUmxn1r58uXWxO/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="best-practices"><a aria-hidden="true" class="anchor-heading icon-link" href="#best-practices"></a>Best Practices</h1>
<p>Have a look at <a href="http://berkeleybop.github.io/best_practice/">http://berkeleybop.github.io/best_practice/</a></p>
<p>This is the best practice / house style guide for the BBOP group. Inspired by / cribbed from Knocean practice and other sources.</p>
<p>Source: berkeleybop/berkeleybop.github.io/blob/master/best_practice</p>
<p>We are a diverse group working on many different projects with different stakeholders and sets of collaborators. Nevertheless we strive to follow a set of core best practices so we can be most efficient and develop the highest quality code, ontologies, standards, schemas, and analyses.</p>
<p>This document may be overwhelming at first but as you become more familiar with projects it should become second nature. If there is anything you don’t understand, ask on slack!</p>
<p>Git and GitHub
use git ubiquitously
commit early, commit often
perfect later!
you should always be working on a branch, so don’t worry about breaking things
make a PR for your branch - mark as draft if not ready
Make repos public by default
Use standard repo layouts
choose a cookiecutter
monarch-project-template for code-oriented projects
don’t reinvent
look at exemplars
Include standard files:
README.md
LICENSE (BSD3 or Apache preferred for software)
CONTRIBUTING.md
CODE_OF_CONDUCT.md (see for example kgx CoC
Changes.md
.gitignore
Makefile or equivalent
see below for more specific recommendations for specific kinds of repos
use GitHub
Like GitLab in principle, but GitHub has network effect
prefer to work on the main repo, not forks, but defer to project-specific guidelines
Read our GitHub Overview
Use GitHub issues
in general you should always be working to a ticket assigned to you
try to assign every issue to somebody
try to have a single assignee / responsible person
tag people if necessary
note: if you tag me with <a title="Private" href="https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html" target="_blank" class="private">@cmungall (Private)</a> it’s likely I won’t see it. alert me to a ticket via slack if I am required
use GitHub’s default labels: bug, question, enhancement, good first issue, etc.
set up standard issue templates (helps ensure tickets are auto-assigned)
When creating issues:
give a meaningful issue title
word title as a bug, e.g. “under condition X, Y fails” or a request, e.g. “add option A to method B”
give issue actionable descriptions, make it clear when an issue can be closed
see Seth’s suggestions for creating awesome issues
use GitHub Pull Requests
read the obook PR review guide
mark as draft until ready for review, then assign reviewers
description should link to an issue (“Resolves #1234”) to automatically close issue when PR is merged
otherwise you have to clean up issues manually
update description as needed
always look over your commits before making a PR
are there unexpected changes? You should only see YOUR changes
Is it adding files unexpectedly? Some git clients are eager to do this
are some changes not recognizable as yours? Be careful not to clobber
follow repo-standard practice for rebase etc
AVOID:
making PRs too large
mixing orthogonal concerns in one PR. Generally 1 PR = 1 issue
mixing in formatting changes on sections of the code unrelated to the semantic changes you are making
working on a PR for too long a time without feedback from others
working on “invisible” branches. ALWAYS make a PR, ALWAYS push. You can mark as draft!
give PRs a meaningful title and description
remember: titles will be used when auto-making release notes
use GitHub Milestones to plan releases
use GitHub Releases to tag versions and attach binaries
use semver (except for ontologies)
use the auto-generate release notes feature
corollary: write informative PR titles and never commit on main
if making a non-patch release, select the previous minor/major to diff from
use GitHub Pages for simple static content and documentation
prefer the docs/ directory option
See exemplars: OAK, Biolink Model
use GitHub Projects (“project boards”) for coordinating issues and PRs
three columns:
To do: for manager to fill and prioritize
In progress: for developer to keep up-to-date
Ready for review: for manager to empty
order of preference for cards: PR link, issue link, text
set up GitHub actions to do CI
Migrate if you are on an old travis repo
All changes should be on PRs thus validated
main branch should never ever be failing
EVERY repo should have actions and PR checking
set up GitHub teams
default to public membership
make sure it is clear who has permission to merge PRs
set up badges
always: CI
pypi, downloads, codecov, zenodo, …
Configure the “About” (see gear icon on right)
use standard topics
biolink
linkml
obofoundry
monarchinitiative
geneontology
Orgs
define a standard topic (see above)
include a .github
examplar: github.com/linkml
pin repos
make sure all relevant artefacts are checked in
use git status and .gitignore
in general avoid checking in derived products (but see below)
avoid checking in .xslx files (use TSVs; or consider cogs instead)
versioning
do not check in files with version numbers e.g. foo.v1.txt into GitHub - git does versioning for you
use the GitHub release mechanism
use ISO-8601 or semver schemes (see guidelines on specific repo types below)
tend your repos
remove cruft such as obsolete files (GitHub preserves history)
avoid random stuff at top level
keep README in sync
avoid using spaces in filenames
always use standard suffixes (e.g. .tsv, .txt, .md)
kabob-case-is-a-good-default.txt. See filenames in google developer guide
Don’t rename files and commit - use “git mv” instead, so that the history of the file is preserved
use topics and “star” relevant repos
<a href="https://github.com/topics/linkml">https://github.com/topics/linkml</a>
<a href="https://github.com/topics/obofoundry">https://github.com/topics/obofoundry</a>
<a href="https://github.com/topics/geneontology">https://github.com/topics/geneontology</a>
<a href="https://github.com/topics/monarchinitiative">https://github.com/topics/monarchinitiative</a>
always star your own repos
star your colleagues and collaborator’s repos
tips
the gh github cli client is very useful, e.g. gh pr Software:
Nico recommends gh Desktop
Code-centric Repos
Use an existing repo from a group member as template for best practice, e.g.,
kgx
linkml
OAK
Or better: monarch project cookiecutter
Include a README.md
provide sufficient context
don’t boil the ocean - put reference material in a separate reference guide
include examples and use examples as tests
Create reference documentation using RTD/Sphinx
let inline docstrings in Python do most of the work for you
read writethedocs
Include installation instructions
use an OSI approved LICENSE, BSD3 preferred
Use unit tests
consult others on framework
Use GitHub-integrated CI
formerly Travis
use GitHub actions
Release code to PyPI or appropriate repo
use GitHub releases
use GitHub actions to trigger releases to PyPI
use GitHub actions to trigger releases to PyPI
see nmdc-schema as exemplar
make release notes automatically see github guide
relies on using PRs with well-described titles
always have multiple owners of a pypi package on the pypi site
use standard semver, start from 0.1.0, move to 1.0.0 when stable
Consider a Dockerfile
For ETL repos, follow standard templates for
kg-hub
koza
For ETL repos
Use Jenkins pipelines
Badges
CI
Code coverage
PyPI
TODO: ADD MORE
Schema/Standards-centric Repos, Data and metadata repos
Use LinkML
Create repo from LinkML template
Examples:
NMDC
MIxS
GFF3 linkml
chemkg/chemrof
Register with w3id.org
Include comprehensive examples
Use LinkML mkdocs framework
Understand the difference between OWL-centric and KG-centric modeling
include mappings to Biolink Model
always include examples
integrate these with documentation
integrate these with unit tests
also include counter-examples
data deliberately designed to fail validation
check validation correctly identifiers these in github actions
enable zenodo syncing
For repos that have data:
consider a dashboard (see semantic dashbaord patterns)
Ontology-centric Repos
Use ODK seed
Register ontology with OBO if appropriate
include detailed metadata
include all products
include descriptive material in markdown
Exceptions:
application ontologies
ontologies that deliberately not OBO-esque
Register non OBOs with Bioportal + w3id
Use GitHub for .owl distribution unless ontology is large, then consider:
GitHub releases
S3
See Nico’s application ontology tutorial
Follow group exemplars: Uberon, Mondo, GO, ENVO, CL, PATO, BERO, PhenIO
but be aware each has their quirks
distribute useful products
distribute SSSOM
always distribute an .obo
always distribute a obo .json
distribute a kgx file (NEW)
distribute a rdftab/semsql sqlite file (NEW)
use a sensible source format (foo-edit.owl)
.obo is best for diffs but less expressive and gotchas for CURIEs
functional syntax is often preferred
for template-based ontologies, much of the source may be TSVs
enable zenodo syncing
Understand issues relating to git conflicts with ontologies
.obo as source mitigates some of these
See this thread
See this post
many issues have since been resolved but unfortunately some remain
Analysis/Paper-centric Repos
One repo per paper
Entire analysis must be reproducible via Makefile
All steps:
download
clean/pre-process
transform
training
evaluation
check with Chris before using snakemake/CWL/alternatives
Use TSVs as default
make pandas-friendly
use unix newline characters, not dos
use human readable but computationally friendly column headers
NO ALL CAPS
alphanumeric characters preferred
spaces or underscores as word separators OK, but underscores preferred for formal formats
csvkit is your friend
ALL TSVs MUST have data dictionaries
use LinkML (see above)
check in small-mid size data files (&#x3C;10m)
consider cogs if TSVs must be managed in google sheets
use JSON for complex data
use KGX for anything that should be modeled as a KG
use descriptive filenames
manage metadata in GitHub
enable zenodo syncing
use S3 for larger files
release files to Zenodo
Dockerize
Use Jupyter notebooks
Consider Manubot
Other recommended best practices
datadryad
Development Environment Setup
Code Editors:
vscode
pycharm
get professional, we will pay
GitHub copilot can be purchased as well, and is an excellent addition to a pycharm environment.
Keyboard Shortcuts
Command palette: Cmd/Ctrl + Shift + P
Search for file in project: Cmd/Ctrl + P
Open integrated terminal in VSCode: Cmd/Ctrl + ~
Open settings page: Cmd/Ctrl + ,
Set up custom keymap bindings
Mac
Code > Preferences > Keyboard Shortcuts > +`
Type in the key combination you want to use and assign it to an action of your choice
For ex., Cmd/Ctrl + i as a shortcut for selecting the Python interpreter
Essentials
Git configuration
Set username: git config --global user.name "YOUR_USERNAME"
Set password: git config --global user.email "<a href="/commons-dws-public/mailto:YOUR_EMAIL@EXAMPLE.COM">YOUR_EMAIL@EXAMPLE.COM</a>"
Workspace setup
Make sure you have correctly selected the Python interpreter
Save workspace in order to open a specific view of the project directory
File > Save Workspace As
File > Open Workspace From File
Useful Extensions
Python
Python IntelliSense
Linting
Debugging
Code navigation
Formatting
Refactoring
AutoDocstring
Docstring for Python methods
black
Opinionated Python code formatter
GitLens
Visualize code authorship
Better Comments
Human friendly comments
Rainbow CSV
Highlight columns in csv and tsv files
Transforms and filtering using querying language
Markdown All in One
Keyboard shortcuts
Table of contents
Auto preview
Prettier
Formatting YAML, JSON
But primarily an opinionated formatter for frontend web code like JS, TS, etc.
YAML
YAML validation
Auto completion
Hover support
Useful while writing LinkML schemas
vs-code-icons
Beautiful icons
Austin VS Code
Code profiler
Can be used when trying to optimize Python codebase
Simple Websites
GitHub pages favored over google sites over wikis
Manage and author content as markdown, managed in github, with PRs as for code
Google Analytics
Example GA 4 conversion and walkthrough info at <a href="https://github.com/berkeleybop/bbops/issues/28#issuecomment-1712154894">https://github.com/berkeleybop/bbops/issues/28#issuecomment-1712154894</a>
avoid manually authoring anything that can be derived from metadata
examplars: obofoundry.github.io, this site
use CC-BY 4.0 or the CC0 public domain declaration
Examplars:
LinkML splash page
Phenopackets splash page
Cell Ontology splash page
Documentation
See google guide on Writing inclusive documentation
Avoid ableist language
Avoid unnecessarily gendered language
Avoid unnecessarily violent language
all code, schemas, analyses, ontologies, MUST be documented
documentation is a love-letter to your future self
understand the Diataxis four-way distinction: tutorial, how-to, reference, explanation
exemplar: OBOOK
exemplar: LinkML docs
google API documentation guide
have strategies to avoid staleness and documentation getting out of sync
use inline documentation
publish via appropriate framework (RTD for code, mkdocs for schema, etc)
follow appropriate style guide
use and test docstring in python
<a href="https://docs.python.org/3/library/doctest.html">https://docs.python.org/3/library/doctest.html</a>
examples, examples, examples
fenced examples in markdown docs
example standalone scripts
example Jupyter notebooks
double up: unit tests can serve as examples and vice versa
See linkml-run-examples framework
Use existing templates
monarch-project-template for code-oriented projects
linkml cookiecutter for schema projects
ODK for ontology projects
kghub template for KG projects
use Markdown as default
RST for Sphinx/Code projects
Google docs acceptable for initial brainstorming
Don’t use Wikis (mediawiki, GitHub wiki)
Manage markdown docs as version control
publish as static site (RTD, mkdocs, etc)
Coding/Python
Python is the default language; use others as appropriate
javascript/typescript for client-side
don’t implement domain/business logic in js. use python + APIs
use typescript
generate typescript datamodels using linkml gen-typescript
Rust for speed
should always have PyO3 wrappers
follow semsimian GH actions for wheels
Scala for performance reasoners or anything requiring owlapi
Historically we used Java for anything requiring OWLAPI but being phased out
Why Python?
ubiquitous, cross-platform
good for scripting, interactive development
strong ecosystem of libraries for almost anything
Easy for developers to pick up
Most bioinformaticians know it
use for anything more than about 10 lines of Bash/Perl
use Python 3.8+
Ensure github actions tests 3.9, 3.11
Conform to the group style guide, or at least some style guide
pep-0008 for Python
use type annotations PEP484
google style guide
We are inspired by knocean/practices/python but differ in some places
We make use of OO as appropriate - just don’t go overboard like in java
Follow conventional variable naming
Example: <a href="https://docs.fast.ai/dev/abbr.html">https://docs.fast.ai/dev/abbr.html</a>
See the Working with Python Environments guide for details on installing Python versions and managing virtual environments.
All repos should use poetry
Set up this way: poetry new --src my-project-name
OR use linkml-ws new for schema-centric repos
follow standard layouts, with code in src/
Linting/formatting:
Use black and flake8 and ruff
Test Runners
To automate building and testing distributions in multiple Python versions
tox
DE FACTO: Github hosted runner via Github Actions
CLI development
click
Testing
unittest
DE FACTO: pytest
Test coverage
Coverage.py
codecov
document all public classes, methods, functions
Always Use type annotations
Always provide docstrings
ReST (reStructuredText) » numpy-style docstrings or google style » nothing
SOME standard is always better than none
Be sure to set up your IDE for automatic docstring generation
use flask/fastAPI for web apps
NEVER author OpenAPI directly; ALWAYS derive
we are exploring GraphQL frameworks like strawberry.rocks
use dataclasses or pydantic
for DAOs, ALWAYS derive from linkml
avoid authoring data models directly in python
list comprehensions » lambdas
use fstrings; never write java-style python
ALWAYS use typing
makes code more understandable
allows code completion in PyCharm etc
helps find bugs
use an IDE
PyCharm or VS is equally popular in the group
ETL/ingest
follow existing exemplar repos
Read Chris’ 10 simple rules for semantic ETL
use requests for URL calls
Always provide a CLI
separate CLI logic from core logic
Read CLIG guidelines
See also [Documenting command-line syntax ]<a href="https://developers.google.com/style/code-syntax">https://developers.google.com/style/code-syntax</a>) in google style guide
Python: use click
design for composability
provide shortforms for common options
Display help text when passed no options, the -h flag, or the –help flag
use de-facto standards
-i, --input
-o, --output
-h, --help
always use dashes as separators, NOT underscores
click will make corresponding python vars with underscores
Follow exemplars
ROBOT
SSSOM
OAK
linkml
Always write unittests for CLIs
see OAK for examples
Profiling:
cProfile and SnakeViz are useful for profiling Python code ```bash
Generate the profile results:
python -m cProfile -o output.prof my_program.py</p>
<p>View them:
pipx run snakeviz output.prof ```</p>
<p>Examplars:
sssom-py
linkml
OAK
Learning resources
Charlie’s Recommended Python Programming Videos
OBOOK - Open Biological and Biomedical Ontologies Organized Knowledge
Web APIs
Authoring
FastAPI » Flask
Seperate business logic from API code
this should be independently testable
Testing
use fastapi.testclient
follow GO exemplar
Accessing
Use python requests library (unless a higher level lib is available)
Do not construct URL strings yourself - use params instead
for non-trivial tasks consider building a reusable client library
use a client library if it already exists!
examplars: OAK bioportal implementation
when querying a sparql endpoint
sparqlfun > sparqlwrapper > requests > curl
if constructing sparql is necessary
use a query builder rather than string manipulation
Shell
Programming
bash/sh
Personal
Use ohmyz
Database Engines
Current preferred stack
sqlite or postgres (normalized/write)
solr (denormalized/read)
that’s it
BUT: use whatever is appropriate for the job
blazegraph/joseki for ttl
neo4j for KGs
Postgresql for SQL db server
never use non-open SQL db solutions
Some legacy apps may use MySQL but Pg is preferred
sqlite for lightweight tabular
mongo for docs
avoid vendor lock-in
use generic sparql 1.1 API vs triplestore specific APIs
solr for searchable / denormalized / analytics
always use golr patterns
read semantic columnar store patterns
always have a schema no matter what the task
always author in LinkML
translate to SQL schema, JSON-Schema, Solr schema etc
familiarize yourself with the tools to do this
SQL vs other DB engines
this is an evolving area
see Knocean SQL guide
LLMs
ontogpt
curategpt
For command line usage and direct Python usage:
<a href="https://llm.datasette.io/en/stable/">https://llm.datasette.io/en/stable/</a>
also follow Simon’s blog for practical guides to LLMs for engineers:
<a href="https://simonwillison.net/">https://simonwillison.net/</a>
code assistance
many of us use copilot + vscode/pycharm; see onboarding for how to charge
gpt-4 works better for de-novo
OpenAI accounts
see onboarding doc on how to get added to Mungall group account
Handy developer and command line tools
runoak
GNU Make – see Knocean guide
cogs
odk
q – query TSVs via SQL
csvkit
jq/yq
robot
bash; small scripts only
pandoc
Docker
editor of your choice
Programming Libraries
Data science
this is a fast changing field so recommendations here are general/loose
generally prefer Python » R » other languages for data sciences
we frequently use tensorflow, scikitlearn, keras
scikit-learn
catboost, xgboost
pandas
TSV » CSV
parquet or sqlite for large files
use # for header comments
always have a data dictionary in LinkML
always be working in a github repo (see below)
notebooks:
seaborn for plotting
Use notebooks for:
generating figs for paper
exploration
NEVER use notebooks for
core logic (extract into separate lib with tests)
ETL
anything that should be run in a pipeline
all notebooks MUST be reproducible
check small files into github
reproducible Makefile or snakemake for obtaining other files
ideally test all notebooks via gh-actions
KGs
kgx
BMT
EnsmallenGraph, (Rust + Python bindings), fast graph ML
Embiggen graph ML (e.g. node2vec), and some other things like word2vec
NEAT is a Python wrapper for reproducible graph ML in a YAML-driven way
also exploring pykeen ampligraph
Follow FAIR in a meaningful way
data dictionaries with LinkML
follow identifier best practice
Ontologies
Read the OAK guide
Use OAK for everything
ontobio is deprecated for non-GO specific tasks
OWLAPI (JVM) – only where absolutely necessary
beware of using rdflib and RDF-level libraries for working with OWL files, too low level (and slow)
access Ubergraph through OAK
access semsql through OAK
obographviz (js)
never, ever use XML parsers to parse RDF/XML
don’t every write a new obo format parser
obographs json direct access sometimes OK
NER/NLP
Read Harry’s awesome caufieldjh/awesome-bioie list
fast changing but some tools to consider:
ontorunNER (which wraps OGER)
BERT for language models (experimental)
Note we are now wrapping more of this functionality in OAK
now subsumed by LLMs
join the monarch nlp slack channel
Shell commands
sh > subprocess
File formats, languages, and standards
General
TSVs for columnar data
always have a data dictionary (use LinkML)
make it pandas-friendly
meaningful column names
SSSOM is an exemplar
understand TidyData and Codd’s normal forms and when to use them
hand-author YAML over JSON (+ follow schema)
Use JSON-LD / YAML-LD as appropriate
understand JSON-LD contexts
get context for free with LinkML
Turtle for some purposes
RDF/XML as default for OWL
Ontologies
Use OAK to access everything
OWL
OBO JSON
consider obo format deprecated. Exception: easier to maintain edit file as obo for git diff/PR purposes
COB as upper ontology, but also pay attention to biolink
Always use official PURLs for downloads
the OBO page gives the list of products. E.g. obofoundry.org/ontology/pato
Mappings (ontology or otherwise)
SSSOM with skos predicates
Cookiecutters for starting a new project.
General-purpose projects using monarch-project-template
LinkML based projects using linkml-project-cookiecutter
Ontology Access Kit (oaklib) plugin projects using `oakx-plugin-cookiecutter
KGs
biolink
kgx » rdf* » rdf
make available as:
RDF dump
Neo4J dump
sparql endpoint (consider putting into larger endpoint and segregating with NGs)
neo4j endpoint
KGX dump
KGX summary stats
Schemas
everything must have a schema, including:
all TSVs should have data dictionary
JSON/YAML
KGs
OWL ontologies and OWL instance graphs
Understand basic concepts:
normalized vs de-normalized
identifiers and URIs
closed-world vs open-world
schema vs ontology
Always author schemas in linkml
derive alternate representations (e.g. json-schema)
JSON-schema for JSON-centric projects (never author, always derive from LinkML)
ShEx or SHACL for ontology-centric (try and derive from LinkML)
Don’t use kwalify any more
Always have a LinkML schema even when using:
python dicts
open-ended JSON/YAML
RDF
Neo4J
ad-hoc TSVs
Include mappings:
map to biolink
Versioning
Semantic Versioning (semver) by default
software MUST use semver
schemas SHOULD use semver, but OBO-style may sometimes be appropriate
ISO-8601 OBO style for OBO ontologies
use GitHub releases for versioning as appropriate
always use the autofill feature to make release notes and to name releases
for software follow the group github-action best practice to auto-release to pypi
release versions to appropriate repository/archive
Compression
use .gz instead of .zip
if compressing multiple files in an archive, use .tar.gz, not .zip
Rememeber compressed files are not diffable in git
For very large files consider distributing gz files via S3 or zenodo rather than in GitHub
remember: if a repo has 10 x 50m files that change every release, the repo will be 10g in size in 20 releases
As a general rule of thumb, think very carefully before committing files > 1m to github
exceptions for existing best practice e.g. odk
ask if unsure
Text
markdown by default
frontmatter metadata where appropriate
track in version control
use .rst for sphinx sites where autodoc features are needed
don’t use wikis or github wikis except where precedent is set
APIs
RESTfulness
true REST may be too high a barrier
RPC-style (i.e. swagger/openAPI) may be fine
All web APIs should have OpenAPI exploration interface
derive OpenAPI from Python code
fastapi > flask »> others
considering GraphQL
Must have Docker container
Deprecated: Use grlc or sparqlfun to make APIs from sparql endpoints
CURIEs and IRIs
Read McMurry et al.
Prefixmaps (a Python library for retrieving semantic prefix maps) is now our source of truth for all things prefix/namespace related
Take the time to read ALL docs on bioregistry.io
always use CURIEs for IDs
CURIEs + prefixmap » URIs »» ad-hoc
always use prefixes registered in bioregistry.io
understand at a broad level the different registries:
<a href="http://identifiers.org">http://identifiers.org</a>
<a href="http://n2t.net">http://n2t.net</a> – synced(?) with identifiers.org but broader context
<a href="http://bioregistry.io/">http://bioregistry.io/</a>
has a lot of advantages over id.org: more transparent, github metadata based, lightweight
<a href="https://github.com/prefixcommons/biocontext">https://github.com/prefixcommons/biocontext</a>
we developed this as an “overlay” on existing registries
have an explicit JSON-LD context or prefixes yaml file
Use the prefixcommons curie util library
Read the identifiers guides closely, even for projects you are not on
Translator SRI/biolink identifiers
Identifiers in NMDC
Identifiers in GO
Genomics
GFF3
SO
Annotation
GAF
GPAD
Phenopackets
Dates
use ISO-8601
use ISO-8601
use ISO-8601
use ISO-8601
never, ever write a date in non-ISO-8601
Portability
it should be easy for anyone to install from any of our repos
everything should run on macos or linux
provide a Docker image for anything complex
use standard installation idioms
Key specialized libraries and command line tools
OAK, for ontologies
kgx
ODK and ROBOT, for ontologies
ontorunNER for NER
Building Ontologies
ontologies are for users, not ontologists
OWL and description logic is necessary for building robust ontologies, but needn’t be exposed
Minimize philosophy
avoid unnecessary abstractions
ontologies should have annotations
annotations, as in the sense used by curators
ontologies without annotations are generally of limited use, avoid working on them
learn tools and best practice for robust ontology engineering
Read Onto-Tips
Use and understand ODK
Use ROBOT
Take the OBO Academy training
work on the components on your own
attend the Monarch tutorials
use the ontologies we work on as examplars
GO
Uberon
Mondo
Phenotype Ontologies
ENVO
RO
CL
follow OBO best practice and principles
ontologies should be open
if OBO is underspecified, follow the examples of projects done in this group
NEW: see ontology-metadata in OAK
oio » IAO
liberal axiom annotations
key annotation properties: synonyms, definitions, mappings
See documentation on uberon synonyms, this is an exemplar for us
Programmatic generation
linkml-owl
dosdp OR robot template
always use the more appropriate tool for the job
include comprehensive definitions clear to biologists
read definitions guide
understand compositional patterns
avoid overmodeling
Document ontologies
document design decisions
write clear operational definitions
document your design patterns
Watch design pattern presentation
DOSDP repo
Mondo is our exemplar
understand limitations
use ontologies only where appropriate
vocabularies
descriptors
don’t use an ontology where a schema is more appropriate
don’t use an ontology where a KG is more appropriate. See KG vs ontology DPs
make best effort attempt to provide mappings
use SSSOM
use boomer
use oak lexmatch
Collaboration
we are a collaborative group, reach out if you have issues
join relevant channels on bbop and other Slack workspaces
questions always welcome but make best effort to see if information available in group reference guides
don’t struggle alone!
others are likely to either have similar questions/frustrations to you, or will have faced them in the past
questions are always welcome but always check standard sources first
for programming questions, search Stack Overflow
for questions regarding group or collaborator tools, is it in the FAQ?
make it easy for people to help you
be concise, yet provide sufficient relevant context
make it actionable
Discouraged: X doesn’t work
Encouraged: when I do A, I get result B, but I expect C
create issues with concise, actionable titles
your problem should be reproducible as far as possible
ideally contribute a a test case following idioms of appropriate repo (learn how to do this)
make things easier for those who follow you
the same questions often come up repeatedly
if someone answers a question for you, update the relevant guide (FAQ etc) to make it clearer for others
upvote answers on Stack Overflow you find useful
give thumbs up to helpful comments
star repos you find useful
follow codes of conduct
be constructive in any criticism
use your Berkeley Lab account for email, calendars
keep your calendar up to date, this facilitates scheduling meetings
Slack
avoid <a title="Private" href="https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html" target="_blank" class="private">@channel (Private)</a> unless necessary
discussion about tickets OK but decisions and key points must be recorded in ticket
use GitHub for requests
Use GitHub for requesting terms from ontologies etc
Data mapping guide: selecting and requesting terms from ontologies, data models, and standards
Google docs/slides/sheets hygiene
Read Julie’s awesome intro to Google Drive
Read [Data Organization in Spreadsheets for Ecologists](<a href="https://datacarpentry.org/spreadsheet-ecology-lesson/">https://datacarpentry.org/spreadsheet-ecology-lesson/</a> from datacarpentry
Read Data Organization in Spreadsheets by Bronan and Woo
be consistent
write dates like YYYY-MM-DD
put just one thing in a cell
no not merge cells
organize the data as a single rectangle (with subjects as rows and variables as columns, and with a single header row)
create a data dictionary
do not include calculations in the raw data files
do not use font color or highlighting as data
choose good names for things
make backups
use data validation to avoid data entry errors
save the data in plain text files
Use google docs/slides over Microsoft/Apple/Desktop
but sometimes markdown+git is more appropriate than either
for grants, papers, and other collaborative documents, move to Word at last possible minute (if at all)
pandocs can be used to make markdown
avoid latex/beamer unless it is really called for
Use tagging/comments/modes appropriately
If it’s not your doc, default to Suggesting mode
use your judgment; minor direct edits to correct typos usually OK
respect conventions of document owner
use comment feature to make comments, don’t write your comment in a different color
avoid use of text color as semantics
assign/tag people appropriately
avoid comment wars
Make the doc outline-mode-friendly
use H1/H2/etc. for headers (don’t just style normal text)
always have outline mode on (list-like icon near top left)
assume the reader has outline mode on
rarely need for a TOC
For google sheets / excel
never manually color code or use font/strikethrough. Always add an explicit field and use conditional formatting
always have a schema, even if it is a flat data dictionary. linkml-model-enrichment will derived one
favour TSV+github over google sheets
workflows clearly favor sheets
when using sheets, use cogs
follow TSV guidelines for google sheets
Use formatted templates where appropriate (grants, papers)
Use Paperpile for citations / reference management (you have access via the Lab)
Give documents meaningful names (e.g., not just “meeting”)–assume that most people will find the doc via search rather than by going through the folder hierarchy
don’t use camelcase or underscores in google doc names, it hinders search
organize google docs in the relevant folder depending on what project is funding the work
understand how navigation works for google docs
make docs and folders viewable by all by default, unless sensitive
include links to slides of general relevance from project repos
reuse slides from existing slide decks, but provide attribution
Tips
search operators
Best practices for meetings
See Best practices for writing a good meeting reminder
Use a rolling agenda/notes doc, rather than one doc per meeting
most recent first
ISO-8601 » human readable dates » anything else
The auto <a title="Private" href="https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html" target="_blank" class="private">@today (Private)</a> feature is useful
always have a google doc for every meeting you are in
record decisions
include a link to the rolling doc in calendar invites
include the Zoom / videoconference link in the rolling notes doc
DevOps
12 factor app
General Principles
DRY: Don’t Repeat Yourself
but avoid over-abstraction and frameworkitis
various 10 simple guides:
10 simple rules of quick and dirty scientific programming
Always reuse
we probably have a Python library for it
reuse general design patterns
GitHub templates
follow exemplar repos
kgx and linkml for general python
kg-covid-19 for ETL
try especially hard not to reinvent what someone in the group or our collaborator has done
Avoid perfectionism
iterate on solutions
smaller batches of incremental progress » long delays on perfect solution (that may turn out to be flawed)
For many tasks, the 80/20 rule may suffice
Don’t boil the ocean
beware of rabbit holes
More to come…</p></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"tiqo5upbg6224t7i8p87iok","title":"Best Practices","desc":"","updated":1714662280611,"created":1714662217081,"custom":{},"fname":"best-practices","type":"note","vault":{"fsPath":"vault"},"contentHash":"dc7c7e9c1d9d01386ed7bcedc2f32a6f","links":[{"type":"wiki","from":{"fname":"best-practices","id":"tiqo5upbg6224t7i8p87iok","vaultName":"vault"},"value":"user.cmungall","alias":"@cmungall","position":{"start":{"line":43,"column":26,"offset":1762},"end":{"line":43,"column":35,"offset":1771},"indent":[]},"xvault":false,"to":{"fname":"user.cmungall"}},{"type":"wiki","from":{"fname":"best-practices","id":"tiqo5upbg6224t7i8p87iok","vaultName":"vault"},"value":"user.channel","alias":"@channel","position":{"start":{"line":830,"column":7,"offset":28717},"end":{"line":830,"column":15,"offset":28725},"indent":[]},"xvault":false,"to":{"fname":"user.channel"}},{"type":"wiki","from":{"fname":"best-practices","id":"tiqo5upbg6224t7i8p87iok","vaultName":"vault"},"value":"user.today","alias":"@today","position":{"start":{"line":892,"column":10,"offset":31923},"end":{"line":892,"column":16,"offset":31929},"indent":[]},"xvault":false,"to":{"fname":"user.today"}}],"anchors":{},"children":[],"parent":"QvYK9hGbCvPpEfSRYhV8j","data":{}},"body":"\u003ch1 id=\"best-practices\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#best-practices\"\u003e\u003c/a\u003eBest Practices\u003c/h1\u003e\n\u003cp\u003eHave a look at \u003ca href=\"http://berkeleybop.github.io/best_practice/\"\u003ehttp://berkeleybop.github.io/best_practice/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThis is the best practice / house style guide for the BBOP group. Inspired by / cribbed from Knocean practice and other sources.\u003c/p\u003e\n\u003cp\u003eSource: berkeleybop/berkeleybop.github.io/blob/master/best_practice\u003c/p\u003e\n\u003cp\u003eWe are a diverse group working on many different projects with different stakeholders and sets of collaborators. Nevertheless we strive to follow a set of core best practices so we can be most efficient and develop the highest quality code, ontologies, standards, schemas, and analyses.\u003c/p\u003e\n\u003cp\u003eThis document may be overwhelming at first but as you become more familiar with projects it should become second nature. If there is anything you don’t understand, ask on slack!\u003c/p\u003e\n\u003cp\u003eGit and GitHub\nuse git ubiquitously\ncommit early, commit often\nperfect later!\nyou should always be working on a branch, so don’t worry about breaking things\nmake a PR for your branch - mark as draft if not ready\nMake repos public by default\nUse standard repo layouts\nchoose a cookiecutter\nmonarch-project-template for code-oriented projects\ndon’t reinvent\nlook at exemplars\nInclude standard files:\nREADME.md\nLICENSE (BSD3 or Apache preferred for software)\nCONTRIBUTING.md\nCODE_OF_CONDUCT.md (see for example kgx CoC\nChanges.md\n.gitignore\nMakefile or equivalent\nsee below for more specific recommendations for specific kinds of repos\nuse GitHub\nLike GitLab in principle, but GitHub has network effect\nprefer to work on the main repo, not forks, but defer to project-specific guidelines\nRead our GitHub Overview\nUse GitHub issues\nin general you should always be working to a ticket assigned to you\ntry to assign every issue to somebody\ntry to have a single assignee / responsible person\ntag people if necessary\nnote: if you tag me with \u003ca title=\"Private\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\" class=\"private\"\u003e@cmungall (Private)\u003c/a\u003e it’s likely I won’t see it. alert me to a ticket via slack if I am required\nuse GitHub’s default labels: bug, question, enhancement, good first issue, etc.\nset up standard issue templates (helps ensure tickets are auto-assigned)\nWhen creating issues:\ngive a meaningful issue title\nword title as a bug, e.g. “under condition X, Y fails” or a request, e.g. “add option A to method B”\ngive issue actionable descriptions, make it clear when an issue can be closed\nsee Seth’s suggestions for creating awesome issues\nuse GitHub Pull Requests\nread the obook PR review guide\nmark as draft until ready for review, then assign reviewers\ndescription should link to an issue (“Resolves #1234”) to automatically close issue when PR is merged\notherwise you have to clean up issues manually\nupdate description as needed\nalways look over your commits before making a PR\nare there unexpected changes? You should only see YOUR changes\nIs it adding files unexpectedly? Some git clients are eager to do this\nare some changes not recognizable as yours? Be careful not to clobber\nfollow repo-standard practice for rebase etc\nAVOID:\nmaking PRs too large\nmixing orthogonal concerns in one PR. Generally 1 PR = 1 issue\nmixing in formatting changes on sections of the code unrelated to the semantic changes you are making\nworking on a PR for too long a time without feedback from others\nworking on “invisible” branches. ALWAYS make a PR, ALWAYS push. You can mark as draft!\ngive PRs a meaningful title and description\nremember: titles will be used when auto-making release notes\nuse GitHub Milestones to plan releases\nuse GitHub Releases to tag versions and attach binaries\nuse semver (except for ontologies)\nuse the auto-generate release notes feature\ncorollary: write informative PR titles and never commit on main\nif making a non-patch release, select the previous minor/major to diff from\nuse GitHub Pages for simple static content and documentation\nprefer the docs/ directory option\nSee exemplars: OAK, Biolink Model\nuse GitHub Projects (“project boards”) for coordinating issues and PRs\nthree columns:\nTo do: for manager to fill and prioritize\nIn progress: for developer to keep up-to-date\nReady for review: for manager to empty\norder of preference for cards: PR link, issue link, text\nset up GitHub actions to do CI\nMigrate if you are on an old travis repo\nAll changes should be on PRs thus validated\nmain branch should never ever be failing\nEVERY repo should have actions and PR checking\nset up GitHub teams\ndefault to public membership\nmake sure it is clear who has permission to merge PRs\nset up badges\nalways: CI\npypi, downloads, codecov, zenodo, …\nConfigure the “About” (see gear icon on right)\nuse standard topics\nbiolink\nlinkml\nobofoundry\nmonarchinitiative\ngeneontology\nOrgs\ndefine a standard topic (see above)\ninclude a .github\nexamplar: github.com/linkml\npin repos\nmake sure all relevant artefacts are checked in\nuse git status and .gitignore\nin general avoid checking in derived products (but see below)\navoid checking in .xslx files (use TSVs; or consider cogs instead)\nversioning\ndo not check in files with version numbers e.g. foo.v1.txt into GitHub - git does versioning for you\nuse the GitHub release mechanism\nuse ISO-8601 or semver schemes (see guidelines on specific repo types below)\ntend your repos\nremove cruft such as obsolete files (GitHub preserves history)\navoid random stuff at top level\nkeep README in sync\navoid using spaces in filenames\nalways use standard suffixes (e.g. .tsv, .txt, .md)\nkabob-case-is-a-good-default.txt. See filenames in google developer guide\nDon’t rename files and commit - use “git mv” instead, so that the history of the file is preserved\nuse topics and “star” relevant repos\n\u003ca href=\"https://github.com/topics/linkml\"\u003ehttps://github.com/topics/linkml\u003c/a\u003e\n\u003ca href=\"https://github.com/topics/obofoundry\"\u003ehttps://github.com/topics/obofoundry\u003c/a\u003e\n\u003ca href=\"https://github.com/topics/geneontology\"\u003ehttps://github.com/topics/geneontology\u003c/a\u003e\n\u003ca href=\"https://github.com/topics/monarchinitiative\"\u003ehttps://github.com/topics/monarchinitiative\u003c/a\u003e\nalways star your own repos\nstar your colleagues and collaborator’s repos\ntips\nthe gh github cli client is very useful, e.g. gh pr Software:\nNico recommends gh Desktop\nCode-centric Repos\nUse an existing repo from a group member as template for best practice, e.g.,\nkgx\nlinkml\nOAK\nOr better: monarch project cookiecutter\nInclude a README.md\nprovide sufficient context\ndon’t boil the ocean - put reference material in a separate reference guide\ninclude examples and use examples as tests\nCreate reference documentation using RTD/Sphinx\nlet inline docstrings in Python do most of the work for you\nread writethedocs\nInclude installation instructions\nuse an OSI approved LICENSE, BSD3 preferred\nUse unit tests\nconsult others on framework\nUse GitHub-integrated CI\nformerly Travis\nuse GitHub actions\nRelease code to PyPI or appropriate repo\nuse GitHub releases\nuse GitHub actions to trigger releases to PyPI\nuse GitHub actions to trigger releases to PyPI\nsee nmdc-schema as exemplar\nmake release notes automatically see github guide\nrelies on using PRs with well-described titles\nalways have multiple owners of a pypi package on the pypi site\nuse standard semver, start from 0.1.0, move to 1.0.0 when stable\nConsider a Dockerfile\nFor ETL repos, follow standard templates for\nkg-hub\nkoza\nFor ETL repos\nUse Jenkins pipelines\nBadges\nCI\nCode coverage\nPyPI\nTODO: ADD MORE\nSchema/Standards-centric Repos, Data and metadata repos\nUse LinkML\nCreate repo from LinkML template\nExamples:\nNMDC\nMIxS\nGFF3 linkml\nchemkg/chemrof\nRegister with w3id.org\nInclude comprehensive examples\nUse LinkML mkdocs framework\nUnderstand the difference between OWL-centric and KG-centric modeling\ninclude mappings to Biolink Model\nalways include examples\nintegrate these with documentation\nintegrate these with unit tests\nalso include counter-examples\ndata deliberately designed to fail validation\ncheck validation correctly identifiers these in github actions\nenable zenodo syncing\nFor repos that have data:\nconsider a dashboard (see semantic dashbaord patterns)\nOntology-centric Repos\nUse ODK seed\nRegister ontology with OBO if appropriate\ninclude detailed metadata\ninclude all products\ninclude descriptive material in markdown\nExceptions:\napplication ontologies\nontologies that deliberately not OBO-esque\nRegister non OBOs with Bioportal + w3id\nUse GitHub for .owl distribution unless ontology is large, then consider:\nGitHub releases\nS3\nSee Nico’s application ontology tutorial\nFollow group exemplars: Uberon, Mondo, GO, ENVO, CL, PATO, BERO, PhenIO\nbut be aware each has their quirks\ndistribute useful products\ndistribute SSSOM\nalways distribute an .obo\nalways distribute a obo .json\ndistribute a kgx file (NEW)\ndistribute a rdftab/semsql sqlite file (NEW)\nuse a sensible source format (foo-edit.owl)\n.obo is best for diffs but less expressive and gotchas for CURIEs\nfunctional syntax is often preferred\nfor template-based ontologies, much of the source may be TSVs\nenable zenodo syncing\nUnderstand issues relating to git conflicts with ontologies\n.obo as source mitigates some of these\nSee this thread\nSee this post\nmany issues have since been resolved but unfortunately some remain\nAnalysis/Paper-centric Repos\nOne repo per paper\nEntire analysis must be reproducible via Makefile\nAll steps:\ndownload\nclean/pre-process\ntransform\ntraining\nevaluation\ncheck with Chris before using snakemake/CWL/alternatives\nUse TSVs as default\nmake pandas-friendly\nuse unix newline characters, not dos\nuse human readable but computationally friendly column headers\nNO ALL CAPS\nalphanumeric characters preferred\nspaces or underscores as word separators OK, but underscores preferred for formal formats\ncsvkit is your friend\nALL TSVs MUST have data dictionaries\nuse LinkML (see above)\ncheck in small-mid size data files (\u0026#x3C;10m)\nconsider cogs if TSVs must be managed in google sheets\nuse JSON for complex data\nuse KGX for anything that should be modeled as a KG\nuse descriptive filenames\nmanage metadata in GitHub\nenable zenodo syncing\nuse S3 for larger files\nrelease files to Zenodo\nDockerize\nUse Jupyter notebooks\nConsider Manubot\nOther recommended best practices\ndatadryad\nDevelopment Environment Setup\nCode Editors:\nvscode\npycharm\nget professional, we will pay\nGitHub copilot can be purchased as well, and is an excellent addition to a pycharm environment.\nKeyboard Shortcuts\nCommand palette: Cmd/Ctrl + Shift + P\nSearch for file in project: Cmd/Ctrl + P\nOpen integrated terminal in VSCode: Cmd/Ctrl + ~\nOpen settings page: Cmd/Ctrl + ,\nSet up custom keymap bindings\nMac\nCode \u003e Preferences \u003e Keyboard Shortcuts \u003e +`\nType in the key combination you want to use and assign it to an action of your choice\nFor ex., Cmd/Ctrl + i as a shortcut for selecting the Python interpreter\nEssentials\nGit configuration\nSet username: git config --global user.name \"YOUR_USERNAME\"\nSet password: git config --global user.email \"\u003ca href=\"/commons-dws-public/mailto:YOUR_EMAIL@EXAMPLE.COM\"\u003eYOUR_EMAIL@EXAMPLE.COM\u003c/a\u003e\"\nWorkspace setup\nMake sure you have correctly selected the Python interpreter\nSave workspace in order to open a specific view of the project directory\nFile \u003e Save Workspace As\nFile \u003e Open Workspace From File\nUseful Extensions\nPython\nPython IntelliSense\nLinting\nDebugging\nCode navigation\nFormatting\nRefactoring\nAutoDocstring\nDocstring for Python methods\nblack\nOpinionated Python code formatter\nGitLens\nVisualize code authorship\nBetter Comments\nHuman friendly comments\nRainbow CSV\nHighlight columns in csv and tsv files\nTransforms and filtering using querying language\nMarkdown All in One\nKeyboard shortcuts\nTable of contents\nAuto preview\nPrettier\nFormatting YAML, JSON\nBut primarily an opinionated formatter for frontend web code like JS, TS, etc.\nYAML\nYAML validation\nAuto completion\nHover support\nUseful while writing LinkML schemas\nvs-code-icons\nBeautiful icons\nAustin VS Code\nCode profiler\nCan be used when trying to optimize Python codebase\nSimple Websites\nGitHub pages favored over google sites over wikis\nManage and author content as markdown, managed in github, with PRs as for code\nGoogle Analytics\nExample GA 4 conversion and walkthrough info at \u003ca href=\"https://github.com/berkeleybop/bbops/issues/28#issuecomment-1712154894\"\u003ehttps://github.com/berkeleybop/bbops/issues/28#issuecomment-1712154894\u003c/a\u003e\navoid manually authoring anything that can be derived from metadata\nexamplars: obofoundry.github.io, this site\nuse CC-BY 4.0 or the CC0 public domain declaration\nExamplars:\nLinkML splash page\nPhenopackets splash page\nCell Ontology splash page\nDocumentation\nSee google guide on Writing inclusive documentation\nAvoid ableist language\nAvoid unnecessarily gendered language\nAvoid unnecessarily violent language\nall code, schemas, analyses, ontologies, MUST be documented\ndocumentation is a love-letter to your future self\nunderstand the Diataxis four-way distinction: tutorial, how-to, reference, explanation\nexemplar: OBOOK\nexemplar: LinkML docs\ngoogle API documentation guide\nhave strategies to avoid staleness and documentation getting out of sync\nuse inline documentation\npublish via appropriate framework (RTD for code, mkdocs for schema, etc)\nfollow appropriate style guide\nuse and test docstring in python\n\u003ca href=\"https://docs.python.org/3/library/doctest.html\"\u003ehttps://docs.python.org/3/library/doctest.html\u003c/a\u003e\nexamples, examples, examples\nfenced examples in markdown docs\nexample standalone scripts\nexample Jupyter notebooks\ndouble up: unit tests can serve as examples and vice versa\nSee linkml-run-examples framework\nUse existing templates\nmonarch-project-template for code-oriented projects\nlinkml cookiecutter for schema projects\nODK for ontology projects\nkghub template for KG projects\nuse Markdown as default\nRST for Sphinx/Code projects\nGoogle docs acceptable for initial brainstorming\nDon’t use Wikis (mediawiki, GitHub wiki)\nManage markdown docs as version control\npublish as static site (RTD, mkdocs, etc)\nCoding/Python\nPython is the default language; use others as appropriate\njavascript/typescript for client-side\ndon’t implement domain/business logic in js. use python + APIs\nuse typescript\ngenerate typescript datamodels using linkml gen-typescript\nRust for speed\nshould always have PyO3 wrappers\nfollow semsimian GH actions for wheels\nScala for performance reasoners or anything requiring owlapi\nHistorically we used Java for anything requiring OWLAPI but being phased out\nWhy Python?\nubiquitous, cross-platform\ngood for scripting, interactive development\nstrong ecosystem of libraries for almost anything\nEasy for developers to pick up\nMost bioinformaticians know it\nuse for anything more than about 10 lines of Bash/Perl\nuse Python 3.8+\nEnsure github actions tests 3.9, 3.11\nConform to the group style guide, or at least some style guide\npep-0008 for Python\nuse type annotations PEP484\ngoogle style guide\nWe are inspired by knocean/practices/python but differ in some places\nWe make use of OO as appropriate - just don’t go overboard like in java\nFollow conventional variable naming\nExample: \u003ca href=\"https://docs.fast.ai/dev/abbr.html\"\u003ehttps://docs.fast.ai/dev/abbr.html\u003c/a\u003e\nSee the Working with Python Environments guide for details on installing Python versions and managing virtual environments.\nAll repos should use poetry\nSet up this way: poetry new --src my-project-name\nOR use linkml-ws new for schema-centric repos\nfollow standard layouts, with code in src/\nLinting/formatting:\nUse black and flake8 and ruff\nTest Runners\nTo automate building and testing distributions in multiple Python versions\ntox\nDE FACTO: Github hosted runner via Github Actions\nCLI development\nclick\nTesting\nunittest\nDE FACTO: pytest\nTest coverage\nCoverage.py\ncodecov\ndocument all public classes, methods, functions\nAlways Use type annotations\nAlways provide docstrings\nReST (reStructuredText) » numpy-style docstrings or google style » nothing\nSOME standard is always better than none\nBe sure to set up your IDE for automatic docstring generation\nuse flask/fastAPI for web apps\nNEVER author OpenAPI directly; ALWAYS derive\nwe are exploring GraphQL frameworks like strawberry.rocks\nuse dataclasses or pydantic\nfor DAOs, ALWAYS derive from linkml\navoid authoring data models directly in python\nlist comprehensions » lambdas\nuse fstrings; never write java-style python\nALWAYS use typing\nmakes code more understandable\nallows code completion in PyCharm etc\nhelps find bugs\nuse an IDE\nPyCharm or VS is equally popular in the group\nETL/ingest\nfollow existing exemplar repos\nRead Chris’ 10 simple rules for semantic ETL\nuse requests for URL calls\nAlways provide a CLI\nseparate CLI logic from core logic\nRead CLIG guidelines\nSee also [Documenting command-line syntax ]\u003ca href=\"https://developers.google.com/style/code-syntax\"\u003ehttps://developers.google.com/style/code-syntax\u003c/a\u003e) in google style guide\nPython: use click\ndesign for composability\nprovide shortforms for common options\nDisplay help text when passed no options, the -h flag, or the –help flag\nuse de-facto standards\n-i, --input\n-o, --output\n-h, --help\nalways use dashes as separators, NOT underscores\nclick will make corresponding python vars with underscores\nFollow exemplars\nROBOT\nSSSOM\nOAK\nlinkml\nAlways write unittests for CLIs\nsee OAK for examples\nProfiling:\ncProfile and SnakeViz are useful for profiling Python code ```bash\nGenerate the profile results:\npython -m cProfile -o output.prof my_program.py\u003c/p\u003e\n\u003cp\u003eView them:\npipx run snakeviz output.prof ```\u003c/p\u003e\n\u003cp\u003eExamplars:\nsssom-py\nlinkml\nOAK\nLearning resources\nCharlie’s Recommended Python Programming Videos\nOBOOK - Open Biological and Biomedical Ontologies Organized Knowledge\nWeb APIs\nAuthoring\nFastAPI » Flask\nSeperate business logic from API code\nthis should be independently testable\nTesting\nuse fastapi.testclient\nfollow GO exemplar\nAccessing\nUse python requests library (unless a higher level lib is available)\nDo not construct URL strings yourself - use params instead\nfor non-trivial tasks consider building a reusable client library\nuse a client library if it already exists!\nexamplars: OAK bioportal implementation\nwhen querying a sparql endpoint\nsparqlfun \u003e sparqlwrapper \u003e requests \u003e curl\nif constructing sparql is necessary\nuse a query builder rather than string manipulation\nShell\nProgramming\nbash/sh\nPersonal\nUse ohmyz\nDatabase Engines\nCurrent preferred stack\nsqlite or postgres (normalized/write)\nsolr (denormalized/read)\nthat’s it\nBUT: use whatever is appropriate for the job\nblazegraph/joseki for ttl\nneo4j for KGs\nPostgresql for SQL db server\nnever use non-open SQL db solutions\nSome legacy apps may use MySQL but Pg is preferred\nsqlite for lightweight tabular\nmongo for docs\navoid vendor lock-in\nuse generic sparql 1.1 API vs triplestore specific APIs\nsolr for searchable / denormalized / analytics\nalways use golr patterns\nread semantic columnar store patterns\nalways have a schema no matter what the task\nalways author in LinkML\ntranslate to SQL schema, JSON-Schema, Solr schema etc\nfamiliarize yourself with the tools to do this\nSQL vs other DB engines\nthis is an evolving area\nsee Knocean SQL guide\nLLMs\nontogpt\ncurategpt\nFor command line usage and direct Python usage:\n\u003ca href=\"https://llm.datasette.io/en/stable/\"\u003ehttps://llm.datasette.io/en/stable/\u003c/a\u003e\nalso follow Simon’s blog for practical guides to LLMs for engineers:\n\u003ca href=\"https://simonwillison.net/\"\u003ehttps://simonwillison.net/\u003c/a\u003e\ncode assistance\nmany of us use copilot + vscode/pycharm; see onboarding for how to charge\ngpt-4 works better for de-novo\nOpenAI accounts\nsee onboarding doc on how to get added to Mungall group account\nHandy developer and command line tools\nrunoak\nGNU Make – see Knocean guide\ncogs\nodk\nq – query TSVs via SQL\ncsvkit\njq/yq\nrobot\nbash; small scripts only\npandoc\nDocker\neditor of your choice\nProgramming Libraries\nData science\nthis is a fast changing field so recommendations here are general/loose\ngenerally prefer Python » R » other languages for data sciences\nwe frequently use tensorflow, scikitlearn, keras\nscikit-learn\ncatboost, xgboost\npandas\nTSV » CSV\nparquet or sqlite for large files\nuse # for header comments\nalways have a data dictionary in LinkML\nalways be working in a github repo (see below)\nnotebooks:\nseaborn for plotting\nUse notebooks for:\ngenerating figs for paper\nexploration\nNEVER use notebooks for\ncore logic (extract into separate lib with tests)\nETL\nanything that should be run in a pipeline\nall notebooks MUST be reproducible\ncheck small files into github\nreproducible Makefile or snakemake for obtaining other files\nideally test all notebooks via gh-actions\nKGs\nkgx\nBMT\nEnsmallenGraph, (Rust + Python bindings), fast graph ML\nEmbiggen graph ML (e.g. node2vec), and some other things like word2vec\nNEAT is a Python wrapper for reproducible graph ML in a YAML-driven way\nalso exploring pykeen ampligraph\nFollow FAIR in a meaningful way\ndata dictionaries with LinkML\nfollow identifier best practice\nOntologies\nRead the OAK guide\nUse OAK for everything\nontobio is deprecated for non-GO specific tasks\nOWLAPI (JVM) – only where absolutely necessary\nbeware of using rdflib and RDF-level libraries for working with OWL files, too low level (and slow)\naccess Ubergraph through OAK\naccess semsql through OAK\nobographviz (js)\nnever, ever use XML parsers to parse RDF/XML\ndon’t every write a new obo format parser\nobographs json direct access sometimes OK\nNER/NLP\nRead Harry’s awesome caufieldjh/awesome-bioie list\nfast changing but some tools to consider:\nontorunNER (which wraps OGER)\nBERT for language models (experimental)\nNote we are now wrapping more of this functionality in OAK\nnow subsumed by LLMs\njoin the monarch nlp slack channel\nShell commands\nsh \u003e subprocess\nFile formats, languages, and standards\nGeneral\nTSVs for columnar data\nalways have a data dictionary (use LinkML)\nmake it pandas-friendly\nmeaningful column names\nSSSOM is an exemplar\nunderstand TidyData and Codd’s normal forms and when to use them\nhand-author YAML over JSON (+ follow schema)\nUse JSON-LD / YAML-LD as appropriate\nunderstand JSON-LD contexts\nget context for free with LinkML\nTurtle for some purposes\nRDF/XML as default for OWL\nOntologies\nUse OAK to access everything\nOWL\nOBO JSON\nconsider obo format deprecated. Exception: easier to maintain edit file as obo for git diff/PR purposes\nCOB as upper ontology, but also pay attention to biolink\nAlways use official PURLs for downloads\nthe OBO page gives the list of products. E.g. obofoundry.org/ontology/pato\nMappings (ontology or otherwise)\nSSSOM with skos predicates\nCookiecutters for starting a new project.\nGeneral-purpose projects using monarch-project-template\nLinkML based projects using linkml-project-cookiecutter\nOntology Access Kit (oaklib) plugin projects using `oakx-plugin-cookiecutter\nKGs\nbiolink\nkgx » rdf* » rdf\nmake available as:\nRDF dump\nNeo4J dump\nsparql endpoint (consider putting into larger endpoint and segregating with NGs)\nneo4j endpoint\nKGX dump\nKGX summary stats\nSchemas\neverything must have a schema, including:\nall TSVs should have data dictionary\nJSON/YAML\nKGs\nOWL ontologies and OWL instance graphs\nUnderstand basic concepts:\nnormalized vs de-normalized\nidentifiers and URIs\nclosed-world vs open-world\nschema vs ontology\nAlways author schemas in linkml\nderive alternate representations (e.g. json-schema)\nJSON-schema for JSON-centric projects (never author, always derive from LinkML)\nShEx or SHACL for ontology-centric (try and derive from LinkML)\nDon’t use kwalify any more\nAlways have a LinkML schema even when using:\npython dicts\nopen-ended JSON/YAML\nRDF\nNeo4J\nad-hoc TSVs\nInclude mappings:\nmap to biolink\nVersioning\nSemantic Versioning (semver) by default\nsoftware MUST use semver\nschemas SHOULD use semver, but OBO-style may sometimes be appropriate\nISO-8601 OBO style for OBO ontologies\nuse GitHub releases for versioning as appropriate\nalways use the autofill feature to make release notes and to name releases\nfor software follow the group github-action best practice to auto-release to pypi\nrelease versions to appropriate repository/archive\nCompression\nuse .gz instead of .zip\nif compressing multiple files in an archive, use .tar.gz, not .zip\nRememeber compressed files are not diffable in git\nFor very large files consider distributing gz files via S3 or zenodo rather than in GitHub\nremember: if a repo has 10 x 50m files that change every release, the repo will be 10g in size in 20 releases\nAs a general rule of thumb, think very carefully before committing files \u003e 1m to github\nexceptions for existing best practice e.g. odk\nask if unsure\nText\nmarkdown by default\nfrontmatter metadata where appropriate\ntrack in version control\nuse .rst for sphinx sites where autodoc features are needed\ndon’t use wikis or github wikis except where precedent is set\nAPIs\nRESTfulness\ntrue REST may be too high a barrier\nRPC-style (i.e. swagger/openAPI) may be fine\nAll web APIs should have OpenAPI exploration interface\nderive OpenAPI from Python code\nfastapi \u003e flask »\u003e others\nconsidering GraphQL\nMust have Docker container\nDeprecated: Use grlc or sparqlfun to make APIs from sparql endpoints\nCURIEs and IRIs\nRead McMurry et al.\nPrefixmaps (a Python library for retrieving semantic prefix maps) is now our source of truth for all things prefix/namespace related\nTake the time to read ALL docs on bioregistry.io\nalways use CURIEs for IDs\nCURIEs + prefixmap » URIs »» ad-hoc\nalways use prefixes registered in bioregistry.io\nunderstand at a broad level the different registries:\n\u003ca href=\"http://identifiers.org\"\u003ehttp://identifiers.org\u003c/a\u003e\n\u003ca href=\"http://n2t.net\"\u003ehttp://n2t.net\u003c/a\u003e – synced(?) with identifiers.org but broader context\n\u003ca href=\"http://bioregistry.io/\"\u003ehttp://bioregistry.io/\u003c/a\u003e\nhas a lot of advantages over id.org: more transparent, github metadata based, lightweight\n\u003ca href=\"https://github.com/prefixcommons/biocontext\"\u003ehttps://github.com/prefixcommons/biocontext\u003c/a\u003e\nwe developed this as an “overlay” on existing registries\nhave an explicit JSON-LD context or prefixes yaml file\nUse the prefixcommons curie util library\nRead the identifiers guides closely, even for projects you are not on\nTranslator SRI/biolink identifiers\nIdentifiers in NMDC\nIdentifiers in GO\nGenomics\nGFF3\nSO\nAnnotation\nGAF\nGPAD\nPhenopackets\nDates\nuse ISO-8601\nuse ISO-8601\nuse ISO-8601\nuse ISO-8601\nnever, ever write a date in non-ISO-8601\nPortability\nit should be easy for anyone to install from any of our repos\neverything should run on macos or linux\nprovide a Docker image for anything complex\nuse standard installation idioms\nKey specialized libraries and command line tools\nOAK, for ontologies\nkgx\nODK and ROBOT, for ontologies\nontorunNER for NER\nBuilding Ontologies\nontologies are for users, not ontologists\nOWL and description logic is necessary for building robust ontologies, but needn’t be exposed\nMinimize philosophy\navoid unnecessary abstractions\nontologies should have annotations\nannotations, as in the sense used by curators\nontologies without annotations are generally of limited use, avoid working on them\nlearn tools and best practice for robust ontology engineering\nRead Onto-Tips\nUse and understand ODK\nUse ROBOT\nTake the OBO Academy training\nwork on the components on your own\nattend the Monarch tutorials\nuse the ontologies we work on as examplars\nGO\nUberon\nMondo\nPhenotype Ontologies\nENVO\nRO\nCL\nfollow OBO best practice and principles\nontologies should be open\nif OBO is underspecified, follow the examples of projects done in this group\nNEW: see ontology-metadata in OAK\noio » IAO\nliberal axiom annotations\nkey annotation properties: synonyms, definitions, mappings\nSee documentation on uberon synonyms, this is an exemplar for us\nProgrammatic generation\nlinkml-owl\ndosdp OR robot template\nalways use the more appropriate tool for the job\ninclude comprehensive definitions clear to biologists\nread definitions guide\nunderstand compositional patterns\navoid overmodeling\nDocument ontologies\ndocument design decisions\nwrite clear operational definitions\ndocument your design patterns\nWatch design pattern presentation\nDOSDP repo\nMondo is our exemplar\nunderstand limitations\nuse ontologies only where appropriate\nvocabularies\ndescriptors\ndon’t use an ontology where a schema is more appropriate\ndon’t use an ontology where a KG is more appropriate. See KG vs ontology DPs\nmake best effort attempt to provide mappings\nuse SSSOM\nuse boomer\nuse oak lexmatch\nCollaboration\nwe are a collaborative group, reach out if you have issues\njoin relevant channels on bbop and other Slack workspaces\nquestions always welcome but make best effort to see if information available in group reference guides\ndon’t struggle alone!\nothers are likely to either have similar questions/frustrations to you, or will have faced them in the past\nquestions are always welcome but always check standard sources first\nfor programming questions, search Stack Overflow\nfor questions regarding group or collaborator tools, is it in the FAQ?\nmake it easy for people to help you\nbe concise, yet provide sufficient relevant context\nmake it actionable\nDiscouraged: X doesn’t work\nEncouraged: when I do A, I get result B, but I expect C\ncreate issues with concise, actionable titles\nyour problem should be reproducible as far as possible\nideally contribute a a test case following idioms of appropriate repo (learn how to do this)\nmake things easier for those who follow you\nthe same questions often come up repeatedly\nif someone answers a question for you, update the relevant guide (FAQ etc) to make it clearer for others\nupvote answers on Stack Overflow you find useful\ngive thumbs up to helpful comments\nstar repos you find useful\nfollow codes of conduct\nbe constructive in any criticism\nuse your Berkeley Lab account for email, calendars\nkeep your calendar up to date, this facilitates scheduling meetings\nSlack\navoid \u003ca title=\"Private\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\" class=\"private\"\u003e@channel (Private)\u003c/a\u003e unless necessary\ndiscussion about tickets OK but decisions and key points must be recorded in ticket\nuse GitHub for requests\nUse GitHub for requesting terms from ontologies etc\nData mapping guide: selecting and requesting terms from ontologies, data models, and standards\nGoogle docs/slides/sheets hygiene\nRead Julie’s awesome intro to Google Drive\nRead [Data Organization in Spreadsheets for Ecologists](\u003ca href=\"https://datacarpentry.org/spreadsheet-ecology-lesson/\"\u003ehttps://datacarpentry.org/spreadsheet-ecology-lesson/\u003c/a\u003e from datacarpentry\nRead Data Organization in Spreadsheets by Bronan and Woo\nbe consistent\nwrite dates like YYYY-MM-DD\nput just one thing in a cell\nno not merge cells\norganize the data as a single rectangle (with subjects as rows and variables as columns, and with a single header row)\ncreate a data dictionary\ndo not include calculations in the raw data files\ndo not use font color or highlighting as data\nchoose good names for things\nmake backups\nuse data validation to avoid data entry errors\nsave the data in plain text files\nUse google docs/slides over Microsoft/Apple/Desktop\nbut sometimes markdown+git is more appropriate than either\nfor grants, papers, and other collaborative documents, move to Word at last possible minute (if at all)\npandocs can be used to make markdown\navoid latex/beamer unless it is really called for\nUse tagging/comments/modes appropriately\nIf it’s not your doc, default to Suggesting mode\nuse your judgment; minor direct edits to correct typos usually OK\nrespect conventions of document owner\nuse comment feature to make comments, don’t write your comment in a different color\navoid use of text color as semantics\nassign/tag people appropriately\navoid comment wars\nMake the doc outline-mode-friendly\nuse H1/H2/etc. for headers (don’t just style normal text)\nalways have outline mode on (list-like icon near top left)\nassume the reader has outline mode on\nrarely need for a TOC\nFor google sheets / excel\nnever manually color code or use font/strikethrough. Always add an explicit field and use conditional formatting\nalways have a schema, even if it is a flat data dictionary. linkml-model-enrichment will derived one\nfavour TSV+github over google sheets\nworkflows clearly favor sheets\nwhen using sheets, use cogs\nfollow TSV guidelines for google sheets\nUse formatted templates where appropriate (grants, papers)\nUse Paperpile for citations / reference management (you have access via the Lab)\nGive documents meaningful names (e.g., not just “meeting”)–assume that most people will find the doc via search rather than by going through the folder hierarchy\ndon’t use camelcase or underscores in google doc names, it hinders search\norganize google docs in the relevant folder depending on what project is funding the work\nunderstand how navigation works for google docs\nmake docs and folders viewable by all by default, unless sensitive\ninclude links to slides of general relevance from project repos\nreuse slides from existing slide decks, but provide attribution\nTips\nsearch operators\nBest practices for meetings\nSee Best practices for writing a good meeting reminder\nUse a rolling agenda/notes doc, rather than one doc per meeting\nmost recent first\nISO-8601 » human readable dates » anything else\nThe auto \u003ca title=\"Private\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\" class=\"private\"\u003e@today (Private)\u003c/a\u003e feature is useful\nalways have a google doc for every meeting you are in\nrecord decisions\ninclude a link to the rolling doc in calendar invites\ninclude the Zoom / videoconference link in the rolling notes doc\nDevOps\n12 factor app\nGeneral Principles\nDRY: Don’t Repeat Yourself\nbut avoid over-abstraction and frameworkitis\nvarious 10 simple guides:\n10 simple rules of quick and dirty scientific programming\nAlways reuse\nwe probably have a Python library for it\nreuse general design patterns\nGitHub templates\nfollow exemplar repos\nkgx and linkml for general python\nkg-covid-19 for ETL\ntry especially hard not to reinvent what someone in the group or our collaborator has done\nAvoid perfectionism\niterate on solutions\nsmaller batches of incremental progress » long delays on perfect solution (that may turn out to be flawed)\nFor many tasks, the 80/20 rule may suffice\nDon’t boil the ocean\nbeware of rabbit holes\nMore to come…\u003c/p\u003e","noteIndex":{"id":"QvYK9hGbCvPpEfSRYhV8j","title":"Welcome to the COMMONS Lab Open Dendron","desc":"","updated":1693056226815,"created":1630130450048,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"20f67df3dd870fc450a162c202c9ff41","links":[{"type":"wiki","from":{"fname":"root","id":"QvYK9hGbCvPpEfSRYhV8j","vaultName":"vault"},"value":"open-notebook.commons.setup","position":{"start":{"line":43,"column":118,"offset":1871},"end":{"line":43,"column":149,"offset":1902},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"open-notebook.commons.setup"}}],"anchors":{"what-is-this-note":{"type":"header","text":"What is this note","value":"what-is-this-note","line":16,"column":0,"depth":2},"tutorial":{"type":"header","text":"Tutorial","value":"tutorial","line":20,"column":0,"depth":2},"dendron":{"type":"header","text":"Dendron.","value":"dendron","line":22,"column":0,"depth":3},"what-is-dendron-":{"type":"header","text":"What is Dendron ?","value":"what-is-dendron-","line":24,"column":0,"depth":4},"where-to-get-more-info-on-dendron-":{"type":"header","text":"Where to get more info on Dendron ?","value":"where-to-get-more-info-on-dendron-","line":30,"column":0,"depth":4},"concrete-steps-to-access-and-contribute-to-the-dbgi-dendron":{"type":"header","text":"Concrete steps to access and contribute to the DBGI Dendron","value":"concrete-steps-to-access-and-contribute-to-the-dbgi-dendron","line":35,"column":0,"depth":4},"questions-comments-suggestions-":{"type":"header","text":"Questions, comments, suggestions ?","value":"questions-comments-suggestions-","line":52,"column":0,"depth":2}},"children":["5o0tvzf4l6t6moau7en1v48","e4ul30admmxm9ilxfq275cq","h78qbvh1fd9bwcykmcm9uo3","6ooxuf27zzf3grb14o18qf2","tiqo5upbg6224t7i8p87iok","ltq8wcrabmq6mlescrdi4m0","bdq3suiz8yriznljea2zpug","ih6vyup3yre4m9woc9ldl7k","vDTgZL9UHWqYtBFdtD3vK","69ekb2qhuwukr0jwrzy6tnw","373694o1o6ocqohko4um7c9","jldFUSJGjDf1mFH8c2yUI","dh2qp7w4tl6otf89xrmxitv","2rvdf4t5qnx5hqjj29bojcc","stj9lq0lxhfuk5ntomiozz0","gvdyfgvq0z08fcfaqzmhtjo","2rvclk21kfedpvxuzjpizi7","dcwgamgyghrlyau1avlh6ug","432qdutuo1i8h5pcuh39ytt","2npxodkvs5jk6p1eksi551b","h81rw16zzgh9kix8ti1mbam","lco50o42dfeph5i5f2k981w","46d1odkovrpdi6g16992phy","s9gzk7nphtjzmpdqvk5y4vj","82ra6p4ykf814hp8yfw4wp6","hpnaglyhnb48vuiniqecnqf","y7nk7xmiht44neo0q7cl5cs","2cxr093kvrg4jojokwgqrbj","8vfu5h3617jbzy78xr2hlo1","w75krbmkkvla3hwd66hn5bh","40po5od17ekcr1e77dluxao","4pqppog2u66rx1tkc8jy5v9","ektni5nfulyro7dkrbtek7j","vfsp2aci6vy7kg2jsyy8tzu","0wm4geq40t6nscn88rcwu47","ib4jmxy1x3l1r0ewe6hln4j","0h57aw0be2jnc3dxcpn3ajn","4789z8f1dqdh5k3nmgr1m4z","p5dszyuhj1klgje0brtv0xj","sk4m9gq7vz2t9phcxlxvqpw","43p60vv8btyhaclugl93jok","zhc9hhpaobkbo4e2votv6wr","ylulfzi7ra5yv6ja7j78t6e","wj0i9czxvt4v0b674nb8501","ovslc641d0h00s16tf6kl8w","4zmlbmcp6q4q69ycvhavzr6","59ftsVxFXXM9bB43vfKwK","nmnpsy2e1rwqnqgurogi2u6","6b5uf8hv44mbgircddcb46i","s9j6c26u6qgl5dvnqv8opam","je0ksq927btmorptaje6a4p","xm4a1smh9gcahxda5bssxfi","3cgqlppr4es3iuoa2o3mhn8","d6edcr5j5kjgdt791uujpn0","zfu2gniwqhgo1j44r3yfx7y","gap1pjhvt94m5izg0zlef0w","o3y0vguickctv1yx4z42qev","g78c0e4ts7wgkof1ykkgzbl","hsqldiv7revakz0fqay51eu","99wwtyhexdqu5bxrtgn9whw","m8e37qw6n4i3cfv9ohq7e82","ds1s2fjqhwvw1zqst8l4z4f","ec4pkybo5iwljo3zdr9894x","cbikmu2vjnxulf5tf9xfist","1icb0ka0yjwpoerg4zym9la"],"parent":null,"data":{},"body":"\n![](/assets/images/allard-lab.jpg)\n\nWelcome the the COMMONS Lab Open Dendron !\n\nIn the [COMMONS Lab](https://www.unifr.ch/bio/en/groups/allard/) we intent to follow the [Open Notebook Science](https://en.wikipedia.org/wiki/Open-notebook_science) approach to document our research.\n\nFor this we use the [Dendron](https://www.dendron.so/) system as a mean to efficiently capture notes and publish them.\n\n## What is this note\n\nThis note is a succinct tutorial note aiming to get you started in the use of the COMMONS Lab Dendron.\n\n## Tutorial\n\n### Dendron. \n\n#### What is Dendron ?\n\n\u003e Dendron is an open-source, local-first, markdown-based, note-taking tool. Think of it as a cache for everything that you care about - if you've spent more then five minutes solving a problem, you should never spent any more time solving the same exact problem.\n\u003e \n\u003e Dendron is a knowledge base built by and for developers and integrates natively with IDEs like VS Code and VSCodium.\n\n#### Where to get more info on Dendron ?\n\n- You can get more information in the Dendron system at the official website www.dendron.so\n- All the Dendron documentation is hosted here https://wiki.dendron.so/. It is, obviously, a Dendron itself.\n\n#### Concrete steps to access and contribute to the DBGI Dendron\n\n1. Install [VSCode](https://code.visualstudio.com/download)\n2. Install [Dendron](https://marketplace.visualstudio.com/items?itemName=dendron.dendron) from the VSCode marketplace \n3. Clone the COMMONS Dendron repo\n\n    In your terminal\n    ```\n    git clone https://github.com/commons-research/commons-dws-public.git\n    ```\n4. In VSCode open (File/Open) the cloned repository.\n5. Voila ! You should now be in the COMMONS Lab Open Dendron.\n\nFeel free to explore and contribute.\nA first, important step could be to configure VSCode so that you can easily add a daily note. See steps described at [[open-notebook.commons.setup]]\n\n\n## Questions, comments, suggestions ?\n\nFeel free to contribute here https://github.com/orgs/commons-research/discussions\n\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"vaultSelectionModeOnCreate":"smart","fuzzThreshold":0.2}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.112.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"assetsPrefix":"/commons-dws-public","copyAssets":true,"siteHierarchies":["root"],"enableSiteLastModified":true,"siteRootDir":"docs","siteUrl":"https://commons-research.github.io","enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"writeStubs":false,"seo":{"title":"COMMONS DWS Public","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Click here to edit this page on Github !","editBranch":"main","editViewMode":"edit","editRepository":"https://github.com/commons-research/commons-dws-public"},"enablePrettyLinks":true,"enableTaskNotes":true,"siteFaviconPath":"favicon.ico","siteIndex":"root","searchMode":"lookup"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"tiqo5upbg6224t7i8p87iok"},"buildId":"KWnqrj5vUmxn1r58uXWxO","assetPrefix":"/commons-dws-public","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>